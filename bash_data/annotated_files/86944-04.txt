    1: //* -*- Mode: C++; tab-width: 8; indent-tabs-mode: nil; c-basic-offset: 2 -*- */
    1: /* ***** BEGIN LICENSE BLOCK *****
    1:  * Version: MPL 1.1/GPL 2.0/LGPL 2.1
    1:  *
    1:  * The contents of this file are subject to the Mozilla Public License Version
    1:  * 1.1 (the "License"); you may not use this file except in compliance with
    1:  * the License. You may obtain a copy of the License at
    1:  * http://www.mozilla.org/MPL/
    1:  *
    1:  * Software distributed under the License is distributed on an "AS IS" basis,
    1:  * WITHOUT WARRANTY OF ANY KIND, either express or implied. See the License
    1:  * for the specific language governing rights and limitations under the
    1:  * License.
    1:  *
    1:  * The Original Code is Url Classifier code
    1:  *
    1:  * The Initial Developer of the Original Code is
    1:  * Google Inc.
    1:  * Portions created by the Initial Developer are Copyright (C) 2006
    1:  * the Initial Developer. All Rights Reserved.
    1:  *
    1:  * Contributor(s):
    1:  *   Tony Chang <tony@ponderer.org> (original author)
    1:  *   Brett Wilson <brettw@gmail.com>
 4024:  *   Dave Camp <dcamp@mozilla.com>
38022:  *   David Dahl <ddahl@mozilla.com>
78085:  *   Gian-Carlo Pascutto <gpascutto@mozilla.com>
    1:  *
    1:  * Alternatively, the contents of this file may be used under the terms of
    1:  * either the GNU General Public License Version 2 or later (the "GPL"), or
    1:  * the GNU Lesser General Public License Version 2.1 or later (the "LGPL"),
    1:  * in which case the provisions of the GPL or the LGPL are applicable instead
    1:  * of those above. If you wish to allow use of your version of this file only
    1:  * under the terms of either the GPL or the LGPL, and not to allow others to
    1:  * use your version of this file under the terms of the MPL, indicate your
    1:  * decision by deleting the provisions above and replace them with the notice
    1:  * and other provisions required by the GPL or the LGPL. If you do not delete
    1:  * the provisions above, a recipient may use your version of this file under
    1:  * the terms of any one of the MPL, the GPL or the LGPL.
    1:  *
    1:  * ***** END LICENSE BLOCK ***** */
    1: 
 5528: #include "nsAutoPtr.h"
 4024: #include "nsCOMPtr.h"
    1: #include "mozIStorageService.h"
    1: #include "mozIStorageConnection.h"
    1: #include "mozIStorageStatement.h"
 4024: #include "mozStorageHelper.h"
    1: #include "mozStorageCID.h"
    1: #include "nsAppDirectoryServiceDefs.h"
    1: #include "nsCRT.h"
14354: #include "nsDataHashtable.h"
 4024: #include "nsICryptoHash.h"
12346: #include "nsICryptoHMAC.h"
    1: #include "nsIDirectoryService.h"
13256: #include "nsIKeyModule.h"
    1: #include "nsIObserverService.h"
69312: #include "nsIPermissionManager.h"
 5528: #include "nsIPrefBranch.h"
 5528: #include "nsIPrefBranch2.h"
 5528: #include "nsIPrefService.h"
    1: #include "nsIProperties.h"
    1: #include "nsToolkitCompsCID.h"
 4024: #include "nsIUrlClassifierUtils.h"
    1: #include "nsUrlClassifierDBService.h"
12346: #include "nsUrlClassifierUtils.h"
76882: #include "nsUrlClassifierProxies.h"
 5528: #include "nsURILoader.h"
    1: #include "nsString.h"
24031: #include "nsReadableUtils.h"
    1: #include "nsTArray.h"
 4024: #include "nsNetUtil.h"
 4024: #include "nsNetCID.h"
    1: #include "nsThreadUtils.h"
    1: #include "nsXPCOMStrings.h"
64576: #include "mozilla/Mutex.h"
78093: #include "mozilla/Telemetry.h"
    1: #include "prlog.h"
    1: #include "prprf.h"
10941: #include "prnetdb.h"
 4024: #include "zlib.h"
 4024: 
16701: // Needed to interpert mozIStorageConnection::GetLastError
16701: #include <sqlite3.h>
16701: 
64576: using namespace mozilla;
64576: 
 4024: /**
 4024:  * The DBServices stores a set of Fragments.  A fragment is one URL
 4024:  * fragment containing two or more domain components and some number
 4024:  * of path components.
 4024:  *
 4024:  * Fragment examples:
 4024:  *   example.com/
 4024:  *   www.example.com/foo/bar
 4024:  *   www.mail.example.com/mail
 4024:  *
 4024:  * Fragments are described in "Simplified Regular Expression Lookup"
 4024:  * section of the protocol document at
 4024:  * http://code.google.com/p/google-safe-browsing/wiki/Protocolv2Spec
 4024:  *
10941:  * A fragment is associated with a domain.  The domain for a given
10941:  * fragment is the three-host-component domain of the fragment (two
10941:  * host components for URLs with only two components) with a trailing
10941:  * slash.  So for the fragments listed above, the domains are
10941:  * example.com/, www.example.com/ and mail.example.com/.
 4024:  *
 4024:  * Fragments and domains are hashed in the database.  The hash is described
 4024:  * in the protocol document, but it's basically a truncated SHA256 hash.
10941:  *
10941:  * A (table, chunk id, domain key, fragment) tuple is referred to as
10941:  * an Entry.
 4024:  */
    1: 
    1: // NSPR_LOG_MODULES=UrlClassifierDbService:5
    1: #if defined(PR_LOGGING)
    1: static const PRLogModuleInfo *gUrlClassifierDbServiceLog = nsnull;
    1: #define LOG(args) PR_LOG(gUrlClassifierDbServiceLog, PR_LOG_DEBUG, args)
 4024: #define LOG_ENABLED() PR_LOG_TEST(gUrlClassifierDbServiceLog, 4)
    1: #else
    1: #define LOG(args)
80486: #define LOG_ENABLED() (false)
    1: #endif
    1: 
 8732: // Schema versioning:  note that we don't bother to migrate between different
 8732: // versions of the schema, we just start fetching the data freshly with each
 8732: // migration.
 8732: 
 8732: // The database filename is updated when there is an incompatible
 8732: // schema change and we expect both implementations to continue
 8732: // accessing the same database (such as between stable versions of the
 8732: // platform).
 4024: #define DATABASE_FILENAME "urlclassifier3.sqlite"
 4024: 
 8732: // The implementation version is updated during development when we
 8732: // want to change schema, or to recover from updating bugs.  When an
 8732: // implementation version change is detected, the database is scrapped
 8732: // and we start over.
38022: #define IMPLEMENTATION_VERSION 7
 8732: 
78090: // Name of the persistent PrefixSet storage
78090: #define PREFIXSET_FILENAME  "urlclassifier.pset"
78090: 
 4024: #define MAX_HOST_COMPONENTS 5
 4024: #define MAX_PATH_COMPONENTS 4
 4024: 
 4024: // Updates will fail if fed chunks larger than this
 4024: #define MAX_CHUNK_SIZE (1024 * 1024)
 4024: 
 5528: // Prefs for implementing nsIURIClassifier to block page loads
 5528: #define CHECK_MALWARE_PREF      "browser.safebrowsing.malware.enabled"
80486: #define CHECK_MALWARE_DEFAULT   false
 5528: 
 8643: #define CHECK_PHISHING_PREF     "browser.safebrowsing.enabled"
80486: #define CHECK_PHISHING_DEFAULT  false
 8643: 
12334: #define GETHASH_NOISE_PREF      "urlclassifier.gethashnoise"
12334: #define GETHASH_NOISE_DEFAULT   4
12334: 
14354: #define GETHASH_TABLES_PREF     "urlclassifier.gethashtables"
14354: 
14354: #define CONFIRM_AGE_PREF        "urlclassifier.confirm-age"
14354: #define CONFIRM_AGE_DEFAULT_SEC (45 * 60)
14354: 
14883: #define UPDATE_CACHE_SIZE_PREF    "urlclassifier.updatecachemax"
14883: #define UPDATE_CACHE_SIZE_DEFAULT -1
14883: 
78088: #define LOOKUP_CACHE_SIZE_PREF    "urlclassifier.lookupcachemax"
78088: #define LOOKUP_CACHE_SIZE_DEFAULT -1
78088: 
15023: // Amount of time to spend updating before committing and delaying, in
15023: // seconds.  This is checked after each update stream, so the actual
15023: // time spent can be higher than this, depending on update stream size.
15023: #define UPDATE_WORKING_TIME         "urlclassifier.workingtime"
15023: #define UPDATE_WORKING_TIME_DEFAULT 5
15023: 
15023: // The amount of time to delay after hitting UPDATE_WORKING_TIME, in
15023: // seconds.
15023: #define UPDATE_DELAY_TIME           "urlclassifier.updatetime"
15023: #define UPDATE_DELAY_TIME_DEFAULT   60
15023: 
10212: class nsUrlClassifierDBServiceWorker;
10212: 
    1: // Singleton instance.
    1: static nsUrlClassifierDBService* sUrlClassifierDBService;
    1: 
76882: nsIThread* nsUrlClassifierDBService::gDbBackgroundThread = nsnull;
    1: 
  762: // Once we've committed to shutting down, don't do work in the background
  762: // thread.
79445: static bool gShuttingDownThread = false;
  762: 
14354: static PRInt32 gFreshnessGuarantee = CONFIRM_AGE_DEFAULT_SEC;
14354: 
14883: static PRInt32 gUpdateCacheSize = UPDATE_CACHE_SIZE_DEFAULT;
78088: static PRInt32 gLookupCacheSize = LOOKUP_CACHE_SIZE_DEFAULT;
14883: 
15023: static PRInt32 gWorkingTimeThreshold = UPDATE_WORKING_TIME_DEFAULT;
15023: static PRInt32 gDelayTime = UPDATE_DELAY_TIME_DEFAULT;
15023: 
14354: static void
14354: SplitTables(const nsACString& str, nsTArray<nsCString>& tables)
14354: {
14354:   tables.Clear();
14354: 
14354:   nsACString::const_iterator begin, iter, end;
14354:   str.BeginReading(begin);
14354:   str.EndReading(end);
14354:   while (begin != end) {
14354:     iter = begin;
14354:     FindCharInReadable(',', iter, end);
14354:     tables.AppendElement(Substring(begin, iter));
14354:     begin = iter;
14354:     if (begin != end)
14354:       begin++;
14354:   }
14354: }
14354: 
 4024: // -------------------------------------------------------------------------
 4024: // Hash class implementation
 4024: 
10941: // A convenience wrapper around the potentially-truncated hash for a
10941: // domain or fragment.
10941: 
10941: template <PRUint32 S>
 4024: struct nsUrlClassifierHash
    1: {
10941:   static const PRUint32 sHashSize = S;
10941:   typedef nsUrlClassifierHash<S> self_type;
10941:   PRUint8 buf[S];
10941: 
10941:   nsresult FromPlaintext(const nsACString& plainText, nsICryptoHash *hash) {
 4024:     // From the protocol doc:
 4024:     // Each entry in the chunk is composed of the 128 most significant bits
 4024:     // of the SHA 256 hash of a suffix/prefix expression.
 4024: 
 4024:     nsresult rv = hash->Init(nsICryptoHash::SHA256);
 4024:     NS_ENSURE_SUCCESS(rv, rv);
 4024: 
 4024:     rv = hash->Update
 4024:       (reinterpret_cast<const PRUint8*>(plainText.BeginReading()),
 4024:        plainText.Length());
 4024:     NS_ENSURE_SUCCESS(rv, rv);
 4024: 
 4024:     nsCAutoString hashed;
80486:     rv = hash->Finish(false, hashed);
 4024:     NS_ENSURE_SUCCESS(rv, rv);
 4024: 
10941:     NS_ASSERTION(hashed.Length() >= sHashSize,
 4024:                  "not enough characters in the hash");
 4024: 
10941:     memcpy(buf, hashed.BeginReading(), sHashSize);
 4024: 
 4024:     return NS_OK;
    1:   }
    1: 
10941:   void Assign(const nsACString& str) {
10941:     NS_ASSERTION(str.Length() >= sHashSize,
10941:                  "string must be at least sHashSize characters long");
10941:     memcpy(buf, str.BeginReading(), sHashSize);
 4024:   }
 4024: 
14354:   void Clear() {
14354:     memset(buf, 0, sizeof(buf));
14354:   }
14354: 
79445:   const bool operator==(const self_type& hash) const {
10941:     return (memcmp(buf, hash.buf, sizeof(buf)) == 0);
10941:   }
79445:   const bool operator!=(const self_type& hash) const {
10941:     return !(*this == hash);
10941:   }
79445:   const bool operator<(const self_type& hash) const {
10941:     return memcmp(buf, hash.buf, sizeof(self_type)) < 0;
10941:   }
79445:   const bool StartsWith(const nsUrlClassifierHash<PARTIAL_LENGTH>& hash) const {
10941:     NS_ASSERTION(sHashSize >= PARTIAL_LENGTH, "nsUrlClassifierHash must be at least PARTIAL_LENGTH bytes long");
10941:     return memcmp(buf, hash.buf, PARTIAL_LENGTH) == 0;
10941:   }
78086:   PRUint32 ToUint32() const {
78086:     return *(reinterpret_cast<const PRUint32*>(buf));
78086:   }
10941: };
10941: 
10941: typedef nsUrlClassifierHash<DOMAIN_LENGTH> nsUrlClassifierDomainHash;
10941: typedef nsUrlClassifierHash<PARTIAL_LENGTH> nsUrlClassifierPartialHash;
10941: typedef nsUrlClassifierHash<COMPLETE_LENGTH> nsUrlClassifierCompleteHash;
10941: 
10941: 
 4024: // -------------------------------------------------------------------------
 4024: // Entry class implementation
 4024: 
10941: // This class represents one entry in the classifier database.  It consists
10941: // of a table id, a chunk id, a domain hash, and a partial or complete hash.
 4024: class nsUrlClassifierEntry
 4024: {
 4024: public:
10941:   nsUrlClassifierEntry()
12334:     : mId(-1)
80486:     , mHavePartial(false)
80486:     , mHaveComplete(false)
10941:     , mTableId(0)
10941:     , mChunkId(0)
10941:     , mAddChunkId(0)
10941:     {}
 4024:   ~nsUrlClassifierEntry() {}
 4024: 
10941:   // Check that this entry could potentially match the complete hash.
79445:   bool Match(const nsUrlClassifierCompleteHash &hash);
10941: 
10941:   // Check that the sub entry should apply to this entry.
79445:   bool SubMatch(const nsUrlClassifierEntry& sub);
 4024: 
 4024:   // Clear out the entry structure
 4024:   void Clear();
 4024: 
10941:   // Set the partial hash for this domain.
10941:   void SetHash(const nsUrlClassifierPartialHash &partialHash) {
10941:     mPartialHash = partialHash;
80486:     mHavePartial = true;
10941:   }
10941: 
10941:   // Set the complete hash for this domain.
10941:   void SetHash(const nsUrlClassifierCompleteHash &completeHash) {
10941:     mCompleteHash = completeHash;
80486:     mHaveComplete = true;
10941:   }
10941: 
79445:   bool operator== (const nsUrlClassifierEntry& entry) const {
10941:     return ! (mTableId != entry.mTableId ||
10941:               mChunkId != entry.mChunkId ||
10941:               mHavePartial != entry.mHavePartial ||
10941:               (mHavePartial && mPartialHash != entry.mPartialHash) ||
10941:               mHaveComplete != entry.mHaveComplete ||
10941:               (mHaveComplete && mCompleteHash != entry.mCompleteHash));
10941:   }
10941: 
79445:   bool operator< (const nsUrlClassifierEntry& entry) const {
10941:     return (mTableId < entry.mTableId ||
10941:             mChunkId < entry.mChunkId ||
84916:             (mHavePartial && !entry.mHavePartial) ||
10941:             (mHavePartial && mPartialHash < entry.mPartialHash) ||
84916:             (mHaveComplete && !entry.mHaveComplete) ||
10941:             (mHaveComplete && mCompleteHash < entry.mCompleteHash));
10941:   }
10941: 
12334:   PRInt64 mId;
10941: 
10941:   nsUrlClassifierDomainHash mKey;
10941: 
79445:   bool mHavePartial;
10941:   nsUrlClassifierPartialHash mPartialHash;
10941: 
79445:   bool mHaveComplete;
10941:   nsUrlClassifierCompleteHash mCompleteHash;
10941: 
10865:   PRUint32 mTableId;
10941:   PRUint32 mChunkId;
10941:   PRUint32 mAddChunkId;
10941: };
10941: 
79445: bool
10941: nsUrlClassifierEntry::Match(const nsUrlClassifierCompleteHash &hash)
10941: {
10941:   if (mHaveComplete)
10941:     return mCompleteHash == hash;
10941: 
10941:   if (mHavePartial)
10941:     return hash.StartsWith(mPartialHash);
10941: 
80486:   return false;
10854: }
10854: 
79445: bool
10941: nsUrlClassifierEntry::SubMatch(const nsUrlClassifierEntry &subEntry)
10865: {
10941:   if ((mTableId != subEntry.mTableId) || (mChunkId != subEntry.mAddChunkId))
80486:     return false;
10941: 
10941:   if (subEntry.mHaveComplete)
10941:     return mHaveComplete && mCompleteHash == subEntry.mCompleteHash;
10941: 
10941:   if (subEntry.mHavePartial)
10941:     return mHavePartial && mPartialHash == subEntry.mPartialHash;
 4024: 
80486:   return false;
 4024: }
 4024: 
 4024: void
 4024: nsUrlClassifierEntry::Clear()
 4024: {
12334:   mId = -1;
80486:   mHavePartial = false;
80486:   mHaveComplete = false;
 4024: }
    1: 
    1: // -------------------------------------------------------------------------
10941: // Lookup result class implementation
10941: 
10941: // This helper class wraps a nsUrlClassifierEntry found during a lookup.
10941: class nsUrlClassifierLookupResult
10941: {
10941: public:
80486:   nsUrlClassifierLookupResult() : mConfirmed(false), mNoise(false) {
14354:     mLookupFragment.Clear();
14354:   }
10941:   ~nsUrlClassifierLookupResult() {}
10941: 
79445:   bool operator==(const nsUrlClassifierLookupResult &result) const {
10941:     // Don't need to compare table name, it's contained by id in the entry.
10941:     return (mLookupFragment == result.mLookupFragment &&
10941:             mConfirmed == result.mConfirmed &&
10941:             mEntry == result.mEntry);
10941:   }
10941: 
79445:   bool operator<(const nsUrlClassifierLookupResult &result) const {
10941:     // Don't need to compare table name, it's contained by id in the entry.
10941:     return (mLookupFragment < result.mLookupFragment ||
10941:             mConfirmed < result.mConfirmed ||
10941:             mEntry < result.mEntry);
10941:   }
10941: 
10941:   // The hash that matched this entry.
10941:   nsUrlClassifierCompleteHash mLookupFragment;
10941: 
10941:   // The entry that was found during the lookup.
10941:   nsUrlClassifierEntry mEntry;
10941: 
10941:   // TRUE if the lookup matched a complete hash (not just a partial
10941:   // one).
79445:   bool mConfirmed;
10941: 
12334:   // TRUE if this lookup is gethash noise.  Does not represent an actual
12334:   // result.
79445:   bool mNoise;
12334: 
10941:   // The table name associated with mEntry.mTableId.
10941:   nsCString mTableName;
10941: };
10941: 
10941: // -------------------------------------------------------------------------
10212: // Store class implementation
10212: 
10212: // This class mediates access to the classifier and chunk entry tables.
10212: class nsUrlClassifierStore
10212: {
10212: public:
10212:   nsUrlClassifierStore() {}
10941:   virtual ~nsUrlClassifierStore() {}
10212: 
10212:   // Initialize the statements for the store.
10212:   nsresult Init(nsUrlClassifierDBServiceWorker *worker,
10212:                 mozIStorageConnection *connection,
10941:                 const nsACString& entriesTableName);
10212:   // Shut down the store.
10212:   void Close();
10212: 
10941:   // Read an entry from a database statement
79445:   virtual bool ReadStatement(mozIStorageStatement* statement,
10941:                                nsUrlClassifierEntry& entry);
10941: 
10941:   // Prepare a statement to write this entry to the database
10941:   virtual nsresult BindStatement(const nsUrlClassifierEntry& entry,
10941:                                  mozIStorageStatement* statement);
10941: 
10212:   // Read the entry with a given ID from the database
79445:   nsresult ReadEntry(PRInt64 id, nsUrlClassifierEntry& entry, bool *exists);
10212: 
10212:   // Remove an entry from the database
10212:   nsresult DeleteEntry(nsUrlClassifierEntry& entry);
10212: 
10212:   // Write an entry to the database
10212:   nsresult WriteEntry(nsUrlClassifierEntry& entry);
10212: 
10988:   // Update an entry in the database.  The entry must already exist in the
10988:   // database or this method will fail.
10988:   nsresult UpdateEntry(nsUrlClassifierEntry& entry);
10988: 
10212:   // Remove all entries for a given table/chunk pair from the database.
10212:   nsresult Expire(PRUint32 tableId,
10212:                   PRUint32 chunkNum);
10212: 
12334:   // Read a certain number of rows adjacent to the requested rowid that
12334:   // don't have complete hash data.
12334:   nsresult ReadNoiseEntries(PRInt64 rowID,
12334:                             PRUint32 numRequested,
79445:                             bool before,
12334:                             nsTArray<nsUrlClassifierEntry> &entries);
12334: 
83146:   // Ask the db for a random number.  This is temporary, and should be
83146:   // replaced with nsIRandomGenerator when 419739 is fixed.
83146:   nsresult RandomNumber(PRInt64 *randomNum);
78086:   // Return an array with all Prefixes known
86944:   nsresult ReadPrefixes(FallibleTArray<PRUint32>& array, PRUint32 aKey);
78086: 
83146: 
10941: protected:
10941:   nsresult ReadEntries(mozIStorageStatement *statement,
10941:                        nsTArray<nsUrlClassifierEntry>& entries);
10212:   nsUrlClassifierDBServiceWorker *mWorker;
10212:   nsCOMPtr<mozIStorageConnection> mConnection;
10212: 
10212:   nsCOMPtr<mozIStorageStatement> mLookupWithIDStatement;
10212: 
10988:   nsCOMPtr<mozIStorageStatement> mInsertStatement;
10212:   nsCOMPtr<mozIStorageStatement> mUpdateStatement;
10212:   nsCOMPtr<mozIStorageStatement> mDeleteStatement;
10941:   nsCOMPtr<mozIStorageStatement> mExpireStatement;
12334: 
12334:   nsCOMPtr<mozIStorageStatement> mPartialEntriesStatement;
12334:   nsCOMPtr<mozIStorageStatement> mPartialEntriesAfterStatement;
12334:   nsCOMPtr<mozIStorageStatement> mLastPartialEntriesStatement;
12334:   nsCOMPtr<mozIStorageStatement> mPartialEntriesBeforeStatement;
78086: 
83146:   nsCOMPtr<mozIStorageStatement> mRandomStatement;
86944:   nsCOMPtr<mozIStorageStatement> mAllPrefixGetStatement;
86944:   nsCOMPtr<mozIStorageStatement> mAllPrefixCountStatement;
10212: };
10212: 
10212: nsresult
10212: nsUrlClassifierStore::Init(nsUrlClassifierDBServiceWorker *worker,
10212:                            mozIStorageConnection *connection,
10941:                            const nsACString& entriesName)
10212: {
10212:   mWorker = worker;
10212:   mConnection = connection;
10212: 
10212:   nsresult rv = mConnection->CreateStatement
10212:     (NS_LITERAL_CSTRING("SELECT * FROM ") + entriesName +
10212:      NS_LITERAL_CSTRING(" WHERE id=?1"),
10212:      getter_AddRefs(mLookupWithIDStatement));
10212:   NS_ENSURE_SUCCESS(rv, rv);
10212: 
10212:   rv = mConnection->CreateStatement
10212:     (NS_LITERAL_CSTRING("DELETE FROM ") + entriesName +
10212:      NS_LITERAL_CSTRING(" WHERE id=?1"),
10212:      getter_AddRefs(mDeleteStatement));
10212:   NS_ENSURE_SUCCESS(rv, rv);
10212: 
10212:   rv = mConnection->CreateStatement
10941:     (NS_LITERAL_CSTRING("DELETE FROM ") + entriesName +
10212:      NS_LITERAL_CSTRING(" WHERE table_id=?1 AND chunk_id=?2"),
10941:      getter_AddRefs(mExpireStatement));
12334:   NS_ENSURE_SUCCESS(rv, rv);
12334: 
12334:   rv = mConnection->CreateStatement
12334:     (NS_LITERAL_CSTRING("SELECT * FROM ") + entriesName +
12334:      NS_LITERAL_CSTRING(" WHERE complete_data ISNULL"
12334:                         " LIMIT ?1"),
12334:      getter_AddRefs(mPartialEntriesStatement));
12334:   NS_ENSURE_SUCCESS(rv, rv);
12334: 
12334:   rv = mConnection->CreateStatement
12334:     (NS_LITERAL_CSTRING("SELECT * FROM ") + entriesName +
12334:      NS_LITERAL_CSTRING(" WHERE id > ?1 AND complete_data ISNULL"
12334:                         " LIMIT ?2"),
12334:      getter_AddRefs(mPartialEntriesAfterStatement));
12334:   NS_ENSURE_SUCCESS(rv, rv);
12334: 
12334:   rv = mConnection->CreateStatement
12334:     (NS_LITERAL_CSTRING("SELECT * FROM ") + entriesName +
12334:      NS_LITERAL_CSTRING(" WHERE complete_data ISNULL"
12334:                         " ORDER BY id DESC LIMIT ?1"),
12334:      getter_AddRefs(mLastPartialEntriesStatement));
12334:   NS_ENSURE_SUCCESS(rv, rv);
12334: 
12334:   rv = mConnection->CreateStatement
12334:     (NS_LITERAL_CSTRING("SELECT * FROM ") + entriesName +
12334:      NS_LITERAL_CSTRING(" WHERE id < ?1 AND complete_data ISNULL"
12334:                         " ORDER BY id DESC LIMIT ?2"),
12334:      getter_AddRefs(mPartialEntriesBeforeStatement));
12334:   NS_ENSURE_SUCCESS(rv, rv);
12334: 
78086:   rv = mConnection->CreateStatement
83146:     (NS_LITERAL_CSTRING("SELECT abs(random())"),
83146:      getter_AddRefs(mRandomStatement));
83146:   NS_ENSURE_SUCCESS(rv, rv);
83146: 
83146:   rv = mConnection->CreateStatement(NS_LITERAL_CSTRING("SELECT domain, partial_data, complete_data FROM ")
78086:     + entriesName,
86944:     getter_AddRefs(mAllPrefixGetStatement));
86944:   NS_ENSURE_SUCCESS(rv, rv);
86944: 
86944:   rv = mConnection->CreateStatement(NS_LITERAL_CSTRING("SELECT COUNT(1) FROM ")
86944:     + entriesName,
86944:     getter_AddRefs(mAllPrefixCountStatement));
78086:   NS_ENSURE_SUCCESS(rv, rv);
78086: 
10212:   return NS_OK;
10212: }
10212: 
10212: void
10212: nsUrlClassifierStore::Close()
10212: {
10212:   mLookupWithIDStatement = nsnull;
10212: 
10988:   mInsertStatement = nsnull;
10212:   mUpdateStatement = nsnull;
10212:   mDeleteStatement = nsnull;
10941:   mExpireStatement = nsnull;
10212: 
12334:   mPartialEntriesStatement = nsnull;
12334:   mPartialEntriesAfterStatement = nsnull;
12334:   mPartialEntriesBeforeStatement = nsnull;
12334:   mLastPartialEntriesStatement = nsnull;
83146:   mRandomStatement = nsnull;
12337: 
86944:   mAllPrefixGetStatement = nsnull;
86944:   mAllPrefixCountStatement = nsnull;
78086: 
10212:   mConnection = nsnull;
10212: }
10212: 
10941: 
79445: bool
10941: nsUrlClassifierStore::ReadStatement(mozIStorageStatement* statement,
10941:                                     nsUrlClassifierEntry& entry)
10941: {
12334:   entry.mId = statement->AsInt64(0);
10941: 
10941:   PRUint32 size;
10941:   const PRUint8* blob = statement->AsSharedBlob(1, &size);
10941:   if (!blob || (size != DOMAIN_LENGTH))
80486:     return false;
10941:   memcpy(entry.mKey.buf, blob, DOMAIN_LENGTH);
10941: 
10941:   blob = statement->AsSharedBlob(2, &size);
10941:   if (!blob || size == 0) {
80486:     entry.mHavePartial = false;
10941:   } else {
10941:     if (size != PARTIAL_LENGTH)
80486:       return false;
80486:     entry.mHavePartial = true;
10941:     memcpy(entry.mPartialHash.buf, blob, PARTIAL_LENGTH);
10941:   }
10941: 
10941:   blob = statement->AsSharedBlob(3, &size);
10941:   if (!blob || size == 0) {
80486:     entry.mHaveComplete = false;
10941:   } else {
10941:     if (size != COMPLETE_LENGTH)
80486:       return false;
80486:     entry.mHaveComplete = true;
10941:     memcpy(entry.mCompleteHash.buf, blob, COMPLETE_LENGTH);
10941:   }
10941: 
10941:   // If we only have a partial entry, and that partial entry matches the
10941:   // domain, we don't save the extra copy to the database.
10941:   if (!(entry.mHavePartial || entry.mHaveComplete)) {
10941:     entry.SetHash(entry.mKey);
10941:   }
10941: 
10941:   entry.mChunkId = statement->AsInt32(4);
10941:   entry.mTableId = statement->AsInt32(5);
10941: 
80486:   return true;
10941: }
10941: 
10865: nsresult
10941: nsUrlClassifierStore::BindStatement(const nsUrlClassifierEntry &entry,
10941:                                     mozIStorageStatement* statement)
10854: {
10941:   nsresult rv;
10941: 
12334:   if (entry.mId == -1)
64474:     rv = statement->BindNullByIndex(0);
10941:   else
64474:     rv = statement->BindInt64ByIndex(0, entry.mId);
10212:   NS_ENSURE_SUCCESS(rv, rv);
10212: 
64474:   rv = statement->BindBlobByIndex(1, entry.mKey.buf, DOMAIN_LENGTH);
10212:   NS_ENSURE_SUCCESS(rv, rv);
10212: 
10941:   if (entry.mHavePartial) {
10941:     // If we only have a partial entry and that entry matches the domain,
10941:     // we'll save some space by only storing the domain hash.
10941:     if (!entry.mHaveComplete && entry.mKey == entry.mPartialHash) {
64474:       rv = statement->BindNullByIndex(2);
10941:     } else {
64474:       rv = statement->BindBlobByIndex(2, entry.mPartialHash.buf,
10941:                                         PARTIAL_LENGTH);
10941:     }
10941:   } else {
64474:     rv = statement->BindNullByIndex(2);
10941:   }
10212:   NS_ENSURE_SUCCESS(rv, rv);
10212: 
10941:   if (entry.mHaveComplete) {
64474:     rv = statement->BindBlobByIndex(3, entry.mCompleteHash.buf, COMPLETE_LENGTH);
10941:   } else {
64474:     rv = statement->BindNullByIndex(3);
10941:   }
10941:   NS_ENSURE_SUCCESS(rv, rv);
10941: 
64474:   rv = statement->BindInt32ByIndex(4, entry.mChunkId);
10941:   NS_ENSURE_SUCCESS(rv, rv);
10941: 
64474:   rv = statement->BindInt32ByIndex(5, entry.mTableId);
10941:   NS_ENSURE_SUCCESS(rv, rv);
10941: 
80486:   return true;
10941: }
10941: 
10941: nsresult
10941: nsUrlClassifierStore::ReadEntries(mozIStorageStatement *statement,
10941:                                   nsTArray<nsUrlClassifierEntry>& entries)
10941: {
79445:   bool exists;
10941:   nsresult rv = statement->ExecuteStep(&exists);
10941:   NS_ENSURE_SUCCESS(rv, rv);
10941: 
10941:   while (exists) {
10941:     nsUrlClassifierEntry *entry = entries.AppendElement();
10941:     if (!entry) {
10941:       return NS_ERROR_OUT_OF_MEMORY;
10941:     }
10941: 
10941:     if (!ReadStatement(statement, *entry))
10941:       return NS_ERROR_FAILURE;
10941: 
10941:     statement->ExecuteStep(&exists);
10941:   }
10941: 
10212:   return NS_OK;
10212: }
10212: 
10941: nsresult
12334: nsUrlClassifierStore::ReadEntry(PRInt64 id,
10941:                                 nsUrlClassifierEntry& entry,
79445:                                 bool *exists)
10941: {
10941:   entry.Clear();
10941: 
10941:   mozStorageStatementScoper scoper(mLookupWithIDStatement);
10941: 
64474:   nsresult rv = mLookupWithIDStatement->BindInt64ByIndex(0, id);
10941:   NS_ENSURE_SUCCESS(rv, rv);
10941: 
10941:   rv = mLookupWithIDStatement->ExecuteStep(exists);
10941:   NS_ENSURE_SUCCESS(rv, rv);
10941: 
10941:   if (*exists) {
10941:     if (ReadStatement(mLookupWithIDStatement, entry))
10941:       return NS_ERROR_FAILURE;
10941:   }
10941: 
10941:   return NS_OK;
10941: }
10941: 
12334: nsresult
12334: nsUrlClassifierStore::ReadNoiseEntries(PRInt64 rowID,
12334:                                        PRUint32 numRequested,
79445:                                        bool before,
12334:                                        nsTArray<nsUrlClassifierEntry> &entries)
12334: {
12334:   if (numRequested == 0) {
12334:     return NS_OK;
12334:   }
12334: 
12334:   mozIStorageStatement *statement =
12334:     before ? mPartialEntriesBeforeStatement : mPartialEntriesAfterStatement;
12334:   mozStorageStatementScoper scoper(statement);
12334: 
64474:   nsresult rv = statement->BindInt64ByIndex(0, rowID);
12334:   NS_ENSURE_SUCCESS(rv, rv);
12334: 
64474:   statement->BindInt32ByIndex(1, numRequested);
12334:   NS_ENSURE_SUCCESS(rv, rv);
12334: 
12334:   PRUint32 length = entries.Length();
12334:   rv = ReadEntries(statement, entries);
12334:   NS_ENSURE_SUCCESS(rv, rv);
12334: 
12334:   PRUint32 numRead = entries.Length() - length;
12334: 
12334:   if (numRead >= numRequested)
12334:     return NS_OK;
12334: 
12334:   // If we didn't get enough entries, we need the search to wrap around from
12334:   // beginning to end (or vice-versa)
12334: 
12334:   mozIStorageStatement *wraparoundStatement =
12334:     before ? mPartialEntriesStatement : mLastPartialEntriesStatement;
12334:   mozStorageStatementScoper wraparoundScoper(wraparoundStatement);
12334: 
64474:   rv = wraparoundStatement->BindInt32ByIndex(0, numRequested - numRead);
12334:   NS_ENSURE_SUCCESS(rv, rv);
12334: 
12334:   return ReadEntries(wraparoundStatement, entries);
12334: }
12334: 
83146: nsresult
83146: nsUrlClassifierStore::RandomNumber(PRInt64 *randomNum)
83146: {
83146:   mozStorageStatementScoper randScoper(mRandomStatement);
83147:   bool exists;
83146:   nsresult rv = mRandomStatement->ExecuteStep(&exists);
83146:   NS_ENSURE_SUCCESS(rv, rv);
83146:   if (!exists)
83146:     return NS_ERROR_NOT_AVAILABLE;
83146: 
83146:   *randomNum = mRandomStatement->AsInt64(0);
83146: 
83146:   return NS_OK;
83146: }
83146: 
10941: // -------------------------------------------------------------------------
10941: // nsUrlClassifierAddStore class implementation
10941: 
10941: // This class accesses the moz_classifier table.
10941: class nsUrlClassifierAddStore: public nsUrlClassifierStore
10941: {
10941: public:
10941:   nsUrlClassifierAddStore() {};
10941:   virtual ~nsUrlClassifierAddStore() {};
10941: 
10941:   nsresult Init(nsUrlClassifierDBServiceWorker *worker,
10941:                 mozIStorageConnection *connection,
10941:                 const nsACString& entriesTableName);
20649: 
20649:   void Close();
20649: 
20649:   // Read the entries for a given key/table/chunk from the database
20649:   nsresult ReadAddEntries(const nsUrlClassifierDomainHash& key,
20649:                           PRUint32 tableId,
20649:                           PRUint32 chunkId,
20649:                           nsTArray<nsUrlClassifierEntry>& entry);
20649: 
20649:   // Read the entries for a given host key from the database.
20649:   nsresult ReadAddEntries(const nsUrlClassifierDomainHash& key,
20649:                           nsTArray<nsUrlClassifierEntry>& entry);
20649: 
20649: protected:
20649:   nsCOMPtr<mozIStorageStatement> mLookupStatement;
20649:   nsCOMPtr<mozIStorageStatement> mLookupWithChunkStatement;
10941: };
10941: 
10941: nsresult
10941: nsUrlClassifierAddStore::Init(nsUrlClassifierDBServiceWorker *worker,
10941:                               mozIStorageConnection *connection,
10941:                               const nsACString &entriesTableName)
10941: {
10941:   nsresult rv = nsUrlClassifierStore::Init(worker, connection,
10941:                                            entriesTableName);
10941:   NS_ENSURE_SUCCESS(rv, rv);
10941: 
10941:   rv = mConnection->CreateStatement
10941:     (NS_LITERAL_CSTRING("INSERT OR REPLACE INTO ") + entriesTableName +
10941:      NS_LITERAL_CSTRING(" VALUES (?1, ?2, ?3, ?4, ?5, ?6)"),
10988:      getter_AddRefs(mInsertStatement));
10988:   NS_ENSURE_SUCCESS(rv, rv);
10988: 
10988:   rv = mConnection->CreateStatement
10988:     (NS_LITERAL_CSTRING("UPDATE ") + entriesTableName +
10988:      NS_LITERAL_CSTRING(" SET domain=?2, partial_data=?3, "
10988:                         " complete_data=?4, chunk_id=?5, table_id=?6"
10988:                         " WHERE id=?1"),
10941:      getter_AddRefs(mUpdateStatement));
10941:   NS_ENSURE_SUCCESS(rv, rv);
10941: 
20649:   rv = mConnection->CreateStatement
20649:     (NS_LITERAL_CSTRING("SELECT * FROM ") + entriesTableName +
20649:      NS_LITERAL_CSTRING(" WHERE domain=?1"),
20649:      getter_AddRefs(mLookupStatement));
20649:   NS_ENSURE_SUCCESS(rv, rv);
20649: 
20649:   rv = mConnection->CreateStatement
20649:     (NS_LITERAL_CSTRING("SELECT * FROM ") + entriesTableName +
20649:      NS_LITERAL_CSTRING(" WHERE domain=?1 AND table_id=?2 AND chunk_id=?3"),
20649:      getter_AddRefs(mLookupWithChunkStatement));
20649:   NS_ENSURE_SUCCESS(rv, rv);
20649: 
10941:   return NS_OK;
10941: }
10941: 
20649: void
20649: nsUrlClassifierAddStore::Close()
20649: {
20649:   nsUrlClassifierStore::Close();
20649: 
20649:   mLookupStatement = nsnull;
20649:   mLookupWithChunkStatement = nsnull;
20649: }
20649: 
20649: nsresult
20649: nsUrlClassifierAddStore::ReadAddEntries(const nsUrlClassifierDomainHash& hash,
20649:                                         PRUint32 tableId,
20649:                                         PRUint32 chunkId,
20649:                                         nsTArray<nsUrlClassifierEntry>& entries)
20649: {
20649:   mozStorageStatementScoper scoper(mLookupWithChunkStatement);
20649: 
64474:   nsresult rv = mLookupWithChunkStatement->BindBlobByIndex
20649:                   (0, hash.buf, DOMAIN_LENGTH);
20649:   NS_ENSURE_SUCCESS(rv, rv);
20649: 
64474:   rv = mLookupWithChunkStatement->BindInt32ByIndex(1, tableId);
20649:   NS_ENSURE_SUCCESS(rv, rv);
64474:   rv = mLookupWithChunkStatement->BindInt32ByIndex(2, chunkId);
20649:   NS_ENSURE_SUCCESS(rv, rv);
20649: 
20649:   return ReadEntries(mLookupWithChunkStatement, entries);
20649: }
20649: 
20649: nsresult
20649: nsUrlClassifierAddStore::ReadAddEntries(const nsUrlClassifierDomainHash& hash,
20649:                                         nsTArray<nsUrlClassifierEntry>& entries)
20649: {
20649:   mozStorageStatementScoper scoper(mLookupStatement);
20649: 
64474:   nsresult rv = mLookupStatement->BindBlobByIndex
20649:                   (0, hash.buf, DOMAIN_LENGTH);
20649:   NS_ENSURE_SUCCESS(rv, rv);
20649: 
20649:   return ReadEntries(mLookupStatement, entries);
20649: }
20649: 
10941: // -------------------------------------------------------------------------
10941: // nsUrlClassifierSubStore class implementation
10941: 
10941: // This class accesses the moz_subs table.
10941: class nsUrlClassifierSubStore : public nsUrlClassifierStore
10941: {
10941: public:
10941:   nsUrlClassifierSubStore() {};
10941:   virtual ~nsUrlClassifierSubStore() {};
10941: 
10941:   nsresult Init(nsUrlClassifierDBServiceWorker *worker,
10941:                 mozIStorageConnection *connection,
10941:                 const nsACString& entriesTableName);
10941: 
10941:   void Close();
10941: 
10941:   // Read an entry from a database statement
79445:   virtual bool ReadStatement(mozIStorageStatement* statement,
10941:                                nsUrlClassifierEntry& entry);
10941: 
10941:   // Prepare a statement to write this entry to the database
10941:   virtual nsresult BindStatement(const nsUrlClassifierEntry& entry,
10941:                                  mozIStorageStatement* statement);
10941: 
20649:   // Read sub entries for a given add chunk
20649:   nsresult ReadSubEntries(PRUint32 tableId, PRUint32 chunkId,
10941:                           nsTArray<nsUrlClassifierEntry> &subEntry);
10941: 
20649:   // Expire sub entries for a given add chunk
20649:   nsresult ExpireAddChunk(PRUint32 tableId, PRUint32 chunkId);
20649: 
10941: protected:
10941:   nsCOMPtr<mozIStorageStatement> mLookupWithAddChunkStatement;
20649:   nsCOMPtr<mozIStorageStatement> mExpireAddChunkStatement;
10941: };
10941: 
10941: nsresult
10941: nsUrlClassifierSubStore::Init(nsUrlClassifierDBServiceWorker *worker,
10941:                               mozIStorageConnection *connection,
10941:                               const nsACString &entriesTableName)
10941: {
10941:   nsresult rv = nsUrlClassifierStore::Init(worker, connection,
10941:                                            entriesTableName);
10941:   NS_ENSURE_SUCCESS(rv, rv);
10941: 
10941:   rv = mConnection->CreateStatement
10941:     (NS_LITERAL_CSTRING("INSERT OR REPLACE INTO ") + entriesTableName +
10941:      NS_LITERAL_CSTRING(" VALUES (?1, ?2, ?3, ?4, ?5, ?6, ?7)"),
10988:      getter_AddRefs(mInsertStatement));
10988:   NS_ENSURE_SUCCESS(rv, rv);
10988: 
10988:   rv = mConnection->CreateStatement
10988:     (NS_LITERAL_CSTRING("UPDATE ") + entriesTableName +
10988:      NS_LITERAL_CSTRING(" SET domain=?2, partial_data=?3, complete_data=?4,"
10988:                         " chunk_id=?5, table_id=?6, add_chunk_id=?7"
10988:                         " WHERE id=?1"),
10941:      getter_AddRefs(mUpdateStatement));
10941:   NS_ENSURE_SUCCESS(rv, rv);
10941: 
10941:   rv = mConnection->CreateStatement
10941:     (NS_LITERAL_CSTRING("SELECT * FROM ") + entriesTableName +
20649:      NS_LITERAL_CSTRING(" WHERE table_id=?1 AND add_chunk_id=?2"),
10941:      getter_AddRefs(mLookupWithAddChunkStatement));
10941:   NS_ENSURE_SUCCESS(rv, rv);
10941: 
20649:   rv = mConnection->CreateStatement
20649:     (NS_LITERAL_CSTRING("DELETE FROM ") + entriesTableName +
20649:      NS_LITERAL_CSTRING(" WHERE table_id=?1 AND add_chunk_id=?2"),
20649:      getter_AddRefs(mExpireAddChunkStatement));
20649:   NS_ENSURE_SUCCESS(rv, rv);
20649: 
10941:   return NS_OK;
10941: }
10941: 
79445: bool
10941: nsUrlClassifierSubStore::ReadStatement(mozIStorageStatement* statement,
10941:                                        nsUrlClassifierEntry& entry)
10941: {
10941:   if (!nsUrlClassifierStore::ReadStatement(statement, entry))
80486:     return false;
10941: 
10941:   entry.mAddChunkId = statement->AsInt32(6);
80486:   return true;
10941: }
10941: 
10941: nsresult
10941: nsUrlClassifierSubStore::BindStatement(const nsUrlClassifierEntry& entry,
10941:                                        mozIStorageStatement* statement)
10941: {
10941:   nsresult rv = nsUrlClassifierStore::BindStatement(entry, statement);
10941:   NS_ENSURE_SUCCESS(rv, rv);
10941: 
64474:   return statement->BindInt32ByIndex(6, entry.mAddChunkId);
10941: }
10941: 
10941: nsresult
20649: nsUrlClassifierSubStore::ReadSubEntries(PRUint32 tableId, PRUint32 addChunkId,
10941:                                         nsTArray<nsUrlClassifierEntry>& entries)
10941: {
10941:   mozStorageStatementScoper scoper(mLookupWithAddChunkStatement);
10941: 
64474:   nsresult rv = mLookupWithAddChunkStatement->BindInt32ByIndex(0, tableId);
10941:   NS_ENSURE_SUCCESS(rv, rv);
64474:   rv = mLookupWithAddChunkStatement->BindInt32ByIndex(1, addChunkId);
10941:   NS_ENSURE_SUCCESS(rv, rv);
20649: 
20649:   return ReadEntries(mLookupWithAddChunkStatement, entries);
20649: }
20649: 
20649: nsresult
20649: nsUrlClassifierSubStore::ExpireAddChunk(PRUint32 tableId, PRUint32 addChunkId)
20649: {
20649:   mozStorageStatementScoper scoper(mExpireAddChunkStatement);
20649: 
64474:   nsresult rv = mExpireAddChunkStatement->BindInt32ByIndex(0, tableId);
10941:   NS_ENSURE_SUCCESS(rv, rv);
64474:   rv = mExpireAddChunkStatement->BindInt32ByIndex(1, addChunkId);
20649:   NS_ENSURE_SUCCESS(rv, rv);
20649: 
20649:   return mExpireAddChunkStatement->Execute();
10941: }
10941: 
10941: void
10941: nsUrlClassifierSubStore::Close()
10941: {
10941:   nsUrlClassifierStore::Close();
10941:   mLookupWithAddChunkStatement = nsnull;
20649:   mExpireAddChunkStatement = nsnull;
10941: }
10941: 
78087: // Similar to GetKey(), but if the domain contains three or more components,
78087: // two keys will be returned:
78087: //  hostname.com/foo/bar -> [hostname.com]
78087: //  mail.hostname.com/foo/bar -> [hostname.com, mail.hostname.com]
78087: //  www.mail.hostname.com/foo/bar -> [hostname.com, mail.hostname.com]
78087: static nsresult GetHostKeys(const nsACString &spec,
78087:                             nsTArray<nsCString> &hostKeys);
78087: 
78091: // take a lookup string (www.hostname.com/path/to/resource.html) and
78091: // expand it into the set of fragments that should be searched for in an
78091: // entry
78091: static nsresult GetLookupFragments(const nsCSubstring& spec,
78091:                                    nsTArray<nsCString>& fragments);
78091: 
78087: // Check for a canonicalized IP address.
79445: static bool IsCanonicalizedIP(const nsACString& host);
78087: 
78092: // Get the database key for a given URI.  This is the top three
78092: // domain components if they exist, otherwise the top two.
78092: //  hostname.com/foo/bar -> hostname.com
78092: //  mail.hostname.com/foo/bar -> mail.hostname.com
78092: //  www.mail.hostname.com/foo/bar -> mail.hostname.com
78092: static nsresult GetKey(const nsACString& spec, nsUrlClassifierDomainHash& hash,
78092:                        nsICryptoHash * aCryptoHash);
78092: 
78092: // We have both a prefix and a domain. Drop the domain, but
78092: // hash the domain, the prefix and a random value together,
78092: // ensuring any collisions happens at a different points for
78092: // different users.
78092: static nsresult KeyedHash(PRUint32 aPref, PRUint32 aDomain,
78092:                           PRUint32 aKey, PRUint32 *aOut);
78092: 
78092: 
10212: // -------------------------------------------------------------------------
    1: // Actual worker implemenatation
    1: class nsUrlClassifierDBServiceWorker : public nsIUrlClassifierDBServiceWorker
    1: {
    1: public:
    1:   nsUrlClassifierDBServiceWorker();
    1: 
    1:   NS_DECL_ISUPPORTS
    1:   NS_DECL_NSIURLCLASSIFIERDBSERVICE
    1:   NS_DECL_NSIURLCLASSIFIERDBSERVICEWORKER
    1: 
 4024:   // Initialize, called in the main thread
78086:   nsresult Init(PRInt32 gethashNoise,
78087:                 nsRefPtr<nsUrlClassifierPrefixSet> & prefSet);
 4024: 
 4024:   // Queue a lookup for the worker to perform, called in the main thread.
 4024:   nsresult QueueLookup(const nsACString& lookupKey,
10941:                        nsIUrlClassifierLookupCallback* callback);
 4024: 
10212:   // Handle any queued-up lookups.  We call this function during long-running
10212:   // update operations to prevent lookups from blocking for too long.
10212:   nsresult HandlePendingLookups();
10212: 
    1: private:
    1:   // No subclassing
    1:   ~nsUrlClassifierDBServiceWorker();
    1: 
    1:   // Disallow copy constructor
    1:   nsUrlClassifierDBServiceWorker(nsUrlClassifierDBServiceWorker&);
    1: 
    1:   // Try to open the db, DATABASE_FILENAME.
    1:   nsresult OpenDb();
    1: 
 4024:   // Create table in the db if they don't exist.
 4024:   nsresult MaybeCreateTables(mozIStorageConnection* connection);
 4024: 
 4024:   nsresult GetTableName(PRUint32 tableId, nsACString& table);
 4024:   nsresult GetTableId(const nsACString& table, PRUint32* tableId);
 4024: 
 4024:   // Decompress a zlib'ed chunk (used for -exp tables)
 4024:   nsresult InflateChunk(nsACString& chunk);
 4024: 
10941:   // Expand shavar chunk into its individual entries
10941:   nsresult GetShaEntries(PRUint32 tableId,
10941:                          PRUint32 chunkType,
10941:                          PRUint32 chunkNum,
10941:                          PRUint32 domainSize,
10941:                          PRUint32 hashSize,
10941:                          nsACString& chunk,
10941:                          nsTArray<nsUrlClassifierEntry>& entries);
10941: 
 4024:   // Expand a chunk into its individual entries
 4024:   nsresult GetChunkEntries(const nsACString& table,
 4024:                            PRUint32 tableId,
10941:                            PRUint32 chunkType,
 4024:                            PRUint32 chunkNum,
10941:                            PRUint32 hashSize,
 4024:                            nsACString& chunk,
 4024:                            nsTArray<nsUrlClassifierEntry>& entries);
 4024: 
11769:   // Parse one stringified range of chunks of the form "n" or "n-m" from a
11769:   // comma-separated list of chunks.  Upon return, 'begin' will point to the
11769:   // next range of chunks in the list of chunks.
79445:   bool ParseChunkRange(nsACString::const_iterator &begin,
11769:                          const nsACString::const_iterator &end,
 8707:                          PRUint32 *first, PRUint32 *last);
 8707: 
 4024:   // Expand a stringified chunk list into an array of ints.
 4024:   nsresult ParseChunkList(const nsACString& chunkStr,
 4024:                           nsTArray<PRUint32>& chunks);
 4024: 
 4024:   // Join an array of ints into a stringified chunk list.
 4024:   nsresult JoinChunkList(nsTArray<PRUint32>& chunks, nsCString& chunkStr);
 4024: 
 4024:   // List the add/subtract chunks that have been applied to a table
 4024:   nsresult GetChunkLists(PRUint32 tableId,
 4024:                          nsACString& addChunks,
 4024:                          nsACString& subChunks);
 4024: 
 4024:   // Set the list of add/subtract chunks that have been applied to a table
 4024:   nsresult SetChunkLists(PRUint32 tableId,
 4024:                          const nsACString& addChunks,
 4024:                          const nsACString& subChunks);
 4024: 
 8642:   // Cache the list of add/subtract chunks applied to the table, optionally
 8642:   // parsing the add or sub lists.  These lists are cached while updating
 8642:   // tables to avoid excessive database reads/writes and parsing.
 8642:   nsresult CacheChunkLists(PRUint32 tableId,
79445:                            bool parseAdds,
79445:                            bool parseSubs);
10941: 
10941:   // Clear the cached list of add/subtract chunks.
10941:   void ClearCachedChunkLists();
10941: 
 8642:   // Flush the cached add/subtract lists to the database.
 8642:   nsresult FlushChunkLists();
 8642: 
14994:   // Inserts a chunk id into the list, sorted.  Returns TRUE if the
14994:   // number was successfully added, FALSE if the chunk already exists.
79445:   bool InsertChunkId(nsTArray<PRUint32>& chunks, PRUint32 chunkNum);
14994: 
 4024:   // Add a list of entries to the database, merging with
 4024:   // existing entries as necessary
 4024:   nsresult AddChunk(PRUint32 tableId, PRUint32 chunkNum,
 4024:                     nsTArray<nsUrlClassifierEntry>& entries);
 4024: 
 4024:   // Expire an add chunk
 4024:   nsresult ExpireAdd(PRUint32 tableId, PRUint32 chunkNum);
 4024: 
 4024:   // Subtract a list of entries from the database
 4024:   nsresult SubChunk(PRUint32 tableId, PRUint32 chunkNum,
 4024:                     nsTArray<nsUrlClassifierEntry>& entries);
 4024: 
 4024:   // Expire a subtract chunk
 4024:   nsresult ExpireSub(PRUint32 tableId, PRUint32 chunkNum);
 4024: 
 4024:   // Handle line-oriented control information from a stream update
79445:   nsresult ProcessResponseLines(bool* done);
 4024:   // Handle chunk data from a stream update
79445:   nsresult ProcessChunk(bool* done);
 4024: 
15023:   // Sets up a transaction and begins counting update time.
15023:   nsresult SetupUpdate();
15023: 
15023:   // Applies the current transaction and resets the update/working times.
15023:   nsresult ApplyUpdate();
15023: 
10213:   // Reset the in-progress update stream
10213:   void ResetStream();
10213: 
10213:   // Reset the in-progress update
 4024:   void ResetUpdate();
 4024: 
 4024:   // Look for a given lookup string (www.hostname.com/path/to/resource.html)
24807:   // Returns a list of entries that match.
24807:   nsresult Check(const nsCSubstring& spec,
10941:                  nsTArray<nsUrlClassifierLookupResult>& results);
 4024: 
 4024:   // Perform a classifier lookup for a given url.
10941:   nsresult DoLookup(const nsACString& spec, nsIUrlClassifierLookupCallback* c);
 4024: 
12334:   // Add entries to the results.
12334:   nsresult AddNoise(PRInt64 nearID,
12334:                     PRInt32 count,
12334:                     nsTArray<nsUrlClassifierLookupResult>& results);
12334: 
78090:   // Construct a Prefix Set with known prefixes
78090:   nsresult LoadPrefixSet(nsCOMPtr<nsIFile> & aFile);
78090:   nsresult ConstructPrefixSet();
78086: 
78088:   // Set the SQLite cache size
78088:   nsresult SetCacheSize(mozIStorageConnection * aConnection,
78088:                         PRInt32 aCacheSize);
78088: 
 4024:   nsCOMPtr<nsIFile> mDBFile;
78090:   nsCOMPtr<nsIFile> mPSFile;
 4024: 
 4024:   nsCOMPtr<nsICryptoHash> mCryptoHash;
    1: 
    1:   // Holds a connection to the Db.  We lazily initialize this because it has
    1:   // to be created in the background thread (currently mozStorageConnection
    1:   // isn't thread safe).
 4024:   nsCOMPtr<mozIStorageConnection> mConnection;
 4024: 
10212:   // The main collection of entries.  This is the store that will be checked
10212:   // when classifying a URL.
10941:   nsUrlClassifierAddStore mMainStore;
10212: 
10212:   // The collection of subs waiting for their accompanying add.
10941:   nsUrlClassifierSubStore mPendingSubStore;
 4024: 
 4024:   nsCOMPtr<mozIStorageStatement> mGetChunkListsStatement;
 4024:   nsCOMPtr<mozIStorageStatement> mSetChunkListsStatement;
 4024: 
 4024:   nsCOMPtr<mozIStorageStatement> mGetTablesStatement;
 4024:   nsCOMPtr<mozIStorageStatement> mGetTableIdStatement;
 4024:   nsCOMPtr<mozIStorageStatement> mGetTableNameStatement;
 4024:   nsCOMPtr<mozIStorageStatement> mInsertTableIdStatement;
46994:   nsCOMPtr<mozIStorageStatement> mGetPageSizeStatement;
    1: 
14354:   // Stores the last time a given table was updated.
14354:   nsDataHashtable<nsCStringHashKey, PRInt64> mTableFreshness;
14354: 
    1:   // We receive data in small chunks that may be broken in the middle of
    1:   // a line.  So we save the last partial line here.
    1:   nsCString mPendingStreamUpdate;
 4024: 
 4024:   PRInt32 mUpdateWait;
 4024: 
79445:   bool mResetRequested;
79445:   bool mGrewCache;
12453: 
 4024:   enum {
 4024:     STATE_LINE,
 4024:     STATE_CHUNK
 4024:   } mState;
 4024: 
 4024:   enum {
 4024:     CHUNK_ADD,
 4024:     CHUNK_SUB
 4024:   } mChunkType;
 4024: 
 4024:   PRUint32 mChunkNum;
10941:   PRUint32 mHashSize;
 4024:   PRUint32 mChunkLen;
 4024: 
14354:   // List of tables included in this update.
14354:   nsTArray<nsCString> mUpdateTables;
14354: 
 4024:   nsCString mUpdateTable;
 4024:   PRUint32 mUpdateTableId;
 4024: 
 4024:   nsresult mUpdateStatus;
 4024: 
10213:   nsCOMPtr<nsIUrlClassifierUpdateObserver> mUpdateObserver;
79445:   bool mInStream;
79445:   bool mPrimaryStream;
79445: 
79445:   bool mHaveCachedLists;
 8642:   PRUint32 mCachedListsTable;
 8642:   nsCAutoString mCachedSubsStr;
 8642:   nsCAutoString mCachedAddsStr;
 8642: 
79445:   bool mHaveCachedAddChunks;
 8642:   nsTArray<PRUint32> mCachedAddChunks;
 8642: 
79445:   bool mHaveCachedSubChunks;
 8642:   nsTArray<PRUint32> mCachedSubChunks;
 8642: 
12346:   // The client key with which the data from the server will be MAC'ed.
12346:   nsCString mUpdateClientKey;
12346: 
12346:   // The MAC stated by the server.
12346:   nsCString mServerMAC;
12346: 
15023:   // Start time of the current update interval.  This will be reset
15023:   // every time we apply the update.
15023:   PRIntervalTime mUpdateStartTime;
15023: 
12346:   nsCOMPtr<nsICryptoHMAC> mHMAC;
12334:   // The number of noise entries to add to the set of lookup results.
12334:   PRInt32 mGethashNoise;
 8642: 
78086:   // Set of prefixes known to be in the database
78087:   nsRefPtr<nsUrlClassifierPrefixSet> mPrefixSet;
20648: 
 4024:   // Pending lookups are stored in a queue for processing.  The queue
 4024:   // is protected by mPendingLookupLock.
64576:   Mutex mPendingLookupLock;
 4024: 
 4024:   class PendingLookup {
 4024:   public:
 4024:     nsCString mKey;
10941:     nsCOMPtr<nsIUrlClassifierLookupCallback> mCallback;
 4024:   };
 4024: 
 4024:   // list of pending lookups
 4024:   nsTArray<PendingLookup> mPendingLookups;
    1: };
    1: 
14031: NS_IMPL_THREADSAFE_ISUPPORTS2(nsUrlClassifierDBServiceWorker,
14031:                               nsIUrlClassifierDBServiceWorker,
14031:                               nsIUrlClassifierDBService)
    1: 
    1: nsUrlClassifierDBServiceWorker::nsUrlClassifierDBServiceWorker()
10941:   : mUpdateWait(0)
80486:   , mResetRequested(false)
80486:   , mGrewCache(false)
10941:   , mState(STATE_LINE)
10941:   , mChunkType(CHUNK_ADD)
10941:   , mChunkNum(0)
10941:   , mHashSize(0)
10941:   , mChunkLen(0)
10941:   , mUpdateTableId(0)
10941:   , mUpdateStatus(NS_OK)
80486:   , mInStream(false)
80486:   , mPrimaryStream(false)
80486:   , mHaveCachedLists(false)
 8642:   , mCachedListsTable(PR_UINT32_MAX)
80486:   , mHaveCachedAddChunks(false)
80486:   , mHaveCachedSubChunks(false)
15023:   , mUpdateStartTime(0)
12334:   , mGethashNoise(0)
78086:   , mPrefixSet(0)
64576:   , mPendingLookupLock("nsUrlClassifierDBServerWorker.mPendingLookupLock")
    1: {
    1: }
 4024: 
    1: nsUrlClassifierDBServiceWorker::~nsUrlClassifierDBServiceWorker()
    1: {
 4024:   NS_ASSERTION(!mConnection,
    1:                "Db connection not closed, leaking memory!  Call CloseDb "
    1:                "to close the connection.");
    1: }
    1: 
 4024: nsresult
78086: nsUrlClassifierDBServiceWorker::Init(PRInt32 gethashNoise,
78087:                                      nsRefPtr<nsUrlClassifierPrefixSet> & prefSet)
 4024: {
12334:   mGethashNoise = gethashNoise;
78086:   mPrefixSet = prefSet;
12334: 
 4024:   // Compute database filename
 4024: 
 4024:   // Because we dump raw integers into the database, this database isn't
 4024:   // portable between machine types, so store it in the local profile dir.
 4024:   nsresult rv = NS_GetSpecialDirectory(NS_APP_USER_PROFILE_LOCAL_50_DIR,
 4024:                                        getter_AddRefs(mDBFile));
 9868: 
 9868:   if (NS_FAILED(rv)) {
 9868:     rv = NS_GetSpecialDirectory(NS_APP_USER_PROFILE_50_DIR,
 9868:                                 getter_AddRefs(mDBFile));
 9868:   }
 9868: 
 9868:   if (NS_FAILED(rv)) return NS_ERROR_NOT_AVAILABLE;
 4024: 
78090:   rv = mDBFile->Clone(getter_AddRefs(mPSFile));
78090:   NS_ENSURE_SUCCESS(rv, rv);
78090: 
 4024:   rv = mDBFile->Append(NS_LITERAL_STRING(DATABASE_FILENAME));
 4024:   NS_ENSURE_SUCCESS(rv, rv);
 4024: 
78090:   rv = mPSFile->Append(NS_LITERAL_STRING(PREFIXSET_FILENAME));
78090:   NS_ENSURE_SUCCESS(rv, rv);
78090: 
 4024:   ResetUpdate();
 4024: 
14354:   mTableFreshness.Init();
14354: 
 4024:   return NS_OK;
 4024: }
 4024: 
 4024: nsresult
 4024: nsUrlClassifierDBServiceWorker::QueueLookup(const nsACString& spec,
10941:                                             nsIUrlClassifierLookupCallback* callback)
 4024: {
64576:   MutexAutoLock lock(mPendingLookupLock);
 4024: 
 4024:   PendingLookup* lookup = mPendingLookups.AppendElement();
 4024:   if (!lookup) return NS_ERROR_OUT_OF_MEMORY;
 4024: 
 4024:   lookup->mKey = spec;
 4024:   lookup->mCallback = callback;
 4024: 
 4024:   return NS_OK;
 4024: }
 4024: 
 4024: nsresult
78091: nsUrlClassifierDBService::CheckClean(const nsACString &spec,
79445:                                      bool *clean)
20648: {
78093:   Telemetry::AutoTimer<Telemetry::URLCLASSIFIER_PS_LOOKUP_TIME> timer;
78093: 
78091:   // Get the set of fragments to look up.
78091:   nsTArray<nsCString> fragments;
78091:   nsresult rv = GetLookupFragments(spec, fragments);
20648:   NS_ENSURE_SUCCESS(rv, rv);
20648: 
78092:   PRUint32 prefixkey;
78092:   rv = mPrefixSet->GetKey(&prefixkey);
78092:   NS_ENSURE_SUCCESS(rv, rv);
78092: 
80486:   *clean = true;
20648: 
78091:   for (PRUint32 i = 0; i < fragments.Length(); i++) {
78091:     nsUrlClassifierDomainHash fragmentKeyHash;
78091:     fragmentKeyHash.FromPlaintext(fragments[i], mHash);
78091: 
78092:     // Find the corresponding host key
78092:     nsUrlClassifierDomainHash hostkey;
78092:     rv = GetKey(fragments[i], hostkey, mHash);
78092:     if (NS_FAILED(rv)) {
78092:       /* This happens for hosts on the local network,
78092:          can't check these against the DB */
78092:       continue;
78092:     }
78092: 
78092:     PRUint32 hostprefix = hostkey.ToUint32();
78091:     PRUint32 fragkey = fragmentKeyHash.ToUint32();
78092:     PRUint32 codedkey;
78092:     rv = KeyedHash(fragkey, hostprefix, prefixkey, &codedkey);
78092:     NS_ENSURE_SUCCESS(rv, rv);
78087: 
80664:     bool found = false;
79445:     bool ready = false;  /* opportunistic probe */
78092:     rv = mPrefixSet->Probe(codedkey, prefixkey, &ready, &found);
78087:     NS_ENSURE_SUCCESS(rv, rv);
78091:     LOG(("CheckClean Probed %X ready: %d found: %d ",
78092:          codedkey, ready, found));
78087:     if (found || !ready) {
80486:       *clean = false;
78087:     }
78087:   }
78087: 
20648:   return NS_OK;
20648: }
20648: 
78091: static nsresult GetHostKeys(const nsACString &spec,
78091:                             nsTArray<nsCString> &hostKeys)
78091: {
78091:   nsACString::const_iterator begin, end, iter;
78091:   spec.BeginReading(begin);
78091:   spec.EndReading(end);
78091: 
78091:   iter = begin;
78091:   if (!FindCharInReadable('/', iter, end)) {
78091:     return NS_OK;
78091:   }
78091: 
78091:   const nsCSubstring& host = Substring(begin, iter);
78091: 
78091:   if (IsCanonicalizedIP(host)) {
78091:     nsCString *key = hostKeys.AppendElement();
78091:     if (!key)
78091:       return NS_ERROR_OUT_OF_MEMORY;
78091: 
78091:     key->Assign(host);
78091:     key->Append("/");
78091:     return NS_OK;
78091:   }
78091: 
78091:   nsTArray<nsCString> hostComponents;
78091:   ParseString(PromiseFlatCString(host), '.', hostComponents);
78091: 
78091:   if (hostComponents.Length() < 2) {
78091:     // no host or toplevel host, this won't match anything in the db
78091:     return NS_OK;
78091:   }
78091: 
78091:   // First check with two domain components
78091:   PRInt32 last = PRInt32(hostComponents.Length()) - 1;
78091:   nsCString *lookupHost = hostKeys.AppendElement();
78091:   if (!lookupHost)
78091:     return NS_ERROR_OUT_OF_MEMORY;
78091: 
78091:   lookupHost->Assign(hostComponents[last - 1]);
78091:   lookupHost->Append(".");
78091:   lookupHost->Append(hostComponents[last]);
78091:   lookupHost->Append("/");
78091: 
78091:   // Now check with three domain components
78091:   if (hostComponents.Length() > 2) {
78091:     nsCString *lookupHost2 = hostKeys.AppendElement();
78091:     if (!lookupHost2)
78091:       return NS_ERROR_OUT_OF_MEMORY;
78091:     lookupHost2->Assign(hostComponents[last - 2]);
78091:     lookupHost2->Append(".");
78091:     lookupHost2->Append(*lookupHost);
78091:   }
78091: 
78091:  return NS_OK;
78091: }
78091: 
20648: nsresult
78091: GetLookupFragments(const nsACString& spec,
20648:                    nsTArray<nsCString>& fragments)
 4024: {
 4024:   fragments.Clear();
 4024: 
 4024:   nsACString::const_iterator begin, end, iter;
 4024:   spec.BeginReading(begin);
 4024:   spec.EndReading(end);
 4024: 
 4024:   iter = begin;
 4024:   if (!FindCharInReadable('/', iter, end)) {
 4024:     return NS_OK;
 4024:   }
 4024: 
 4024:   const nsCSubstring& host = Substring(begin, iter++);
 6503:   nsCAutoString path;
 6503:   path.Assign(Substring(iter, end));
 4024: 
 4024:   /**
 4024:    * From the protocol doc:
 4024:    * For the hostname, the client will try at most 5 different strings.  They
 4024:    * are:
 4024:    * a) The exact hostname of the url
 4024:    * b) The 4 hostnames formed by starting with the last 5 components and
 4024:    *    successivly removing the leading component.  The top-level component
72778:    *    can be skipped. This is not done if the hostname is a numerical IP.
 4024:    */
24031:   nsTArray<nsCString> hosts;
24031:   hosts.AppendElement(host);
 4024: 
72778:   if (!IsCanonicalizedIP(host)) {
 4024:     host.BeginReading(begin);
 4024:     host.EndReading(end);
72777:     int numHostComponents = 0;
 4024:     while (RFindInReadable(NS_LITERAL_CSTRING("."), begin, end) &&
72777:            numHostComponents < MAX_HOST_COMPONENTS) {
 4024:       // don't bother checking toplevel domains
72777:       if (++numHostComponents >= 2) {
 4024:         host.EndReading(iter);
24031:         hosts.AppendElement(Substring(end, iter));
 4024:       }
 4024:       end = begin;
 4024:       host.BeginReading(begin);
 4024:     }
72778:   }
 4024: 
 4024:   /**
 4024:    * From the protocol doc:
 6503:    * For the path, the client will also try at most 6 different strings.
 4024:    * They are:
 6503:    * a) the exact path of the url, including query parameters
 6503:    * b) the exact path of the url, without query parameters
 6503:    * c) the 4 paths formed by starting at the root (/) and
 4024:    *    successively appending path components, including a trailing
 4024:    *    slash.  This behavior should only extend up to the next-to-last
 4024:    *    path component, that is, a trailing slash should never be
 4024:    *    appended that was not present in the original url.
 4024:    */
24031:   nsTArray<nsCString> paths;
72777:   nsCAutoString pathToAdd;
72777: 
 4024:   path.BeginReading(begin);
 4024:   path.EndReading(end);
 4024:   iter = begin;
72777:   if (FindCharInReadable('?', iter, end)) {
72777:     pathToAdd = Substring(begin, iter);
72777:     paths.AppendElement(pathToAdd);
72777:     end = iter;
72777:   }
72777: 
72777:   int numPathComponents = 1;
72777:   iter = begin;
 4024:   while (FindCharInReadable('/', iter, end) &&
72777:          numPathComponents < MAX_PATH_COMPONENTS) {
 4024:     iter++;
72777:     pathToAdd.Assign(Substring(begin, iter));
72777:     paths.AppendElement(pathToAdd);
72777:     numPathComponents++;
72777:   }
72777: 
72777:   // If we haven't already done so, add the full path
72777:   if (!pathToAdd.Equals(path)) {
72777:     paths.AppendElement(path);
72777:   }
72777:   // Check an empty path (for whole-domain blacklist entries)
72777:   paths.AppendElement(EmptyCString());
 4024: 
24031:   for (PRUint32 hostIndex = 0; hostIndex < hosts.Length(); hostIndex++) {
24031:     for (PRUint32 pathIndex = 0; pathIndex < paths.Length(); pathIndex++) {
20648:       nsCString key;
24031:       key.Assign(hosts[hostIndex]);
 4024:       key.Append('/');
24031:       key.Append(paths[pathIndex]);
 4024:       LOG(("Chking %s", key.get()));
 4024: 
20648:       fragments.AppendElement(key);
 4024:     }
 4024:   }
 4024: 
 4024:   return NS_OK;
 4024: }
 4024: 
 4024: nsresult
78086: nsUrlClassifierDBServiceWorker::Check(const nsACString& spec,
78086:                                       nsTArray<nsUrlClassifierLookupResult>& results)
24807: {
78091:   PRInt64 now = (PR_Now() / PR_USEC_PER_SEC);
78091: 
78091:   // Get list of host keys to look up
78091:   nsAutoTArray<nsCString, 2> lookupHosts;
78091:   nsresult rv = GetHostKeys(spec, lookupHosts);
78091: 
78091:   nsTArray<nsUrlClassifierEntry> mCachedEntries;
78091: 
78091:   // Gather host's prefixes
78091:   for (PRUint32 i = 0; i < lookupHosts.Length(); i++) {
78091:     // Find the corresponding host key
78091:     nsUrlClassifierDomainHash hostKey;
78092:     nsresult rv = GetKey(lookupHosts[i], hostKey, mCryptoHash);
78091:     NS_ENSURE_SUCCESS(rv, rv);
78091:     // Read the entries for this fragments host from SQLite
78091:     mMainStore.ReadAddEntries(hostKey, mCachedEntries);
78091:   }
78091: 
20648:   // Now get the set of fragments to look up.
20648:   nsTArray<nsCString> fragments;
78091:   rv = GetLookupFragments(spec, fragments);
 4024:   NS_ENSURE_SUCCESS(rv, rv);
 4024: 
20648:   // Now check each lookup fragment against the entries in the DB.
 4024:   for (PRUint32 i = 0; i < fragments.Length(); i++) {
20648:     nsUrlClassifierCompleteHash lookupHash;
20648:     lookupHash.FromPlaintext(fragments[i], mCryptoHash);
20648: 
20648:     for (PRUint32 j = 0; j < mCachedEntries.Length(); j++) {
20648:       nsUrlClassifierEntry &entry = mCachedEntries[j];
20648:       if (entry.Match(lookupHash)) {
10941:         // If the entry doesn't contain a complete hash, we need to
10941:         // save it here so that it can be compared against the
10941:         // complete hash.  However, we don't set entry.mHaveComplete
10941:         // because it isn't a verified part of the entry yet.
10941:         nsUrlClassifierLookupResult *result = results.AppendElement();
10941:         if (!result)
10941:           return NS_ERROR_OUT_OF_MEMORY;
10941: 
20648:         result->mLookupFragment = lookupHash;
10941:         result->mEntry = entry;
10941: 
10941:         // Fill in the table name.
10941:         GetTableName(entry.mTableId, result->mTableName);
14354: 
79445:         bool fresh;
14354:         PRInt64 tableUpdateTime;
14354:         if (mTableFreshness.Get(result->mTableName, &tableUpdateTime)) {
14354:           LOG(("tableUpdateTime: %lld, now: %lld, freshnessGuarantee: %d\n",
14354:                tableUpdateTime, now, gFreshnessGuarantee));
14354:           fresh = ((now - tableUpdateTime) <= gFreshnessGuarantee);
14354:         } else {
14354:           LOG(("No expiration time for this table.\n"));
80486:           fresh = false;
14354:         }
14354: 
14354:         // This is a confirmed result if we match a complete fragment in
14354:         // an up-to-date table.
14354:         result->mConfirmed = entry.mHaveComplete && fresh;
14354: 
14354:         LOG(("Found a result.  complete=%d, fresh=%d",
14354:              entry.mHaveComplete, fresh));
20648:       }
20648:     }
20648:   }
 4024: 
 4024:   return NS_OK;
 4024: }
 4024: 
 4024: /**
 4024:  * Lookup up a key in the database is a two step process:
 4024:  *
 4024:  * a) First we look for any Entries in the database that might apply to this
 4024:  *    url.  For each URL there are one or two possible domain names to check:
 4024:  *    the two-part domain name (example.com) and the three-part name
 4024:  *    (www.example.com).  We check the database for both of these.
 4024:  * b) If we find any entries, we check the list of fragments for that entry
 4024:  *    against the possible subfragments of the URL as described in the
 4024:  *    "Simplified Regular Expression Lookup" section of the protocol doc.
 4024:  */
 4024: nsresult
 4024: nsUrlClassifierDBServiceWorker::DoLookup(const nsACString& spec,
10941:                                          nsIUrlClassifierLookupCallback* c)
 4024: {
 4024:   if (gShuttingDownThread) {
10941:     c->LookupComplete(nsnull);
 4024:     return NS_ERROR_NOT_INITIALIZED;
 4024:   }
 4024: 
 4024:   nsresult rv = OpenDb();
 4024:   if (NS_FAILED(rv)) {
10941:     c->LookupComplete(nsnull);
 4024:     return NS_ERROR_FAILURE;
 4024:   }
 4024: 
 4024: #if defined(PR_LOGGING)
 4024:   PRIntervalTime clockStart = 0;
 4024:   if (LOG_ENABLED()) {
 4024:     clockStart = PR_IntervalNow();
 4024:   }
 4024: #endif
 4024: 
10941:   nsAutoPtr<nsTArray<nsUrlClassifierLookupResult> > results;
10941:   results = new nsTArray<nsUrlClassifierLookupResult>();
10941:   if (!results) {
10941:     c->LookupComplete(nsnull);
10941:     return NS_ERROR_OUT_OF_MEMORY;
10941:   }
10941: 
24807:   // we ignore failures from Check because we'd rather return the
24807:   // results that were found than fail.
24807:   Check(spec, *results);
 4024: 
 4024: #if defined(PR_LOGGING)
 4024:   if (LOG_ENABLED()) {
 4024:     PRIntervalTime clockEnd = PR_IntervalNow();
 4024:     LOG(("query took %dms\n",
 4024:          PR_IntervalToMilliseconds(clockEnd - clockStart)));
 4024:   }
 4024: #endif
 4024: 
12334:   for (PRUint32 i = 0; i < results->Length(); i++) {
12334:     if (!results->ElementAt(i).mConfirmed) {
12334:       // We're going to be doing a gethash request, add some extra entries.
12334:       AddNoise(results->ElementAt(i).mEntry.mId, mGethashNoise, *results);
12334:       break;
12334:     }
12334:   }
12334: 
10941:   // At this point ownership of 'results' is handed to the callback.
10941:   c->LookupComplete(results.forget());
 4024: 
 4024:   return NS_OK;
 4024: }
 4024: 
 4024: nsresult
 4024: nsUrlClassifierDBServiceWorker::HandlePendingLookups()
 4024: {
64576:   MutexAutoLock lock(mPendingLookupLock);
 4024:   while (mPendingLookups.Length() > 0) {
 4024:     PendingLookup lookup = mPendingLookups[0];
 4024:     mPendingLookups.RemoveElementAt(0);
64576:     {
64576:       MutexAutoUnlock unlock(mPendingLookupLock);
 4024:       DoLookup(lookup.mKey, lookup.mCallback);
64576:     }
 4024:   }
 4024: 
 4024:   return NS_OK;
 4024: }
    1: 
12334: nsresult
12334: nsUrlClassifierDBServiceWorker::AddNoise(PRInt64 nearID,
12334:                                          PRInt32 count,
12334:                                          nsTArray<nsUrlClassifierLookupResult>& results)
12334: {
12334:   if (count < 1) {
12334:     return NS_OK;
12334:   }
12334: 
83146:   PRInt64 randomNum;
83146:   nsresult rv = mMainStore.RandomNumber(&randomNum);
12334:   NS_ENSURE_SUCCESS(rv, rv);
12334: 
12334:   PRInt32 numBefore = randomNum % count;
12334: 
12334:   nsTArray<nsUrlClassifierEntry> noiseEntries;
80486:   rv = mMainStore.ReadNoiseEntries(nearID, numBefore, true, noiseEntries);
12334:   NS_ENSURE_SUCCESS(rv, rv);
12334: 
80486:   rv = mMainStore.ReadNoiseEntries(nearID, count - numBefore, false, noiseEntries);
12334:   NS_ENSURE_SUCCESS(rv, rv);
12334: 
12334:   for (PRUint32 i = 0; i < noiseEntries.Length(); i++) {
12334:     nsUrlClassifierLookupResult *result = results.AppendElement();
12334:     if (!result)
12334:       return NS_ERROR_OUT_OF_MEMORY;
12334: 
12334:     result->mEntry = noiseEntries[i];
80486:     result->mConfirmed = false;
80486:     result->mNoise = true;
12334: 
12334:     // Fill in the table name.
12334:     GetTableName(noiseEntries[i].mTableId, result->mTableName);
12334:   }
12334: 
12334:   return NS_OK;
12334: }
12334: 
12334: 
    1: // Lookup a key in the db.
    1: NS_IMETHODIMP
 4024: nsUrlClassifierDBServiceWorker::Lookup(const nsACString& spec,
10941:                                        nsIUrlClassifierCallback* c)
 4024: {
 4024:   return HandlePendingLookups();
 4024: }
 4024: 
 4024: NS_IMETHODIMP
 4024: nsUrlClassifierDBServiceWorker::GetTables(nsIUrlClassifierCallback* c)
    1: {
  762:   if (gShuttingDownThread)
  762:     return NS_ERROR_NOT_INITIALIZED;
  762: 
    1:   nsresult rv = OpenDb();
    1:   if (NS_FAILED(rv)) {
73472:     NS_ERROR("Unable to open database");
    1:     return NS_ERROR_FAILURE;
    1:   }
    1: 
 4024:   mozStorageStatementScoper scoper(mGetTablesStatement);
 4024: 
 4024:   nsCAutoString response;
79445:   bool hasMore;
 4024:   while (NS_SUCCEEDED(rv = mGetTablesStatement->ExecuteStep(&hasMore)) &&
 4024:          hasMore) {
 4024:     nsCAutoString val;
 4024:     mGetTablesStatement->GetUTF8String(0, val);
 4024: 
 4024:     if (val.IsEmpty()) {
 4024:       continue;
 4024:     }
 4024: 
 4024:     response.Append(val);
 4024:     response.Append(';');
 4024: 
 4024:     mGetTablesStatement->GetUTF8String(1, val);
 4024: 
79445:     bool haveAdds = false;
 4024:     if (!val.IsEmpty()) {
 4024:       response.Append("a:");
 4024:       response.Append(val);
80486:       haveAdds = true;
 4024:     }
 4024: 
 4024:     mGetTablesStatement->GetUTF8String(2, val);
 4024:     if (!val.IsEmpty()) {
 6852:       if (haveAdds)
 6852:         response.Append(":");
 6852: 
 4024:       response.Append("s:");
 4024:       response.Append(val);
 4024:     }
 4024: 
 4024:     response.Append('\n');
 4024:   }
 4024: 
 4024:   if (NS_FAILED(rv)) {
 4024:     response.Truncate();
 4024:   }
 4024: 
 4024:   c->HandleEvent(response);
 4024: 
 4024:   return rv;
 4024: }
 4024: 
 4024: nsresult
 4024: nsUrlClassifierDBServiceWorker::GetTableId(const nsACString& table,
 4024:                                            PRUint32* tableId)
 4024: {
 4024:   mozStorageStatementScoper findScoper(mGetTableIdStatement);
 4024: 
64474:   nsresult rv = mGetTableIdStatement->BindUTF8StringByIndex(0, table);
 4001:   NS_ENSURE_SUCCESS(rv, rv);
 4001: 
79445:   bool exists;
 4024:   rv = mGetTableIdStatement->ExecuteStep(&exists);
 4024:   NS_ENSURE_SUCCESS(rv, rv);
 4024:   if (exists) {
 4024:     *tableId = mGetTableIdStatement->AsInt32(0);
    1:     return NS_OK;
    1:   }
    1: 
 4024:   mozStorageStatementScoper insertScoper(mInsertTableIdStatement);
64474:   rv = mInsertTableIdStatement->BindUTF8StringByIndex(0, table);
 4024:   NS_ENSURE_SUCCESS(rv, rv);
 4024: 
 4024:   rv = mInsertTableIdStatement->Execute();
 4024:   NS_ENSURE_SUCCESS(rv, rv);
 4024: 
 4024:   PRInt64 rowId;
 4024:   rv = mConnection->GetLastInsertRowID(&rowId);
 4024:   NS_ENSURE_SUCCESS(rv, rv);
 4024: 
 4024:   if (rowId > PR_UINT32_MAX)
 4024:     return NS_ERROR_FAILURE;
 4024: 
 4024:   *tableId = rowId;
 4024: 
 4024:   return NS_OK;
 4024: }
 4024: 
 4024: nsresult
 4024: nsUrlClassifierDBServiceWorker::GetTableName(PRUint32 tableId,
 4024:                                              nsACString& tableName)
 4024: {
 4024:   mozStorageStatementScoper findScoper(mGetTableNameStatement);
64474:   nsresult rv = mGetTableNameStatement->BindInt32ByIndex(0, tableId);
 4024:   NS_ENSURE_SUCCESS(rv, rv);
79445:   bool exists;
 4024:   rv = mGetTableNameStatement->ExecuteStep(&exists);
 4024:   NS_ENSURE_SUCCESS(rv, rv);
 4024:   if (!exists) return NS_ERROR_FAILURE;
 4024: 
 4024:   return mGetTableNameStatement->GetUTF8String(0, tableName);
 4024: }
 4024: 
 4024: nsresult
 4024: nsUrlClassifierDBServiceWorker::InflateChunk(nsACString& chunk)
 4024: {
 4024:   nsCAutoString inflated;
 4024:   char buf[4096];
 4024: 
 4024:   const nsPromiseFlatCString& flat = PromiseFlatCString(chunk);
 4024: 
 4024:   z_stream stream;
 4024:   memset(&stream, 0, sizeof(stream));
 4024:   stream.next_in = (Bytef*)flat.get();
 4024:   stream.avail_in = flat.Length();
 4024: 
 4024:   if (inflateInit(&stream) != Z_OK) {
 4024:     return NS_ERROR_FAILURE;
 4024:   }
 4024: 
 4024:   int code;
 4024:   do {
 4024:     stream.next_out = (Bytef*)buf;
 4024:     stream.avail_out = sizeof(buf);
 4024: 
 4024:     code = inflate(&stream, Z_NO_FLUSH);
 4024:     PRUint32 numRead = sizeof(buf) - stream.avail_out;
 4024: 
 4024:     if (code == Z_OK || code == Z_STREAM_END) {
 4024:       inflated.Append(buf, numRead);
 4024:     }
 4024:   } while (code == Z_OK);
 4024: 
 4024:   inflateEnd(&stream);
 4024: 
 4024:   if (code != Z_STREAM_END) {
 4024:     return NS_ERROR_FAILURE;
 4024:   }
 4024: 
 4024:   chunk = inflated;
 4024: 
 4024:   return NS_OK;
 4024: }
 4024: 
 4024: nsresult
10212: nsUrlClassifierStore::DeleteEntry(nsUrlClassifierEntry& entry)
 4024: {
12334:   if (entry.mId == -1) {
 4024:     return NS_OK;
 4024:   }
 4024: 
 4024:   mozStorageStatementScoper scoper(mDeleteStatement);
64474:   mDeleteStatement->BindInt64ByIndex(0, entry.mId);
 4024:   nsresult rv = mDeleteStatement->Execute();
 4024:   NS_ENSURE_SUCCESS(rv, rv);
 4024: 
12334:   entry.mId = -1;
 4024: 
 4024:   return NS_OK;
 4024: }
 4024: 
 4024: nsresult
10212: nsUrlClassifierStore::WriteEntry(nsUrlClassifierEntry& entry)
 4024: {
23818:   if (entry.mId != -1) {
23818:     // existing entry, just ignore it
23818:     return NS_OK;
23818:   }
23818: 
10988:   mozStorageStatementScoper scoper(mInsertStatement);
 4024: 
23818:   nsresult rv = BindStatement(entry, mInsertStatement);
 4024:   NS_ENSURE_SUCCESS(rv, rv);
 4024: 
10988:   rv = mInsertStatement->Execute();
 4024:   NS_ENSURE_SUCCESS(rv, rv);
 4024: 
 4024:   PRInt64 rowId;
 4024:   rv = mConnection->GetLastInsertRowID(&rowId);
 4024:   NS_ENSURE_SUCCESS(rv, rv);
 4024: 
 4024:   if (rowId > PR_UINT32_MAX) {
 4024:     return NS_ERROR_FAILURE;
 4024:   }
 4024: 
 4024:   entry.mId = rowId;
 4024: 
 4024:   return NS_OK;
 4024: }
 4024: 
10988: nsresult
10988: nsUrlClassifierStore::UpdateEntry(nsUrlClassifierEntry& entry)
10988: {
10988:   mozStorageStatementScoper scoper(mUpdateStatement);
10988: 
12334:   NS_ENSURE_ARG(entry.mId != -1);
10988: 
10988:   nsresult rv = BindStatement(entry, mUpdateStatement);
10988:   NS_ENSURE_SUCCESS(rv, rv);
10988: 
10988:   rv = mUpdateStatement->Execute();
10988:   NS_ENSURE_SUCCESS(rv, rv);
10988: 
10988:   return NS_OK;
10988: }
10988: 
79445: static bool
78087: IsCanonicalizedIP(const nsACString& host)
 6507: {
 6507:   // The canonicalization process will have left IP addresses in dotted
 6507:   // decimal with no surprises.
 6507:   PRUint32 i1, i2, i3, i4;
 6507:   char c;
 6507:   if (PR_sscanf(PromiseFlatCString(host).get(), "%u.%u.%u.%u%c",
 6507:                 &i1, &i2, &i3, &i4, &c) == 4) {
17096:     return (i1 <= 0xFF && i2 <= 0xFF && i3 <= 0xFF && i4 <= 0xFF);
 6507:   }
 6507: 
80486:   return false;
 6507: }
 6507: 
78092: static nsresult
78092: GetKey(const nsACString& spec,
78092:        nsUrlClassifierDomainHash& hash,
78092:        nsICryptoHash * aCryptoHash)
 4024: {
 4024:   nsACString::const_iterator begin, end, iter;
 4024:   spec.BeginReading(begin);
 4024:   spec.EndReading(end);
 4024: 
 4024:   iter = begin;
 4024:   if (!FindCharInReadable('/', iter, end)) {
 4024:     return NS_OK;
 4024:   }
 4024: 
 6507:   const nsCSubstring& host = Substring(begin, iter);
 6507: 
 6507:   if (IsCanonicalizedIP(host)) {
10941:     nsCAutoString key;
10941:     key.Assign(host);
10941:     key.Append("/");
78092:     return hash.FromPlaintext(key, aCryptoHash);
 6507:   }
 6507: 
24031:   nsTArray<nsCString> hostComponents;
24031:   ParseString(PromiseFlatCString(host), '.', hostComponents);
24031: 
24031:   if (hostComponents.Length() < 2)
 4024:     return NS_ERROR_FAILURE;
 4024: 
24031:   PRInt32 last = PRInt32(hostComponents.Length()) - 1;
 4024:   nsCAutoString lookupHost;
 4024: 
24031:   if (hostComponents.Length() > 2) {
24031:     lookupHost.Append(hostComponents[last - 2]);
 4024:     lookupHost.Append(".");
 4024:   }
 4024: 
24031:   lookupHost.Append(hostComponents[last - 1]);
 4024:   lookupHost.Append(".");
24031:   lookupHost.Append(hostComponents[last]);
 4024:   lookupHost.Append("/");
 4024: 
78092:   return hash.FromPlaintext(lookupHost, aCryptoHash);
 4024: }
 4024: 
20648: nsresult
10941: nsUrlClassifierDBServiceWorker::GetShaEntries(PRUint32 tableId,
10941:                                               PRUint32 chunkType,
10941:                                               PRUint32 chunkNum,
10941:                                               PRUint32 domainSize,
10941:                                               PRUint32 fragmentSize,
10941:                                               nsACString& chunk,
10941:                                               nsTArray<nsUrlClassifierEntry>& entries)
10941: {
10941:   PRUint32 start = 0;
10941:   while (start + domainSize + 1 <= chunk.Length()) {
10941:     nsUrlClassifierDomainHash domain;
10941:     domain.Assign(Substring(chunk, start, DOMAIN_LENGTH));
10941:     start += domainSize;
10941: 
10941:     // then there is a one-byte count of fragments
10941:     PRUint8 numEntries = static_cast<PRUint8>(chunk[start]);
10941:     start++;
10941: 
10941:     if (numEntries == 0) {
10941:       // if there are no fragments, the domain itself is treated as a
10941:       // fragment.  This will only work if domainHashSize == hashSize
10941:       if (domainSize != fragmentSize) {
10941:         NS_WARNING("Received 0-fragment entry where domainSize != fragmentSize");
10941:         return NS_ERROR_FAILURE;
10941:       }
10941: 
10941:       nsUrlClassifierEntry* entry = entries.AppendElement();
10941:       if (!entry) return NS_ERROR_OUT_OF_MEMORY;
10941: 
10941:       entry->mKey = domain;
10941:       entry->mTableId = tableId;
10941:       entry->mChunkId = chunkNum;
10941:       entry->SetHash(domain);
10941: 
10941:       if (chunkType == CHUNK_SUB) {
10941:         if (start + 4 > chunk.Length()) {
10941:           // there isn't as much data as there should be.
10941:           NS_WARNING("Received a zero-entry sub chunk without an associated add.");
10941:           return NS_ERROR_FAILURE;
10941:         }
10941:         const nsCSubstring& str = Substring(chunk, start, 4);
24899:         PRUint32 p;
24899:         memcpy(&p, str.BeginReading(), 4);
24899:         entry->mAddChunkId = PR_ntohl(p);
10941:         if (entry->mAddChunkId == 0) {
10941:           NS_WARNING("Received invalid chunk number.");
10941:           return NS_ERROR_FAILURE;
10941:         }
10941:         start += 4;
10941:       }
10941:     } else {
10941:       PRUint32 entrySize = fragmentSize;
10941:       if (chunkType == CHUNK_SUB) {
10941:         entrySize += 4;
10941:       }
10941:       if (start + (numEntries * entrySize) > chunk.Length()) {
10941:         // there isn't as much data as they said there would be.
10941:         NS_WARNING("Received a chunk without enough data");
10941:         return NS_ERROR_FAILURE;
10941:       }
10941: 
10941:       for (PRUint8 i = 0; i < numEntries; i++) {
10941:         nsUrlClassifierEntry* entry = entries.AppendElement();
10941:         if (!entry) return NS_ERROR_OUT_OF_MEMORY;
10941: 
10941:         entry->mKey = domain;
10941:         entry->mTableId = tableId;
10941:         entry->mChunkId = chunkNum;
10941: 
10941:         if (chunkType == CHUNK_SUB) {
10941:           const nsCSubstring& str = Substring(chunk, start, 4);
24899:           PRUint32 p;
24899:           memcpy(&p, str.BeginReading(), 4);
24899:           entry->mAddChunkId = PR_ntohl(p);
10941:           if (entry->mAddChunkId == 0) {
10941:             NS_WARNING("Received invalid chunk number.");
10941:             return NS_ERROR_FAILURE;
10941:           }
10941:           start += 4;
10941:         }
10941: 
10941:         if (fragmentSize == PARTIAL_LENGTH) {
10941:           nsUrlClassifierPartialHash hash;
10941:           hash.Assign(Substring(chunk, start, PARTIAL_LENGTH));
10941:           entry->SetHash(hash);
10941:         } else if (fragmentSize == COMPLETE_LENGTH) {
10941:           nsUrlClassifierCompleteHash hash;
10941:           hash.Assign(Substring(chunk, start, COMPLETE_LENGTH));
10941:           entry->SetHash(hash);
10941:         } else {
80486:           NS_ASSERTION(false, "Invalid fragment size!");
10941:           return NS_ERROR_FAILURE;
10941:         }
10941: 
10941:         start += fragmentSize;
10941:       }
10941:     }
10941:   }
10941: 
10941:   return NS_OK;
10941: }
10941: 
10941: nsresult
 4024: nsUrlClassifierDBServiceWorker::GetChunkEntries(const nsACString& table,
 4024:                                                 PRUint32 tableId,
10941:                                                 PRUint32 chunkType,
 4024:                                                 PRUint32 chunkNum,
10941:                                                 PRUint32 hashSize,
 4024:                                                 nsACString& chunk,
 4024:                                                 nsTArray<nsUrlClassifierEntry>& entries)
 4024: {
 4024:   nsresult rv;
 4024:   if (StringEndsWith(table, NS_LITERAL_CSTRING("-exp"))) {
 4024:     // regexp tables need to be ungzipped
 4024:     rv = InflateChunk(chunk);
 4024:     NS_ENSURE_SUCCESS(rv, rv);
 4024:   }
 4024: 
10941:   if (StringEndsWith(table, NS_LITERAL_CSTRING("-shavar"))) {
10941:     rv = GetShaEntries(tableId, chunkType, chunkNum, DOMAIN_LENGTH, hashSize,
10941:                        chunk, entries);
10941:     NS_ENSURE_SUCCESS(rv, rv);
 4024:   } else {
24031:     nsTArray<nsCString> lines;
24031:     ParseString(PromiseFlatCString(chunk), '\n', lines);
 7994: 
 7994:     // non-hashed tables need to be hashed
24031:     for (PRInt32 i = 0; i < PRInt32(lines.Length()); i++) {
10941:       nsUrlClassifierEntry *entry = entries.AppendElement();
10941:       if (!entry)
10941:         return NS_ERROR_OUT_OF_MEMORY;
10941: 
10941:       nsCAutoString entryStr;
10941:       if (chunkType == CHUNK_SUB) {
10941:         nsCString::const_iterator begin, iter, end;
24031:         lines[i].BeginReading(begin);
24031:         lines[i].EndReading(end);
10941:         iter = begin;
10941:         if (!FindCharInReadable(':', iter, end) ||
24031:             PR_sscanf(lines[i].get(), "%d:", &entry->mAddChunkId) != 1) {
10941:           NS_WARNING("Received sub chunk without associated add chunk.");
10941:           return NS_ERROR_FAILURE;
10941:         }
10941:         iter++;
10941:         entryStr = Substring(iter, end);
10941:       } else {
24031:         entryStr = lines[i];
10941:       }
10941: 
78092:       rv = GetKey(entryStr, entry->mKey, mCryptoHash);
10865:       NS_ENSURE_SUCCESS(rv, rv);
10865: 
10941:       entry->mTableId = tableId;
10941:       entry->mChunkId = chunkNum;
10941:       if (hashSize == PARTIAL_LENGTH) {
10941:         nsUrlClassifierPartialHash hash;
10941:         hash.FromPlaintext(entryStr, mCryptoHash);
10941:         entry->SetHash(hash);
10941:       } else if (hashSize == COMPLETE_LENGTH) {
10941:         nsUrlClassifierCompleteHash hash;
10941:         hash.FromPlaintext(entryStr, mCryptoHash);
10941:         entry->SetHash(hash);
10941:       } else {
80486:         NS_ASSERTION(false, "Invalid fragment size!");
10941:         return NS_ERROR_FAILURE;
10854:       }
 7994:     }
 4024:   }
 4024: 
 4024:   return NS_OK;
 4024: }
 4024: 
79445: bool
11769: nsUrlClassifierDBServiceWorker::ParseChunkRange(nsACString::const_iterator &begin,
11769:                                                 const nsACString::const_iterator &end,
 8707:                                                 PRUint32 *first,
 8707:                                                 PRUint32 *last)
 8707: {
11769:   nsACString::const_iterator iter = begin;
11769:   FindCharInReadable(',', iter, end);
11769: 
11769:   nsCAutoString element(Substring(begin, iter));
11769:   begin = iter;
11769:   if (begin != end)
11769:     begin++;
11769: 
11769:   PRUint32 numRead = PR_sscanf(element.get(), "%u-%u", first, last);
 8707:   if (numRead == 2) {
 8707:     if (*first > *last) {
 8707:       PRUint32 tmp = *first;
 8707:       *first = *last;
 8707:       *last = tmp;
 8707:     }
80486:     return true;
 8707:   }
 8707: 
 8707:   if (numRead == 1) {
 8707:     *last = *first;
80486:     return true;
80486:   }
80486: 
80486:   return false;
 8707: }
 8707: 
 4024: nsresult
 4024: nsUrlClassifierDBServiceWorker::ParseChunkList(const nsACString& chunkStr,
 4024:                                                nsTArray<PRUint32>& chunks)
 4024: {
 4024:   LOG(("Parsing %s", PromiseFlatCString(chunkStr).get()));
 4024: 
11769:   nsACString::const_iterator begin, end;
11769:   chunkStr.BeginReading(begin);
11769:   chunkStr.EndReading(end);
11769:   while (begin != end) {
11769:     PRUint32 first, last;
11769:     if (ParseChunkRange(begin, end, &first, &last)) {
 4024:       for (PRUint32 num = first; num <= last; num++) {
 4024:         chunks.AppendElement(num);
 4024:       }
 4024:     }
 7994:   }
 4024: 
 4024:   LOG(("Got %d elements.", chunks.Length()));
 4024: 
 4024:   return NS_OK;
 4024: }
 4024: 
 4024: nsresult
 4024: nsUrlClassifierDBServiceWorker::JoinChunkList(nsTArray<PRUint32>& chunks,
 4024:                                               nsCString& chunkStr)
 4024: {
 4024:   chunkStr.Truncate();
 4024:   chunks.Sort();
 4024: 
 4024:   PRUint32 i = 0;
 4024:   while (i < chunks.Length()) {
 4024:     if (i != 0) {
 4024:       chunkStr.Append(',');
 4024:     }
 4024:     chunkStr.AppendInt(chunks[i]);
 4024: 
 4024:     PRUint32 first = i;
 4024:     PRUint32 last = first;
 4024:     i++;
14883:     while (i < chunks.Length() && (chunks[i] == chunks[i - 1] + 1 || chunks[i] == chunks[i - 1])) {
14883:       last = i++;
 4024:     }
 4024: 
 4024:     if (last != first) {
 4024:       chunkStr.Append('-');
14883:       chunkStr.AppendInt(chunks[last]);
 4024:     }
 4024:   }
 4024: 
 4024:   return NS_OK;
 4024: }
 4024: 
 4024: 
 4024: nsresult
 4024: nsUrlClassifierDBServiceWorker::GetChunkLists(PRUint32 tableId,
 4024:                                               nsACString& addChunks,
 4024:                                               nsACString& subChunks)
 4024: {
 4024:   addChunks.Truncate();
 4024:   subChunks.Truncate();
 4024: 
 4024:   mozStorageStatementScoper scoper(mGetChunkListsStatement);
 4024: 
64474:   nsresult rv = mGetChunkListsStatement->BindInt32ByIndex(0, tableId);
 4024:   NS_ENSURE_SUCCESS(rv, rv);
 4024: 
79445:   bool hasMore = false;
 4024:   rv = mGetChunkListsStatement->ExecuteStep(&hasMore);
 4024:   NS_ENSURE_SUCCESS(rv, rv);
 4024: 
 4024:   if (!hasMore) {
 4024:     LOG(("Getting chunks for %d, found nothing", tableId));
 4024:     return NS_OK;
 4024:   }
 4024: 
 4024:   rv = mGetChunkListsStatement->GetUTF8String(0, addChunks);
 4024:   NS_ENSURE_SUCCESS(rv, rv);
 4024: 
 4024:   rv = mGetChunkListsStatement->GetUTF8String(1, subChunks);
 4024:   NS_ENSURE_SUCCESS(rv, rv);
 4024: 
20649:   LOG(("Getting chunks for %d, got %s/%s",
 4024:        tableId,
 4024:        PromiseFlatCString(addChunks).get(),
 4024:        PromiseFlatCString(subChunks).get()));
 4024: 
 4024:   return NS_OK;
 4024: }
 4024: 
 4024: nsresult
 4024: nsUrlClassifierDBServiceWorker::SetChunkLists(PRUint32 tableId,
 4024:                                               const nsACString& addChunks,
 4024:                                               const nsACString& subChunks)
 4024: {
 4024:   mozStorageStatementScoper scoper(mSetChunkListsStatement);
 4024: 
64474:   mSetChunkListsStatement->BindUTF8StringByIndex(0, addChunks);
64474:   mSetChunkListsStatement->BindUTF8StringByIndex(1, subChunks);
64474:   mSetChunkListsStatement->BindInt32ByIndex(2, tableId);
 4024:   nsresult rv = mSetChunkListsStatement->Execute();
 4024:   NS_ENSURE_SUCCESS(rv, rv);
 4024: 
 4024:   return NS_OK;
 4024: }
 4024: 
 4024: nsresult
 8642: nsUrlClassifierDBServiceWorker::CacheChunkLists(PRUint32 tableId,
79445:                                                 bool parseAdds,
79445:                                                 bool parseSubs)
 8642: {
 8642:   nsresult rv;
 8642: 
 8642:   if (mHaveCachedLists && mCachedListsTable != tableId) {
 8642:     rv = FlushChunkLists();
 8642:     NS_ENSURE_SUCCESS(rv, rv);
 8642:   }
 8642: 
 8642:   if (!mHaveCachedLists) {
 8642:     rv = GetChunkLists(tableId, mCachedAddsStr, mCachedSubsStr);
 8642:     NS_ENSURE_SUCCESS(rv, rv);
 8642: 
80486:     mHaveCachedLists = true;
 8642:     mCachedListsTable = tableId;
 8642:   }
 8642: 
 8642:   if (parseAdds && !mHaveCachedAddChunks) {
 8642:     ParseChunkList(mCachedAddsStr, mCachedAddChunks);
80486:     mHaveCachedAddChunks = true;
 8642:   }
 8642: 
 8642:   if (parseSubs && !mHaveCachedSubChunks) {
 8642:     ParseChunkList(mCachedSubsStr, mCachedSubChunks);
80486:     mHaveCachedSubChunks = true;
 8642:   }
 8642: 
 8642:   return NS_OK;
 8642: }
 8642: 
 8642: nsresult
 8642: nsUrlClassifierDBServiceWorker::FlushChunkLists()
 8642: {
 8642:   if (!mHaveCachedLists) {
 8642:     return NS_OK;
 8642:   }
 8642: 
 8642:   if (mHaveCachedAddChunks) {
 8642:     JoinChunkList(mCachedAddChunks, mCachedAddsStr);
 8642:   }
 8642: 
 8642:   if (mHaveCachedSubChunks) {
 8642:     JoinChunkList(mCachedSubChunks, mCachedSubsStr);
 8642:   }
 8642: 
 8642:   nsresult rv = SetChunkLists(mCachedListsTable,
 8642:                               mCachedAddsStr, mCachedSubsStr);
10941: 
 8642:   // clear out the cache before checking/returning the error here.
10941:   ClearCachedChunkLists();
10941: 
10941:   return rv;
10941: }
10941: 
10941: void
10941: nsUrlClassifierDBServiceWorker::ClearCachedChunkLists()
10941: {
 8642:   mCachedAddsStr.Truncate();
 8642:   mCachedSubsStr.Truncate();
 8642:   mCachedListsTable = PR_UINT32_MAX;
80486:   mHaveCachedLists = false;
 8642: 
 8642:   mCachedAddChunks.Clear();
80486:   mHaveCachedAddChunks = false;
 8642: 
 8642:   mCachedSubChunks.Clear();
80486:   mHaveCachedSubChunks = false;
 8642: }
 8642: 
79445: bool
14994: nsUrlClassifierDBServiceWorker::InsertChunkId(nsTArray<PRUint32> &chunks,
14994:                                               PRUint32 chunkNum)
14994: {
14994:   PRUint32 low = 0, high = chunks.Length();
14994:   while (high > low) {
14994:     PRUint32 mid = (high + low) >> 1;
14994:     if (chunks[mid] == chunkNum)
80486:       return false;
14994:     if (chunks[mid] < chunkNum)
14994:       low = mid + 1;
14994:     else
14994:       high = mid;
14994:   }
14994: 
14994:   PRUint32 *item = chunks.InsertElementAt(low, chunkNum);
14994:   return (item != nsnull);
14994: }
14994: 
 8642: nsresult
 4024: nsUrlClassifierDBServiceWorker::AddChunk(PRUint32 tableId,
 4024:                                          PRUint32 chunkNum,
 4024:                                          nsTArray<nsUrlClassifierEntry>& entries)
 4024: {
 4024: #if defined(PR_LOGGING)
 4024:   PRIntervalTime clockStart = 0;
 4024:   if (LOG_ENABLED()) {
 4024:     clockStart = PR_IntervalNow();
 4024:   }
 4024: #endif
 4024: 
80486:   nsresult rv = CacheChunkLists(tableId, true, false);
 4024:   NS_ENSURE_SUCCESS(rv, rv);
14994: 
14994:   if (!InsertChunkId(mCachedAddChunks, chunkNum)) {
14994:     LOG(("Ignoring duplicate add chunk %d in table %d", chunkNum, tableId));
14994:     return NS_OK;
14994:   }
14994: 
14994:   LOG(("Adding %d entries to chunk %d in table %d", entries.Length(), chunkNum, tableId));
 4024: 
 4024:   nsTArray<PRUint32> entryIDs;
 4024: 
10941:   nsAutoTArray<nsUrlClassifierEntry, 5> subEntries;
20649:   rv = mPendingSubStore.ReadSubEntries(tableId, chunkNum, subEntries);
20649:   NS_ENSURE_SUCCESS(rv, rv);
10941: 
 4024:   for (PRUint32 i = 0; i < entries.Length(); i++) {
 4024:     nsUrlClassifierEntry& thisEntry = entries[i];
 4024: 
 4024:     HandlePendingLookups();
 4024: 
79445:     bool writeEntry = true;
10941:     for (PRUint32 j = 0; j < subEntries.Length(); j++) {
10941:       if (thisEntry.SubMatch(subEntries[j])) {
10941:         subEntries.RemoveElementAt(j);
10941: 
80486:         writeEntry = false;
10941:         break;
10854:       }
10865:     }
10865: 
10941:     HandlePendingLookups();
10941: 
10941:     if (writeEntry) {
10941:       rv = mMainStore.WriteEntry(thisEntry);
10212:       NS_ENSURE_SUCCESS(rv, rv);
10212:     }
10941:   }
 4024: 
20649:   rv = mPendingSubStore.ExpireAddChunk(tableId, chunkNum);
20649:   NS_ENSURE_SUCCESS(rv, rv);
20649: 
 4024: #if defined(PR_LOGGING)
 4024:   if (LOG_ENABLED()) {
 4024:     PRIntervalTime clockEnd = PR_IntervalNow();
10941:     LOG(("adding chunk %d took %dms\n", chunkNum,
10941:          PR_IntervalToMilliseconds(clockEnd - clockStart)));
 4024:   }
 4024: #endif
 4024: 
 4024:   return rv;
 4024: }
 4024: 
 4024: nsresult
10941: nsUrlClassifierStore::Expire(PRUint32 tableId, PRUint32 chunkNum)
 4024: {
 4024:   LOG(("Expiring chunk %d\n", chunkNum));
 4024: 
10941:   mozStorageStatementScoper expireScoper(mExpireStatement);
10941: 
64474:   nsresult rv = mExpireStatement->BindInt32ByIndex(0, tableId);
 4024:   NS_ENSURE_SUCCESS(rv, rv);
64474:   rv = mExpireStatement->BindInt32ByIndex(1, chunkNum);
 4024:   NS_ENSURE_SUCCESS(rv, rv);
 4024: 
10212:   mWorker->HandlePendingLookups();
 4024: 
10941:   rv = mExpireStatement->Execute();
 4024:   NS_ENSURE_SUCCESS(rv, rv);
 4024: 
 8639:   return NS_OK;
 4024: }
 4024: 
 4024: nsresult
10212: nsUrlClassifierDBServiceWorker::ExpireAdd(PRUint32 tableId,
10212:                                           PRUint32 chunkNum)
10212: {
80486:   nsresult rv = CacheChunkLists(tableId, true, false);
10212:   NS_ENSURE_SUCCESS(rv, rv);
10212:   mCachedAddChunks.RemoveElement(chunkNum);
10212: 
10212:   return mMainStore.Expire(tableId, chunkNum);
10212: }
10212: 
10212: nsresult
 4024: nsUrlClassifierDBServiceWorker::SubChunk(PRUint32 tableId,
 4024:                                          PRUint32 chunkNum,
 4024:                                          nsTArray<nsUrlClassifierEntry>& entries)
 4024: {
80486:   nsresult rv = CacheChunkLists(tableId, true, true);
14994: 
14994:   if (!InsertChunkId(mCachedSubChunks, chunkNum)) {
14994:     LOG(("Ignoring duplicate sub chunk %d in table %d", chunkNum, tableId));
14994:     return NS_OK;
14994:   }
14994: 
14994:   LOG(("Subbing %d entries in chunk %d in table %d", entries.Length(), chunkNum, tableId));
 4024: 
38022:   for (PRUint32 i = 0; i < entries.Length(); i++) {
10941:     nsAutoTArray<nsUrlClassifierEntry, 5> existingEntries;
 4024:     nsUrlClassifierEntry& thisEntry = entries[i];
 4024: 
 4024:     HandlePendingLookups();
 4024: 
20649:     // Check if we have the add chunk associated with the sub.
79445:     bool haveAdds = (mCachedAddChunks.BinaryIndexOf(thisEntry.mAddChunkId) !=
20649:                        mCachedAddChunks.NoIndex);
20649: 
20649:     if (haveAdds) {
20649:       rv = mMainStore.ReadAddEntries(thisEntry.mKey, thisEntry.mTableId,
10941:                                      thisEntry.mAddChunkId, existingEntries);
 4024:       NS_ENSURE_SUCCESS(rv, rv);
20649:     }
20649: 
10941:     for (PRUint32 j = 0; j < existingEntries.Length(); j++) {
10941:       if (existingEntries[j].SubMatch(thisEntry)) {
10941:         rv = mMainStore.DeleteEntry(existingEntries[j]);
10941:         NS_ENSURE_SUCCESS(rv, rv);
10941:         existingEntries.RemoveElementAt(j);
10941:         break;
10941:       }
10941:     }
10941: 
20649:     if (!haveAdds) {
10941:       // Save this entry in the pending subtraction store.
10941:       rv = mPendingSubStore.WriteEntry(thisEntry);
10212:       NS_ENSURE_SUCCESS(rv, rv);
10212:     }
 4024:   }
 4024: 
 8639:   return NS_OK;
 4024: }
 4024: 
 4024: nsresult
 4024: nsUrlClassifierDBServiceWorker::ExpireSub(PRUint32 tableId, PRUint32 chunkNum)
 4024: {
80486:   nsresult rv = CacheChunkLists(tableId, false, true);
 4024:   NS_ENSURE_SUCCESS(rv, rv);
 8642:   mCachedSubChunks.RemoveElement(chunkNum);
 4024: 
10212:   return mPendingSubStore.Expire(tableId, chunkNum);
 4024: }
 4024: 
 4024: nsresult
79445: nsUrlClassifierDBServiceWorker::ProcessChunk(bool* done)
 4024: {
10941:   // wait until the chunk has been read
10941:   if (mPendingStreamUpdate.Length() < static_cast<PRUint32>(mChunkLen)) {
80486:     *done = true;
 4024:     return NS_OK;
 4024:   }
 4024: 
 4024:   nsCAutoString chunk;
 4024:   chunk.Assign(Substring(mPendingStreamUpdate, 0, mChunkLen));
 4024:   mPendingStreamUpdate = Substring(mPendingStreamUpdate, mChunkLen);
 4024: 
 4024:   LOG(("Handling a chunk sized %d", chunk.Length()));
 4024: 
 4024:   nsTArray<nsUrlClassifierEntry> entries;
10941:   nsresult rv = GetChunkEntries(mUpdateTable, mUpdateTableId, mChunkType,
10941:                                 mChunkNum, mHashSize, chunk, entries);
 8645:   NS_ENSURE_SUCCESS(rv, rv);
 4024: 
 4024:   if (mChunkType == CHUNK_ADD) {
 4024:     rv = AddChunk(mUpdateTableId, mChunkNum, entries);
 4024:   } else {
 4024:     rv = SubChunk(mUpdateTableId, mChunkNum, entries);
 4024:   }
 4024: 
 4024:   mState = STATE_LINE;
80486:   *done = false;
 4024: 
 4024:   return rv;
 4024: }
 4024: 
 4024: nsresult
79445: nsUrlClassifierDBServiceWorker::ProcessResponseLines(bool* done)
 4024: {
 4024:   PRUint32 cur = 0;
 4024:   PRInt32 next;
 4024: 
 4024:   nsresult rv;
 4024:   // We will run to completion unless we find a chunk line
80486:   *done = true;
 4024: 
 4024:   nsACString& updateString = mPendingStreamUpdate;
 4024: 
 4024:   while(cur < updateString.Length() &&
 4024:         (next = updateString.FindChar('\n', cur)) != kNotFound) {
 4024:     const nsCSubstring& line = Substring(updateString, cur, next - cur);
 4024:     cur = next + 1;
 4024: 
 4024:     LOG(("Processing %s\n", PromiseFlatCString(line).get()));
 4024: 
12346:     if (mHMAC && mServerMAC.IsEmpty()) {
12346:       // If we did not receive a server MAC during BeginStream(), we
12346:       // require the first line of the update to be either a MAC or
12346:       // a request to rekey.
12346:       if (StringBeginsWith(line, NS_LITERAL_CSTRING("m:"))) {
12346:         mServerMAC = Substring(line, 2);
12346:         nsUrlClassifierUtils::UnUrlsafeBase64(mServerMAC);
12346: 
12346:         // The remainder of the pending update needs to be digested.
12346:         const nsCSubstring &toDigest = Substring(updateString, cur);
12346:         rv = mHMAC->Update(reinterpret_cast<const PRUint8*>(toDigest.BeginReading()),
12346:                            toDigest.Length());
12346:         NS_ENSURE_SUCCESS(rv, rv);
12346:       } else if (line.EqualsLiteral("e:pleaserekey")) {
12346:         mUpdateObserver->RekeyRequested();
12346:       } else {
12346:         LOG(("No MAC specified!"));
12346:         return NS_ERROR_FAILURE;
12346:       }
12346:     } else if (StringBeginsWith(line, NS_LITERAL_CSTRING("n:"))) {
 4024:       if (PR_sscanf(PromiseFlatCString(line).get(), "n:%d",
 4024:                     &mUpdateWait) != 1) {
 4024:         LOG(("Error parsing n: field: %s", PromiseFlatCString(line).get()));
 4024:         mUpdateWait = 0;
 4024:       }
12453:     } else if (line.EqualsLiteral("r:pleasereset")) {
80486:       mResetRequested = true;
12346:     } else if (line.EqualsLiteral("e:pleaserekey")) {
12346:       mUpdateObserver->RekeyRequested();
 4024:     } else if (StringBeginsWith(line, NS_LITERAL_CSTRING("i:"))) {
12346:       mUpdateTable.Assign(Substring(line, 2));
 4024:       GetTableId(mUpdateTable, &mUpdateTableId);
 4024:       LOG(("update table: '%s' (%d)", mUpdateTable.get(), mUpdateTableId));
10213:     } else if (StringBeginsWith(line, NS_LITERAL_CSTRING("u:"))) {
10213:       if (!mPrimaryStream) {
10213:         LOG(("Forwarded update tried to add its own forwarded update."));
10213:         return NS_ERROR_FAILURE;
10213:       }
10213: 
10213:       const nsCSubstring& data = Substring(line, 2);
12346:       if (mHMAC) {
12346:         // We're expecting MACs alongside any url forwards.
12346:         nsCSubstring::const_iterator begin, end, sepBegin, sepEnd;
12346:         data.BeginReading(begin);
12346:         sepBegin = begin;
12346: 
12346:         data.EndReading(end);
12346:         sepEnd = end;
12346: 
12346:         if (!RFindInReadable(NS_LITERAL_CSTRING(","), sepBegin, sepEnd)) {
12346:           NS_WARNING("No MAC specified for a redirect in a request that expects a MAC");
12346:           return NS_ERROR_FAILURE;
12346:         }
12346: 
12346:         nsCString serverMAC(Substring(sepEnd, end));
12346:         nsUrlClassifierUtils::UnUrlsafeBase64(serverMAC);
12346:         mUpdateObserver->UpdateUrlRequested(Substring(begin, sepBegin),
12346:                                             mUpdateTable,
12346:                                             serverMAC);
10213:       } else {
12346:         // We didn't ask for a MAC, none should have been specified.
12346:         mUpdateObserver->UpdateUrlRequested(data, mUpdateTable,
12346:                                             NS_LITERAL_CSTRING(""));
10213:       }
 4024:     } else if (StringBeginsWith(line, NS_LITERAL_CSTRING("a:")) ||
 4024:                StringBeginsWith(line, NS_LITERAL_CSTRING("s:"))) {
 4024:       mState = STATE_CHUNK;
 4024:       char command;
 4024:       if (PR_sscanf(PromiseFlatCString(line).get(),
10941:                     "%c:%d:%d:%d", &command, &mChunkNum, &mHashSize, &mChunkLen) != 4) {
 4024:         return NS_ERROR_FAILURE;
 4024:       }
10941: 
10941:       if (mChunkLen > MAX_CHUNK_SIZE) {
10941:         return NS_ERROR_FAILURE;
10941:       }
10941: 
10941:       if (!(mHashSize == PARTIAL_LENGTH || mHashSize == COMPLETE_LENGTH)) {
10941:         NS_WARNING("Invalid hash size specified in update.");
10941:         return NS_ERROR_FAILURE;
10941:       }
10941: 
 4024:       mChunkType = (command == 'a') ? CHUNK_ADD : CHUNK_SUB;
 4024: 
 4024:       // Done parsing lines, move to chunk state now
80486:       *done = false;
 4024:       break;
 4024:     } else if (StringBeginsWith(line, NS_LITERAL_CSTRING("ad:"))) {
11769:       const nsCSubstring &list = Substring(line, 3);
11769:       nsACString::const_iterator begin, end;
11769:       list.BeginReading(begin);
11769:       list.EndReading(end);
11769:       while (begin != end) {
11769:         PRUint32 first, last;
11769:         if (ParseChunkRange(begin, end, &first, &last)) {
11769:           for (PRUint32 num = first; num <= last; num++) {
11769:             rv = ExpireAdd(mUpdateTableId, num);
11769:             NS_ENSURE_SUCCESS(rv, rv);
11769:           }
11769:         } else {
 4024:           return NS_ERROR_FAILURE;
 4024:         }
11769:       }
11769:     } else if (StringBeginsWith(line, NS_LITERAL_CSTRING("sd:"))) {
11769:       const nsCSubstring &list = Substring(line, 3);
11769:       nsACString::const_iterator begin, end;
11769:       list.BeginReading(begin);
11769:       list.EndReading(end);
11769:       while (begin != end) {
11769:         PRUint32 first, last;
11769:         if (ParseChunkRange(begin, end, &first, &last)) {
11769:           for (PRUint32 num = first; num <= last; num++) {
11769:             rv = ExpireSub(mUpdateTableId, num);
 4024:             NS_ENSURE_SUCCESS(rv, rv);
 8707:           }
11769:         } else {
 4024:           return NS_ERROR_FAILURE;
 4024:         }
 8707:       }
 4024:     } else {
 4024:       LOG(("ignoring unknown line: '%s'", PromiseFlatCString(line).get()));
 4024:     }
 4024:   }
 4024: 
 4024:   mPendingStreamUpdate = Substring(updateString, cur);
 4024: 
 4024:   return NS_OK;
 4024: }
 4024: 
 4024: void
10213: nsUrlClassifierDBServiceWorker::ResetStream()
10213: {
10213:   mState = STATE_LINE;
10213:   mChunkNum = 0;
10941:   mHashSize = 0;
10213:   mChunkLen = 0;
80486:   mInStream = false;
80486:   mPrimaryStream = false;
10213:   mUpdateTable.Truncate();
10213:   mPendingStreamUpdate.Truncate();
12346:   mServerMAC.Truncate();
12346:   mHMAC = nsnull;
10213: }
10213: 
10213: void
 4024: nsUrlClassifierDBServiceWorker::ResetUpdate()
 4024: {
 4024:   mUpdateWait = 0;
 4024:   mUpdateStatus = NS_OK;
10213:   mUpdateObserver = nsnull;
12346:   mUpdateClientKey.Truncate();
80486:   mResetRequested = false;
14354:   mUpdateTables.Clear();
10213: }
10213: 
10213: NS_IMETHODIMP
10941: nsUrlClassifierDBServiceWorker::SetHashCompleter(const nsACString &tableName,
10941:                                                  nsIUrlClassifierHashCompleter *completer)
10941: {
10941:   return NS_ERROR_NOT_IMPLEMENTED;
10941: }
10941: 
10941: NS_IMETHODIMP
12346: nsUrlClassifierDBServiceWorker::BeginUpdate(nsIUrlClassifierUpdateObserver *observer,
14354:                                             const nsACString &tables,
12346:                                             const nsACString &clientKey)
10213: {
10337:   if (gShuttingDownThread)
10337:     return NS_ERROR_NOT_INITIALIZED;
10337: 
10213:   NS_ENSURE_STATE(!mUpdateObserver);
10213: 
10213:   nsresult rv = OpenDb();
10213:   if (NS_FAILED(rv)) {
73472:     NS_ERROR("Unable to open database");
10213:     return NS_ERROR_FAILURE;
10213:   }
10213: 
79445:   bool transaction;
10213:   rv = mConnection->GetTransactionInProgress(&transaction);
10213:   if (NS_FAILED(rv)) {
10213:     mUpdateStatus = rv;
10213:     return rv;
10213:   }
10213: 
10213:   if (transaction) {
10213:     NS_WARNING("Transaction already in progress in nsUrlClassifierDBServiceWorker::BeginUpdate.  Cancelling update.");
10213:     mUpdateStatus = NS_ERROR_FAILURE;
10213:     return rv;
10213:   }
10213: 
15023:   rv = SetupUpdate();
10213:   if (NS_FAILED(rv)) {
10213:     mUpdateStatus = rv;
10213:     return rv;
10213:   }
10213: 
10213:   mUpdateObserver = observer;
10213: 
12346:   if (!clientKey.IsEmpty()) {
12346:     rv = nsUrlClassifierUtils::DecodeClientKey(clientKey, mUpdateClientKey);
12346:     NS_ENSURE_SUCCESS(rv, rv);
12346:   }
12346: 
10213:   // The first stream in an update is the only stream that may request
10213:   // forwarded updates.
80486:   mPrimaryStream = true;
10213: 
14354:   SplitTables(tables, mUpdateTables);
14354: 
10213:   return NS_OK;
10213: }
10213: 
10213: NS_IMETHODIMP
12346: nsUrlClassifierDBServiceWorker::BeginStream(const nsACString &table,
12346:                                             const nsACString &serverMAC)
10213: {
10337:   if (gShuttingDownThread)
10337:     return NS_ERROR_NOT_INITIALIZED;
10337: 
10213:   NS_ENSURE_STATE(mUpdateObserver);
10213:   NS_ENSURE_STATE(!mInStream);
10213: 
15023:   // We may have committed the update in FinishStream, if so set it up
15023:   // again here.
15023:   nsresult rv = SetupUpdate();
15023:   if (NS_FAILED(rv)) {
15023:     mUpdateStatus = rv;
15023:     return rv;
15023:   }
15023: 
80486:   mInStream = true;
10213: 
12346:   // If we're expecting a MAC, create the nsICryptoHMAC component now.
12346:   if (!mUpdateClientKey.IsEmpty()) {
13256:     nsCOMPtr<nsIKeyObjectFactory> keyObjectFactory(do_GetService(
13256:         "@mozilla.org/security/keyobjectfactory;1", &rv));
13256:     if (NS_FAILED(rv)) {
13256:       NS_WARNING("Failed to get nsIKeyObjectFactory service");
13256:       mUpdateStatus = rv;
13256:       return mUpdateStatus;
13256:     }
13256: 
13256:     nsCOMPtr<nsIKeyObject> keyObject;
13256:     rv = keyObjectFactory->KeyFromString(nsIKeyObject::HMAC, mUpdateClientKey, 
13256:         getter_AddRefs(keyObject));
13256:     if (NS_FAILED(rv)) {
13256:       NS_WARNING("Failed to create key object, maybe not FIPS compliant?");
13256:       mUpdateStatus = rv;
13256:       return mUpdateStatus;
13256:     }
13256: 
12346:     mHMAC = do_CreateInstance(NS_CRYPTO_HMAC_CONTRACTID, &rv);
12346:     if (NS_FAILED(rv)) {
12346:       NS_WARNING("Failed to create nsICryptoHMAC instance");
12346:       mUpdateStatus = rv;
12346:       return mUpdateStatus;
12346:     }
13256: 
13256:     rv = mHMAC->Init(nsICryptoHMAC::SHA1, keyObject);
12346:     if (NS_FAILED(rv)) {
12346:       NS_WARNING("Failed to initialize nsICryptoHMAC instance");
12346:       mUpdateStatus = rv;
12346:       return mUpdateStatus;
12346:     }
12346:   }
12346: 
12346:   mServerMAC = serverMAC;
12346: 
10941:   if (!table.IsEmpty()) {
10941:     mUpdateTable = table;
10941:     GetTableId(mUpdateTable, &mUpdateTableId);
10941:     LOG(("update table: '%s' (%d)", mUpdateTable.get(), mUpdateTableId));
10941:   }
10941: 
10213:   return NS_OK;
 4024: }
 4024: 
 4024: /**
 4024:  * Updating the database:
 4024:  *
42263:  * The Update() method takes a series of chunks separated with control data,
 4024:  * as described in
 4024:  * http://code.google.com/p/google-safe-browsing/wiki/Protocolv2Spec
 4024:  *
 4024:  * It will iterate through the control data until it reaches a chunk.  By
 4024:  * the time it reaches a chunk, it should have received
 4024:  * a) the table to which this chunk applies
 4024:  * b) the type of chunk (add, delete, expire add, expire delete).
 4024:  * c) the chunk ID
 4024:  * d) the length of the chunk.
 4024:  *
 4024:  * For add and subtract chunks, it needs to read the chunk data (expires
 4024:  * don't have any data).  Chunk data is a list of URI fragments whose
 4024:  * encoding depends on the type of table (which is indicated by the end
 4024:  * of the table name):
 4024:  * a) tables ending with -exp are a zlib-compressed list of URI fragments
 4024:  *    separated by newlines.
 4024:  * b) tables ending with -sha128 have the form
 4024:  *    [domain][N][frag0]...[fragN]
 4024:  *       16    1   16        16
 4024:  *    If N is 0, the domain is reused as a fragment.
 4024:  * c) any other tables are assumed to be a plaintext list of URI fragments
 4024:  *    separated by newlines.
 4024:  *
 4024:  * Update() can be fed partial data;  It will accumulate data until there is
 4024:  * enough to act on.  Finish() should be called when there will be no more
 4024:  * data.
 4024:  */
    1: NS_IMETHODIMP
10213: nsUrlClassifierDBServiceWorker::UpdateStream(const nsACString& chunk)
    1: {
  762:   if (gShuttingDownThread)
  762:     return NS_ERROR_NOT_INITIALIZED;
  762: 
10213:   NS_ENSURE_STATE(mInStream);
10213: 
 4024:   HandlePendingLookups();
 4024: 
    1:   LOG(("Update from Stream."));
    1:   nsresult rv = OpenDb();
    1:   if (NS_FAILED(rv)) {
73472:     NS_ERROR("Unable to open database");
    1:     return NS_ERROR_FAILURE;
    1:   }
    1: 
 4024:   // if something has gone wrong during this update, just throw it away
 4024:   if (NS_FAILED(mUpdateStatus)) {
 4024:     return mUpdateStatus;
 4024:   }
 4024: 
12346:   if (mHMAC && !mServerMAC.IsEmpty()) {
12346:     rv = mHMAC->Update(reinterpret_cast<const PRUint8*>(chunk.BeginReading()),
12346:                        chunk.Length());
12346:     if (NS_FAILED(rv)) {
12346:       mUpdateStatus = rv;
12346:       return mUpdateStatus;
12346:     }
12346:   }
12346: 
 4024:   LOG(("Got %s\n", PromiseFlatCString(chunk).get()));
 4024: 
 4024:   mPendingStreamUpdate.Append(chunk);
 4024: 
79445:   bool done = false;
 4024:   while (!done) {
 4024:     if (mState == STATE_CHUNK) {
 4024:       rv = ProcessChunk(&done);
 4001:     } else {
 4024:       rv = ProcessResponseLines(&done);
 4001:     }
 4024:     if (NS_FAILED(rv)) {
 4024:       mUpdateStatus = rv;
 4024:       return rv;
 3997:     }
 4001:   }
    1: 
    1:   return NS_OK;
    1: }
    1: 
    1: NS_IMETHODIMP
10213: nsUrlClassifierDBServiceWorker::FinishStream()
    1: {
10337:   if (gShuttingDownThread)
10337:     return NS_ERROR_NOT_INITIALIZED;
10337: 
10213:   NS_ENSURE_STATE(mInStream);
10213:   NS_ENSURE_STATE(mUpdateObserver);
10213: 
15023:   PRInt32 nextStreamDelay = 0;
15023: 
12346:   if (NS_SUCCEEDED(mUpdateStatus) && mHMAC) {
12346:     nsCAutoString clientMAC;
80486:     mHMAC->Finish(true, clientMAC);
12346: 
12346:     if (clientMAC != mServerMAC) {
12346:       NS_WARNING("Invalid update MAC!");
12346:       LOG(("Invalid update MAC: expected %s, got %s",
12346:            mServerMAC.get(), clientMAC.get()));
12346:       mUpdateStatus = NS_ERROR_FAILURE;
12346:     }
15023:     PRIntervalTime updateTime = PR_IntervalNow() - mUpdateStartTime;
15023:     if (PR_IntervalToSeconds(updateTime) >=
15023:         static_cast<PRUint32>(gWorkingTimeThreshold)) {
15023:       // We've spent long enough working that we should commit what we
15023:       // have and hold off for a bit.
83144:       nsresult rv = ApplyUpdate();
83144:       if (NS_FAILED(rv)) {
83144:         if (rv == NS_ERROR_FILE_CORRUPTED) {
83144:           ResetDatabase();
83144:         }
83144:         return rv;
83144:       }
15023:       nextStreamDelay = gDelayTime * 1000;
15023:     }
15023:   }
15023: 
15023:   mUpdateObserver->StreamFinished(mUpdateStatus,
15023:                                   static_cast<PRUint32>(nextStreamDelay));
10213: 
10213:   ResetStream();
10213: 
10213:   return NS_OK;
10213: }
10213: 
15023: nsresult
78088: nsUrlClassifierDBServiceWorker::SetCacheSize(
78088:   mozIStorageConnection * aConnection, PRInt32 aCacheSize)
78088: {
78088:   mozStorageStatementScoper scoper(mGetPageSizeStatement);
79445:   bool hasResult;
78088:   nsresult rv = mGetPageSizeStatement->ExecuteStep(&hasResult);
78088:   NS_ENSURE_SUCCESS(rv, rv);
78088: 
78088:   NS_ASSERTION(hasResult, "Should always be able to get page size from sqlite");
78088:   PRUint32 pageSize = mGetPageSizeStatement->AsInt32(0);
78088:   PRUint32 cachePages = aCacheSize / pageSize;
86727:   nsCAutoString cacheSizePragma(MOZ_STORAGE_UNIQUIFY_QUERY_STR
86727:                                 "PRAGMA cache_size=");
78088:   cacheSizePragma.AppendInt(cachePages);
78088:   rv = aConnection->ExecuteSimpleSQL(cacheSizePragma);
78088:   NS_ENSURE_SUCCESS(rv, rv);
78088: 
78088:   return NS_OK;
78088: }
78088: 
78088: nsresult
15023: nsUrlClassifierDBServiceWorker::SetupUpdate()
15023: {
15023:   LOG(("nsUrlClassifierDBServiceWorker::SetupUpdate"));
79445:   bool inProgress;
15023:   nsresult rv = mConnection->GetTransactionInProgress(&inProgress);
15023:   if (inProgress) {
15023:     return NS_OK;
15023:   }
15023: 
15023:   mUpdateStartTime = PR_IntervalNow();
15023: 
15023:   rv = mConnection->BeginTransaction();
15023:   NS_ENSURE_SUCCESS(rv, rv);
15023: 
15023:   if (gUpdateCacheSize > 0) {
78088:     rv = SetCacheSize(mConnection, gUpdateCacheSize);
46994:     NS_ENSURE_SUCCESS(rv, rv);
78088:     if (gUpdateCacheSize != gLookupCacheSize) {
80486:       mGrewCache = true;
15023:     }
78088:   }
15023: 
15023:   return NS_OK;
15023: }
15023: 
15023: nsresult
15023: nsUrlClassifierDBServiceWorker::ApplyUpdate()
15023: {
15023:   LOG(("nsUrlClassifierDBServiceWorker::ApplyUpdate"));
15023: 
57898:   if (mConnection) {
15023:     if (NS_FAILED(mUpdateStatus)) {
15023:       mConnection->RollbackTransaction();
15023:     } else {
15023:       mUpdateStatus = FlushChunkLists();
15023:       if (NS_SUCCEEDED(mUpdateStatus)) {
15023:         mUpdateStatus = mConnection->CommitTransaction();
15023:       }
15023:     }
57898:   }
15023: 
20648:   if (NS_SUCCEEDED(mUpdateStatus)) {
78086:     // Reconstruct the prefix tree from the DB
78090:     nsresult rv = ConstructPrefixSet();
78086:     NS_ENSURE_SUCCESS(rv, rv);
20648:   }
20648: 
15023:   if (mGrewCache) {
15023:     // During the update we increased the page cache to bigger than we
15023:     // want to keep around.  At the moment, the only reliable way to make
15023:     // sure that the page cache is freed is to reopen the connection.
78087:     LOG(("GrewCache true, reopening DB"));
80486:     mGrewCache = false;
15023:     CloseDb();
15023:     OpenDb();
15023:   }
15023: 
15023:   mUpdateStartTime = 0;
15023: 
15023:   return NS_OK;
15023: }
15023: 
15016: NS_IMETHODIMP
15016: nsUrlClassifierDBServiceWorker::FinishUpdate()
15006: {
15023:   LOG(("nsUrlClassifierDBServiceWorker::FinishUpdate()"));
15016:   if (gShuttingDownThread)
15016:     return NS_ERROR_NOT_INITIALIZED;
15016: 
15016:   NS_ENSURE_STATE(!mInStream);
15016:   NS_ENSURE_STATE(mUpdateObserver);
15016: 
16701:   // We need to get the error code before ApplyUpdate, because it might
16701:   // close/open the connection.
16701:   PRInt32 errcode = SQLITE_OK;
57898:   if (mConnection)
16701:     mConnection->GetLastError(&errcode);
16701: 
83144:   nsresult rv = ApplyUpdate();
83144:   if (NS_FAILED(rv)) {
83144:     if (rv == NS_ERROR_FILE_CORRUPTED) {
83144:       ResetDatabase();
83144:     }
83144:     return rv;
83144:   }
15016: 
15016:   if (NS_SUCCEEDED(mUpdateStatus)) {
15016:     mUpdateObserver->UpdateSuccess(mUpdateWait);
15016:   } else {
15016:     mUpdateObserver->UpdateError(mUpdateStatus);
15016:   }
15016: 
16701:   // It's important that we only reset the database on an update
16701:   // command if the update was successful, otherwise unauthenticated
16701:   // updates could cause a database reset.
79445:   bool resetDB = (NS_SUCCEEDED(mUpdateStatus) && mResetRequested) ||
16701:                     errcode == SQLITE_CORRUPT;
16701: 
16701:   if (!resetDB) {
15016:     if (NS_SUCCEEDED(mUpdateStatus)) {
15016:       PRInt64 now = (PR_Now() / PR_USEC_PER_SEC);
15016:       for (PRUint32 i = 0; i < mUpdateTables.Length(); i++) {
15016:         LOG(("Successfully updated %s", mUpdateTables[i].get()));
15016:         mTableFreshness.Put(mUpdateTables[i], now);
15016:       }
15016:     } else {
15016:       for (PRUint32 i = 0; i < mUpdateTables.Length(); i++) {
15016:         LOG(("Failed updating %s", mUpdateTables[i].get()));
15016:         mTableFreshness.Remove(mUpdateTables[i]);
15016:       }
15016:     }
15016:   }
15016: 
15016:   ResetUpdate();
15016: 
16701:   if (resetDB) {
15016:     ResetDatabase();
15006:   }
15006: 
    1:   return NS_OK;
    1: }
    1: 
    1: NS_IMETHODIMP
10212: nsUrlClassifierDBServiceWorker::ResetDatabase()
10212: {
12453:   LOG(("nsUrlClassifierDBServiceWorker::ResetDatabase [%p]", this));
10941:   ClearCachedChunkLists();
10941: 
14354:   mTableFreshness.Clear();
14354: 
10212:   nsresult rv = CloseDb();
10212:   NS_ENSURE_SUCCESS(rv, rv);
10212: 
78087:   rv = mPrefixSet->SetPrefixes(nsnull, 0);
78087:   NS_ENSURE_SUCCESS(rv, rv);
78087: 
80486:   mDBFile->Remove(false);
80486:   mPSFile->Remove(false);
10212: 
10212:   return NS_OK;
10212: }
10212: 
10212: NS_IMETHODIMP
10213: nsUrlClassifierDBServiceWorker::CancelUpdate()
    1: {
10213:   LOG(("CancelUpdate"));
10213: 
10262:   if (mUpdateObserver) {
10213:     mUpdateStatus = NS_BINDING_ABORTED;
10213: 
10941:     ClearCachedChunkLists();
10213:     mConnection->RollbackTransaction();
10213:     mUpdateObserver->UpdateError(mUpdateStatus);
10213: 
14354:     for (PRUint32 i = 0; i < mUpdateTables.Length(); i++) {
14354:       LOG(("Failed updating %s", mUpdateTables[i].get()));
14354:       mTableFreshness.Remove(mUpdateTables[i]);
14354:     }
14354: 
10213:     ResetStream();
 4024:     ResetUpdate();
10262:   }
    1: 
    1:   return NS_OK;
    1: }
    1: 
    1: // Allows the main thread to delete the connection which may be in
    1: // a background thread.
    1: // XXX This could be turned into a single shutdown event so the logic
    1: // is simpler in nsUrlClassifierDBService::Shutdown.
    1: NS_IMETHODIMP
    1: nsUrlClassifierDBServiceWorker::CloseDb()
    1: {
 4024:   if (mConnection) {
10212:     mMainStore.Close();
10212:     mPendingSubStore.Close();
 4024: 
 4024:     mGetChunkListsStatement = nsnull;
 4024:     mSetChunkListsStatement = nsnull;
 4024: 
 4024:     mGetTablesStatement = nsnull;
 4024:     mGetTableIdStatement = nsnull;
 4024:     mGetTableNameStatement = nsnull;
 4024:     mInsertTableIdStatement = nsnull;
46994:     mGetPageSizeStatement = nsnull;
 4024: 
 4024:     mConnection = nsnull;
    1:     LOG(("urlclassifier db closed\n"));
    1:   }
 4024: 
 4024:   mCryptoHash = nsnull;
 4024: 
    1:   return NS_OK;
    1: }
    1: 
10988: NS_IMETHODIMP
10988: nsUrlClassifierDBServiceWorker::CacheCompletions(nsTArray<nsUrlClassifierLookupResult> *results)
10988: {
10988:   LOG(("nsUrlClassifierDBServiceWorker::CacheCompletions [%p]", this));
10988: 
10988:   nsAutoPtr<nsTArray<nsUrlClassifierLookupResult> > resultsPtr(results);
10988: 
10988:   // Start a new transaction.  If a transaction is open for an update
10988:   // this will be a noop, and this cache will be included in the
10988:   // update's transaction.
80486:   mozStorageTransaction trans(mConnection, true);
10988: 
10988:   for (PRUint32 i = 0; i < results->Length(); i++) {
10988:     nsUrlClassifierLookupResult& result = results->ElementAt(i);
10988:     // Failing to update here shouldn't be fatal (and might be common,
10988:     // if we're updating entries that were removed since they were
10988:     // returned after a lookup).
10988:     mMainStore.UpdateEntry(result.mEntry);
10988:   }
10988: 
10988:   return NS_OK;
10988: }
10988: 
    1: nsresult
 4001: nsUrlClassifierDBServiceWorker::OpenDb()
 4001: {
 4001:   // Connection already open, don't do anything.
78087:   if (mConnection) {
 4001:     return NS_OK;
78087:   }
 4001: 
 4001:   LOG(("Opening db\n"));
 4024: 
 4024:   nsresult rv;
 4001:   // open the connection
 4001:   nsCOMPtr<mozIStorageService> storageService =
 4001:     do_GetService(MOZ_STORAGE_SERVICE_CONTRACTID, &rv);
 4001:   NS_ENSURE_SUCCESS(rv, rv);
 4024: 
79445:   bool exists;
 8732:   rv = mDBFile->Exists(&exists);
 8732:   NS_ENSURE_SUCCESS(rv, rv);
79445:   bool newDB = !exists;
 8732: 
 4024:   nsCOMPtr<mozIStorageConnection> connection;
 4024:   rv = storageService->OpenDatabase(mDBFile, getter_AddRefs(connection));
13508:   if (rv == NS_ERROR_FILE_CORRUPTED) {
 4001:     // delete the db and try opening again
80486:     rv = mDBFile->Remove(false);
 4001:     NS_ENSURE_SUCCESS(rv, rv);
 8732: 
80486:     newDB = true;
 8732: 
 4024:     rv = storageService->OpenDatabase(mDBFile, getter_AddRefs(connection));
13508:   }
12208:   NS_ENSURE_SUCCESS(rv, rv);
 3997: 
 8732:   if (!newDB) {
 8732:     PRInt32 databaseVersion;
 8732:     rv = connection->GetSchemaVersion(&databaseVersion);
 8732:     NS_ENSURE_SUCCESS(rv, rv);
 8732: 
 8732:     if (databaseVersion != IMPLEMENTATION_VERSION) {
 8732:       LOG(("Incompatible database, removing."));
 8732: 
 8732:       rv = connection->Close();
 8732:       NS_ENSURE_SUCCESS(rv, rv);
 8732: 
80486:       rv = mDBFile->Remove(false);
 8732:       NS_ENSURE_SUCCESS(rv, rv);
 8732: 
80486:       newDB = true;
 8732: 
 8732:       rv = storageService->OpenDatabase(mDBFile, getter_AddRefs(connection));
 8732:       NS_ENSURE_SUCCESS(rv, rv);
 8732:     }
 8732:   }
 8732: 
51868:   connection->SetGrowthIncrement(5 * 1024 * 1024, EmptyCString());
14883:   rv = connection->ExecuteSimpleSQL(NS_LITERAL_CSTRING("PRAGMA synchronous=OFF"));
14883:   NS_ENSURE_SUCCESS(rv, rv);
14883: 
78088:   rv = connection->CreateStatement
86727:     (NS_LITERAL_CSTRING(MOZ_STORAGE_UNIQUIFY_QUERY_STR "PRAGMA page_size"),
78088:      getter_AddRefs(mGetPageSizeStatement));
78088:   NS_ENSURE_SUCCESS(rv, rv);
78088: 
78088:   rv = SetCacheSize(connection, gLookupCacheSize);
78088:   NS_ENSURE_SUCCESS(rv, rv);
78088: 
 8732:   if (newDB) {
 8732:     rv = connection->SetSchemaVersion(IMPLEMENTATION_VERSION);
 8732:     NS_ENSURE_SUCCESS(rv, rv);
 8732:   }
 8732: 
 4024:   // Create the table
 4024:   rv = MaybeCreateTables(connection);
 4024:   NS_ENSURE_SUCCESS(rv, rv);
 4024: 
10212:   rv = mMainStore.Init(this, connection,
10941:                        NS_LITERAL_CSTRING("moz_classifier"));
 4024:   NS_ENSURE_SUCCESS(rv, rv);
 4024: 
10212:   rv = mPendingSubStore.Init(this, connection,
10941:                              NS_LITERAL_CSTRING("moz_subs"));
10988:   NS_ENSURE_SUCCESS(rv, rv);
 4024: 
 4024:   rv = connection->CreateStatement
 4024:          (NS_LITERAL_CSTRING("SELECT add_chunks, sub_chunks FROM moz_tables"
 4024:                              " WHERE id=?1"),
 4024:           getter_AddRefs(mGetChunkListsStatement));
 4024:   NS_ENSURE_SUCCESS(rv, rv);
 4024: 
 4024:   rv = connection->CreateStatement
 4024:          (NS_LITERAL_CSTRING("UPDATE moz_tables"
 4024:                              " SET add_chunks=?1, sub_chunks=?2"
 4024:                              " WHERE id=?3"),
 4024:           getter_AddRefs(mSetChunkListsStatement));
 4024:   NS_ENSURE_SUCCESS(rv, rv);
 4024: 
 4024:   rv = connection->CreateStatement
 4024:          (NS_LITERAL_CSTRING("SELECT name, add_chunks, sub_chunks"
 4024:                              " FROM moz_tables"),
 4024:           getter_AddRefs(mGetTablesStatement));
 4024:   NS_ENSURE_SUCCESS(rv, rv);
 4024: 
 4024:   rv = connection->CreateStatement
 4024:     (NS_LITERAL_CSTRING("SELECT id FROM moz_tables"
 4024:                         " WHERE name = ?1"),
 4024:      getter_AddRefs(mGetTableIdStatement));
 4024:   NS_ENSURE_SUCCESS(rv, rv);
 4024: 
 4024:   rv = connection->CreateStatement
 4024:     (NS_LITERAL_CSTRING("SELECT name FROM moz_tables"
 4024:                         " WHERE id = ?1"),
 4024:      getter_AddRefs(mGetTableNameStatement));
 4024:   NS_ENSURE_SUCCESS(rv, rv);
 4024: 
 4024:   rv = connection->CreateStatement
 4024:     (NS_LITERAL_CSTRING("INSERT INTO moz_tables(id, name, add_chunks, sub_chunks)"
 4024:                         " VALUES (null, ?1, null, null)"),
 4024:      getter_AddRefs(mInsertTableIdStatement));
 4024:   NS_ENSURE_SUCCESS(rv, rv);
 4024: 
 4024:   mConnection = connection;
 4024: 
 4024:   mCryptoHash = do_CreateInstance(NS_CRYPTO_HASH_CONTRACTID, &rv);
 4024:   NS_ENSURE_SUCCESS(rv, rv);
 4001: 
78090:   LOG(("loading Prefix Set\n"));
78090:   rv = LoadPrefixSet(mPSFile);
83144:   if (NS_FAILED(rv)) {
83144:     if (rv == NS_ERROR_FILE_CORRUPTED) {
83144:       ResetDatabase();
83144:     }
83144:     return rv;
83144:   }
78086: 
78086:   return NS_OK;
78086: }
78086: 
78092: // We have both a prefix and a domain. Drop the domain, but
78092: // hash the domain, the prefix and a random value together,
78092: // ensuring any collisions happens at a different points for
78092: // different users.
78092: // We need to calculate +- 500k hashes each update.
78092: // The extensive initialization and finalization of normal
78092: // cryptographic hashes, as well as fairly low speed, causes them
78092: // to be prohibitively slow here, hence we can't use them.
78092: // We use MurmurHash3 instead because it's reasonably well
78092: // researched, trusted inside some other big projects, extremely
78092: // fast and with a specific a 32-bit output version, and fairly
78092: // compact. Upon testing with the actual prefix data, it does
78092: // not appear to increase the number of collisions by any
78092: // meaningful amount.
78092: static nsresult KeyedHash(PRUint32 aPref, PRUint32 aDomain,
78092:                           PRUint32 aKey, PRUint32 *aOut)
78092: {
78092:   // This is a reimplementation of MurmurHash3 32-bit
78092:   // based on the public domain C++ sources.
78092:   // http://code.google.com/p/smhasher/source/browse/trunk/MurmurHash3.cpp
78092:   // for nblocks = 2
78092:   PRUint32 c1 = 0xCC9E2D51;
78092:   PRUint32 c2 = 0x1B873593;
78092:   PRUint32 c3 = 0xE6546B64;
78092:   PRUint32 c4 = 0x85EBCA6B;
78092:   PRUint32 c5 = 0xC2B2AE35;
78092:   PRUint32 h1 = aPref; // seed
78092:   PRUint32 k1;
78092:   PRUint32 karr[2];
78092: 
78092:   karr[0] = aDomain;
78092:   karr[1] = aKey;
78092: 
78092:   for (PRUint32 i = 0; i < 2; i++) {
78092:     k1 = karr[i];
78092:     k1 *= c1;
78092:     k1 = (k1 << 15) | (k1 >> (32-15));
78092:     k1 *= c2;
78092: 
78092:     h1 ^= k1;
78092:     h1 = (h1 << 13) | (h1 >> (32-13));
78092:     h1 *= 5;
78092:     h1 += c3;
78092:   }
78092: 
78092:   h1 ^= 2; // len
78092:   // fmix
78092:   h1 ^= h1 >> 16;
78092:   h1 *= c4;
78092:   h1 ^= h1 >> 13;
78092:   h1 *= c5;
78092:   h1 ^= h1 >> 16;
78092: 
78092:   *aOut = h1;
78092: 
78092:   return NS_OK;
78092: }
78092: 
86944: nsresult nsUrlClassifierStore::ReadPrefixes(FallibleTArray<PRUint32>& array,
78092:                                             PRUint32 aKey)
78086: {
86944:   mozStorageStatementScoper scoper(mAllPrefixGetStatement);
86944:   mozStorageStatementScoper scoperToo(mAllPrefixCountStatement);
79445:   bool hasMoreData;
78086:   PRUint32 pcnt = 0;
78086:   PRUint32 fcnt = 0;
78086: 
78092: #if defined(PR_LOGGING)
78092:   PRIntervalTime clockStart = 0;
78092:   if (LOG_ENABLED()) {
78092:     clockStart = PR_IntervalNow();
78092:   }
78092: #endif
78092: 
86944:   // Make sure we allocate no more than we really need, so first
86944:   // check how much entries there are
86944:   if (NS_SUCCEEDED(mAllPrefixCountStatement->ExecuteStep(&hasMoreData)) && hasMoreData) {
86944:     PRUint32 count = mAllPrefixCountStatement->AsInt32(0);
86944:     if (!array.SetCapacity(count)) {
86944:       return NS_ERROR_OUT_OF_MEMORY;
86944:     }
86944:   } else {
86944:     return NS_ERROR_FILE_CORRUPTED;
86944:   }
86944: 
86944:   while (NS_SUCCEEDED(mAllPrefixGetStatement->ExecuteStep(&hasMoreData)) && hasMoreData) {
78086:     PRUint32 prefixval;
78086:     PRUint32 domainval;
78086:     PRUint32 size;
78086: 
86944:     const PRUint8 *blobdomain = mAllPrefixGetStatement->AsSharedBlob(0, &size);
78086:     if (!blobdomain || (size != DOMAIN_LENGTH))
80486:       return false;
78086: 
78086:     domainval = *(reinterpret_cast<const PRUint32*>(blobdomain));
78086: 
86944:     const PRUint8 *blobprefix = mAllPrefixGetStatement->AsSharedBlob(1, &size);
78086:     if (!blobprefix || (size != PARTIAL_LENGTH)) {
86944:       const PRUint8 *blobfull = mAllPrefixGetStatement->AsSharedBlob(2, &size);
78086:       if (!blobfull || (size != COMPLETE_LENGTH)) {
78086:         prefixval = domainval;
78086:         fcnt++;
78086:       } else {
78086:         prefixval = *(reinterpret_cast<const PRUint32*>(blobfull));
78086:       }
78086:     } else {
78086:       prefixval = *(reinterpret_cast<const PRUint32*>(blobprefix));
78086:     }
78086: 
78092:     PRUint32 keyedVal;
78092:     nsresult rv = KeyedHash(prefixval, domainval, aKey, &keyedVal);
78092:     NS_ENSURE_SUCCESS(rv, rv);
78092: 
86944:     PRUint32 *res = array.AppendElement(keyedVal);
86944:     MOZ_ASSERT(res != nsnull);
78086:     pcnt++;
83144:     // Normal DB size is about 500k entries. If we are getting 10x
83144:     // as much, the database must be corrupted.
83144:     if (pcnt > 5000000) {
83144:       return NS_ERROR_FILE_CORRUPTED;
83144:     }
78086:   }
78086: 
78091:   LOG(("SB prefixes: %d fulldomain: %d\n", pcnt, fcnt));
78086: 
78092: #if defined(PR_LOGGING)
78092:   if (LOG_ENABLED()) {
78092:     PRIntervalTime clockEnd = PR_IntervalNow();
78092:     LOG(("Gathering took %dms\n",
78092:          PR_IntervalToMilliseconds(clockEnd - clockStart)));
78092:   }
78092: #endif
78092: 
78086:   return NS_OK;
78086: }
78086: 
78086: nsresult
78090: nsUrlClassifierDBServiceWorker::ConstructPrefixSet()
78086: {
78093:   Telemetry::AutoTimer<Telemetry::URLCLASSIFIER_PS_CONSTRUCT_TIME> timer;
78093: 
78092:   PRUint32 key;
78092:   nsresult rv = mPrefixSet->GetKey(&key);
78092:   NS_ENSURE_SUCCESS(rv, rv);
78092: 
86944:   FallibleTArray<PRUint32> array;
78092:   rv = mMainStore.ReadPrefixes(array, key);
86944:   if (NS_FAILED(rv)) {
86944:     goto error_bailout;
86944:   }
78086: 
78092: #ifdef HASHFUNCTION_COLLISION_TEST
78092:   array.Sort();
78092:   PRUint32 collisions = 0;
78092:   for (int i = 1; i < array.Length(); i++) {
78092:     if (array[i - 1] == array[i]) {
78092:       collisions++;
78092:     }
78092:   }
78092:   LOG(("%d collisions in the set", collisions));
78092: #endif
78092: 
78087:   if (array.IsEmpty()) {
86944:     // DB is empty, put a sentinel to show that we loaded it
86944:     if (!array.AppendElement(0)) {
86944:       goto error_bailout;
86944:     }
86944:   }
86944:   // SetPrefixes requires sorted arrays
86944:   array.Sort();
86944: 
86944:   // construct new prefixset
78086:   rv = mPrefixSet->SetPrefixes(array.Elements(), array.Length());
86944:   if (NS_FAILED(rv)) {
86944:     goto error_bailout;
86944:   }
78090: 
78090:   // store the new tree to disk
78090:   rv = mPrefixSet->StoreToFile(mPSFile);
78090:   NS_WARN_IF_FALSE(NS_SUCCEEDED(rv), "failed to store the prefixset");
78090: 
78090:   return NS_OK;
86944: 
86944:  error_bailout:
86944:   // load an empty prefixset so the browser can work
86944:   nsAutoTArray<PRUint32, 1> sentinel;
86944:   sentinel.Clear();
86944:   sentinel.AppendElement(0);
86944:   mPrefixSet->SetPrefixes(sentinel.Elements(), sentinel.Length());
86944:   if (rv == NS_ERROR_OUT_OF_MEMORY) {
86944:     Telemetry::Accumulate(Telemetry::URLCLASSIFIER_PS_OOM, 1);
86944:   }
86944:   return rv;
78090: }
78090: 
78090: nsresult
78090: nsUrlClassifierDBServiceWorker::LoadPrefixSet(nsCOMPtr<nsIFile> & aFile)
78090: {
79445:   bool empty;
78090:   nsresult rv = mPrefixSet->IsEmpty(&empty);
78090:   NS_ENSURE_SUCCESS(rv, rv);
78090: 
78090:   if (!empty) {
78090:     LOG(("PrefixSet already loaded, not loading again"));
78090:     return NS_OK;
78090:   }
78090: 
79445:   bool exists;
78090:   rv = aFile->Exists(&exists);
78090:   NS_ENSURE_SUCCESS(rv, rv);
78090: 
78092: #if defined(PR_LOGGING)
78092:   PRIntervalTime clockStart = 0;
78092:   if (LOG_ENABLED()) {
78092:     clockStart = PR_IntervalNow();
78092:   }
78092: #endif
78092: 
78090:   if (exists) {
78093:     Telemetry::AutoTimer<Telemetry::URLCLASSIFIER_PS_FILELOAD_TIME> timer;
78090:     LOG(("stored PrefixSet exists, loading from disk"));
78090:     rv = mPrefixSet->LoadFromFile(aFile);
78090:   }
78090:   if (!exists || NS_FAILED(rv)) {
78090:     LOG(("no (usable) stored PrefixSet found, constructing from store"));
83144:     rv = ConstructPrefixSet();
83144:     NS_ENSURE_SUCCESS(rv, rv);
78090:   }
78090: 
78086: #ifdef DEBUG
84704:   LOG(("SB tree done, size = %d bytes\n",
84704:        mPrefixSet->SizeOfIncludingThis(moz_malloc_size_of)));
78086: #endif
78092: #if defined(PR_LOGGING)
78092:   if (LOG_ENABLED()) {
78092:     PRIntervalTime clockEnd = PR_IntervalNow();
78092:     LOG(("Loading took %dms\n",
78092:          PR_IntervalToMilliseconds(clockEnd - clockStart)));
78092:   }
78092: #endif
78086: 
 4001:   return NS_OK;
 4001: }
 4001: 
 4001: nsresult
 4024: nsUrlClassifierDBServiceWorker::MaybeCreateTables(mozIStorageConnection* connection)
 4001: {
 4024:   LOG(("MaybeCreateTables\n"));
 4024: 
 4024:   nsresult rv = connection->ExecuteSimpleSQL(
 4024:     NS_LITERAL_CSTRING("CREATE TABLE IF NOT EXISTS moz_classifier"
 4024:                        " (id INTEGER PRIMARY KEY,"
 4024:                        "  domain BLOB,"
10941:                        "  partial_data BLOB,"
10941:                        "  complete_data BLOB,"
10941:                        "  chunk_id INTEGER,"
 4024:                        "  table_id INTEGER)"));
 4024:   NS_ENSURE_SUCCESS(rv, rv);
 4024: 
 4024:   rv = connection->ExecuteSimpleSQL(
10941:     NS_LITERAL_CSTRING("CREATE INDEX IF NOT EXISTS"
 4024:                        " moz_classifier_domain_index"
10941:                        " ON moz_classifier(domain)"));
 4024:   NS_ENSURE_SUCCESS(rv, rv);
 4024: 
 4024:   rv = connection->ExecuteSimpleSQL(
10941:     NS_LITERAL_CSTRING("CREATE INDEX IF NOT EXISTS"
10941:                        " moz_classifier_chunk_index"
10941:                        " ON moz_classifier(chunk_id)"));
10212:   NS_ENSURE_SUCCESS(rv, rv);
10212: 
10212:   rv = connection->ExecuteSimpleSQL(
10212:     NS_LITERAL_CSTRING("CREATE TABLE IF NOT EXISTS moz_subs"
10212:                        " (id INTEGER PRIMARY KEY,"
10212:                        "  domain BLOB,"
10941:                        "  partial_data BLOB,"
10941:                        "  complete_data BLOB,"
10941:                        "  chunk_id INTEGER,"
10941:                        "  table_id INTEGER,"
10941:                        "  add_chunk_id INTEGER)"));
10865:   NS_ENSURE_SUCCESS(rv, rv);
10865: 
10865:   rv = connection->ExecuteSimpleSQL(
10941:     NS_LITERAL_CSTRING("CREATE INDEX IF NOT EXISTS"
20649:                        " moz_subs_addchunk_index"
20649:                        " ON moz_subs(add_chunk_id)"));
10865:   NS_ENSURE_SUCCESS(rv, rv);
10865: 
10865:   rv = connection->ExecuteSimpleSQL(
10941:     NS_LITERAL_CSTRING("CREATE INDEX IF NOT EXISTS"
10941:                        " moz_subs_chunk_index"
10941:                        " ON moz_subs(chunk_id)"));
10212:   NS_ENSURE_SUCCESS(rv, rv);
10212: 
10212:   rv = connection->ExecuteSimpleSQL(
 4024:     NS_LITERAL_CSTRING("CREATE TABLE IF NOT EXISTS moz_tables"
 4024:                        " (id INTEGER PRIMARY KEY,"
 4024:                        "  name TEXT,"
 4024:                        "  add_chunks TEXT,"
 4024:                        "  sub_chunks TEXT);"));
 4024:   NS_ENSURE_SUCCESS(rv, rv);
 4024: 
 4024:   return rv;
    1: }
    1: 
    1: // -------------------------------------------------------------------------
10941: // nsUrlClassifierLookupCallback
10941: //
10941: // This class takes the results of a lookup found on the worker thread
10941: // and handles any necessary partial hash expansions before calling
10941: // the client callback.
10941: 
10941: class nsUrlClassifierLookupCallback : public nsIUrlClassifierLookupCallback
10941:                                     , public nsIUrlClassifierHashCompleterCallback
10941: {
10941: public:
10941:   NS_DECL_ISUPPORTS
10941:   NS_DECL_NSIURLCLASSIFIERLOOKUPCALLBACK
10941:   NS_DECL_NSIURLCLASSIFIERHASHCOMPLETERCALLBACK
10941: 
10941:   nsUrlClassifierLookupCallback(nsUrlClassifierDBService *dbservice,
10941:                                 nsIUrlClassifierCallback *c)
10941:     : mDBService(dbservice)
10941:     , mResults(nsnull)
10941:     , mPendingCompletions(0)
10941:     , mCallback(c)
10941:     {}
10941: 
10941: private:
10941:   nsresult HandleResults();
10941: 
10941:   nsRefPtr<nsUrlClassifierDBService> mDBService;
10941:   nsAutoPtr<nsTArray<nsUrlClassifierLookupResult> > mResults;
10988: 
10988:   // Completed results to send back to the worker for caching.
10988:   nsAutoPtr<nsTArray<nsUrlClassifierLookupResult> > mCacheResults;
10988: 
10941:   PRUint32 mPendingCompletions;
10941:   nsCOMPtr<nsIUrlClassifierCallback> mCallback;
10941: };
10941: 
10941: NS_IMPL_THREADSAFE_ISUPPORTS2(nsUrlClassifierLookupCallback,
10941:                               nsIUrlClassifierLookupCallback,
10941:                               nsIUrlClassifierHashCompleterCallback)
10941: 
10941: NS_IMETHODIMP
10941: nsUrlClassifierLookupCallback::LookupComplete(nsTArray<nsUrlClassifierLookupResult>* results)
10941: {
10941:   NS_ASSERTION(mResults == nsnull,
10941:                "Should only get one set of results per nsUrlClassifierLookupCallback!");
10941: 
10941:   if (!results) {
10941:     HandleResults();
10941:     return NS_OK;
10941:   }
10941: 
10941:   mResults = results;
12334:   mResults->Sort();
10941: 
14354:   // Check the results entries that need to be completed.
10941:   for (PRUint32 i = 0; i < results->Length(); i++) {
10941:     nsUrlClassifierLookupResult& result = results->ElementAt(i);
14354: 
14354:     // We will complete partial matches and matches that are stale.
10941:     if (!result.mConfirmed) {
10941:       nsCOMPtr<nsIUrlClassifierHashCompleter> completer;
10941:       if (mDBService->GetCompleter(result.mTableName,
10941:                                    getter_AddRefs(completer))) {
10941:         nsCAutoString partialHash;
14354:         PRUint8 *buf =
14354:           result.mEntry.mHavePartial ? result.mEntry.mPartialHash.buf
14354:                                      : result.mEntry.mCompleteHash.buf;
14354:         partialHash.Assign(reinterpret_cast<char*>(buf), PARTIAL_LENGTH);
10941: 
10941:         nsresult rv = completer->Complete(partialHash, this);
10941:         if (NS_SUCCEEDED(rv)) {
10941:           mPendingCompletions++;
10941:         }
10941:       } else {
14354:         // For tables with no hash completer, a complete hash match is
14354:         // good enough, it doesn't need to be fresh. (we need the
14354:         // mLookupFragment comparison to weed out noise entries, which
14354:         // should never be confirmed).
14354:         if (result.mEntry.mHaveComplete
14354:             && (result.mLookupFragment == result.mEntry.mCompleteHash)) {
80486:           result.mConfirmed = true;
14354:         } else {
10941:           NS_WARNING("Partial match in a table without a valid completer, ignoring partial match.");
10941:         }
10941:       }
10941:     }
14354:   }
10941: 
10941:   if (mPendingCompletions == 0) {
10941:     // All results were complete, we're ready!
10941:     HandleResults();
10941:   }
10941: 
10941:   return NS_OK;
10941: }
10941: 
10941: NS_IMETHODIMP
10941: nsUrlClassifierLookupCallback::CompletionFinished(nsresult status)
10941: {
10941:   LOG(("nsUrlClassifierLookupCallback::CompletionFinished [%p, %08x]",
10941:        this, status));
10941:   if (NS_FAILED(status)) {
10941:     NS_WARNING("gethash response failed.");
10941:   }
10941: 
10941:   mPendingCompletions--;
10941:   if (mPendingCompletions == 0) {
10941:     HandleResults();
10988: 
10988:     if (mCacheResults) {
10988:       // This hands ownership of the cache results array back to the worker
10988:       // thread.
10988:       mDBService->CacheCompletions(mCacheResults.forget());
10988:     }
10941:   }
10941: 
10941:   return NS_OK;
10941: }
10941: 
10941: NS_IMETHODIMP
10941: nsUrlClassifierLookupCallback::Completion(const nsACString& completeHash,
10941:                                           const nsACString& tableName,
12346:                                           PRUint32 chunkId,
79445:                                           bool verified)
10941: {
14354:   LOG(("nsUrlClassifierLookupCallback::Completion [%p, %s, %d, %d]",
14354:        this, PromiseFlatCString(tableName).get(), chunkId, verified));
10941:   nsUrlClassifierCompleteHash hash;
10941:   hash.Assign(completeHash);
10941: 
10941:   for (PRUint32 i = 0; i < mResults->Length(); i++) {
10941:     nsUrlClassifierLookupResult& result = mResults->ElementAt(i);
10941: 
14354:     // First, see if this result can be used to update an entry.
14354:     if (verified &&
14354:         !result.mEntry.mHaveComplete &&
10941:         hash.StartsWith(result.mEntry.mPartialHash) &&
10941:         result.mTableName == tableName &&
10941:         result.mEntry.mChunkId == chunkId) {
10941:       // We have a completion for this entry.  Fill it in...
10941:       result.mEntry.SetHash(hash);
10941: 
10988:       if (!mCacheResults) {
10988:         mCacheResults = new nsTArray<nsUrlClassifierLookupResult>();
10988:         if (!mCacheResults)
10988:           return NS_ERROR_OUT_OF_MEMORY;
10988:       }
10988: 
10988:       mCacheResults->AppendElement(result);
10941:     }
14354: 
14354:     // Now, see if it verifies a lookup
14354:     if (result.mLookupFragment == hash) {
80486:       result.mConfirmed = true;
14354: 
14354:       if (result.mTableName != tableName ||
14354:           result.mEntry.mChunkId != chunkId) {
12580:         // The hash we got for this completion matches the hash we
12580:         // looked up, but doesn't match the table/chunk id.  This could
12580:         // happen in rare cases where a given URL was moved between
12580:         // lists or added/removed/re-added to the list in the time since
12580:         // we've updated.
12580:         //
12580:         // Update the lookup result, but don't update the entry or try
14354:         // cache the results of this completion, as it might confuse
12580:         // things.
12580:         result.mTableName = tableName;
12580:         NS_WARNING("Accepting a gethash with an invalid table name or chunk id");
78092:         LOG(("Tablename: %s ?= %s, ChunkId %d ?= %d",
78092:              result.mTableName.get(), PromiseFlatCString(tableName).get(),
78092:              result.mEntry.mChunkId, chunkId));
10941:       }
12346:     }
14354:   }
10941: 
10941:   return NS_OK;
10941: }
10941: 
10941: nsresult
10941: nsUrlClassifierLookupCallback::HandleResults()
10941: {
10941:   if (!mResults) {
10941:     // No results, this URI is clean.
10941:     return mCallback->HandleEvent(NS_LITERAL_CSTRING(""));
10941:   }
10941: 
10941:   // Build a stringified list of result tables.
10941:   mResults->Sort();
10941:   PRUint32 lastTableId = 0;
10941:   nsCAutoString tables;
10941:   for (PRUint32 i = 0; i < mResults->Length(); i++) {
10941:     nsUrlClassifierLookupResult& result = mResults->ElementAt(i);
10941:     // Leave out results that weren't confirmed, as their existence on
12334:     // the list can't be verified.  Also leave out randomly-generated
12334:     // noise.
12334:     if (!result.mConfirmed || result.mNoise)
10941:       continue;
10941: 
10941:     if (tables.Length() > 0) {
10941:       if (lastTableId == result.mEntry.mTableId)
10941:         continue;
10941:       tables.Append(",");
10941:     }
10941: 
10941:     tables.Append(result.mTableName);
10941:     lastTableId = result.mEntry.mTableId;
10941:   }
10941: 
10941:   return mCallback->HandleEvent(tables);
10941: }
10941: 
10941: 
10941: // -------------------------------------------------------------------------
 5528: // Helper class for nsIURIClassifier implementation, translates table names
 5528: // to nsIURIClassifier enums.
 5528: 
 5528: class nsUrlClassifierClassifyCallback : public nsIUrlClassifierCallback
 5528: {
 5528: public:
 5528:   NS_DECL_ISUPPORTS
 5528:   NS_DECL_NSIURLCLASSIFIERCALLBACK
 5528: 
 8643:   nsUrlClassifierClassifyCallback(nsIURIClassifierCallback *c,
79445:                                   bool checkMalware,
79445:                                   bool checkPhishing)
 5528:     : mCallback(c)
 8643:     , mCheckMalware(checkMalware)
 8643:     , mCheckPhishing(checkPhishing)
 5528:     {}
 5528: 
 5528: private:
 5528:   nsCOMPtr<nsIURIClassifierCallback> mCallback;
79445:   bool mCheckMalware;
79445:   bool mCheckPhishing;
 5528: };
 5528: 
 5528: NS_IMPL_THREADSAFE_ISUPPORTS1(nsUrlClassifierClassifyCallback,
 5530:                               nsIUrlClassifierCallback)
 5528: 
 5528: NS_IMETHODIMP
 5528: nsUrlClassifierClassifyCallback::HandleEvent(const nsACString& tables)
 5528: {
 5528:   // XXX: we should probably have the wardens tell the service which table
 5528:   // names match with which classification.  For now the table names give
 5528:   // enough information.
 5528:   nsresult response = NS_OK;
 5528: 
 5528:   nsACString::const_iterator begin, end;
 5528: 
 5528:   tables.BeginReading(begin);
 5528:   tables.EndReading(end);
 8643:   if (mCheckMalware &&
 8643:       FindInReadable(NS_LITERAL_CSTRING("-malware-"), begin, end)) {
 5528:     response = NS_ERROR_MALWARE_URI;
 7236:   } else {
 7236:     // Reset begin before checking phishing table
 7236:     tables.BeginReading(begin);
 7236: 
 8643:     if (mCheckPhishing &&
 8643:         FindInReadable(NS_LITERAL_CSTRING("-phish-"), begin, end)) {
 7236:       response = NS_ERROR_PHISHING_URI;
 7236:     }
 5528:   }
 5528: 
 5528:   mCallback->OnClassifyComplete(response);
 5528: 
 5528:   return NS_OK;
 5528: }
 5528: 
 5528: 
 5528: // -------------------------------------------------------------------------
    1: // Proxy class implementation
    1: 
 5528: NS_IMPL_THREADSAFE_ISUPPORTS3(nsUrlClassifierDBService,
    1:                               nsIUrlClassifierDBService,
 5528:                               nsIURIClassifier,
    1:                               nsIObserver)
    1: 
    1: /* static */ nsUrlClassifierDBService*
 9868: nsUrlClassifierDBService::GetInstance(nsresult *result)
    1: {
 9868:   *result = NS_OK;
    1:   if (!sUrlClassifierDBService) {
    1:     sUrlClassifierDBService = new nsUrlClassifierDBService();
 9868:     if (!sUrlClassifierDBService) {
 9868:       *result = NS_ERROR_OUT_OF_MEMORY;
    1:       return nsnull;
 9868:     }
    1: 
    1:     NS_ADDREF(sUrlClassifierDBService);   // addref the global
    1: 
 9868:     *result = sUrlClassifierDBService->Init();
 9868:     if (NS_FAILED(*result)) {
    1:       NS_RELEASE(sUrlClassifierDBService);
    1:       return nsnull;
    1:     }
    1:   } else {
    1:     // Already exists, just add a ref
    1:     NS_ADDREF(sUrlClassifierDBService);   // addref the return result
    1:   }
    1:   return sUrlClassifierDBService;
    1: }
    1: 
    1: 
    1: nsUrlClassifierDBService::nsUrlClassifierDBService()
 5528:  : mCheckMalware(CHECK_MALWARE_DEFAULT)
 8643:  , mCheckPhishing(CHECK_PHISHING_DEFAULT)
80486:  , mInUpdate(false)
    1: {
    1: }
    1: 
    1: nsUrlClassifierDBService::~nsUrlClassifierDBService()
    1: {
    1:   sUrlClassifierDBService = nsnull;
    1: }
    1: 
    1: nsresult
    1: nsUrlClassifierDBService::Init()
    1: {
    1: #if defined(PR_LOGGING)
    1:   if (!gUrlClassifierDbServiceLog)
    1:     gUrlClassifierDbServiceLog = PR_NewLogModule("UrlClassifierDbService");
    1: #endif
    1: 
    1:   // Force the storage service to be created on the main thread.
    1:   nsresult rv;
    1:   nsCOMPtr<mozIStorageService> storageService =
    1:     do_GetService(MOZ_STORAGE_SERVICE_CONTRACTID, &rv);
    1:   NS_ENSURE_SUCCESS(rv, rv);
    1: 
 4432:   // Force PSM to be loaded on the main thread.
78087:   mHash = do_CreateInstance(NS_CRYPTO_HASH_CONTRACTID, &rv);
 4432:   NS_ENSURE_SUCCESS(rv, rv);
 4432: 
78087:   mPrefixSet = new nsUrlClassifierPrefixSet();
78086:   NS_ENSURE_SUCCESS(rv, rv);
78086: 
 5528:   // Should we check document loads for malware URIs?
 5528:   nsCOMPtr<nsIPrefBranch2> prefs = do_GetService(NS_PREFSERVICE_CONTRACTID);
 5528: 
12334:   PRInt32 gethashNoise = 0;
 5528:   if (prefs) {
79445:     bool tmpbool;
 5528:     rv = prefs->GetBoolPref(CHECK_MALWARE_PREF, &tmpbool);
 5528:     mCheckMalware = NS_SUCCEEDED(rv) ? tmpbool : CHECK_MALWARE_DEFAULT;
 5528: 
80486:     prefs->AddObserver(CHECK_MALWARE_PREF, this, false);
 8643: 
 8643:     rv = prefs->GetBoolPref(CHECK_PHISHING_PREF, &tmpbool);
 8643:     mCheckPhishing = NS_SUCCEEDED(rv) ? tmpbool : CHECK_PHISHING_DEFAULT;
 8643: 
80486:     prefs->AddObserver(CHECK_PHISHING_PREF, this, false);
12334: 
12334:     if (NS_FAILED(prefs->GetIntPref(GETHASH_NOISE_PREF, &gethashNoise))) {
12334:       gethashNoise = GETHASH_NOISE_DEFAULT;
12334:     }
14354: 
14354:     nsXPIDLCString tmpstr;
14354:     if (NS_SUCCEEDED(prefs->GetCharPref(GETHASH_TABLES_PREF, getter_Copies(tmpstr)))) {
14354:       SplitTables(tmpstr, mGethashWhitelist);
14354:     }
14354: 
80486:     prefs->AddObserver(GETHASH_TABLES_PREF, this, false);
14354: 
14354:     PRInt32 tmpint;
14354:     rv = prefs->GetIntPref(CONFIRM_AGE_PREF, &tmpint);
64101:     PR_ATOMIC_SET(&gFreshnessGuarantee, NS_SUCCEEDED(rv) ? tmpint : CONFIRM_AGE_DEFAULT_SEC);
14354: 
80486:     prefs->AddObserver(CONFIRM_AGE_PREF, this, false);
14354: 
14883:     rv = prefs->GetIntPref(UPDATE_CACHE_SIZE_PREF, &tmpint);
64101:     PR_ATOMIC_SET(&gUpdateCacheSize, NS_SUCCEEDED(rv) ? tmpint : UPDATE_CACHE_SIZE_DEFAULT);
15023: 
78088:     rv = prefs->GetIntPref(LOOKUP_CACHE_SIZE_PREF, &tmpint);
78088:     PR_ATOMIC_SET(&gLookupCacheSize, NS_SUCCEEDED(rv) ? tmpint : LOOKUP_CACHE_SIZE_DEFAULT);
78088: 
15023:     rv = prefs->GetIntPref(UPDATE_WORKING_TIME, &tmpint);
64101:     PR_ATOMIC_SET(&gWorkingTimeThreshold,
15023:                   NS_SUCCEEDED(rv) ? tmpint : UPDATE_WORKING_TIME_DEFAULT);
15023: 
15023:     rv = prefs->GetIntPref(UPDATE_DELAY_TIME, &tmpint);
64101:     PR_ATOMIC_SET(&gDelayTime,
15023:                   NS_SUCCEEDED(rv) ? tmpint : UPDATE_DELAY_TIME_DEFAULT);
 5528:   }
 5528: 
    1:   // Start the background thread.
    1:   rv = NS_NewThread(&gDbBackgroundThread);
    1:   if (NS_FAILED(rv))
    1:     return rv;
    1: 
    1:   mWorker = new nsUrlClassifierDBServiceWorker();
    1:   if (!mWorker)
    1:     return NS_ERROR_OUT_OF_MEMORY;
    1: 
78086:   rv = mWorker->Init(gethashNoise, mPrefixSet);
 4024:   if (NS_FAILED(rv)) {
 4024:     mWorker = nsnull;
 4024:     return rv;
 4024:   }
 4024: 
10213:   // Proxy for calling the worker on the background thread
76882:   mWorkerProxy = new UrlClassifierDBServiceWorkerProxy(mWorker);
10213: 
10941:   mCompleters.Init();
10941: 
    1:   // Add an observer for shutdown
    1:   nsCOMPtr<nsIObserverService> observerService =
41540:       mozilla::services::GetObserverService();
    1:   if (!observerService)
    1:     return NS_ERROR_FAILURE;
    1: 
80486:   observerService->AddObserver(this, "profile-before-change", false);
80486:   observerService->AddObserver(this, "xpcom-shutdown-threads", false);
    1: 
    1:   return NS_OK;
    1: }
    1: 
 5528: NS_IMETHODIMP
 5528: nsUrlClassifierDBService::Classify(nsIURI *uri,
 5528:                                    nsIURIClassifierCallback* c,
79445:                                    bool* result)
 5528: {
 5528:   NS_ENSURE_TRUE(gDbBackgroundThread, NS_ERROR_NOT_INITIALIZED);
 5528: 
 8643:   if (!(mCheckMalware || mCheckPhishing)) {
80486:     *result = false;
 5528:     return NS_OK;
 5528:   }
 5528: 
 5528:   nsRefPtr<nsUrlClassifierClassifyCallback> callback =
 8643:     new nsUrlClassifierClassifyCallback(c, mCheckMalware, mCheckPhishing);
 5528:   if (!callback) return NS_ERROR_OUT_OF_MEMORY;
 5528: 
80486:   nsresult rv = LookupURI(uri, callback, false, result);
 8378:   if (rv == NS_ERROR_MALFORMED_URI) {
80486:     *result = false;
19928:     // The URI had no hostname, don't try to classify it.
 8378:     return NS_OK;
 8378:   }
12006:   NS_ENSURE_SUCCESS(rv, rv);
 8378: 
 8378:   return NS_OK;
 5528: }
 5528: 
 5528: NS_IMETHODIMP
 4024: nsUrlClassifierDBService::Lookup(const nsACString& spec,
10941:                                  nsIUrlClassifierCallback* c)
 4024: {
 4024:   NS_ENSURE_TRUE(gDbBackgroundThread, NS_ERROR_NOT_INITIALIZED);
 4024: 
 4024:   nsCOMPtr<nsIURI> uri;
 4024: 
 4024:   nsresult rv = NS_NewURI(getter_AddRefs(uri), spec);
 4024:   NS_ENSURE_SUCCESS(rv, rv);
 4024: 
 4024:   uri = NS_GetInnermostURI(uri);
 4024:   if (!uri) {
 4024:     return NS_ERROR_FAILURE;
 4024:   }
 4024: 
79445:   bool didLookup;
80486:   return LookupURI(uri, c, true, &didLookup);
 5528: }
 5528: 
 5528: nsresult
 5528: nsUrlClassifierDBService::LookupURI(nsIURI* uri,
20648:                                     nsIUrlClassifierCallback* c,
79445:                                     bool forceLookup,
79445:                                     bool *didLookup)
 5528: {
 5528:   NS_ENSURE_TRUE(gDbBackgroundThread, NS_ERROR_NOT_INITIALIZED);
 5528: 
 4024:   nsCAutoString key;
 4024:   // Canonicalize the url
 4024:   nsCOMPtr<nsIUrlClassifierUtils> utilsService =
 4024:     do_GetService(NS_URLCLASSIFIERUTILS_CONTRACTID);
 5528:   nsresult rv = utilsService->GetKeyForURI(uri, key);
12006:   if (NS_FAILED(rv))
12006:     return rv;
 4024: 
20648:   if (forceLookup) {
80486:     *didLookup = true;
20648:   } else {
78091:     // Check if the URI is clean.  If so, we don't need to
78091:     // bother queueing up a lookup, we can just return.;
79445:     bool clean;
78091:     rv = CheckClean(key, &clean);
20648:     NS_ENSURE_SUCCESS(rv, rv);
20648: 
69312:     if (!clean) {
69312:       nsCOMPtr<nsIPermissionManager> permissionManager =
69312:         do_GetService(NS_PERMISSIONMANAGER_CONTRACTID);
69312: 
69312:       if (permissionManager) {
69312:         PRUint32 perm;
69312:         permissionManager->TestPermission(uri, "safe-browsing", &perm);
69312:         clean |= (perm == nsIPermissionManager::ALLOW_ACTION);
69312:       }
69312:     }
69312: 
20648:     *didLookup = !clean;
20648:     if (clean) {
20648:       return NS_OK;
20648:     }
20648:   }
20648: 
10941:   // Create an nsUrlClassifierLookupCallback object.  This object will
10941:   // take care of confirming partial hash matches if necessary before
10941:   // calling the client's callback.
10941:   nsCOMPtr<nsIUrlClassifierLookupCallback> callback =
10941:     new nsUrlClassifierLookupCallback(this, c);
10941:   if (!callback)
10941:     return NS_ERROR_OUT_OF_MEMORY;
10941: 
76882:   nsCOMPtr<nsIUrlClassifierLookupCallback> proxyCallback =
76882:     new UrlClassifierLookupCallbackProxy(callback);
 4024: 
 4024:   // Queue this lookup and call the lookup function to flush the queue if
 4024:   // necessary.
 4024:   rv = mWorker->QueueLookup(key, proxyCallback);
 4024:   NS_ENSURE_SUCCESS(rv, rv);
 4024: 
10941:   return mWorkerProxy->Lookup(EmptyCString(), nsnull);
 4024: }
 4024: 
    1: NS_IMETHODIMP
 4024: nsUrlClassifierDBService::GetTables(nsIUrlClassifierCallback* c)
    1: {
    1:   NS_ENSURE_TRUE(gDbBackgroundThread, NS_ERROR_NOT_INITIALIZED);
    1: 
    1:   // The proxy callback uses the current thread.
76882:   nsCOMPtr<nsIUrlClassifierCallback> proxyCallback =
76882:     new UrlClassifierCallbackProxy(c);
    1: 
10213:   return mWorkerProxy->GetTables(proxyCallback);
 4001: }
 4001: 
 4001: NS_IMETHODIMP
10941: nsUrlClassifierDBService::SetHashCompleter(const nsACString &tableName,
10941:                                            nsIUrlClassifierHashCompleter *completer)
10941: {
10941:   if (completer) {
10941:     if (!mCompleters.Put(tableName, completer)) {
10941:       return NS_ERROR_OUT_OF_MEMORY;
10941:     }
10941:   } else {
10941:     mCompleters.Remove(tableName);
10941:   }
10941: 
10941:   return NS_OK;
10941: }
10941: 
10941: NS_IMETHODIMP
12346: nsUrlClassifierDBService::BeginUpdate(nsIUrlClassifierUpdateObserver *observer,
14354:                                       const nsACString &updateTables,
12346:                                       const nsACString &clientKey)
 4001: {
 4001:   NS_ENSURE_TRUE(gDbBackgroundThread, NS_ERROR_NOT_INITIALIZED);
 4001: 
10582:   if (mInUpdate)
10582:     return NS_ERROR_NOT_AVAILABLE;
10582: 
80486:   mInUpdate = true;
10582: 
10213:   // The proxy observer uses the current thread
76882:   nsCOMPtr<nsIUrlClassifierUpdateObserver> proxyObserver =
76882:     new UrlClassifierUpdateObserverProxy(observer);
 4001: 
14354:   return mWorkerProxy->BeginUpdate(proxyObserver, updateTables, clientKey);
 4001: }
 4001: 
 4001: NS_IMETHODIMP
12346: nsUrlClassifierDBService::BeginStream(const nsACString &table,
12346:                                       const nsACString &serverMAC)
 4001: {
 4001:   NS_ENSURE_TRUE(gDbBackgroundThread, NS_ERROR_NOT_INITIALIZED);
 4001: 
12346:   return mWorkerProxy->BeginStream(table, serverMAC);
 4024: }
 4024: 
10213: NS_IMETHODIMP
10213: nsUrlClassifierDBService::UpdateStream(const nsACString& aUpdateChunk)
10213: {
10213:   NS_ENSURE_TRUE(gDbBackgroundThread, NS_ERROR_NOT_INITIALIZED);
10213: 
10213:   return mWorkerProxy->UpdateStream(aUpdateChunk);
 4024: }
 4001: 
10213: NS_IMETHODIMP
10213: nsUrlClassifierDBService::FinishStream()
10213: {
10213:   NS_ENSURE_TRUE(gDbBackgroundThread, NS_ERROR_NOT_INITIALIZED);
10213: 
10213:   return mWorkerProxy->FinishStream();
10213: }
10213: 
10213: NS_IMETHODIMP
10213: nsUrlClassifierDBService::FinishUpdate()
10213: {
10213:   NS_ENSURE_TRUE(gDbBackgroundThread, NS_ERROR_NOT_INITIALIZED);
10213: 
80486:   mInUpdate = false;
10582: 
10213:   return mWorkerProxy->FinishUpdate();
10213: }
10213: 
10213: 
10213: NS_IMETHODIMP
10213: nsUrlClassifierDBService::CancelUpdate()
10213: {
10213:   NS_ENSURE_TRUE(gDbBackgroundThread, NS_ERROR_NOT_INITIALIZED);
10213: 
80486:   mInUpdate = false;
10582: 
10213:   return mWorkerProxy->CancelUpdate();
    1: }
    1: 
    1: NS_IMETHODIMP
10212: nsUrlClassifierDBService::ResetDatabase()
10212: {
    1:   NS_ENSURE_TRUE(gDbBackgroundThread, NS_ERROR_NOT_INITIALIZED);
    1: 
10213:   return mWorkerProxy->ResetDatabase();
    1: }
    1: 
10995: nsresult
10988: nsUrlClassifierDBService::CacheCompletions(nsTArray<nsUrlClassifierLookupResult> *results)
10988: {
10988:   NS_ENSURE_TRUE(gDbBackgroundThread, NS_ERROR_NOT_INITIALIZED);
10988: 
10988:   return mWorkerProxy->CacheCompletions(results);
10988: }
10988: 
79445: bool
12571: nsUrlClassifierDBService::GetCompleter(const nsACString &tableName,
12571:                                        nsIUrlClassifierHashCompleter **completer)
12571: {
12571:   if (mCompleters.Get(tableName, completer)) {
80486:     return true;
12571:   }
12571: 
14354:   if (!mGethashWhitelist.Contains(tableName)) {
80486:     return false;
14354:   }
14354: 
12571:   return NS_SUCCEEDED(CallGetService(NS_URLCLASSIFIERHASHCOMPLETER_CONTRACTID,
12571:                                      completer));
12571: }
12571: 
10988: NS_IMETHODIMP
    1: nsUrlClassifierDBService::Observe(nsISupports *aSubject, const char *aTopic,
    1:                                   const PRUnichar *aData)
    1: {
 5528:   if (!strcmp(aTopic, NS_PREFBRANCH_PREFCHANGE_TOPIC_ID)) {
 5528:     nsresult rv;
 5528:     nsCOMPtr<nsIPrefBranch> prefs(do_QueryInterface(aSubject, &rv));
 5528:     NS_ENSURE_SUCCESS(rv, rv);
 5528:     if (NS_LITERAL_STRING(CHECK_MALWARE_PREF).Equals(aData)) {
79445:       bool tmpbool;
 5528:       rv = prefs->GetBoolPref(CHECK_MALWARE_PREF, &tmpbool);
 5528:       mCheckMalware = NS_SUCCEEDED(rv) ? tmpbool : CHECK_MALWARE_DEFAULT;
 8643:     } else if (NS_LITERAL_STRING(CHECK_PHISHING_PREF).Equals(aData)) {
79445:       bool tmpbool;
 8643:       rv = prefs->GetBoolPref(CHECK_PHISHING_PREF, &tmpbool);
 8643:       mCheckPhishing = NS_SUCCEEDED(rv) ? tmpbool : CHECK_PHISHING_DEFAULT;
14354:     } else if (NS_LITERAL_STRING(GETHASH_TABLES_PREF).Equals(aData)) {
14354:       mGethashWhitelist.Clear();
14354:       nsXPIDLCString val;
14354:       if (NS_SUCCEEDED(prefs->GetCharPref(GETHASH_TABLES_PREF, getter_Copies(val)))) {
14354:         SplitTables(val, mGethashWhitelist);
14354:       }
14354:     } else if (NS_LITERAL_STRING(CONFIRM_AGE_PREF).Equals(aData)) {
14354:       PRInt32 tmpint;
14354:       rv = prefs->GetIntPref(CONFIRM_AGE_PREF, &tmpint);
64101:       PR_ATOMIC_SET(&gFreshnessGuarantee, NS_SUCCEEDED(rv) ? tmpint : CONFIRM_AGE_DEFAULT_SEC);
14883:     } else if (NS_LITERAL_STRING(UPDATE_CACHE_SIZE_PREF).Equals(aData)) {
14883:       PRInt32 tmpint;
14883:       rv = prefs->GetIntPref(UPDATE_CACHE_SIZE_PREF, &tmpint);
64101:       PR_ATOMIC_SET(&gUpdateCacheSize, NS_SUCCEEDED(rv) ? tmpint : UPDATE_CACHE_SIZE_DEFAULT);
78088:     } else if (NS_LITERAL_STRING(LOOKUP_CACHE_SIZE_PREF).Equals(aData)) {
78088:       PRInt32 tmpint;
78088:       rv = prefs->GetIntPref(LOOKUP_CACHE_SIZE_PREF, &tmpint);
78088:       PR_ATOMIC_SET(&gLookupCacheSize, NS_SUCCEEDED(rv) ? tmpint : LOOKUP_CACHE_SIZE_DEFAULT);
15023:     } else if (NS_LITERAL_STRING(UPDATE_WORKING_TIME).Equals(aData)) {
15023:       PRInt32 tmpint;
15023:       rv = prefs->GetIntPref(UPDATE_WORKING_TIME, &tmpint);
64101:       PR_ATOMIC_SET(&gWorkingTimeThreshold,
15023:                     NS_SUCCEEDED(rv) ? tmpint : UPDATE_WORKING_TIME_DEFAULT);
15023:     } else if (NS_LITERAL_STRING(UPDATE_DELAY_TIME).Equals(aData)) {
15023:       PRInt32 tmpint;
15023:       rv = prefs->GetIntPref(UPDATE_DELAY_TIME, &tmpint);
64101:       PR_ATOMIC_SET(&gDelayTime,
15023:                     NS_SUCCEEDED(rv) ? tmpint : UPDATE_DELAY_TIME_DEFAULT);
 5528:     }
 5528:   } else if (!strcmp(aTopic, "profile-before-change") ||
 5528:              !strcmp(aTopic, "xpcom-shutdown-threads")) {
    1:     Shutdown();
 5528:   } else {
 5528:     return NS_ERROR_UNEXPECTED;
 5528:   }
 3338: 
    1:   return NS_OK;
    1: }
    1: 
    1: // Join the background thread if it exists.
    1: nsresult
    1: nsUrlClassifierDBService::Shutdown()
    1: {
 3338:   LOG(("shutting down db service\n"));
 3338: 
    1:   if (!gDbBackgroundThread)
    1:     return NS_OK;
    1: 
10941:   mCompleters.Clear();
10941: 
 5528:   nsCOMPtr<nsIPrefBranch2> prefs = do_GetService(NS_PREFSERVICE_CONTRACTID);
 5528:   if (prefs) {
 5528:     prefs->RemoveObserver(CHECK_MALWARE_PREF, this);
 8643:     prefs->RemoveObserver(CHECK_PHISHING_PREF, this);
14354:     prefs->RemoveObserver(GETHASH_TABLES_PREF, this);
14354:     prefs->RemoveObserver(CONFIRM_AGE_PREF, this);
 5528:   }
 5528: 
    1:   nsresult rv;
    1:   // First close the db connection.
    1:   if (mWorker) {
15023:     rv = mWorkerProxy->CancelUpdate();
29285:     NS_ASSERTION(NS_SUCCEEDED(rv), "failed to post cancel update event");
78090: 
10213:     rv = mWorkerProxy->CloseDb();
  762:     NS_ASSERTION(NS_SUCCEEDED(rv), "failed to post close db event");
  762:   }
10213: 
10213:   mWorkerProxy = nsnull;
10213: 
    1:   LOG(("joining background thread"));
    1: 
80486:   gShuttingDownThread = true;
10337: 
10337:   nsIThread *backgroundThread = gDbBackgroundThread;
10337:   gDbBackgroundThread = nsnull;
10337:   backgroundThread->Shutdown();
10337:   NS_RELEASE(backgroundThread);
    1: 
    1:   return NS_OK;
    1: }
76882: 
76882: nsIThread*
76882: nsUrlClassifierDBService::BackgroundThread()
76882: {
76882:   return gDbBackgroundThread;
76882: }
76882: 
