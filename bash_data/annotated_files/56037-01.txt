53414: /* -*- Mode: C++; tab-width: 8; indent-tabs-mode: nil; c-basic-offset: 4 -*-
53414:  * vim: set ts=8 sw=4 et tw=79:
53414:  *
53414:  * ***** BEGIN LICENSE BLOCK *****
50491:  * Copyright (C) 2009 University of Szeged
50491:  * All rights reserved.
50491:  *
50491:  * Redistribution and use in source and binary forms, with or without
50491:  * modification, are permitted provided that the following conditions
50491:  * are met:
50491:  * 1. Redistributions of source code must retain the above copyright
50491:  *    notice, this list of conditions and the following disclaimer.
50491:  * 2. Redistributions in binary form must reproduce the above copyright
50491:  *    notice, this list of conditions and the following disclaimer in the
50491:  *    documentation and/or other materials provided with the distribution.
50491:  *
50491:  * THIS SOFTWARE IS PROVIDED BY UNIVERSITY OF SZEGED ``AS IS'' AND ANY
50491:  * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
50491:  * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
50491:  * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL UNIVERSITY OF SZEGED OR
50491:  * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
50491:  * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
50491:  * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
50491:  * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
50491:  * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
50491:  * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
50491:  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
53414:  * 
53414:  * ***** END LICENSE BLOCK ***** */
50491: 
50491: #include "assembler/wtf/Platform.h"
50491: 
50491: #if ENABLE_ASSEMBLER && WTF_CPU_ARM_TRADITIONAL
50491: 
50491: #include "ARMAssembler.h"
50491: 
50491: namespace JSC {
50491: 
50491: // Patching helpers
50491: 
50491: void ARMAssembler::patchConstantPoolLoad(void* loadAddr, void* constPoolAddr)
50491: {
50491:     ARMWord *ldr = reinterpret_cast<ARMWord*>(loadAddr);
50491:     ARMWord diff = reinterpret_cast<ARMWord*>(constPoolAddr) - ldr;
50491:     ARMWord index = (*ldr & 0xfff) >> 1;
50491: 
50491:     ASSERT(diff >= 1);
50491:     if (diff >= 2 || index > 0) {
50491:         diff = (diff + index - 2) * sizeof(ARMWord);
50491:         ASSERT(diff <= 0xfff);
50491:         *ldr = (*ldr & ~0xfff) | diff;
50491:     } else
50491:         *ldr = (*ldr & ~(0xfff | ARMAssembler::DT_UP)) | sizeof(ARMWord);
50491: }
50491: 
50491: // Handle immediates
50491: 
50491: ARMWord ARMAssembler::getOp2(ARMWord imm)
50491: {
50491:     int rol;
50491: 
50491:     if (imm <= 0xff)
50491:         return OP2_IMM | imm;
50491: 
50491:     if ((imm & 0xff000000) == 0) {
50491:         imm <<= 8;
50491:         rol = 8;
50491:     }
50491:     else {
50491:         imm = (imm << 24) | (imm >> 8);
50491:         rol = 0;
50491:     }
50491: 
50491:     if ((imm & 0xff000000) == 0) {
50491:         imm <<= 8;
50491:         rol += 4;
50491:     }
50491: 
50491:     if ((imm & 0xf0000000) == 0) {
50491:         imm <<= 4;
50491:         rol += 2;
50491:     }
50491: 
50491:     if ((imm & 0xc0000000) == 0) {
50491:         imm <<= 2;
50491:         rol += 1;
50491:     }
50491: 
50491:     if ((imm & 0x00ffffff) == 0)
50491:         return OP2_IMM | (imm >> 24) | (rol << 8);
50491: 
50491:     return INVALID_IMM;
50491: }
50491: 
50491: int ARMAssembler::genInt(int reg, ARMWord imm, bool positive)
50491: {
50491:     // Step1: Search a non-immediate part
50491:     ARMWord mask;
50491:     ARMWord imm1;
50491:     ARMWord imm2;
50491:     int rol;
50491: 
50491:     mask = 0xff000000;
50491:     rol = 8;
50491:     while(1) {
50491:         if ((imm & mask) == 0) {
50491:             imm = (imm << rol) | (imm >> (32 - rol));
50491:             rol = 4 + (rol >> 1);
50491:             break;
50491:         }
50491:         rol += 2;
50491:         mask >>= 2;
50491:         if (mask & 0x3) {
50491:             // rol 8
50491:             imm = (imm << 8) | (imm >> 24);
50491:             mask = 0xff00;
50491:             rol = 24;
50491:             while (1) {
50491:                 if ((imm & mask) == 0) {
50491:                     imm = (imm << rol) | (imm >> (32 - rol));
50491:                     rol = (rol >> 1) - 8;
50491:                     break;
50491:                 }
50491:                 rol += 2;
50491:                 mask >>= 2;
50491:                 if (mask & 0x3)
50491:                     return 0;
50491:             }
50491:             break;
50491:         }
50491:     }
50491: 
50491:     ASSERT((imm & 0xff) == 0);
50491: 
50491:     if ((imm & 0xff000000) == 0) {
50491:         imm1 = OP2_IMM | ((imm >> 16) & 0xff) | (((rol + 4) & 0xf) << 8);
50491:         imm2 = OP2_IMM | ((imm >> 8) & 0xff) | (((rol + 8) & 0xf) << 8);
50491:     } else if (imm & 0xc0000000) {
50491:         imm1 = OP2_IMM | ((imm >> 24) & 0xff) | ((rol & 0xf) << 8);
50491:         imm <<= 8;
50491:         rol += 4;
50491: 
50491:         if ((imm & 0xff000000) == 0) {
50491:             imm <<= 8;
50491:             rol += 4;
50491:         }
50491: 
50491:         if ((imm & 0xf0000000) == 0) {
50491:             imm <<= 4;
50491:             rol += 2;
50491:         }
50491: 
50491:         if ((imm & 0xc0000000) == 0) {
50491:             imm <<= 2;
50491:             rol += 1;
50491:         }
50491: 
50491:         if ((imm & 0x00ffffff) == 0)
50491:             imm2 = OP2_IMM | (imm >> 24) | ((rol & 0xf) << 8);
50491:         else
50491:             return 0;
50491:     } else {
50491:         if ((imm & 0xf0000000) == 0) {
50491:             imm <<= 4;
50491:             rol += 2;
50491:         }
50491: 
50491:         if ((imm & 0xc0000000) == 0) {
50491:             imm <<= 2;
50491:             rol += 1;
50491:         }
50491: 
50491:         imm1 = OP2_IMM | ((imm >> 24) & 0xff) | ((rol & 0xf) << 8);
50491:         imm <<= 8;
50491:         rol += 4;
50491: 
50491:         if ((imm & 0xf0000000) == 0) {
50491:             imm <<= 4;
50491:             rol += 2;
50491:         }
50491: 
50491:         if ((imm & 0xc0000000) == 0) {
50491:             imm <<= 2;
50491:             rol += 1;
50491:         }
50491: 
50491:         if ((imm & 0x00ffffff) == 0)
50491:             imm2 = OP2_IMM | (imm >> 24) | ((rol & 0xf) << 8);
50491:         else
50491:             return 0;
50491:     }
50491: 
50491:     if (positive) {
50491:         mov_r(reg, imm1);
50491:         orr_r(reg, reg, imm2);
50491:     } else {
50491:         mvn_r(reg, imm1);
50491:         bic_r(reg, reg, imm2);
50491:     }
50491: 
50491:     return 1;
50491: }
50491: 
50491: ARMWord ARMAssembler::getImm(ARMWord imm, int tmpReg, bool invert)
50491: {
50491:     ARMWord tmp;
50491: 
50491:     // Do it by 1 instruction
50491:     tmp = getOp2(imm);
50491:     if (tmp != INVALID_IMM)
50491:         return tmp;
50491: 
50491:     tmp = getOp2(~imm);
50491:     if (tmp != INVALID_IMM) {
50491:         if (invert)
50491:             return tmp | OP2_INV_IMM;
50491:         mvn_r(tmpReg, tmp);
50491:         return tmpReg;
50491:     }
50491: 
50491:     return encodeComplexImm(imm, tmpReg);
50491: }
50491: 
50491: void ARMAssembler::moveImm(ARMWord imm, int dest)
50491: {
50491:     ARMWord tmp;
50491: 
50491:     // Do it by 1 instruction
50491:     tmp = getOp2(imm);
50491:     if (tmp != INVALID_IMM) {
50491:         mov_r(dest, tmp);
50491:         return;
50491:     }
50491: 
50491:     tmp = getOp2(~imm);
50491:     if (tmp != INVALID_IMM) {
50491:         mvn_r(dest, tmp);
50491:         return;
50491:     }
50491: 
50491:     encodeComplexImm(imm, dest);
50491: }
50491: 
50491: ARMWord ARMAssembler::encodeComplexImm(ARMWord imm, int dest)
50491: {
50491: #if WTF_ARM_ARCH_VERSION >= 7
50491:     ARMWord tmp = getImm16Op2(imm);
50491:     if (tmp != INVALID_IMM) {
50491:         movw_r(dest, tmp);
50491:         return dest;
50491:     }
50491:     movw_r(dest, getImm16Op2(imm & 0xffff));
50491:     movt_r(dest, getImm16Op2(imm >> 16));
50491:     return dest;
50491: #else
50491:     // Do it by 2 instruction
50491:     if (genInt(dest, imm, true))
50491:         return dest;
50491:     if (genInt(dest, ~imm, false))
50491:         return dest;
50491: 
50491:     ldr_imm(dest, imm);
50491:     return dest;
50491: #endif
50491: }
50491: 
50491: // Memory load/store helpers
50491: 
50693: void ARMAssembler::dataTransfer32(bool isLoad, RegisterID srcDst, RegisterID base, int32_t offset)
50491: {
50491:     if (offset >= 0) {
50491:         if (offset <= 0xfff)
50693:             dtr_u(isLoad, srcDst, base, offset);
50491:         else if (offset <= 0xfffff) {
50491:             add_r(ARMRegisters::S0, base, OP2_IMM | (offset >> 12) | (10 << 8));
50693:             dtr_u(isLoad, srcDst, ARMRegisters::S0, (offset & 0xfff));
50491:         } else {
53443:             moveImm(offset, ARMRegisters::S0);
53443:             dtr_ur(isLoad, srcDst, base, ARMRegisters::S0);
50491:         }
50491:     } else {
50491:         offset = -offset;
50491:         if (offset <= 0xfff)
50693:             dtr_d(isLoad, srcDst, base, offset);
50491:         else if (offset <= 0xfffff) {
50491:             sub_r(ARMRegisters::S0, base, OP2_IMM | (offset >> 12) | (10 << 8));
50693:             dtr_d(isLoad, srcDst, ARMRegisters::S0, (offset & 0xfff));
50491:         } else {
53443:             moveImm(offset, ARMRegisters::S0);
53443:             dtr_dr(isLoad, srcDst, base, ARMRegisters::S0);
50693:         }
50693:     }
50693: }
50693: 
50693: void ARMAssembler::dataTransfer8(bool isLoad, RegisterID srcDst, RegisterID base, int32_t offset)
50693: {
50693:     if (offset >= 0) {
50693:         if (offset <= 0xfff)
50693:             dtrb_u(isLoad, srcDst, base, offset);
50693:         else if (offset <= 0xfffff) {
50693:             add_r(ARMRegisters::S0, base, OP2_IMM | (offset >> 12) | (10 << 8));
50693:             dtrb_u(isLoad, srcDst, ARMRegisters::S0, (offset & 0xfff));
50693:         } else {
53443:             moveImm(offset, ARMRegisters::S0);
53443:             dtrb_ur(isLoad, srcDst, base, ARMRegisters::S0);
50693:         }
50693:     } else {
50693:         offset = -offset;
50693:         if (offset <= 0xfff)
50693:             dtrb_d(isLoad, srcDst, base, offset);
50693:         else if (offset <= 0xfffff) {
50693:             sub_r(ARMRegisters::S0, base, OP2_IMM | (offset >> 12) | (10 << 8));
50693:             dtrb_d(isLoad, srcDst, ARMRegisters::S0, (offset & 0xfff));
50693:         } else {
53443:             moveImm(offset, ARMRegisters::S0);
53443:             dtrb_dr(isLoad, srcDst, base, ARMRegisters::S0);
50491:         }
50491:     }
50491: }
50491: 
50491: void ARMAssembler::baseIndexTransfer32(bool isLoad, RegisterID srcDst, RegisterID base, RegisterID index, int scale, int32_t offset)
50491: {
50491:     ARMWord op2;
50491: 
50491:     ASSERT(scale >= 0 && scale <= 3);
50491:     op2 = lsl(index, scale);
50491: 
50491:     if (offset >= 0 && offset <= 0xfff) {
50491:         add_r(ARMRegisters::S0, base, op2);
50491:         dtr_u(isLoad, srcDst, ARMRegisters::S0, offset);
50491:         return;
50491:     }
50491:     if (offset <= 0 && offset >= -0xfff) {
50491:         add_r(ARMRegisters::S0, base, op2);
50491:         dtr_d(isLoad, srcDst, ARMRegisters::S0, -offset);
50491:         return;
50491:     }
50491: 
50491:     ldr_un_imm(ARMRegisters::S0, offset);
50491:     add_r(ARMRegisters::S0, ARMRegisters::S0, op2);
50491:     dtr_ur(isLoad, srcDst, base, ARMRegisters::S0);
50491: }
50491: 
50491: void ARMAssembler::doubleTransfer(bool isLoad, FPRegisterID srcDst, RegisterID base, int32_t offset)
50491: {
50491:     if (offset & 0x3) {
50491:         if (offset <= 0x3ff && offset >= 0) {
50491:             fdtr_u(isLoad, srcDst, base, offset >> 2);
50491:             return;
50491:         }
50491:         if (offset <= 0x3ffff && offset >= 0) {
50491:             add_r(ARMRegisters::S0, base, OP2_IMM | (offset >> 10) | (11 << 8));
50491:             fdtr_u(isLoad, srcDst, ARMRegisters::S0, (offset >> 2) & 0xff);
50491:             return;
50491:         }
50491:         offset = -offset;
50491: 
50491:         if (offset <= 0x3ff && offset >= 0) {
50491:             fdtr_d(isLoad, srcDst, base, offset >> 2);
50491:             return;
50491:         }
50491:         if (offset <= 0x3ffff && offset >= 0) {
50491:             sub_r(ARMRegisters::S0, base, OP2_IMM | (offset >> 10) | (11 << 8));
50491:             fdtr_d(isLoad, srcDst, ARMRegisters::S0, (offset >> 2) & 0xff);
50491:             return;
50491:         }
50491:         offset = -offset;
50491:     }
50491: 
50491:     // TODO: This is broken in the case that offset is unaligned. VFP can never
50491:     // perform unaligned accesses, even from an unaligned register base. (NEON
50491:     // can, but VFP isn't NEON. It is not advisable to interleave a NEON load
50491:     // with VFP code, so the best solution here is probably to perform an
50491:     // unaligned integer load, then move the result into VFP using VMOV.)
50491:     ASSERT((offset & 0x3) == 0);
50491: 
50491:     ldr_un_imm(ARMRegisters::S0, offset);
50491:     add_r(ARMRegisters::S0, ARMRegisters::S0, base);
50491:     fdtr_u(isLoad, srcDst, ARMRegisters::S0, 0);
50491: }
50491: 
50491: // Fix up the offsets and literal-pool loads in buffer. The buffer should
50491: // already contain the code from m_buffer.
50491: inline void ARMAssembler::fixUpOffsets(void * buffer)
50491: {
50491:     char * data = reinterpret_cast<char *>(buffer);
50491:     for (Jumps::Iterator iter = m_jumps.begin(); iter != m_jumps.end(); ++iter) {
50491:         // The last bit is set if the constant must be placed on constant pool.
50491:         int pos = (*iter) & (~0x1);
50491:         ARMWord* ldrAddr = reinterpret_cast<ARMWord*>(data + pos);
50491:         ARMWord* addr = getLdrImmAddress(ldrAddr);
50491:         if (*addr != InvalidBranchTarget) {
53380: // The following is disabled for JM because we patch some branches after
53380: // calling fixUpOffset, and the branch patcher doesn't know how to handle 'B'
53380: // instructions.
53380: #if 0
50491:             if (!(*iter & 1)) {
50491:                 int diff = reinterpret_cast<ARMWord*>(data + *addr) - (ldrAddr + DefaultPrefetching);
50491: 
50491:                 if ((diff <= BOFFSET_MAX && diff >= BOFFSET_MIN)) {
50491:                     *ldrAddr = B | getConditionalField(*ldrAddr) | (diff & BRANCH_MASK);
50491:                     continue;
50491:                 }
50491:             }
53380: #endif
50491:             *addr = reinterpret_cast<ARMWord>(data + *addr);
50491:         }
50491:     }
50491: }
50491: 
50491: void* ARMAssembler::executableCopy(ExecutablePool* allocator)
50491: {
50491:     // 64-bit alignment is required for next constant pool and JIT code as well
50491:     m_buffer.flushWithoutBarrier(true);
50491:     if (m_buffer.uncheckedSize() & 0x7)
50491:         bkpt(0);
50491: 
50491:     void * data = m_buffer.executableCopy(allocator);
56037:     if (data)
50491:         fixUpOffsets(data);
50491:     return data;
50491: }
50491: 
50491: // This just dumps the code into the specified buffer, fixing up absolute
50491: // offsets and literal pool loads as it goes. The buffer is assumed to be large
50491: // enough to hold the code, and any pre-existing literal pool is assumed to
50491: // have been flushed.
50491: void* ARMAssembler::executableCopy(void * buffer)
50491: {
56037:     if (m_buffer.oom())
56037:         return NULL;
56037: 
50491:     ASSERT(m_buffer.sizeOfConstantPool() == 0);
50491: 
50491:     memcpy(buffer, m_buffer.data(), m_buffer.size());
50491:     fixUpOffsets(buffer);
50491:     return buffer;
50491: }
50491: 
50491: } // namespace JSC
50491: 
50491: #endif // ENABLE(ASSEMBLER) && CPU(ARM_TRADITIONAL)
