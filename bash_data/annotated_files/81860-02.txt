52560: /* -*- Mode: C++; tab-width: 4; indent-tabs-mode: nil; c-basic-offset: 4 -*-
52560:  * vim: set ts=4 sw=4 et tw=99:
52560:  *
52560:  * ***** BEGIN LICENSE BLOCK *****
52560:  * Version: MPL 1.1/GPL 2.0/LGPL 2.1
52560:  *
52560:  * The contents of this file are subject to the Mozilla Public License Version
52560:  * 1.1 (the "License"); you may not use this file except in compliance with
52560:  * the License. You may obtain a copy of the License at
52560:  * http://www.mozilla.org/MPL/
52560:  *
52560:  * Software distributed under the License is distributed on an "AS IS" basis,
52560:  * WITHOUT WARRANTY OF ANY KIND, either express or implied. See the License
52560:  * for the specific language governing rights and limitations under the
52560:  * License.
52560:  *
52560:  * The Original Code is Mozilla SpiderMonkey JavaScript 1.9 code, released
52560:  * May 28, 2008.
52560:  *
52560:  * The Initial Developer of the Original Code is
52560:  *   Brendan Eich <brendan@mozilla.org>
52560:  *
52560:  * Contributor(s):
52560:  *   David Anderson <danderson@mozilla.com>
52560:  *
52560:  * Alternatively, the contents of this file may be used under the terms of
52560:  * either of the GNU General Public License Version 2 or later (the "GPL"),
52560:  * or the GNU Lesser General Public License Version 2.1 or later (the "LGPL"),
52560:  * in which case the provisions of the GPL or the LGPL are applicable instead
52560:  * of those above. If you wish to allow use of your version of this file only
52560:  * under the terms of either the GPL or the LGPL, and not to allow others to
52560:  * use your version of this file under the terms of the MPL, indicate your
52560:  * decision by deleting the provisions above and replace them with the notice
52560:  * and other provisions required by the GPL or the LGPL. If you do not delete
52560:  * the provisions above, a recipient may use your version of this file under
52560:  * the terms of any one of the MPL, the GPL or the LGPL.
52560:  *
52560:  * ***** END LICENSE BLOCK ***** */
52560: 
52560: #if !defined jsjaeger_framestate_h__ && defined JS_METHODJIT
52560: #define jsjaeger_framestate_h__
52560: 
77343: #include "jsanalyze.h"
52560: #include "jsapi.h"
52606: #include "methodjit/MachineRegs.h"
52617: #include "methodjit/FrameEntry.h"
52617: #include "CodeGenIncludes.h"
52839: #include "ImmutableSync.h"
54707: #include "jscompartment.h"
52560: 
52560: namespace js {
52560: namespace mjit {
52560: 
53087: struct Uses {
53088:     explicit Uses(uint32 nuses)
53087:       : nuses(nuses)
53087:     { }
53087:     uint32 nuses;
53087: };
53087: 
53088: struct Changes {
53088:     explicit Changes(uint32 nchanges)
53088:       : nchanges(nchanges)
53088:     { }
53088:     uint32 nchanges;
53088: };
53088: 
77343: struct TemporaryCopy {
77343:     TemporaryCopy(JSC::MacroAssembler::Address copy, JSC::MacroAssembler::Address temporary)
77343:         : copy(copy), temporary(temporary)
77343:     {}
77343:     JSC::MacroAssembler::Address copy;
77343:     JSC::MacroAssembler::Address temporary;
77343: };
77343: 
77343: class StubCompiler;
77343: class LoopState;
77343: 
52617: /*
52617:  * The FrameState keeps track of values on the frame during compilation.
52618:  * The compiler can query FrameState for information about arguments, locals,
52618:  * and stack slots (all hereby referred to as "slots"). Slot information can
52618:  * be requested in constant time. For each slot there is a FrameEntry *. If
52618:  * this is non-NULL, it contains valid information and can be returned.
52618:  *
52620:  * The register allocator keeps track of registers as being in one of two
52620:  * states. These are:
52620:  *
52620:  * 1) Unowned. Some code in the compiler is working on a register.
52620:  * 2) Owned. The FrameState owns the register, and may spill it at any time.
52620:  *
52620:  * ------------------ Implementation Details ------------------
52620:  * 
52617:  * Observations:
52617:  *
77343:  * 1) Every time we need a slow call, we must sync everything.
77343:  * 2) Efficient side-exits need to quickly deltize state snapshots.
77343:  * 3) Syncing is limited to constants and registers.
77343:  * 4) Entries are not forgotten unless they are entirely in memory and are
77343:  *    not constants or copies.
52617:  * 
52617:  * With these in mind, we want to make sure that the compiler doesn't degrade
52617:  * badly as functions get larger.
52617:  *
52617:  * If the FE is NULL, a new one is allocated, initialized, and stored. They
52617:  * are allocated from a pool such that (fe - pool) can be used to compute
52617:  * the slot's Address.
52617:  *
52617:  * We keep a side vector of all tracked FrameEntry * to quickly generate
52617:  * memory stores and clear the tracker.
52617:  *
52617:  * It is still possible to get really bad behavior with a very large script
52617:  * that doesn't have branches or calls. That's okay, having this code in
52617:  * minimizes damage and lets us introduce a hard cut-off point.
52617:  */
52560: class FrameState
52560: {
52839:     friend class ImmutableSync;
52839: 
52560:     typedef JSC::MacroAssembler::RegisterID RegisterID;
52851:     typedef JSC::MacroAssembler::FPRegisterID FPRegisterID;
52560:     typedef JSC::MacroAssembler::Address Address;
77343:     typedef JSC::MacroAssembler::AbsoluteAddress AbsoluteAddress;
52623:     typedef JSC::MacroAssembler::Jump Jump;
52611:     typedef JSC::MacroAssembler::Imm32 Imm32;
77343:     typedef JSC::MacroAssembler::ImmPtr ImmPtr;
52617: 
52691:     static const uint32 InvalidIndex = 0xFFFFFFFF;
52691: 
52617:     struct Tracker {
52617:         Tracker()
52617:           : entries(NULL), nentries(0)
52617:         { }
52617: 
52705:         void add(FrameEntry *fe) {
52705:             entries[nentries++] = fe;
52617:         }
52617: 
52617:         void reset() {
52617:             nentries = 0;
52617:         }
52617: 
52705:         FrameEntry * operator [](uint32 n) const {
52708:             JS_ASSERT(n < nentries);
52617:             return entries[n];
52617:         }
52617: 
52705:         FrameEntry **entries;
52617:         uint32 nentries;
52617:     };
52617: 
54719:     /*
54719:      * Some RegisterState invariants.
54719:      *
54719:      *  If |fe| is non-NULL, |save| is NULL.
54719:      *  If |save| is non-NULL, |fe| is NULL.
54719:      *  That is, both |fe| and |save| cannot be non-NULL.
54719:      *
54719:      *  If either |fe| or |save| is non-NULL, the register is not in freeRegs.
54719:      *  If both |fe| and |save| are NULL, the register is either in freeRegs,
54719:      *  or owned by the compiler.
54719:      */
52617:     struct RegisterState {
54719:         RegisterState() : fe_(NULL), save_(NULL)
52617:         { }
52617: 
53002:         RegisterState(FrameEntry *fe, RematInfo::RematType type)
54719:           : fe_(fe), save_(NULL), type_(type)
54719:         {
54719:             JS_ASSERT(!save_);
54719:         }
52617: 
54719:         bool isPinned() const {
54719:             assertConsistency();
54719:             return !!save_;
54719:         }
54719: 
54719:         void assertConsistency() const {
54719:             JS_ASSERT_IF(fe_, !save_);
54719:             JS_ASSERT_IF(save_, !fe_);
54719:         }
54719: 
54719:         FrameEntry *fe() const {
54719:             assertConsistency();
54719:             return fe_;
54719:         }
54719: 
54719:         RematInfo::RematType type() const {
54719:             assertConsistency();
54719:             return type_;
54719:         }
54719: 
54719:         FrameEntry *usedBy() const {
54719:             if (fe_)
54719:                 return fe_;
54719:             return save_;
54719:         }
54719: 
54719:         void associate(FrameEntry *fe, RematInfo::RematType type) {
54719:             JS_ASSERT(!fe_);
54719:             JS_ASSERT(!save_);
54719: 
54719:             fe_ = fe;
54719:             type_ = type;
54719:         }
54719: 
54719:         /* Change ownership. */
54719:         void reassociate(FrameEntry *fe) {
54719:             assertConsistency();
54719:             JS_ASSERT(fe);
54719: 
54719:             fe_ = fe;
54719:         }
54719: 
54719:         /* Unassociate this register from the FE. */
54719:         void forget() {
54719:             JS_ASSERT(fe_);
54719:             fe_ = NULL;
54719:             JS_ASSERT(!save_);
54719:         }
54719: 
54719:         void pin() {
56214:             JS_ASSERT(fe_ != NULL);
54719:             assertConsistency();
54719:             save_ = fe_;
54719:             fe_ = NULL;
54719:         }
54719: 
54719:         void unpin() {
56214:             JS_ASSERT(save_ != NULL);
54719:             assertConsistency();
54719:             fe_ = save_;
54719:             save_ = NULL;
54719:         }
54719: 
54719:         void unpinUnsafe() {
54719:             assertConsistency();
54719:             save_ = NULL;
54719:         }
54719: 
54719:       private:
52617:         /* FrameEntry owning this register, or NULL if not owned by a frame. */
54719:         FrameEntry *fe_;
52617: 
52685:         /* Hack - simplifies register allocation for pairs. */
54719:         FrameEntry *save_;
52685: 
52617:         /* Part of the FrameEntry that owns the FE. */
54719:         RematInfo::RematType type_;
52617:     };
52560: 
77343:     struct ActiveFrame;
77343: 
57776:     FrameState *thisFromCtor() { return this; }
52560:   public:
77343:     FrameState(JSContext *cx, Compiler &cc, Assembler &masm, StubCompiler &stubcc);
52560:     ~FrameState();
52560: 
52617:     /*
77343:      * Pushes a synced slot that may have a known type.
52617:      */
77343:     inline void pushSynced(JSValueType knownType);
52617: 
52617:     /*
52617:      * Pushes a slot that has a known, synced type and payload.
52617:      */
77343:     inline void pushSynced(JSValueType knownType, RegisterID reg);
52719: 
52719:     /*
52617:      * Pushes a constant value.
52617:      */
52618:     inline void push(const Value &v);
52617: 
52617:     /*
77343:      * Loads a value from memory and pushes it. If reuseBase is set, the
77343:      * Compiler owns the register and it should be reused if possible.
52617:      */
77343:     inline void push(Address address, JSValueType knownType, bool reuseBase = false);
77343: 
77435:     /*
77435:      * Loads a word from memory and pushes it. If reuseBase is set, the
77435:      * Compiler owns the register and it should be reused if possible.
77435:      * It takes an address and loads/pushes an unboxed word of a given non-double type.
77435:      */
77435:     inline void pushWord(Address address, JSValueType knownType, bool reuseBase = false);
77435: 
77343:     /* Loads a value from memory into a register pair, returning the register. */
77343:     inline void loadIntoRegisters(Address address, bool reuseBase,
77343:                                   RegisterID *ptypeReg, RegisterID *pdataReg);
76087: 
52617:     /*
52617:      * Pushes a known type and allocated payload onto the operation stack.
52617:      */
53025:     inline void pushTypedPayload(JSValueType type, RegisterID payload);
52617: 
52617:     /*
77343:      * Clobbers a stack entry with a type register and data register pair,
77343:      * converting to the specified known type if necessary.  If the type is
77343:      * JSVAL_TYPE_DOUBLE, the registers are converted into a floating point
77343:      * register, which is returned.
52831:      */
77343:     inline FPRegisterID storeRegs(int32 depth, RegisterID type, RegisterID data,
77343:                                   JSValueType knownType);
77343:     inline FPRegisterID pushRegs(RegisterID type, RegisterID data, JSValueType knownType);
77343: 
77343:     /*
77343:      * Load an address into a frame entry in registers. For handling call paths
77343:      * where merge() would otherwise reload from the wrong address.
77343:      */
77343:     inline void reloadEntry(Assembler &masm, Address address, FrameEntry *fe);
77343: 
77343:     /* Push a value which is definitely a double. */
77343:     void pushDouble(FPRegisterID fpreg);
77343:     void pushDouble(Address address);
77343: 
77343:     /* Ensure that fe is definitely a double. It must already be either int or double. */
77343:     void ensureDouble(FrameEntry *fe);
77343: 
77343:     /* Revert an entry just converted to double by ensureDouble. */
77343:     void ensureInteger(FrameEntry *fe);
77343: 
77343:     /*
77343:      * Emit code to masm ensuring that all in memory slots thought to be
77343:      * doubles are in fact doubles.
77343:      */
77343:     void ensureInMemoryDoubles(Assembler &masm);
77343: 
77343:     /* Forget that fe is definitely a double. */
77343:     void forgetKnownDouble(FrameEntry *fe);
52831: 
52831:     /*
52623:      * Pushes a known type and allocated payload onto the operation stack.
52623:      * This must be used when the type is known, but cannot be propagated
52623:      * because it is not known to be correct at a slow-path merge point.
52960:      *
52960:      * The caller guarantees that the tag was a fast-path check; that is,
52960:      * the value it replaces on the stack had the same tag if the fast-path
52960:      * was taken.
52623:      */
53181:     inline void pushUntypedPayload(JSValueType type, RegisterID payload);
52623: 
52623:     /*
63236:      * Pushes a value onto the operation stack. This must be used when the
63236:      * value is known, but its type cannot be propagated because it is not
63236:      * known to be correct at a slow-path merge point.
63236:      */
63236:     inline void pushUntypedValue(const Value &value);
63236: 
63236:     /*
53153:      * Pushes a number onto the operation stack.
53181:      *
53181:      * If asInt32 is set to true, then the FS will attempt to optimize
53181:      * syncing the type as int32. Only use this parameter when the fast-path
53181:      * guaranteed that the stack slot was guarded to be an int32 originally.
53181:      *
53181:      * For example, checking LHS and RHS as ints guarantees that if the LHS
53181:      * was synced, then popping both and pushing a maybe-int32 does not need
53181:      * to be synced.
53153:      */
77343:     inline void pushNumber(RegisterID payload, bool asInt32 = false);
53153: 
53153:     /*
53200:      * Pushes an int32 onto the operation stack. This is a specialized version
53200:      * of pushNumber. The caller must guarantee that (a) an int32 is to be 
53200:      * pushed on the inline path, and (b) if any slow path pushes a double,
53200:      * the slow path also stores the double to memory.
53200:      */
53200:     inline void pushInt32(RegisterID payload);
53200: 
53200:     /*
52617:      * Pops a value off the operation stack, freeing any of its resources.
52617:      */
52618:     inline void pop();
52617: 
52617:     /*
52617:      * Pops a number of values off the operation stack, freeing any of their
52617:      * resources.
52617:      */
52618:     inline void popn(uint32 n);
52617: 
52617:     /*
53115:      * Returns true iff lhs and rhs are copies of the same FrameEntry.
53115:      */
53115:     inline bool haveSameBacking(FrameEntry *lhs, FrameEntry *rhs);
53115: 
77343:     /* If the rhs to a binary operation directly copies the lhs, uncopy the lhs. */
77343:     void separateBinaryEntries(FrameEntry *lhs, FrameEntry *rhs);
77343: 
53115:     /*
52785:      * Temporarily increase and decrease local variable depth.
52785:      */
52785:     inline void enterBlock(uint32 n);
52785:     inline void leaveBlock(uint32 n);
52785: 
57787:     // Pushes a copy of a slot (formal argument, local variable, or stack slot)
57787:     // onto the operation stack.
52670:     void pushLocal(uint32 n);
57787:     void pushArg(uint32 n);
57787:     void pushCallee();
57787:     void pushThis();
77343:     void pushCopyOf(FrameEntry *fe);
77413:     inline void setThis(RegisterID reg);
77431:     inline void syncThis();
77343:     inline void learnThisIsObject(bool unsync = true);
77343: 
77343:     inline FrameEntry *getStack(uint32 slot);
77343:     inline FrameEntry *getLocal(uint32 slot);
77343:     inline FrameEntry *getArg(uint32 slot);
77343:     inline FrameEntry *getSlotEntry(uint32 slot);
52670: 
52670:     /*
52623:      * Allocates a temporary register for a FrameEntry's type. The register
52623:      * can be spilled or clobbered by the frame. The compiler may only operate
52623:      * on it temporarily, and must take care not to clobber it.
52617:      */
52618:     inline RegisterID tempRegForType(FrameEntry *fe);
52617: 
52617:     /*
53137:      * Try to use a register already allocated for fe's type, but if one
53137:      * is not already available, use fallback.
53137:      *
53137:      * Note: this does NOT change fe's type-register remat info. It's supposed
53137:      * to be a super lightweight/transparent operation.
53137:      */
53137:     inline RegisterID tempRegForType(FrameEntry *fe, RegisterID fallback);
53137: 
53137:     /*
52623:      * Returns a register that is guaranteed to contain the frame entry's
52898:      * data payload. The compiler may not modify the contents of the register.
52898:      * The compiler should NOT explicitly free it.
52620:      */
52620:     inline RegisterID tempRegForData(FrameEntry *fe);
77343:     inline FPRegisterID tempFPRegForData(FrameEntry *fe);
52620: 
52620:     /*
52685:      * Same as above, except register must match identically.
52685:      */
77343:     inline AnyRegisterID tempRegInMaskForData(FrameEntry *fe, uint32 mask);
52685: 
52685:     /*
53228:      * Same as above, except loads into reg (using masm) if the entry does not
53228:      * already have a register, and does not change the frame state in doing so.
53228:      */
53228:     inline RegisterID tempRegForData(FrameEntry *fe, RegisterID reg, Assembler &masm) const;
53228: 
53228:     /*
77343:      * For opcodes which expect to operate on an object, forget the entry if it
77343:      * is either a known constant or a non-object. This simplifies path
77343:      * generation in the Compiler for such unusual cases.
77343:      */
77343:     inline void forgetMismatchedObject(FrameEntry *fe);
77343: 
77343:     /*
52962:      * Convert an integer to a double without applying
52962:      * additional Register pressure.
52962:      */
52962:     inline void convertInt32ToDouble(Assembler &masm, FrameEntry *fe,
52962:                                      FPRegisterID fpreg) const;
52962: 
52962:     /*
52962:      * Dive into a FrameEntry and check whether it's in a register.
52962:      */
52962:     inline bool peekTypeInRegister(FrameEntry *fe) const;
52962: 
52962:     /*
52620:      * Allocates a register for a FrameEntry's data, such that the compiler
52623:      * can modify it in-place.
52623:      *
52623:      * The caller guarantees the FrameEntry will not be observed again. This
52623:      * allows the compiler to avoid spilling. Only call this if the FE is
52623:      * going to be popped before stubcc joins/guards or the end of the current
52623:      * opcode.
52620:      */
52623:     RegisterID ownRegForData(FrameEntry *fe);
52623: 
52623:     /*
52831:      * Allocates a register for a FrameEntry's type, such that the compiler
52831:      * can modify it in-place.
52831:      *
52831:      * The caller guarantees the FrameEntry will not be observed again. This
52831:      * allows the compiler to avoid spilling. Only call this if the FE is
52831:      * going to be popped before stubcc joins/guards or the end of the current
52831:      * opcode.
52831:      */
52831:     RegisterID ownRegForType(FrameEntry *fe);
52831: 
52831:     /*
52623:      * Allocates a register for a FrameEntry's data, such that the compiler
52623:      * can modify it in-place. The actual FE is not modified.
52623:      */
52846:     RegisterID copyDataIntoReg(FrameEntry *fe);
53156:     void copyDataIntoReg(FrameEntry *fe, RegisterID exact);
52962:     RegisterID copyDataIntoReg(Assembler &masm, FrameEntry *fe);
52962: 
52962:     /*
52906:      * Allocates a register for a FrameEntry's type, such that the compiler
52906:      * can modify it in-place. The actual FE is not modified.
52906:      */
52906:     RegisterID copyTypeIntoReg(FrameEntry *fe);
52906: 
52906:     /*
53032:      * Returns a register that contains the constant Int32 value of the
53031:      * frame entry's data payload.
53031:      * Since the register is not bound to a FrameEntry,
53031:      * it MUST be explicitly freed with freeReg().
53031:      */
53032:     RegisterID copyInt32ConstantIntoReg(FrameEntry *fe);
53032:     RegisterID copyInt32ConstantIntoReg(Assembler &masm, FrameEntry *fe);
53031: 
54160:     /*
77343:      * Gets registers for the components of fe where needed, pins them and
77343:      * stores into vr. If breakDouble is set, vr is guaranteed not to be a
77343:      * floating point register.
54160:      */
77343:     void pinEntry(FrameEntry *fe, ValueRemat &vr, bool breakDouble = true);
54160: 
54160:     /* Unpins registers from a call to pinEntry. */
54160:     void unpinEntry(const ValueRemat &vr);
54160: 
54160:     /* Syncs fe to memory, given its state as constructed by a call to pinEntry. */
56004:     void ensureValueSynced(Assembler &masm, FrameEntry *fe, const ValueRemat &vr);
54160: 
53152:     struct BinaryAlloc {
53152:         MaybeRegisterID lhsType;
53152:         MaybeRegisterID lhsData;
53152:         MaybeRegisterID rhsType;
53152:         MaybeRegisterID rhsData;
53152:         MaybeRegisterID extraFree;
53152:         RegisterID result;  // mutable result reg
77343:         FPRegisterID lhsFP; // mutable scratch floating point reg
77343:         FPRegisterID rhsFP; // mutable scratch floating point reg
53152:         bool resultHasRhs;  // whether the result has the RHS instead of the LHS
53152:         bool lhsNeedsRemat; // whether LHS needs memory remat
53152:         bool rhsNeedsRemat; // whether RHS needs memory remat
77343:         bool undoResult;    // whether to remat LHS/RHS by undoing operation
53152:     };
53152: 
53152:     /*
53152:      * Ensures that the two given FrameEntries have registers for both their
53152:      * type and data. The register allocations are returned in a struct.
53152:      *
53152:      * One mutable register is allocated as well, holding the LHS payload. If
53152:      * this would cause a spill that could be avoided by using a mutable RHS,
53152:      * and the operation is commutative, then the resultHasRhs is set to true.
53152:      */
53201:     void allocForBinary(FrameEntry *lhs, FrameEntry *rhs, JSOp op, BinaryAlloc &alloc,
53201:                         bool resultNeeded = true);
53152: 
77343:     /*
77343:      * After the result register in a BinaryAlloc has been clobbered, rematerialize
77343:      * the left or right side if necessary to restore the original values.
77343:      */
77343:     void rematBinary(FrameEntry *lhs, FrameEntry *rhs, const BinaryAlloc &alloc, Assembler &masm);
77343: 
53590:     /* Ensures that an FE has both type and data remat'd in registers. */
56219:     void ensureFullRegs(FrameEntry *fe, MaybeRegisterID *typeReg, MaybeRegisterID *dataReg);
53590: 
53152:     /*
53152:      * Similar to allocForBinary, except works when the LHS and RHS have the
53152:      * same backing FE. Only a reduced subset of BinaryAlloc is used:
53152:      *   lhsType
53152:      *   lhsData
53152:      *   result
53152:      *   lhsNeedsRemat
53152:      */
53152:     void allocForSameBinary(FrameEntry *fe, JSOp op, BinaryAlloc &alloc);
53152: 
53152:     /* Loads an FE into an fp reg. */
53152:     inline void loadDouble(FrameEntry *fe, FPRegisterID fpReg, Assembler &masm) const;
53152: 
53031:     /*
53229:      * Slightly more specialized version when more precise register
53229:      * information is known.
53229:      */
53229:     inline void loadDouble(RegisterID type, RegisterID data, FrameEntry *fe, FPRegisterID fpReg,
53229:                            Assembler &masm) const;
53229: 
53229:     /*
52623:      * Types don't always have to be in registers, sometimes the compiler
52623:      * can use addresses and avoid spilling. If this FrameEntry has a synced
52623:      * address and no register, this returns true.
52623:      */
52623:     inline bool shouldAvoidTypeRemat(FrameEntry *fe);
52620: 
52620:     /*
52620:      * Payloads don't always have to be in registers, sometimes the compiler
52620:      * can use addresses and avoid spilling. If this FrameEntry has a synced
52620:      * address and no register, this returns true.
52620:      */
52620:     inline bool shouldAvoidDataRemat(FrameEntry *fe);
52620: 
52620:     /*
52617:      * Frees a temporary register. If this register is being tracked, then it
52617:      * is not spilled; the backing data becomes invalidated!
52617:      */
77343:     inline void freeReg(AnyRegisterID reg);
52617: 
52617:     /*
52617:      * Allocates a register. If none are free, one may be spilled from the
52617:      * tracker. If there are none available for spilling in the tracker,
52617:      * then this is considered a compiler bug and an assert will fire.
52617:      */
52618:     inline RegisterID allocReg();
77343:     inline FPRegisterID allocFPReg();
52617: 
52617:     /*
52653:      * Allocates a register, except using a mask.
52653:      */
77343:     inline AnyRegisterID allocReg(uint32 mask);
52653: 
52653:     /*
52652:      * Allocates a specific register, evicting it if it's not avaliable.
52652:      */
77343:     void takeReg(AnyRegisterID reg);
52652: 
52652:     /*
52617:      * Returns a FrameEntry * for a slot on the operation stack.
52617:      */
52618:     inline FrameEntry *peek(int32 depth);
52617: 
52617:     /*
52617:      * Fully stores a FrameEntry at an arbitrary address. popHint specifies
52617:      * how hard the register allocator should try to keep the FE in registers.
52617:      */
54582:     void storeTo(FrameEntry *fe, Address address, bool popHint = false);
52617: 
52617:     /*
54832:      * Fully stores a FrameEntry into two arbitrary registers. tempReg may be
54832:      * used as a temporary.
54832:      */
56572:     void loadForReturn(FrameEntry *fe, RegisterID typeReg, RegisterID dataReg, RegisterID tempReg);
57787:     void loadThisForReturn(RegisterID typeReg, RegisterID dataReg, RegisterID tempReg);
54832: 
77343:     /* Stores the top stack slot back to a local or slot. */
77343:     void storeLocal(uint32 n, bool popGuaranteed = false);
57787:     void storeArg(uint32 n, bool popGuaranteed = false);
77343:     void storeTop(FrameEntry *target);
52670: 
52670:     /*
52620:      * Restores state from a slow path.
52620:      */
53088:     void merge(Assembler &masm, Changes changes) const;
52620: 
52620:     /*
52619:      * Writes unsynced stores to an arbitrary buffer.
52619:      */
53088:     void sync(Assembler &masm, Uses uses) const;
52619: 
52619:     /*
52617:      * Syncs all outstanding stores to memory and possibly kills regs in the
54160:      * process.  The top [ignored..uses-1] frame entries will be synced.
52617:      */
54160:     void syncAndKill(Registers kill, Uses uses, Uses ignored);
54160:     void syncAndKill(Registers kill, Uses uses) { syncAndKill(kill, uses, Uses(0)); }
77343:     void syncAndKill(Uses uses) { syncAndKill(Registers(Registers::AvailAnyRegs), uses, Uses(0)); }
52617: 
54719:     /* Syncs and kills everything. */
54719:     void syncAndKillEverything() {
77343:         syncAndKill(Registers(Registers::AvailAnyRegs), Uses(frameSlots()));
54719:     }
52878: 
52878:     /*
54719:      * Throw away the entire frame state, without syncing anything.
54719:      * This can only be called after a syncAndKill() against all registers.
54719:      */
54580:     void forgetEverything();
54575: 
77343:     void syncAndForgetEverything()
77343:     {
77343:         syncAndKillEverything();
77343:         forgetEverything();
77343:     }
77343: 
54575:     /*
54719:      * Discard the entire framestate forcefully.
54575:      */
54719:     void discardFrame();
52847: 
52847:     /*
77343:      * Make a copy of the current frame state, and restore from that snapshot.
77343:      * The stack depth must match between the snapshot and restore points.
76019:      */
77343:     FrameEntry *snapshotState();
77343:     void restoreFromSnapshot(FrameEntry *snapshot);
77343: 
77343:     /*
77343:      * Tries to sync and shuffle registers in accordance with the register state
77343:      * at target, constructing that state if necessary. Forgets all constants and
77343:      * copies, and nothing can be pinned. Keeps the top Uses in registers; if Uses
77343:      * is non-zero the state may not actually be consistent with target.
77343:      */
77343:     bool syncForBranch(jsbytecode *target, Uses uses);
77343:     void syncForAllocation(RegisterAllocation *alloc, bool inlineReturn, Uses uses);
77343: 
77343:     /* Discards the current frame state and updates to a new register allocation. */
77343:     bool discardForJoin(RegisterAllocation *&alloc, uint32 stackDepth);
77343: 
77343:     RegisterAllocation * computeAllocation(jsbytecode *target);
77343: 
77343:     /* Return whether the register state is consistent with that at target. */
77343:     bool consistentRegisters(jsbytecode *target);
77343: 
77343:     /*
77343:      * Load all registers to update from either the current register state (if synced
77343:      * is unset) or a synced state (if synced is set) to target.
77343:      */
77343:     void prepareForJump(jsbytecode *target, Assembler &masm, bool synced);
77343: 
77343:     /*
77343:      * Mark an existing slot with a type. unsync indicates whether type is already synced.
77343:      * Do not call this on entries which might be copied.
77343:      */
77343:     inline void learnType(FrameEntry *fe, JSValueType type, bool unsync = true);
77343:     inline void learnType(FrameEntry *fe, JSValueType type, RegisterID payload);
52619: 
52619:     /*
52804:      * Forget a type, syncing in the process.
52804:      */
52804:     inline void forgetType(FrameEntry *fe);
52804: 
52804:     /*
55503:      * Discards a FrameEntry, tricking the FS into thinking it's synced.
55503:      */
55503:     void discardFe(FrameEntry *fe);
55503: 
77343:     /* Compiler-owned metadata about stack entries, reset on push/pop/copy. */
77343:     struct StackEntryExtra {
77343:         bool initArray;
77343:         JSObject *initObject;
77343:         types::TypeSet *types;
77343:         JSAtom *name;
77343:         void reset() { PodZero(this); }
77343:     };
77343:     StackEntryExtra& extra(const FrameEntry *fe) {
77343:         JS_ASSERT(fe >= a->spBase && fe < a->sp);
77343:         return extraArray[fe - entries];
77343:     }
77343:     StackEntryExtra& extra(uint32 slot) { return extra(entries + slot); }
77343: 
55503:     /*
55712:      * Helper function. Tests if a slot's type is null. Condition must
53004:      * be Equal or NotEqual.
53004:      */
53004:     inline Jump testNull(Assembler::Condition cond, FrameEntry *fe);
53004: 
53004:     /*
55712:      * Helper function. Tests if a slot's type is undefined. Condition must
55712:      * be Equal or NotEqual.
55712:      */
55712:     inline Jump testUndefined(Assembler::Condition cond, FrameEntry *fe);
55712: 
55712:     /*
55712:      * Helper function. Tests if a slot's type is an integer. Condition must
52623:      * be Equal or NotEqual.
52623:      */
52623:     inline Jump testInt32(Assembler::Condition cond, FrameEntry *fe);
52623: 
52623:     /*
55712:      * Helper function. Tests if a slot's type is a double. Condition must
52823:      * be Equal or Not Equal.
52823:      */
52823:     inline Jump testDouble(Assembler::Condition cond, FrameEntry *fe);
52823: 
52823:     /*
55712:      * Helper function. Tests if a slot's type is a boolean. Condition must
52734:      * be Equal or NotEqual.
52734:      */
52734:     inline Jump testBoolean(Assembler::Condition cond, FrameEntry *fe);
52734: 
52734:     /*
55712:      * Helper function. Tests if a slot's type is a string. Condition must
53137:      * be Equal or NotEqual.
53137:      */
53137:     inline Jump testString(Assembler::Condition cond, FrameEntry *fe);
53137: 
53137:     /*
55712:      * Helper function. Tests if a slot's type is a non-funobj. Condition must
52838:      * be Equal or NotEqual.
52838:      */
53023:     inline Jump testObject(Assembler::Condition cond, FrameEntry *fe);
52850: 
52850:     /*
55712:      * Helper function. Tests if a slot's type is primitive. Condition must
52894:      * be Equal or NotEqual.
52894:      */
52894:     inline Jump testPrimitive(Assembler::Condition cond, FrameEntry *fe);
52894: 
52894:     /*
52685:      * Marks a register such that it cannot be spilled by the register
54719:      * allocator. Any pinned registers must be unpinned at the end of the op,
54719:      * no matter what. In addition, pinReg() can only be used on registers
54719:      * which are associated with FrameEntries.
52685:      */
77343:     inline void pinReg(AnyRegisterID reg) { regstate(reg).pin(); }
52685: 
52685:     /*
52685:      * Unpins a previously pinned register.
52685:      */
77343:     inline void unpinReg(AnyRegisterID reg) { regstate(reg).unpin(); }
52685: 
52685:     /*
54719:      * Same as unpinReg(), but does not restore the FrameEntry.
54719:      */
54719:     inline void unpinKilledReg(RegisterID reg);
54719: 
56572:     /* Pins a data or type register if one exists. */
56572:     MaybeRegisterID maybePinData(FrameEntry *fe);
56572:     MaybeRegisterID maybePinType(FrameEntry *fe);
56572:     void maybeUnpinReg(MaybeRegisterID reg);
56572: 
54719:     /*
52714:      * Dups the top item on the stack.
52714:      */
52714:     inline void dup();
52714: 
52714:     /*
52715:      * Dups the top 2 items on the stack.
52715:      */
52715:     inline void dup2();
52715: 
52715:     /*
52916:      * Dups an item n-deep in the stack. n must be < 0
52916:      */
52916:     inline void dupAt(int32 n);
52916: 
52916:     /*
77343:      * Syncs an item n-deep in the stack.
77343:      */
77343:     inline void syncAt(int32 n);
77343: 
77343:     /*
53052:      * If the frameentry is a copy, give it its own registers.
53052:      * This may only be called on the topmost fe.
53052:      */
53052:     inline void giveOwnRegs(FrameEntry *fe);
53052: 
77343:     uint32 stackDepth() const { return a->sp - a->spBase; }
77343: 
77343:     /*
77343:      * The stack depth of the current frame plus any locals and space
77343:      * for inlined frames, i.e. the difference between the end of the
77343:      * current fp and sp.
77343:      */
77343:     uint32 totalDepth() const { return a->depth + a->script->nfixed + stackDepth(); }
75864: 
57787:     // Returns the number of entries in the frame, that is:
57787:     //   2 for callee, this +
57787:     //   nargs +
57787:     //   nfixed +
57787:     //   currently pushed stack slots
77343:     uint32 frameSlots() const { return uint32(a->sp - a->callee_); }
57787: 
52617: #ifdef DEBUG
52617:     void assertValidRegisterState() const;
77343: #else
77343:     inline void assertValidRegisterState() const {};
52617: #endif
52617: 
69223:     // Return an address, relative to the StackFrame, that represents where
57787:     // this FrameEntry is stored in memory. Note that this is its canonical
57787:     // address, not its backing store. There is no guarantee that the memory
57787:     // is coherent.
76019:     Address addressOf(const FrameEntry *fe) const;
77343:     Address addressOf(uint32 slot) const { return addressOf(a->callee_ + slot); }
57787: 
77407:     Address addressOfTop() const { return addressOf(a->sp); }
77407: 
69223:     // Returns an address, relative to the StackFrame, that represents where
57787:     // this FrameEntry is backed in memory. This is not necessarily its
57787:     // canonical address, but the address for which the payload has been synced
57787:     // to memory. The caller guarantees that the payload has been synced.
53497:     Address addressForDataRemat(const FrameEntry *fe) const;
52620: 
77343:     // Inside an inline frame, the address for the return value in the caller.
81860:     Address addressForInlineReturn();
77343: 
52880:     inline StateRemat dataRematInfo(const FrameEntry *fe) const;
52880: 
52838:     /*
52838:      * This is similar to freeReg(ownRegForData(fe)) - except no movement takes place.
52838:      * The fe is simply invalidated as if it were popped. This can be used to free
52838:      * registers in the working area of the stack. Obviously, this can only be called
52838:      * in infallible code that will pop these entries soon after.
52838:      */
52838:     inline void eviscerate(FrameEntry *fe);
52838: 
52838:     /*
52838:      * Moves the top of the stack down N slots, popping each item above it.
52838:      * Caller guarantees the slots below have been observed and eviscerated.
52838:      */
52838:     void shimmy(uint32 n);
52838: 
52896:     /*
52896:      * Stores the top item on the stack to a stack slot, count down from the
52896:      * current stack depth. For example, to move the top (-1) to -3, you would
52896:      * call shift(-2).
52896:      */
52896:     void shift(int32 n);
52896: 
77343:     /* Swaps the top two items on the stack. Requires two temp slots. */
77343:     void swap();
76020: 
53113:     inline void setInTryBlock(bool inTryBlock) {
53113:         this->inTryBlock = inTryBlock;
53113:     }
53113: 
76019:     inline uint32 regsInUse() const { return Registers::AvailRegs & ~freeRegs.freeMask; }
63240: 
77343:     void setPC(jsbytecode *PC) { a->PC = PC; }
77343:     void setLoop(LoopState *loop) { this->loop = loop; }
77343: 
77343:     void pruneDeadEntries();
77343: 
77343:     bool pushActiveFrame(JSScript *script, uint32 argc);
77343:     void popActiveFrame();
77343: 
77343:     uint32 entrySlot(const FrameEntry *fe) const {
77343:         return frameSlot(a, fe);
77343:     }
77343: 
77343:     uint32 outerSlot(const FrameEntry *fe) const {
77343:         ActiveFrame *na = a;
77343:         while (na->parent) { na = na->parent; }
77343:         return frameSlot(na, fe);
77343:     }
77343: 
77343:     bool isOuterSlot(const FrameEntry *fe) const {
77343:         if (isTemporary(fe))
77343:             return true;
77343:         ActiveFrame *na = a;
77343:         while (na->parent) { na = na->parent; }
77343:         return fe < na->spBase && fe != na->callee_;
77343:     }
77343: 
77343: #ifdef DEBUG
77343:     const char * entryName(const FrameEntry *fe) const;
77343:     void dumpAllocation(RegisterAllocation *alloc);
77343: #else
77343:     const char * entryName(const FrameEntry *fe) const { return NULL; }
77343: #endif
77343:     const char * entryName(uint32 slot) { return entryName(entries + slot); }
77343: 
77343:     /* Maximum number of analysis temporaries the FrameState can track. */
77343:     static const uint32 TEMPORARY_LIMIT = 10;
77343: 
77343:     uint32 allocTemporary();  /* -1 if limit reached. */
77343:     void clearTemporaries();
77343:     inline FrameEntry *getTemporary(uint32 which);
77343: 
78454:     /*
78454:      * Return NULL or a new vector with all current copies of temporaries,
78454:      * excluding those about to be popped per 'uses'.
78454:      */
78454:     Vector<TemporaryCopy> *getTemporaryCopies(Uses uses);
77343: 
77343:     inline void syncAndForgetFe(FrameEntry *fe, bool markSynced = false);
77471:     inline void forgetLoopReg(FrameEntry *fe);
77343: 
77884:     /*
77884:      * Get an address for the specified name access in another script.
77884:      * The compiler owns the result's base register.
77884:      */
77884:     inline Address loadNameAddress(const analyze::ScriptAnalysis::NameAccess &access);
77884: 
52617:   private:
77343:     inline AnyRegisterID allocAndLoadReg(FrameEntry *fe, bool fp, RematInfo::RematType type);
77343:     inline void forgetReg(AnyRegisterID reg);
77343:     AnyRegisterID evictSomeReg(uint32 mask);
77343:     void evictReg(AnyRegisterID reg);
52618:     inline FrameEntry *rawPush();
54719:     inline void addToTracker(FrameEntry *fe);
56004: 
56004:     /* Guarantee sync, but do not set any sync flag. */
56004:     inline void ensureFeSynced(const FrameEntry *fe, Assembler &masm) const;
56004:     inline void ensureTypeSynced(const FrameEntry *fe, Assembler &masm) const;
56004:     inline void ensureDataSynced(const FrameEntry *fe, Assembler &masm) const;
56004: 
56004:     /* Guarantee sync, even if register allocation is required, and set sync. */
56004:     inline void syncFe(FrameEntry *fe);
56004:     inline void syncType(FrameEntry *fe);
56004:     inline void syncData(FrameEntry *fe);
56004: 
77343:     /* For a frame entry whose value is dead, mark as synced. */
77343:     inline void fakeSync(FrameEntry *fe);
77343: 
57787:     inline FrameEntry *getCallee();
57787:     inline FrameEntry *getThis();
77343:     inline FrameEntry *getOrTrack(uint32 index);
77343: 
52846:     inline void forgetAllRegs(FrameEntry *fe);
52708:     inline void swapInTracker(FrameEntry *lhs, FrameEntry *rhs);
56005: #if defined JS_NUNBOX32
81079:     void syncFancy(Assembler &masm, Registers avail, int trackerIndex) const;
56005: #endif
53229:     inline bool tryFastDoubleLoad(FrameEntry *fe, FPRegisterID fpReg, Assembler &masm) const;
54719:     void resetInternalState();
52691: 
52691:     /*
52691:      * "Uncopies" the backing store of a FrameEntry that has been copied. The
52691:      * original FrameEntry is not invalidated; this is the responsibility of
52691:      * the caller. The caller can check isCopied() to see if the registers
52691:      * were moved to a copy.
53243:      *
53243:      * Later addition: uncopy() returns the first copy found.
52691:      */
53243:     FrameEntry *uncopy(FrameEntry *original);
54719:     FrameEntry *walkTrackerForUncopy(FrameEntry *original);
54719:     FrameEntry *walkFrameForUncopy(FrameEntry *original);
54719: 
77343:     /* Whether fe is the only copy of backing. */
77343:     bool hasOnlyCopy(FrameEntry *backing, FrameEntry *fe);
77343: 
54719:     /*
54719:      * All registers in the FE are forgotten. If it is copied, it is uncopied
54719:      * beforehand.
54719:      */
54719:     void forgetEntry(FrameEntry *fe);
52617: 
77343:     /* Stack and temporary entries whose contents should be disregarded. */
77343:     bool deadEntry(const FrameEntry *fe, unsigned uses = 0) const {
77343:         return (fe >= (a->sp - uses) && fe < temporaries) || fe >= temporariesTop;
75864:     }
63240: 
77343:     RegisterState & regstate(AnyRegisterID reg) {
77343:         JS_ASSERT(reg.reg_ < Registers::TotalAnyRegisters);
77343:         return regstate_[reg.reg_];
75647:     }
77343: 
77343:     const RegisterState & regstate(AnyRegisterID reg) const {
77343:         JS_ASSERT(reg.reg_ < Registers::TotalAnyRegisters);
77343:         return regstate_[reg.reg_];
76206:     }
75647: 
77343:     AnyRegisterID bestEvictReg(uint32 mask, bool includePinned) const;
77343:     void evictDeadEntries(bool includePinned);
77343: 
77343:     inline analyze::Lifetime * variableLive(FrameEntry *fe, jsbytecode *pc) const;
77343:     inline bool binaryEntryLive(FrameEntry *fe) const;
77343:     void relocateReg(AnyRegisterID reg, RegisterAllocation *alloc, Uses uses);
77343: 
77343:     bool isThis(const FrameEntry *fe) const {
77343:         return fe == a->this_;
77343:     }
77343: 
77432:     inline bool isConstructorThis(const FrameEntry *fe) const;
77432: 
77343:     bool isArg(const FrameEntry *fe) const {
77391:         return a->script->hasFunction && fe >= a->args && fe - a->args < a->script->function()->nargs;
77343:     }
77343: 
77343:     bool isLocal(const FrameEntry *fe) const {
77343:         return fe >= a->locals && fe - a->locals < a->script->nfixed;
77343:     }
77343: 
77343:     bool isTemporary(const FrameEntry *fe) const {
77343:         JS_ASSERT_IF(fe >= temporaries, fe < temporariesTop);
77343:         return fe >= temporaries;
77343:     }
77343: 
77343:     int32 frameOffset(const FrameEntry *fe, ActiveFrame *a) const;
77343:     Address addressOf(const FrameEntry *fe, ActiveFrame *a) const;
77343:     uint32 frameSlot(ActiveFrame *a, const FrameEntry *fe) const;
77343: 
77343:     void associateReg(FrameEntry *fe, RematInfo::RematType type, AnyRegisterID reg);
77343: 
77343:     inline void modifyReg(AnyRegisterID reg);
77343: 
77343:     MaybeJump guardArrayLengthBase(FrameEntry *obj, Int32Key key);
63240: 
52560:   private:
52560:     JSContext *cx;
77343:     Assembler &masm;
77343:     Compiler &cc;
77343:     StubCompiler &stubcc;
77343: 
77343:     /* State for the active stack frame. */
77343: 
77343:     struct ActiveFrame {
77343:         ActiveFrame() { PodZero(this); }
77343: 
77343:         ActiveFrame *parent;
77343: 
77343:         /* Number of values between the start of the outer frame and the start of this frame. */
77343:         uint32 depth;
77343: 
76206:         JSScript *script;
77343:         jsbytecode *PC;
77343:         analyze::ScriptAnalysis *analysis;
63240: 
77343:         /* Indexes into the main FrameEntry buffer of entries for this frame. */
75864:         FrameEntry *callee_;
75864:         FrameEntry *this_;
77343:         FrameEntry *args;
77343:         FrameEntry *locals;
77343:         FrameEntry *spBase;
77343:         FrameEntry *sp;
77343:     };
77343:     ActiveFrame *a;
76206: 
77343:     /* Common buffer of frame entries. */
77343:     FrameEntry *entries;
77343:     uint32 nentries;
76206: 
77343:     /* Compiler-owned metadata for stack contents. */
77343:     StackEntryExtra *extraArray;
52617: 
75864:     /* Vector of tracked slot indexes. */
75864:     Tracker tracker;
75864: 
77343: #if defined JS_NUNBOX32
77343:     mutable ImmutableSync reifier;
77343: #endif
77343: 
76206:     /*
76206:      * Register ownership state. This can't be used alone; to find whether an
76206:      * entry is active, you must check the allocated registers.
76206:      */
77343:     RegisterState regstate_[Registers::TotalAnyRegisters];
76206: 
77343:     /* All unallocated registers. */
77343:     Registers freeRegs;
75864: 
77343:     /* Stack of active loops. */
77343:     LoopState *loop;
77343: 
77343:     /*
77343:      * Track state for analysis temporaries. The meaning of these temporaries
77343:      * is opaque to the frame state, which just tracks where they are stored.
77343:      */
77343:     FrameEntry *temporaries;
77343:     FrameEntry *temporariesTop;
77343: 
63240:     bool inTryBlock;
63240: };
52617: 
77343: /*
77343:  * Register allocation overview. We want to allocate registers at the same time
77343:  * as we emit code, in a single forward pass over the script. This is good both
77343:  * for compilation speed and for design simplicity; we allocate registers for
77343:  * variables and temporaries as the compiler needs them. To get a good allocation,
77343:  * however, we need knowledge of which variables will be used in the future and
77343:  * in what order --- we must prioritize keeping variables in registers which
77343:  * will be used soon, and evict variables after they are no longer needed.
77343:  * We get this from the analyze::LifetimeScript analysis, an initial backwards
77343:  * pass over the script.
77343:  *
77343:  * Combining a backwards lifetime pass with a forward allocation pass in this
77343:  * way produces a Linear-scan register allocator. These can generate code at
77343:  * a speed close to that produced by a graph coloring register allocator,
77343:  * at a fraction of the compilation time.
77343:  */
77343: 
77343: /* Register allocation to use at a join point. */
77343: struct RegisterAllocation {
77343:   private:
77343:     typedef JSC::MacroAssembler::RegisterID RegisterID;
77343:     typedef JSC::MacroAssembler::FPRegisterID FPRegisterID;
77343: 
77343:     /* Entry for an unassigned register at the join point. */
77343:     static const uint32 UNASSIGNED_REGISTER = uint32(-1);
77343: 
77343:     /*
77343:      * In the body of a loop, entry for an unassigned register that has not been
77343:      * used since the start of the loop. We do not finalize the register state
77343:      * at the start of a loop body until after generating code for the entire loop,
77343:      * so we can decide on which variables to carry around the loop after seeing
77343:      * them accessed early on in the body.
77343:      */
77343:     static const uint32 LOOP_REGISTER = uint32(-2);
77343: 
77343:     /*
77343:      * Assignment of registers to payloads. Type tags are always in memory,
77343:      * except for known doubles in FP registers. These are indexes into the
77343:      * frame's entries[] buffer, not slots.
77343:      */
77343:     uint32 regstate_[Registers::TotalAnyRegisters];
77343: 
77343:     /* Mask for regstate entries indicating if the slot is synced. */
77343:     static const uint32 SYNCED = 0x80000000;
77343: 
77343:     uint32 & regstate(AnyRegisterID reg) {
77343:         JS_ASSERT(reg.reg_ < Registers::TotalAnyRegisters);
77343:         return regstate_[reg.reg_];
77343:     }
77343: 
77343:   public:
77343:     RegisterAllocation(bool forLoop)
77343:     {
77343:         uint32 entry = forLoop ? (uint32) LOOP_REGISTER : (uint32) UNASSIGNED_REGISTER;
77343:         for (unsigned i = 0; i < Registers::TotalAnyRegisters; i++) {
77343:             AnyRegisterID reg = AnyRegisterID::fromRaw(i);
77343:             bool avail = Registers::maskReg(reg) & Registers::AvailAnyRegs;
77343:             regstate_[i] = avail ? entry : UNASSIGNED_REGISTER;
77343:         }
77343:     }
77343: 
77343:     bool assigned(AnyRegisterID reg) {
77343:         return regstate(reg) != UNASSIGNED_REGISTER && regstate(reg) != LOOP_REGISTER;
77343:     }
77343: 
77343:     bool loop(AnyRegisterID reg) {
77343:         return regstate(reg) == LOOP_REGISTER;
77343:     }
77343: 
77343:     bool synced(AnyRegisterID reg) {
77343:         JS_ASSERT(assigned(reg));
77343:         return regstate(reg) & SYNCED;
77343:     }
77343: 
77343:     uint32 index(AnyRegisterID reg) {
77343:         JS_ASSERT(assigned(reg));
77343:         return regstate(reg) & ~SYNCED;
77343:     }
77343: 
77343:     void set(AnyRegisterID reg, uint32 index, bool synced) {
77343:         JS_ASSERT(index != LOOP_REGISTER && index != UNASSIGNED_REGISTER);
77343:         regstate(reg) = index | (synced ? SYNCED : 0);
77343:     }
77343: 
77343:     void setUnassigned(AnyRegisterID reg) {
77343:         regstate(reg) = UNASSIGNED_REGISTER;
77343:     }
77343: 
77343:     bool synced() {
77343:         for (unsigned i = 0; i < Registers::TotalAnyRegisters; i++) {
77343:             if (assigned(AnyRegisterID::fromRaw(i)))
77343:                 return false;
77343:         }
77343:         return true;
77343:     }
77343: 
77343:     void clearLoops() {
77343:         for (unsigned i = 0; i < Registers::TotalAnyRegisters; i++) {
77343:             AnyRegisterID reg = AnyRegisterID::fromRaw(i);
77343:             if (loop(reg))
77343:                 setUnassigned(reg);
77343:         }
77343:     }
77343: 
77343:     bool hasAnyReg(uint32 n) {
77343:         for (unsigned i = 0; i < Registers::TotalAnyRegisters; i++) {
77343:             AnyRegisterID reg = AnyRegisterID::fromRaw(i);
77343:             if (assigned(reg) && index(reg) == n)
77343:                 return true;
77343:         }
77343:         return false;
77343:     }
77343: };
77343: 
57713: class AutoPreserveAcrossSyncAndKill;
57713: 
52560: } /* namespace mjit */
52560: } /* namespace js */
52560: 
52560: #endif /* jsjaeger_framestate_h__ */
52560: 
