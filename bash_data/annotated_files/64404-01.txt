40132: /* vim:set ts=2 sw=2 sts=2 et cindent: */
40132: /* ***** BEGIN LICENSE BLOCK *****
40132:  * Version: ML 1.1/GPL 2.0/LGPL 2.1
40132:  *
40132:  * The contents of this file are subject to the Mozilla Public License Version
40132:  * 1.1 (the "License"); you may not use this file except in compliance with
40132:  * the License. You may obtain a copy of the License at
40132:  * http://www.mozilla.org/MPL/
40132:  *
40132:  * Software distributed under the License is distributed on an "AS IS" basis,
40132:  * WITHOUT WARRANTY OF ANY KIND, either express or implied. See the License
40132:  * for the specific language governing rights and limitations under the
40132:  * License.
40132:  *
40132:  * The Original Code is Mozilla code.
40132:  *
40132:  * The Initial Developer of the Original Code is the Mozilla Corporation.
40132:  * Portions created by the Initial Developer are Copyright (C) 2007
40132:  * the Initial Developer. All Rights Reserved.
40132:  *
40132:  * Contributor(s):
40132:  *  Chris Double <chris.double@double.co.nz>
40132:  *  Chris Pearce <chris@pearce.org.nz>
40132:  *
40132:  * Alternatively, the contents of this file may be used under the terms of
40132:  * either the GNU General Public License Version 2 or later (the "GPL"), or
40132:  * the GNU Lesser General Public License Version 2.1 or later (the "LGPL"),
40132:  * in which case the provisions of the GPL or the LGPL are applicable instead
40132:  * of those above. If you wish to allow use of your version of this file only
40132:  * under the terms of either the GPL or the LGPL, and not to allow others to
40132:  * use your version of this file under the terms of the MPL, indicate your
40132:  * decision by deleting the provisions above and replace them with the notice
40132:  * and other provisions required by the GPL or the LGPL. If you do not delete
40132:  * the provisions above, a recipient may use your version of this file under
40132:  * the terms of any one of the MPL, the GPL or the LGPL.
40132:  *
40132:  * ***** END LICENSE BLOCK ***** */
40132: 
40132: #include <limits>
40132: #include "nsAudioStream.h"
40132: #include "nsTArray.h"
41387: #include "nsBuiltinDecoder.h"
41954: #include "nsBuiltinDecoderReader.h"
41954: #include "nsBuiltinDecoderStateMachine.h"
40132: #include "mozilla/mozalloc.h"
41387: #include "VideoUtils.h"
63622: #include "nsTimeRanges.h"
40132: 
41954: using namespace mozilla;
40132: using namespace mozilla::layers;
40132: 
40132: #ifdef PR_LOGGING
41387: extern PRLogModuleInfo* gBuiltinDecoderLog;
41387: #define LOG(type, msg) PR_LOG(gBuiltinDecoderLog, type, msg)
40132: #else
40132: #define LOG(type, msg)
40132: #endif
40132: 
40132: // Wait this number of seconds when buffering, then leave and play
40132: // as best as we can if the required amount of data hasn't been
40132: // retrieved.
40132: #define BUFFERING_WAIT 30
40132: 
40132: // The amount of data to retrieve during buffering is computed based
40132: // on the download rate. BUFFERING_MIN_RATE is the minimum download
40132: // rate to be used in that calculation to help avoid constant buffering
40132: // attempts at a time when the average download rate has not stabilised.
40132: #define BUFFERING_MIN_RATE 50000
40132: #define BUFFERING_RATE(x) ((x)< BUFFERING_MIN_RATE ? BUFFERING_MIN_RATE : (x))
40132: 
41388: // If audio queue has less than this many ms of decoded audio, we won't risk
41388: // trying to decode the video, we'll skip decoding video up to the next
58312: // keyframe. We may increase this value for an individual decoder if we
58312: // encounter video frames which take a long time to decode.
43340: static const PRUint32 LOW_AUDIO_MS = 300;
41388: 
42254: // If more than this many ms of decoded audio is queued, we'll hold off
58312: // decoding more audio. If we increase the low audio threshold (see
58312: // LOW_AUDIO_MS above) we'll also increase this value to ensure it's not
58312: // less than the low audio threshold.
63624: const PRInt64 AMPLE_AUDIO_MS = 1000;
42254: 
50359: // Maximum number of bytes we'll allocate and write at once to the audio
50359: // hardware when the audio stream contains missing samples and we're
50359: // writing silence in order to fill the gap. We limit our silence-writes
50359: // to 32KB in order to avoid allocating an impossibly large chunk of
50359: // memory if we encounter a large chunk of silence.
50359: const PRUint32 SILENCE_BYTES_CHUNK = 32 * 1024;
50359: 
41388: // If we have fewer than LOW_VIDEO_FRAMES decoded frames, and
41388: // we're not "pumping video", we'll skip the video up to the next keyframe
41388: // which is at or after the current playback position.
41388: static const PRUint32 LOW_VIDEO_FRAMES = 1;
41388: 
53827: // If we've got more than AMPLE_VIDEO_FRAMES decoded video frames waiting in
53827: // the video queue, we will not decode any more video frames until some have
53827: // been consumed by the play state machine thread.
53827: static const PRUint32 AMPLE_VIDEO_FRAMES = 10;
53827: 
43445: // Arbitrary "frame duration" when playing only audio.
63232: static const int AUDIO_DURATION_MS = 40;
43445: 
58312: // If we increase our "low audio threshold" (see LOW_AUDIO_MS above), we
58312: // use this as a factor in all our calculations. Increasing this will cause
58312: // us to be more likely to increase our low audio threshold, and to
58312: // increase it by more.
58312: static const int THRESHOLD_FACTOR = 2;
58312: 
63622: // If we have less than this much undecoded data available, we'll consider
63622: // ourselves to be running low on undecoded data. We determine how much
63622: // undecoded data we have remaining using the reader's GetBuffered()
63622: // implementation.
63622: static const PRInt64 LOW_DATA_THRESHOLD_MS = 5000;
58312: 
63622: // LOW_DATA_THRESHOLD_MS needs to be greater than AMPLE_AUDIO_MS, otherwise
63622: // the skip-to-keyframe logic can activate when we're running low on data.
63622: PR_STATIC_ASSERT(LOW_DATA_THRESHOLD_MS > AMPLE_AUDIO_MS);
58312: 
63621: // Amount of excess ms of data to add in to the "should we buffer" calculation.
63621: static const PRUint32 EXHAUSTED_DATA_MARGIN_MS = 60;
63621: 
63623: // If we enter buffering within QUICK_BUFFER_THRESHOLD_MS seconds of starting
63623: // decoding, we'll enter "quick buffering" mode, which exits a lot sooner than
63623: // normal buffering mode. This exists so that if the decode-ahead exhausts the
63623: // downloaded data while decode/playback is just starting up (for example
63623: // after a seek while the media is still playing, or when playing a media
63623: // as soon as it's load started), we won't necessarily stop for 30s and wait
63623: // for buffering. We may actually be able to playback in this case, so exit
63623: // buffering early and try to play. If it turns out we can't play, we'll fall
63623: // back to buffering normally.
63623: static const PRUint32 QUICK_BUFFER_THRESHOLD_MS = 2000;
63623: 
63623: // If we're quick buffering, we'll remain in buffering mode while we have less than
63623: // QUICK_BUFFERING_LOW_DATA_MS of decoded data available.
63623: static const PRUint32 QUICK_BUFFERING_LOW_DATA_MS = 1000;
63623: 
63623: // If QUICK_BUFFERING_LOW_DATA_MS is > AMPLE_AUDIO_MS, we won't exit
63623: // quick buffering in a timely fashion, as the decode pauses when it
63623: // reaches AMPLE_AUDIO_MS decoded data, and thus we'll never reach
63623: // QUICK_BUFFERING_LOW_DATA_MS.
63623: PR_STATIC_ASSERT(QUICK_BUFFERING_LOW_DATA_MS <= AMPLE_AUDIO_MS);
63623: 
63621: static TimeDuration MsToDuration(PRInt64 aMs) {
63621:   return TimeDuration::FromMilliseconds(static_cast<double>(aMs));
63621: }
63621: 
63621: static PRInt64 DurationToMs(TimeDuration aDuration) {
63621:   return static_cast<PRInt64>(aDuration.ToSeconds() * 1000);
63621: }
63621: 
51477: class nsAudioMetadataEventRunner : public nsRunnable
51477: {
51477: private:
51477:   nsCOMPtr<nsBuiltinDecoder> mDecoder;
51477: public:
51477:   nsAudioMetadataEventRunner(nsBuiltinDecoder* aDecoder, PRUint32 aChannels,
51477:                              PRUint32 aRate, PRUint32 aFrameBufferLength) :
51477:     mDecoder(aDecoder),
51477:     mChannels(aChannels),
51477:     mRate(aRate),
51477:     mFrameBufferLength(aFrameBufferLength)
51477:   {
51477:   }
51477: 
51477:   NS_IMETHOD Run()
51477:   {
51477:     mDecoder->MetadataLoaded(mChannels, mRate, mFrameBufferLength);
51477:     return NS_OK;
51477:   }
51477: 
51477:   const PRUint32 mChannels;
51477:   const PRUint32 mRate;
51477:   const PRUint32 mFrameBufferLength;
51477: };
51477: 
41954: nsBuiltinDecoderStateMachine::nsBuiltinDecoderStateMachine(nsBuiltinDecoder* aDecoder,
41954:                                                            nsBuiltinDecoderReader* aReader) :
40132:   mDecoder(aDecoder),
40132:   mState(DECODER_STATE_DECODING_METADATA),
40132:   mAudioMonitor("media.audiostream"),
40132:   mCbCrSize(0),
40132:   mPlayDuration(0),
40132:   mStartTime(-1),
40132:   mEndTime(-1),
40132:   mSeekTime(0),
41954:   mReader(aReader),
40132:   mCurrentFrameTime(0),
40132:   mAudioStartTime(-1),
40132:   mAudioEndTime(-1),
43445:   mVideoFrameEndTime(-1),
40132:   mVolume(1.0),
40132:   mSeekable(PR_TRUE),
40132:   mPositionChangeQueued(PR_FALSE),
40132:   mAudioCompleted(PR_FALSE),
54994:   mGotDurationFromMetaData(PR_FALSE),
51477:   mStopDecodeThreads(PR_TRUE),
63623:   mQuickBuffering(PR_FALSE),
51477:   mEventManager(aDecoder)
40132: {
41954:   MOZ_COUNT_CTOR(nsBuiltinDecoderStateMachine);
40132: }
40132: 
41954: nsBuiltinDecoderStateMachine::~nsBuiltinDecoderStateMachine()
40132: {
41954:   MOZ_COUNT_DTOR(nsBuiltinDecoderStateMachine);
40132: }
40132: 
42254: PRBool nsBuiltinDecoderStateMachine::HasFutureAudio() const {
42254:   mDecoder->GetMonitor().AssertCurrentThreadIn();
53827:   NS_ASSERTION(HasAudio(), "Should only call HasFutureAudio() when we have audio");
53827:   // We've got audio ready to play if:
53827:   // 1. We've not completed playback of audio, and
53827:   // 2. we either have more than the threshold of decoded audio available, or
53827:   //    we've completely decoded all audio (but not finished playing it yet
53827:   //    as per 1).
53827:   return !mAudioCompleted &&
53827:          (AudioDecodedMs() > LOW_AUDIO_MS || mReader->mAudioQueue.IsFinished());
42254: }
42254: 
42254: PRBool nsBuiltinDecoderStateMachine::HaveNextFrameData() const {
53827:   mDecoder->GetMonitor().AssertCurrentThreadIn();
53827:   return (!HasAudio() || HasFutureAudio()) &&
53827:          (!HasVideo() || mReader->mVideoQueue.GetSize() > 0);
42254: }
42254: 
60416: PRInt64 nsBuiltinDecoderStateMachine::GetDecodedAudioDuration() {
60416:   NS_ASSERTION(OnDecodeThread(), "Should be on decode thread.");
60416:   mDecoder->GetMonitor().AssertCurrentThreadIn();
60416:   PRInt64 audioDecoded = mReader->mAudioQueue.Duration();
60416:   if (mAudioEndTime != -1) {
60416:     audioDecoded += mAudioEndTime - GetMediaTime();
60416:   }
60416:   return audioDecoded;
60416: }
60416: 
41954: void nsBuiltinDecoderStateMachine::DecodeLoop()
40132: {
40132:   NS_ASSERTION(OnDecodeThread(), "Should be on decode thread.");
40132: 
40132:   // We want to "pump" the decode until we've got a few frames/samples decoded
40132:   // before we consider whether decode is falling behind.
40132:   PRBool audioPump = PR_TRUE;
40132:   PRBool videoPump = PR_TRUE;
40132: 
40132:   // If the video decode is falling behind the audio, we'll start dropping the
40132:   // inter-frames up until the next keyframe which is at or before the current
40132:   // playback position. skipToNextKeyframe is PR_TRUE if we're currently
40132:   // skipping up to the next keyframe.
40132:   PRBool skipToNextKeyframe = PR_FALSE;
40132: 
40132:   // Once we've decoded more than videoPumpThreshold video frames, we'll
40132:   // no longer be considered to be "pumping video".
53827:   const unsigned videoPumpThreshold = AMPLE_VIDEO_FRAMES / 2;
40132: 
40132:   // After the audio decode fills with more than audioPumpThresholdMs ms
40132:   // of decoded audio, we'll start to check whether the audio or video decode
40132:   // is falling behind.
43340:   const unsigned audioPumpThresholdMs = LOW_AUDIO_MS * 2;
40132: 
58312:   // Our local low audio threshold. We may increase this if we're slow to
58312:   // decode video frames, in order to reduce the chance of audio underruns.
58312:   PRInt64 lowAudioThreshold = LOW_AUDIO_MS;
58312: 
58312:   // Our local ample audio threshold. If we increase lowAudioThreshold, we'll
60416:   // also increase this too appropriately (we don't want lowAudioThreshold to
58312:   // be greater than ampleAudioThreshold, else we'd stop decoding!).
58312:   PRInt64 ampleAudioThreshold = AMPLE_AUDIO_MS;
58312: 
60416:   MediaQueue<VideoData>& videoQueue = mReader->mVideoQueue;
60416:   MediaQueue<SoundData>& audioQueue = mReader->mAudioQueue;
60416: 
60416:   MonitorAutoEnter mon(mDecoder->GetMonitor());
60416: 
60416:   PRBool videoPlaying = HasVideo();
60416:   PRBool audioPlaying = HasAudio();
60416: 
40132:   // Main decode loop.
60416:   while (mState != DECODER_STATE_SHUTDOWN &&
60416:          !mStopDecodeThreads &&
60416:          (videoPlaying || audioPlaying))
40132:   {
60416:     // We don't want to consider skipping to the next keyframe if we've
60416:     // only just started up the decode loop, so wait until we've decoded
60416:     // some frames before enabling the keyframe skip logic on video.
61822:     if (videoPump &&
61822:         static_cast<PRUint32>(videoQueue.GetSize()) >= videoPumpThreshold)
61822:     {
60416:       videoPump = PR_FALSE;
40132:     }
40132: 
40132:     // We don't want to consider skipping to the next keyframe if we've
40132:     // only just started up the decode loop, so wait until we've decoded
60416:     // some audio data before enabling the keyframe skip logic on audio.
60416:     if (audioPump && GetDecodedAudioDuration() >= audioPumpThresholdMs) {
60416:       audioPump = PR_FALSE;
40132:     }
40132: 
58312:     // We'll skip the video decode to the nearest keyframe if we're low on
58312:     // audio, or if we're low on video, provided we're not running low on
58312:     // data to decode. If we're running low on downloaded data to decode,
58312:     // we won't start keyframe skipping, as we'll be pausing playback to buffer
58312:     // soon anyway and we'll want to be able to display frames immediately
58312:     // after buffering finishes.
63622:     if (mState == DECODER_STATE_DECODING &&
63622:         !skipToNextKeyframe &&
58312:         videoPlaying &&
60416:         ((!audioPump && audioPlaying && GetDecodedAudioDuration() < lowAudioThreshold) ||
61822:          (!videoPump &&
61822:            videoPlaying &&
63622:            static_cast<PRUint32>(videoQueue.GetSize()) < LOW_VIDEO_FRAMES)) &&
63622:         !HasLowUndecodedData())
63622: 
58312:     {
40132:       skipToNextKeyframe = PR_TRUE;
58312:       LOG(PR_LOG_DEBUG, ("Skipping video decode to the next keyframe"));
40132:     }
40132: 
58312:     // Video decode.
61822:     if (videoPlaying &&
61822:         static_cast<PRUint32>(videoQueue.GetSize()) < AMPLE_VIDEO_FRAMES)
61822:     {
58312:       // Time the video decode, so that if it's slow, we can increase our low
58312:       // audio threshold to reduce the chance of an audio underrun while we're
58312:       // waiting for a video decode to complete.
60416:       TimeDuration decodeTime;
60416:       {
60416:         PRInt64 currentTime = GetMediaTime();
60416:         MonitorAutoExit exitMon(mDecoder->GetMonitor());
58312:         TimeStamp start = TimeStamp::Now();
41954:         videoPlaying = mReader->DecodeVideoFrame(skipToNextKeyframe, currentTime);
60416:         decodeTime = TimeStamp::Now() - start;
60416:       }
63624:       if (THRESHOLD_FACTOR * DurationToMs(decodeTime) > lowAudioThreshold &&
63622:           !HasLowUndecodedData())
58312:       {
58312:         lowAudioThreshold =
63624:           NS_MIN(THRESHOLD_FACTOR * DurationToMs(decodeTime), AMPLE_AUDIO_MS);
58312:         ampleAudioThreshold = NS_MAX(THRESHOLD_FACTOR * lowAudioThreshold,
58312:                                      ampleAudioThreshold);
58312:         LOG(PR_LOG_DEBUG,
58312:             ("Slow video decode, set lowAudioThreshold=%lld ampleAudioThreshold=%lld",
58312:              lowAudioThreshold, ampleAudioThreshold));
58312:       }
40132:     }
40132: 
58312:     // Audio decode.
60416:     if (audioPlaying &&
60416:         (GetDecodedAudioDuration() < ampleAudioThreshold || audioQueue.GetSize() == 0))
60416:     {
60416:       MonitorAutoExit exitMon(mDecoder->GetMonitor());
41954:       audioPlaying = mReader->DecodeAudioData();
40132:     }
40132:     
60416:     // Notify to ensure that the AudioLoop() is not waiting, in case it was
60416:     // waiting for more audio to be decoded.
60416:     mDecoder->GetMonitor().NotifyAll();
40132: 
53828:     if (!IsPlaying()) {
53828:       // Update the ready state, so that the play DOM events fire. We only
53828:       // need to do this if we're not playing; if we're playing the playback
53828:       // code will do an update whenever it advances a frame.
40132:       UpdateReadyState();
40132:     }
40132: 
60416:     if (mState != DECODER_STATE_SHUTDOWN &&
60416:         !mStopDecodeThreads &&
60416:         (!audioPlaying || (GetDecodedAudioDuration() >= ampleAudioThreshold &&
60416:                            audioQueue.GetSize() > 0))
60416:         &&
61822:         (!videoPlaying ||
61822:           static_cast<PRUint32>(videoQueue.GetSize()) >= AMPLE_VIDEO_FRAMES))
60416:     {
60416:       // All active bitstreams' decode is well ahead of the playback
60416:       // position, we may as well wait for the playback to catch up. Note the
60416:       // audio push thread acquires and notifies the decoder monitor every time
60416:       // it pops SoundData off the audio queue. So if the audio push thread pops
60416:       // the last SoundData off the audio queue right after that queue reported
60416:       // it was non-empty here, we'll receive a notification on the decoder
60416:       // monitor which will wake us up shortly after we sleep, thus preventing
60416:       // both the decode and audio push threads waiting at the same time.
60416:       // See bug 620326.
60416:       mon.Wait();
40132:     }
53827: 
60416:   } // End decode loop.
40132: 
40132:   if (!mStopDecodeThreads &&
40132:       mState != DECODER_STATE_SHUTDOWN &&
40132:       mState != DECODER_STATE_SEEKING)
40132:   {
40132:     mState = DECODER_STATE_COMPLETED;
40132:     mDecoder->GetMonitor().NotifyAll();
40132:   }
60416: 
40132:   LOG(PR_LOG_DEBUG, ("Shutting down DecodeLoop this=%p", this));
40132: }
40132: 
41954: PRBool nsBuiltinDecoderStateMachine::IsPlaying()
40132: {
40132:   mDecoder->GetMonitor().AssertCurrentThreadIn();
40132: 
40132:   return !mPlayStartTime.IsNull();
40132: }
40132: 
41954: void nsBuiltinDecoderStateMachine::AudioLoop()
40132: {
40132:   NS_ASSERTION(OnAudioThread(), "Should be on audio thread.");
40132:   LOG(PR_LOG_DEBUG, ("Begun audio thread/loop"));
59468:   PRInt64 audioDuration = 0;
50359:   PRInt64 audioStartTime = -1;
50359:   PRUint32 channels, rate;
60727:   double volume = -1;
52052:   PRBool setVolume;
59468:   PRInt32 minWriteSamples = -1;
59468:   PRInt64 samplesAtLastSleep = 0;
40132:   {
40132:     MonitorAutoEnter mon(mDecoder->GetMonitor());
40132:     mAudioCompleted = PR_FALSE;
50359:     audioStartTime = mAudioStartTime;
63857:     channels = mInfo.mAudioChannels;
63857:     rate = mInfo.mAudioRate;
50359:     NS_ASSERTION(audioStartTime != -1, "Should have audio start time by now");
40132:   }
40132:   while (1) {
40132: 
40132:     // Wait while we're not playing, and we're not shutting down, or we're
40132:     // playing and we've got no audio to play.
40132:     {
40132:       MonitorAutoEnter mon(mDecoder->GetMonitor());
40132:       NS_ASSERTION(mState != DECODER_STATE_DECODING_METADATA,
40132:                    "Should have meta data before audio started playing.");
40132:       while (mState != DECODER_STATE_SHUTDOWN &&
40132:              !mStopDecodeThreads &&
40132:              (!IsPlaying() ||
40132:               mState == DECODER_STATE_BUFFERING ||
40134:               (mReader->mAudioQueue.GetSize() == 0 &&
40132:                !mReader->mAudioQueue.AtEndOfStream())))
40132:       {
59468:         samplesAtLastSleep = audioDuration;
40132:         mon.Wait();
40132:       }
40132: 
40132:       // If we're shutting down, break out and exit the audio thread.
40132:       if (mState == DECODER_STATE_SHUTDOWN ||
40132:           mStopDecodeThreads ||
40132:           mReader->mAudioQueue.AtEndOfStream())
40132:       {
40132:         break;
40132:       }
52052: 
52052:       // We only want to go to the expense of taking the audio monitor and
52052:       // changing the volume if it's the first time we've entered the loop
52052:       // (as we must sync the volume in case it's changed since the
52052:       // nsAudioStream was created) or if the volume has changed.
52052:       setVolume = volume != mVolume;
52052:       volume = mVolume;
40132:     }
40132: 
59468:     if (setVolume || minWriteSamples == -1) {
52052:       MonitorAutoEnter audioMon(mAudioMonitor);
52052:       if (mAudioStream) {
59468:         if (setVolume) {
52052:           mAudioStream->SetVolume(volume);
52052:         }
59468:         if (minWriteSamples == -1) {
59468:           minWriteSamples = mAudioStream->GetMinWriteSamples();
59468:         }
59468:       }
52052:     }
40134:     NS_ASSERTION(mReader->mAudioQueue.GetSize() > 0,
40132:                  "Should have data to play");
50359:     // See if there's missing samples in the audio stream. If there is, push
50359:     // silence into the audio hardware, so we can play across the gap.
50359:     const SoundData* s = mReader->mAudioQueue.PeekFront();
50359: 
50359:     // Calculate the number of samples that have been pushed onto the audio
50359:     // hardware.
50359:     PRInt64 playedSamples = 0;
50359:     if (!MsToSamples(audioStartTime, rate, playedSamples)) {
50359:       NS_WARNING("Int overflow converting playedSamples");
50359:       break;
50359:     }
50359:     if (!AddOverflow(playedSamples, audioDuration, playedSamples)) {
50359:       NS_WARNING("Int overflow adding playedSamples");
50359:       break;
50359:     }
50359: 
50359:     // Calculate the timestamp of the next chunk of audio in numbers of
50359:     // samples.
50359:     PRInt64 sampleTime = 0;
50359:     if (!MsToSamples(s->mTime, rate, sampleTime)) {
50359:       NS_WARNING("Int overflow converting sampleTime");
50359:       break;
50359:     }
50359:     PRInt64 missingSamples = 0;
50359:     if (!AddOverflow(sampleTime, -playedSamples, missingSamples)) {
50359:       NS_WARNING("Int overflow adding missingSamples");
50359:       break;
50359:     }
50359: 
50359:     if (missingSamples > 0) {
50359:       // The next sound chunk begins some time after the end of the last chunk
50359:       // we pushed to the sound hardware. We must push silence into the audio
50359:       // hardware so that the next sound chunk begins playback at the correct
50359:       // time.
50359:       missingSamples = NS_MIN(static_cast<PRInt64>(PR_UINT32_MAX), missingSamples);
51477:       audioDuration += PlaySilence(static_cast<PRUint32>(missingSamples),
54997:                                    channels, playedSamples);
50359:     } else {
51477:       audioDuration += PlayFromAudioQueue(sampleTime, channels);
50359:     }
40132:     {
40132:       MonitorAutoEnter mon(mDecoder->GetMonitor());
50359:       PRInt64 playedMs;
50359:       if (!SamplesToMs(audioDuration, rate, playedMs)) {
50359:         NS_WARNING("Int overflow calculating playedMs");
50359:         break;
50359:       }
50359:       if (!AddOverflow(audioStartTime, playedMs, mAudioEndTime)) {
50359:         NS_WARNING("Int overflow calculating audio end time");
50359:         break;
40132:       }
40132: 
53826:       PRInt64 audioAhead = mAudioEndTime - GetMediaTime();
59468:       if (audioAhead > AMPLE_AUDIO_MS &&
59468:           audioDuration - samplesAtLastSleep > minWriteSamples)
59468:       {
59468:         samplesAtLastSleep = audioDuration;
42254:         // We've pushed enough audio onto the hardware that we've queued up a
42254:         // significant amount ahead of the playback position. The decode
42254:         // thread will be going to sleep, so we won't get any new samples
42254:         // anyway, so sleep until we need to push to the hardware again.
42254:         Wait(AMPLE_AUDIO_MS / 2);
42254:         // Kick the decode thread; since above we only do a NotifyAll when
42254:         // we pop an audio chunk of the queue, the decoder won't wake up if
42254:         // we've got no more decoded chunks to push to the hardware. We can
42254:         // hit this condition if the last sample in the stream doesn't have
42254:         // it's EOS flag set, and the decode thread sleeps just after decoding
42254:         // that packet, but before realising there's no more packets.
42254:         mon.NotifyAll();
42254:       }
42254:     }
42254:   }
42254:   if (mReader->mAudioQueue.AtEndOfStream() &&
42254:       mState != DECODER_STATE_SHUTDOWN &&
42254:       !mStopDecodeThreads)
42254:   {
40132:     // Last sample pushed to audio hardware, wait for the audio to finish,
40132:     // before the audio thread terminates.
40132:     MonitorAutoEnter audioMon(mAudioMonitor);
40132:     if (mAudioStream) {
61820:       PRBool seeking = PR_FALSE;
61820:       PRInt64 oldPosition = -1;
61820: 
61820:       {
61820:         MonitorAutoExit audioExit(mAudioMonitor);
61820:         MonitorAutoEnter mon(mDecoder->GetMonitor());
61820:         PRInt64 position = GetMediaTime();
61820:         while (oldPosition != position &&
61820:                mAudioEndTime - position > 0 &&
61820:                mState != DECODER_STATE_SEEKING &&
61820:                mState != DECODER_STATE_SHUTDOWN)
61820:         {
61820:           const PRInt64 DRAIN_BLOCK_MS = 100;
61820:           Wait(NS_MIN(mAudioEndTime - position, DRAIN_BLOCK_MS));
61820:           oldPosition = position;
61820:           position = GetMediaTime();
61820:         }
61820:         if (mState == DECODER_STATE_SEEKING) {
61820:           seeking = PR_TRUE;
61820:         }
61820:       }
61820: 
61821:       if (!seeking && mAudioStream && !mAudioStream->IsPaused()) {
40132:         mAudioStream->Drain();
61820: 
51477:         // Fire one last event for any extra samples that didn't fill a framebuffer.
51477:         mEventManager.Drain(mAudioEndTime);
40132:       }
61820:     }
40132:     LOG(PR_LOG_DEBUG, ("%p Reached audio stream end.", mDecoder));
40132:   }
40132:   {
40132:     MonitorAutoEnter mon(mDecoder->GetMonitor());
40132:     mAudioCompleted = PR_TRUE;
42254:     UpdateReadyState();
42254:     // Kick the decode and state machine threads; they may be sleeping waiting
42254:     // for this to finish.
42254:     mDecoder->GetMonitor().NotifyAll();
40132:   }
40132:   LOG(PR_LOG_DEBUG, ("Audio stream finished playing, audio thread exit"));
40132: }
40132: 
51477: PRUint32 nsBuiltinDecoderStateMachine::PlaySilence(PRUint32 aSamples,
51477:                                                    PRUint32 aChannels,
51477:                                                    PRUint64 aSampleOffset)
51477: 
50359: {
50359:   MonitorAutoEnter audioMon(mAudioMonitor);
64404:   if (!mAudioStream || mAudioStream->IsPaused()) {
50359:     // The state machine has paused since we've released the decoder
50359:     // monitor and acquired the audio monitor. Don't write any audio.
50359:     return 0;
50359:   }
50359:   PRUint32 maxSamples = SILENCE_BYTES_CHUNK / aChannels;
50359:   PRUint32 samples = NS_MIN(aSamples, maxSamples);
56070:   PRUint32 numValues = samples * aChannels;
56070:   nsAutoArrayPtr<SoundDataValue> buf(new SoundDataValue[numValues]);
56070:   memset(buf.get(), 0, sizeof(SoundDataValue) * numValues);
56070:   mAudioStream->Write(buf, numValues, PR_TRUE);
51477:   // Dispatch events to the DOM for the audio just written.
56070:   mEventManager.QueueWrittenAudioData(buf.get(), numValues,
51477:                                       (aSampleOffset + samples) * aChannels);
50359:   return samples;
50359: }
50359: 
51477: PRUint32 nsBuiltinDecoderStateMachine::PlayFromAudioQueue(PRUint64 aSampleOffset,
51477:                                                           PRUint32 aChannels)
50359: {
50359:   nsAutoPtr<SoundData> sound(mReader->mAudioQueue.PopFront());
50359:   {
50359:     MonitorAutoEnter mon(mDecoder->GetMonitor());
50359:     NS_WARN_IF_FALSE(IsPlaying(), "Should be playing");
50359:     // Awaken the decode loop if it's waiting for space to free up in the
50359:     // audio queue.
50359:     mDecoder->GetMonitor().NotifyAll();
50359:   }
50359:   PRInt64 offset = -1;
50359:   PRUint32 samples = 0;
50359:   {
50359:     MonitorAutoEnter audioMon(mAudioMonitor);
50359:     if (!mAudioStream) {
50359:       return 0;
50359:     }
50359:     // The state machine could have paused since we've released the decoder
50359:     // monitor and acquired the audio monitor. Rather than acquire both
50359:     // monitors, the audio stream also maintains whether its paused or not.
50359:     // This prevents us from doing a blocking write while holding the audio
50359:     // monitor while paused; we would block, and the state machine won't be
50359:     // able to acquire the audio monitor in order to resume or destroy the
50359:     // audio stream.
50359:     if (!mAudioStream->IsPaused()) {
50359:       mAudioStream->Write(sound->mAudioData,
50359:                           sound->AudioDataLength(),
50359:                           PR_TRUE);
51477: 
50359:       offset = sound->mOffset;
50359:       samples = sound->mSamples;
51477: 
51477:       // Dispatch events to the DOM for the audio just written.
51477:       mEventManager.QueueWrittenAudioData(sound->mAudioData.get(),
51477:                                           sound->AudioDataLength(),
51477:                                           (aSampleOffset + samples) * aChannels);
50359:     } else {
50359:       mReader->mAudioQueue.PushFront(sound);
50359:       sound.forget();
50359:     }
50359:   }
50359:   if (offset != -1) {
50359:     mDecoder->UpdatePlaybackOffset(offset);
50359:   }
50359:   return samples;
50359: }
50359: 
54993: nsresult nsBuiltinDecoderStateMachine::Init(nsDecoderStateMachine* aCloneDonor)
40132: {
54993:   nsBuiltinDecoderReader* cloneReader = nsnull;
54993:   if (aCloneDonor) {
54993:     cloneReader = static_cast<nsBuiltinDecoderStateMachine*>(aCloneDonor)->mReader;
54993:   }
54993:   return mReader->Init(cloneReader);
40132: }
40132: 
41954: void nsBuiltinDecoderStateMachine::StopPlayback(eStopMode aMode)
40132: {
41387:   NS_ASSERTION(IsCurrentThread(mDecoder->mStateMachineThread),
40132:                "Should be on state machine thread.");
40132:   mDecoder->GetMonitor().AssertCurrentThreadIn();
40132: 
60723:   mDecoder->mPlaybackStatistics.Stop(TimeStamp::Now());
60723: 
40132:   // Reset mPlayStartTime before we pause/shutdown the nsAudioStream. This is
40132:   // so that if the audio loop is about to write audio, it will have the chance
40132:   // to check to see if we're paused and not write the audio. If not, the
40132:   // audio thread can block in the write, and we deadlock trying to acquire
40132:   // the audio monitor upon resume playback.
40132:   if (IsPlaying()) {
40132:     mPlayDuration += TimeStamp::Now() - mPlayStartTime;
40132:     mPlayStartTime = TimeStamp();
40132:   }
40132:   if (HasAudio()) {
40132:     MonitorAutoExit exitMon(mDecoder->GetMonitor());
40132:     MonitorAutoEnter audioMon(mAudioMonitor);
40132:     if (mAudioStream) {
40132:       if (aMode == AUDIO_PAUSE) {
40132:         mAudioStream->Pause();
40132:       } else if (aMode == AUDIO_SHUTDOWN) {
40132:         mAudioStream->Shutdown();
40132:         mAudioStream = nsnull;
51477:         mEventManager.Clear();
40132:       }
40132:     }
40132:   }
40132: }
40132: 
41954: void nsBuiltinDecoderStateMachine::StartPlayback()
40132: {
41387:   NS_ASSERTION(IsCurrentThread(mDecoder->mStateMachineThread),
40132:                "Should be on state machine thread.");
40132:   NS_ASSERTION(!IsPlaying(), "Shouldn't be playing when StartPlayback() is called");
40132:   mDecoder->GetMonitor().AssertCurrentThreadIn();
40132:   LOG(PR_LOG_DEBUG, ("%p StartPlayback", mDecoder));
60723:   mDecoder->mPlaybackStatistics.Start(TimeStamp::Now());
40132:   if (HasAudio()) {
63857:     PRInt32 rate = mInfo.mAudioRate;
63857:     PRInt32 channels = mInfo.mAudioChannels;
63857: 
63857:     {
40132:       MonitorAutoExit exitMon(mDecoder->GetMonitor());
40132:       MonitorAutoEnter audioMon(mAudioMonitor);
40132:       if (mAudioStream) {
40132:         // We have an audiostream, so it must have been paused the last time
40132:         // StopPlayback() was called.
40132:         mAudioStream->Resume();
40132:       } else {
40132:         // No audiostream, create one.
57627:         mAudioStream = nsAudioStream::AllocateStream();
63857:         mAudioStream->Init(channels, rate, MOZ_SOUND_DATA_FORMAT);
40132:         mAudioStream->SetVolume(mVolume);
40132:       }
40132:     }
63857:   }
40132:   mPlayStartTime = TimeStamp::Now();
40132:   mDecoder->GetMonitor().NotifyAll();
40132: }
40132: 
61823: void nsBuiltinDecoderStateMachine::UpdatePlaybackPositionInternal(PRInt64 aTime)
40132: {
41387:   NS_ASSERTION(IsCurrentThread(mDecoder->mStateMachineThread),
40132:                "Should be on state machine thread.");
40132:   mDecoder->GetMonitor().AssertCurrentThreadIn();
40132: 
40132:   NS_ASSERTION(mStartTime >= 0, "Should have positive mStartTime");
40132:   mCurrentFrameTime = aTime - mStartTime;
40132:   NS_ASSERTION(mCurrentFrameTime >= 0, "CurrentTime should be positive!");
40132:   if (aTime > mEndTime) {
40132:     NS_ASSERTION(mCurrentFrameTime > GetDuration(),
40132:                  "CurrentTime must be after duration if aTime > endTime!");
40132:     mEndTime = aTime;
40132:     nsCOMPtr<nsIRunnable> event =
41387:       NS_NewRunnableMethod(mDecoder, &nsBuiltinDecoder::DurationChanged);
40132:     NS_DispatchToMainThread(event, NS_DISPATCH_NORMAL);
40132:   }
61823: }
61823: 
61823: void nsBuiltinDecoderStateMachine::UpdatePlaybackPosition(PRInt64 aTime)
61823: {
61823:   UpdatePlaybackPositionInternal(aTime);
61823: 
40132:   if (!mPositionChangeQueued) {
40132:     mPositionChangeQueued = PR_TRUE;
40132:     nsCOMPtr<nsIRunnable> event =
41387:       NS_NewRunnableMethod(mDecoder, &nsBuiltinDecoder::PlaybackPositionChanged);
40132:     NS_DispatchToMainThread(event, NS_DISPATCH_NORMAL);
40132:   }
51477: 
51477:   // Notify DOM of any queued up audioavailable events
53826:   mEventManager.DispatchPendingEvents(GetMediaTime());
40132: }
40132: 
41954: void nsBuiltinDecoderStateMachine::ClearPositionChangeFlag()
40132: {
40132:   NS_ASSERTION(NS_IsMainThread(), "Should be on main thread.");
40132:   mDecoder->GetMonitor().AssertCurrentThreadIn();
40132: 
40132:   mPositionChangeQueued = PR_FALSE;
40132: }
40132: 
41954: nsHTMLMediaElement::NextFrameStatus nsBuiltinDecoderStateMachine::GetNextFrameStatus()
40132: {
40132:   MonitorAutoEnter mon(mDecoder->GetMonitor());
40132:   if (IsBuffering() || IsSeeking()) {
40132:     return nsHTMLMediaElement::NEXT_FRAME_UNAVAILABLE_BUFFERING;
40132:   } else if (HaveNextFrameData()) {
40132:     return nsHTMLMediaElement::NEXT_FRAME_AVAILABLE;
40132:   }
40132:   return nsHTMLMediaElement::NEXT_FRAME_UNAVAILABLE;
40132: }
40132: 
60727: void nsBuiltinDecoderStateMachine::SetVolume(double volume)
40132: {
40132:   NS_ASSERTION(NS_IsMainThread(), "Should be on main thread.");
40132:   MonitorAutoEnter mon(mDecoder->GetMonitor());
40132:   mVolume = volume;
40132: }
40132: 
63622: double nsBuiltinDecoderStateMachine::GetCurrentTime() const
40132: {
63622:   NS_ASSERTION(NS_IsMainThread() ||
63622:                mDecoder->OnStateMachineThread() ||
63622:                OnDecodeThread(),
63622:                "Should be on main, decode, or state machine thread.");
40132: 
60727:   return static_cast<double>(mCurrentFrameTime) / 1000.0;
40132: }
40132: 
41954: PRInt64 nsBuiltinDecoderStateMachine::GetDuration()
40132: {
40132:   mDecoder->GetMonitor().AssertCurrentThreadIn();
40132: 
40132:   if (mEndTime == -1 || mStartTime == -1)
40132:     return -1;
40132:   return mEndTime - mStartTime;
40132: }
40132: 
41954: void nsBuiltinDecoderStateMachine::SetDuration(PRInt64 aDuration)
40132: {
43340:   NS_ASSERTION(NS_IsMainThread() || mDecoder->OnStateMachineThread(),
43340:     "Should be on main or state machine thread.");
40132:   mDecoder->GetMonitor().AssertCurrentThreadIn();
40132: 
40132:   if (mStartTime != -1) {
40132:     mEndTime = mStartTime + aDuration;
40132:   } else {
40132:     mStartTime = 0;
40132:     mEndTime = aDuration;
40132:   }
40132: }
40132: 
41954: void nsBuiltinDecoderStateMachine::SetSeekable(PRBool aSeekable)
40132: {
40132:   NS_ASSERTION(NS_IsMainThread(), "Should be on main thread.");
40132:   mDecoder->GetMonitor().AssertCurrentThreadIn();
40132: 
40132:   mSeekable = aSeekable;
40132: }
40132: 
41954: void nsBuiltinDecoderStateMachine::Shutdown()
40132: {
40132:   NS_ASSERTION(NS_IsMainThread(), "Should be on main thread.");
40132: 
40132:   // Once we've entered the shutdown state here there's no going back.
40132:   MonitorAutoEnter mon(mDecoder->GetMonitor());
40132: 
40132:   // Change state before issuing shutdown request to threads so those
40132:   // threads can start exiting cleanly during the Shutdown call.
40132:   LOG(PR_LOG_DEBUG, ("%p Changed state to SHUTDOWN", mDecoder));
40132:   mState = DECODER_STATE_SHUTDOWN;
40132:   mDecoder->GetMonitor().NotifyAll();
40132: }
40132: 
63623: void nsBuiltinDecoderStateMachine::StartDecoding()
63623: {
63623:   NS_ASSERTION(IsCurrentThread(mDecoder->mStateMachineThread),
63623:                "Should be on state machine thread.");
63623:   MonitorAutoEnter mon(mDecoder->GetMonitor());
63623:   if (mState != DECODER_STATE_DECODING) {
63623:     mDecodeStartTime = TimeStamp::Now();
63623:   }
63623:   mState = DECODER_STATE_DECODING;
63623: }
63623: 
63623: void nsBuiltinDecoderStateMachine::Play()
40132: {
40132:   NS_ASSERTION(NS_IsMainThread(), "Should be on main thread.");
63623:   // When asked to play, switch to decoding state only if
63623:   // we are currently buffering. In other cases, we'll start playing anyway
63623:   // when the state machine notices the decoder's state change to PLAYING.
40132:   MonitorAutoEnter mon(mDecoder->GetMonitor());
40132:   if (mState == DECODER_STATE_BUFFERING) {
40132:     LOG(PR_LOG_DEBUG, ("%p Changed state from BUFFERING to DECODING", mDecoder));
40132:     mState = DECODER_STATE_DECODING;
63623:     mDecodeStartTime = TimeStamp::Now();
40132:     mDecoder->GetMonitor().NotifyAll();
40132:   }
40132: }
40132: 
41954: void nsBuiltinDecoderStateMachine::ResetPlayback()
40132: {
41387:   NS_ASSERTION(IsCurrentThread(mDecoder->mStateMachineThread),
40132:                "Should be on state machine thread.");
43445:   mVideoFrameEndTime = -1;
40132:   mAudioStartTime = -1;
40132:   mAudioEndTime = -1;
40132:   mAudioCompleted = PR_FALSE;
40132: }
40132: 
60727: void nsBuiltinDecoderStateMachine::Seek(double aTime)
40132: {
40132:   NS_ASSERTION(NS_IsMainThread(), "Should be on main thread.");
40132:   MonitorAutoEnter mon(mDecoder->GetMonitor());
41387:   // nsBuiltinDecoder::mPlayState should be SEEKING while we seek, and
41387:   // in that case nsBuiltinDecoder shouldn't be calling us.
40132:   NS_ASSERTION(mState != DECODER_STATE_SEEKING,
40132:                "We shouldn't already be seeking");
40132:   NS_ASSERTION(mState >= DECODER_STATE_DECODING,
40132:                "We should have loaded metadata");
40132:   double t = aTime * 1000.0;
40132:   if (t > PR_INT64_MAX) {
40132:     // Prevent integer overflow.
40132:     return;
40132:   }
40132: 
40132:   mSeekTime = static_cast<PRInt64>(t) + mStartTime;
40132:   NS_ASSERTION(mSeekTime >= mStartTime && mSeekTime <= mEndTime,
40132:                "Can only seek in range [0,duration]");
40132: 
40132:   // Bound the seek time to be inside the media range.
40132:   NS_ASSERTION(mStartTime != -1, "Should know start time by now");
40132:   NS_ASSERTION(mEndTime != -1, "Should know end time by now");
40132:   mSeekTime = NS_MIN(mSeekTime, mEndTime);
40132:   mSeekTime = NS_MAX(mStartTime, mSeekTime);
40132:   LOG(PR_LOG_DEBUG, ("%p Changed state to SEEKING (to %f)", mDecoder, aTime));
40132:   mState = DECODER_STATE_SEEKING;
40132: }
40132: 
41954: void nsBuiltinDecoderStateMachine::StopDecodeThreads()
40132: {
41387:   NS_ASSERTION(IsCurrentThread(mDecoder->mStateMachineThread),
40132:                "Should be on state machine thread.");
40132:   mDecoder->GetMonitor().AssertCurrentThreadIn();
40132:   mStopDecodeThreads = PR_TRUE;
40132:   mDecoder->GetMonitor().NotifyAll();
40132:   if (mDecodeThread) {
40132:     {
40132:       MonitorAutoExit exitMon(mDecoder->GetMonitor());
40132:       mDecodeThread->Shutdown();
40132:     }
40132:     mDecodeThread = nsnull;
40132:   }
40132:   if (mAudioThread) {
40132:     {
40132:       MonitorAutoExit exitMon(mDecoder->GetMonitor());
40132:       mAudioThread->Shutdown();
40132:     }
40132:     mAudioThread = nsnull;
40132:   }
40132: }
40132: 
40132: nsresult
41954: nsBuiltinDecoderStateMachine::StartDecodeThreads()
40132: {
41387:   NS_ASSERTION(IsCurrentThread(mDecoder->mStateMachineThread),
40132:                "Should be on state machine thread.");
40132:   mDecoder->GetMonitor().AssertCurrentThreadIn();
40132:   mStopDecodeThreads = PR_FALSE;
40132:   if (!mDecodeThread && mState < DECODER_STATE_COMPLETED) {
40132:     nsresult rv = NS_NewThread(getter_AddRefs(mDecodeThread));
40132:     if (NS_FAILED(rv)) {
40132:       mState = DECODER_STATE_SHUTDOWN;
40132:       return rv;
40132:     }
40132:     nsCOMPtr<nsIRunnable> event =
41954:       NS_NewRunnableMethod(this, &nsBuiltinDecoderStateMachine::DecodeLoop);
40132:     mDecodeThread->Dispatch(event, NS_DISPATCH_NORMAL);
40132:   }
40132:   if (HasAudio() && !mAudioThread) {
40132:     nsresult rv = NS_NewThread(getter_AddRefs(mAudioThread));
40132:     if (NS_FAILED(rv)) {
40132:       mState = DECODER_STATE_SHUTDOWN;
40132:       return rv;
40132:     }
40132:     nsCOMPtr<nsIRunnable> event =
41954:       NS_NewRunnableMethod(this, &nsBuiltinDecoderStateMachine::AudioLoop);
40132:     mAudioThread->Dispatch(event, NS_DISPATCH_NORMAL);
40132:   }
40132:   return NS_OK;
40132: }
40132: 
53827: PRInt64 nsBuiltinDecoderStateMachine::AudioDecodedMs() const
53827: {
53827:   NS_ASSERTION(HasAudio(),
53827:                "Should only call AudioDecodedMs() when we have audio");
53827:   // The amount of audio we have decoded is the amount of audio data we've
53827:   // already decoded and pushed to the hardware, plus the amount of audio
53827:   // data waiting to be pushed to the hardware.
53827:   PRInt64 pushed = (mAudioEndTime != -1) ? (mAudioEndTime - GetMediaTime()) : 0;
53827:   return pushed + mReader->mAudioQueue.Duration();
53827: }
53827: 
63621: PRBool nsBuiltinDecoderStateMachine::HasLowDecodedData(PRInt64 aAudioMs) const
60724: {
63621:   mDecoder->GetMonitor().AssertCurrentThreadIn();
63621:   // We consider ourselves low on decoded data if we're low on audio,
63621:   // provided we've not decoded to the end of the audio stream, or
63621:   // if we're only playing video and we're low on video frames, provided
63621:   // we've not decoded to the end of the video stream.
63621:   return ((HasAudio() &&
63621:            !mReader->mAudioQueue.IsFinished() &&
63621:            AudioDecodedMs() < aAudioMs)
63621:           ||
63621:          (!HasAudio() &&
63621:           HasVideo() &&
63621:           !mReader->mVideoQueue.IsFinished() &&
63621:           static_cast<PRUint32>(mReader->mVideoQueue.GetSize()) < LOW_VIDEO_FRAMES));
60724: }
60724: 
63622: PRBool nsBuiltinDecoderStateMachine::HasLowUndecodedData() const
63622: {
63622:   return GetUndecodedData() < LOW_DATA_THRESHOLD_MS;
63622: }
63622: 
63622: PRInt64 nsBuiltinDecoderStateMachine::GetUndecodedData() const
63622: {
63622:   mDecoder->GetMonitor().AssertCurrentThreadIn();
63622:   NS_ASSERTION(mState > DECODER_STATE_DECODING_METADATA,
63622:                "Must have loaded metadata for GetBuffered() to work");
63622:   nsTimeRanges buffered;
63622:   
63622:   nsresult res = mDecoder->GetBuffered(&buffered);
63622:   NS_ENSURE_SUCCESS(res, 0);
63622:   double currentTime = GetCurrentTime();
63622: 
63622:   nsIDOMTimeRanges* r = static_cast<nsIDOMTimeRanges*>(&buffered);
63622:   PRUint32 length = 0;
63622:   res = r->GetLength(&length);
63622:   NS_ENSURE_SUCCESS(res, 0);
63622: 
63622:   for (PRUint32 index = 0; index < length; ++index) {
63622:     double start, end;
63622:     res = r->Start(index, &start);
63622:     NS_ENSURE_SUCCESS(res, 0);
63622: 
63622:     res = r->End(index, &end);
63622:     NS_ENSURE_SUCCESS(res, 0);
63622: 
63622:     if (start <= currentTime && end >= currentTime) {
63622:       return static_cast<PRInt64>((end - currentTime) * 1000);
63622:     }
63622:   }
63622:   return 0;
63622: }
63622: 
41954: nsresult nsBuiltinDecoderStateMachine::Run()
40132: {
41387:   NS_ASSERTION(IsCurrentThread(mDecoder->mStateMachineThread),
40132:                "Should be on state machine thread.");
41387:   nsMediaStream* stream = mDecoder->GetCurrentStream();
40132:   NS_ENSURE_TRUE(stream, NS_ERROR_NULL_POINTER);
40132: 
40132:   while (PR_TRUE) {
40132:     MonitorAutoEnter mon(mDecoder->GetMonitor());
40132:     switch (mState) {
40132:     case DECODER_STATE_SHUTDOWN:
40132:       if (IsPlaying()) {
40132:         StopPlayback(AUDIO_SHUTDOWN);
40132:       }
40132:       StopDecodeThreads();
40132:       NS_ASSERTION(mState == DECODER_STATE_SHUTDOWN,
40132:                    "How did we escape from the shutdown state???");
40132:       return NS_OK;
40132: 
40132:     case DECODER_STATE_DECODING_METADATA:
40132:       {
41954:         LoadMetadata();
40132:         if (mState == DECODER_STATE_SHUTDOWN) {
40132:           continue;
40132:         }
40132: 
40132:         VideoData* videoData = FindStartTime();
40132:         if (videoData) {
63857:           nsIntSize display = mInfo.mDisplay;
63857:           float aspect = mInfo.mPixelAspectRatio;
63857:           {
40132:             MonitorAutoExit exitMon(mDecoder->GetMonitor());
63857:             RenderVideoFrame(videoData, TimeStamp::Now(), display, aspect);
63857:           }
40132:         }
62748: 
62748:         // Start the decode threads, so that we can pre buffer the streams.
40132:         // and calculate the start time in order to determine the duration.
40132:         if (NS_FAILED(StartDecodeThreads())) {
40132:           continue;
40132:         }
40132: 
40132:         NS_ASSERTION(mStartTime != -1, "Must have start time");
40132:         NS_ASSERTION((!HasVideo() && !HasAudio()) ||
40132:                      !mSeekable || mEndTime != -1,
40132:                      "Active seekable media should have end time");
40132:         NS_ASSERTION(!mSeekable || GetDuration() != -1, "Seekable media should have duration");
40132:         LOG(PR_LOG_DEBUG, ("%p Media goes from %lldms to %lldms (duration %lldms) seekable=%d",
40132:                            mDecoder, mStartTime, mEndTime, GetDuration(), mSeekable));
40132: 
40132:         if (mState == DECODER_STATE_SHUTDOWN)
40132:           continue;
40132: 
51477:         // Inform the element that we've loaded the metadata and the first frame,
51477:         // setting the default framebuffer size for audioavailable events.  Also,
51477:         // if there is audio, let the MozAudioAvailable event manager know about
51477:         // the metadata.
63857:         PRUint32 frameBufferLength = mInfo.mAudioChannels * FRAMEBUFFER_LENGTH_PER_CHANNEL;
40132:         nsCOMPtr<nsIRunnable> metadataLoadedEvent =
63857:           new nsAudioMetadataEventRunner(mDecoder, mInfo.mAudioChannels,
63857:                                          mInfo.mAudioRate, frameBufferLength);
40132:         NS_DispatchToMainThread(metadataLoadedEvent, NS_DISPATCH_NORMAL);
51477:         if (HasAudio()) {
63857:           mEventManager.Init(mInfo.mAudioChannels, mInfo.mAudioRate);
51477:           mDecoder->RequestFrameBufferLength(frameBufferLength);
51477:         }
40132: 
40132:         if (mState == DECODER_STATE_DECODING_METADATA) {
40132:           LOG(PR_LOG_DEBUG, ("%p Changed state from DECODING_METADATA to DECODING", mDecoder));
63623:           StartDecoding();
62748:         }
40132: 
40132:         // Start playback.
41387:         if (mDecoder->GetState() == nsBuiltinDecoder::PLAY_STATE_PLAYING) {
40132:           if (!IsPlaying()) {
40132:             StartPlayback();
40132:           }
40132:         }
40132:       }
40132:       break;
40132: 
40132:     case DECODER_STATE_DECODING:
40132:       {
40132:         if (NS_FAILED(StartDecodeThreads())) {
40132:           continue;
40132:         }
40132: 
40132:         AdvanceFrame();
40132: 
40132:         if (mState != DECODER_STATE_DECODING)
40132:           continue;
40132:       }
40132:       break;
40132: 
40132:     case DECODER_STATE_SEEKING:
40132:       {
40132:         // During the seek, don't have a lock on the decoder state,
40132:         // otherwise long seek operations can block the main thread.
40132:         // The events dispatched to the main thread are SYNC calls.
40132:         // These calls are made outside of the decode monitor lock so
40132:         // it is safe for the main thread to makes calls that acquire
40132:         // the lock since it won't deadlock. We check the state when
40132:         // acquiring the lock again in case shutdown has occurred
40132:         // during the time when we didn't have the lock.
40132:         PRInt64 seekTime = mSeekTime;
40132:         mDecoder->StopProgressUpdates();
40132: 
52451:         PRBool currentTimeChanged = false;
53828:         PRInt64 mediaTime = GetMediaTime();
53828:         if (mediaTime != seekTime) {
52451:           currentTimeChanged = true;
61823:           UpdatePlaybackPositionInternal(seekTime);
52451:         }
52451: 
40132:         // SeekingStarted will do a UpdateReadyStateForData which will
40132:         // inform the element and its users that we have no frames
40132:         // to display
40132:         {
40132:           MonitorAutoExit exitMon(mDecoder->GetMonitor());
40132:           nsCOMPtr<nsIRunnable> startEvent =
41387:             NS_NewRunnableMethod(mDecoder, &nsBuiltinDecoder::SeekingStarted);
40132:           NS_DispatchToMainThread(startEvent, NS_DISPATCH_SYNC);
40132:         }
61823: 
52451:         if (currentTimeChanged) {
50361:           // The seek target is different than the current playback position,
50361:           // we'll need to seek the playback position, so shutdown our decode
50361:           // and audio threads.
50361:           StopPlayback(AUDIO_SHUTDOWN);
50361:           StopDecodeThreads();
50361:           ResetPlayback();
40132:           nsresult res;
40132:           {
40132:             MonitorAutoExit exitMon(mDecoder->GetMonitor());
40132:             // Now perform the seek. We must not hold the state machine monitor
40132:             // while we seek, since the seek decodes.
50947:             res = mReader->Seek(seekTime,
50947:                                 mStartTime,
50947:                                 mEndTime,
53828:                                 mediaTime);
40132:           }
40132:           if (NS_SUCCEEDED(res)){
40132:             SoundData* audio = HasAudio() ? mReader->mAudioQueue.PeekFront() : nsnull;
55001:             NS_ASSERTION(!audio || (audio->mTime <= seekTime &&
55001:                                     seekTime <= audio->mTime + audio->mDuration),
55001:                          "Seek target should lie inside the first audio block after seek");
55001:             PRInt64 startTime = (audio && audio->mTime < seekTime) ? audio->mTime : seekTime;
55001:             mAudioStartTime = startTime;
63621:             mPlayDuration = MsToDuration(startTime - mStartTime);
40132:             if (HasVideo()) {
40132:               nsAutoPtr<VideoData> video(mReader->mVideoQueue.PeekFront());
40132:               if (video) {
55001:                 NS_ASSERTION(video->mTime <= seekTime && seekTime <= video->mEndTime,
55001:                              "Seek target should lie inside the first frame after seek");
63857:                 nsIntSize display = mInfo.mDisplay;
63857:                 float aspect = mInfo.mPixelAspectRatio;
63857:                 {
63857:                   MonitorAutoExit exitMon(mDecoder->GetMonitor());
63857:                   RenderVideoFrame(video, TimeStamp::Now(), display, aspect);
63857:                 }
40132:                 mReader->mVideoQueue.PopFront();
61823:                 nsCOMPtr<nsIRunnable> event =
61823:                   NS_NewRunnableMethod(mDecoder, &nsBuiltinDecoder::Invalidate);
61823:                 NS_DispatchToMainThread(event, NS_DISPATCH_NORMAL);
40132:               }
55001:             }
40132:           }
40132:         }
40132:         mDecoder->StartProgressUpdates();
40132:         if (mState == DECODER_STATE_SHUTDOWN)
40132:           continue;
40132: 
40132:         // Try to decode another frame to detect if we're at the end...
40132:         LOG(PR_LOG_DEBUG, ("Seek completed, mCurrentFrameTime=%lld\n", mCurrentFrameTime));
40132: 
40132:         // Change state to DECODING or COMPLETED now. SeekingStopped will
41954:         // call nsBuiltinDecoderStateMachine::Seek to reset our state to SEEKING
40132:         // if we need to seek again.
40132:         
40132:         nsCOMPtr<nsIRunnable> stopEvent;
53826:         if (GetMediaTime() == mEndTime) {
40132:           LOG(PR_LOG_DEBUG, ("%p Changed state from SEEKING (to %lldms) to COMPLETED",
40132:                              mDecoder, seekTime));
41387:           stopEvent = NS_NewRunnableMethod(mDecoder, &nsBuiltinDecoder::SeekingStoppedAtEnd);
40132:           mState = DECODER_STATE_COMPLETED;
40132:         } else {
40132:           LOG(PR_LOG_DEBUG, ("%p Changed state from SEEKING (to %lldms) to DECODING",
40132:                              mDecoder, seekTime));
41387:           stopEvent = NS_NewRunnableMethod(mDecoder, &nsBuiltinDecoder::SeekingStopped);
63623:           StartDecoding();
40132:         }
40132:         mDecoder->GetMonitor().NotifyAll();
40132: 
40132:         {
40132:           MonitorAutoExit exitMon(mDecoder->GetMonitor());
40132:           NS_DispatchToMainThread(stopEvent, NS_DISPATCH_SYNC);
40132:         }
63623: 
63623:         // Reset quick buffering status. This ensures that if we began the
63623:         // seek while quick-buffering, we won't bypass quick buffering mode
63623:         // if we need to buffer after the seek.
63623:         mQuickBuffering = PR_FALSE;
40132:       }
40132:       break;
40132: 
40132:     case DECODER_STATE_BUFFERING:
40132:       {
60724:         if (IsPlaying()) {
60724:           StopPlayback(AUDIO_PAUSE);
60724:           mDecoder->GetMonitor().NotifyAll();
60724:         }
60724: 
60723:         TimeStamp now = TimeStamp::Now();
63623:         NS_ASSERTION(!mBufferingStart.IsNull(), "Must know buffering start time.");
60723: 
53827:         // We will remain in the buffering state if we've not decoded enough
53827:         // data to begin playback, or if we've not downloaded a reasonable
53827:         // amount of data inside our buffering time.
60723:         TimeDuration elapsed = now - mBufferingStart;
54998:         PRBool isLiveStream = mDecoder->GetCurrentStream()->GetLength() == -1;
58312:         if ((isLiveStream || !mDecoder->CanPlayThrough()) &&
53827:              elapsed < TimeDuration::FromSeconds(BUFFERING_WAIT) &&
63623:              (mQuickBuffering ? HasLowDecodedData(QUICK_BUFFERING_LOW_DATA_MS)
63623:                               : (GetUndecodedData() < BUFFERING_WAIT * 1000)) &&
48104:              !stream->IsDataCachedToEndOfStream(mDecoder->mDecoderPosition) &&
53827:              !stream->IsSuspended())
53827:         {
40132:           LOG(PR_LOG_DEBUG,
63623:               ("Buffering: %.3lfs/%ds, timeout in %.3lfs %s",
63623:                GetUndecodedData() / 1000.0,
63623:                BUFFERING_WAIT,
63623:                BUFFERING_WAIT - elapsed.ToSeconds(),
63623:                (mQuickBuffering ? "(quick exit)" : "")));
40132:           Wait(1000);
40132:           if (mState == DECODER_STATE_SHUTDOWN)
40132:             continue;
40132:         } else {
40132:           LOG(PR_LOG_DEBUG, ("%p Changed state from BUFFERING to DECODING", mDecoder));
63622:           LOG(PR_LOG_DEBUG, ("%p Buffered for %.3lfs",
40132:                              mDecoder,
60723:                              (now - mBufferingStart).ToSeconds()));
63623:           StartDecoding();
40132:         }
40132: 
40132:         if (mState != DECODER_STATE_BUFFERING) {
40132:           // Notify to allow blocked decoder thread to continue
40132:           mDecoder->GetMonitor().NotifyAll();
40132:           UpdateReadyState();
41387:           if (mDecoder->GetState() == nsBuiltinDecoder::PLAY_STATE_PLAYING) {
40132:             if (!IsPlaying()) {
40132:               StartPlayback();
40132:             }
40132:           }
40132:         }
40132:         break;
40132:       }
40132: 
40132:     case DECODER_STATE_COMPLETED:
40132:       {
40132:         if (NS_FAILED(StartDecodeThreads())) {
40132:           continue;
40132:         }
40132: 
42254:         // Play the remaining media. We want to run AdvanceFrame() at least
42254:         // once to ensure the current playback position is advanced to the
42254:         // end of the media, and so that we update the readyState.
42254:         do {
42254:           AdvanceFrame();
42254:         } while (mState == DECODER_STATE_COMPLETED &&
40132:                  (mReader->mVideoQueue.GetSize() > 0 ||
42254:                  (HasAudio() && !mAudioCompleted)));
40132: 
40619:         if (mAudioStream) {
43445:           // Close the audio stream so that next time audio is used a new stream
40132:           // is created. The StopPlayback call also resets the IsPlaying() state
40132:           // so audio is restarted correctly.
40132:           StopPlayback(AUDIO_SHUTDOWN);
40132:         }
40132: 
40132:         if (mState != DECODER_STATE_COMPLETED)
40132:           continue;
40132: 
40132:         LOG(PR_LOG_DEBUG, ("Shutting down the state machine thread"));
40132:         StopDecodeThreads();
40132: 
41387:         if (mDecoder->GetState() == nsBuiltinDecoder::PLAY_STATE_PLAYING) {
43445:           PRInt64 videoTime = HasVideo() ? mVideoFrameEndTime : 0;
40132:           PRInt64 clockTime = NS_MAX(mEndTime, NS_MAX(videoTime, GetAudioClock()));
40132:           UpdatePlaybackPosition(clockTime);
40132:           {
40132:             MonitorAutoExit exitMon(mDecoder->GetMonitor());
40132:             nsCOMPtr<nsIRunnable> event =
41387:               NS_NewRunnableMethod(mDecoder, &nsBuiltinDecoder::PlaybackEnded);
40132:             NS_DispatchToMainThread(event, NS_DISPATCH_SYNC);
40132:           }
40132:         }
40132: 
51397:         if (mState == DECODER_STATE_COMPLETED) {
51397:           // We've finished playback. Shutdown the state machine thread, 
51397:           // in order to save memory on thread stacks, particuarly on Linux.
51397:           nsCOMPtr<nsIRunnable> event =
51397:             new ShutdownThreadEvent(mDecoder->mStateMachineThread);
51397:           NS_DispatchToMainThread(event, NS_DISPATCH_NORMAL);
51397:           mDecoder->mStateMachineThread = nsnull;
51397:           return NS_OK;
40132:         }
40132:       }
40132:       break;
40132:     }
40132:   }
40132: 
40132:   return NS_OK;
40132: }
40132: 
63612: void nsBuiltinDecoderStateMachine::RenderVideoFrame(VideoData* aData,
63857:                                                     TimeStamp aTarget,
63857:                                                     nsIntSize aDisplaySize,
63857:                                                     float aAspectRatio)
40132: {
41387:   NS_ASSERTION(IsCurrentThread(mDecoder->mStateMachineThread), "Should be on state machine thread.");
63857:   mDecoder->GetMonitor().AssertNotCurrentThreadIn();
40132: 
40132:   if (aData->mDuplicate) {
40132:     return;
40132:   }
40132: 
42438:   nsRefPtr<Image> image = aData->mImage;
40132:   if (image) {
63857:     mDecoder->SetVideoData(gfxIntSize(aDisplaySize.width, aDisplaySize.height),
63857:                            aAspectRatio, image, aTarget);
40132:   }
40132: }
40132: 
40132: PRInt64
41954: nsBuiltinDecoderStateMachine::GetAudioClock()
40132: {
41387:   NS_ASSERTION(IsCurrentThread(mDecoder->mStateMachineThread), "Should be on state machine thread.");
40619:   if (!mAudioStream || !HasAudio())
40132:     return -1;
40619:   PRInt64 t = mAudioStream->GetPosition();
40132:   return (t == -1) ? -1 : t + mAudioStartTime;
40132: }
40132: 
41954: void nsBuiltinDecoderStateMachine::AdvanceFrame()
40132: {
41387:   NS_ASSERTION(IsCurrentThread(mDecoder->mStateMachineThread), "Should be on state machine thread.");
40132:   mDecoder->GetMonitor().AssertCurrentThreadIn();
40132: 
40132:   // When it's time to display a frame, decode the frame and display it.
41387:   if (mDecoder->GetState() == nsBuiltinDecoder::PLAY_STATE_PLAYING) {
40132:     if (HasAudio() && mAudioStartTime == -1 && !mAudioCompleted) {
43445:       // We've got audio (so we should sync off the audio clock), but we've not
43445:       // played a sample on the audio thread, so we can't get a time from the
43445:       // audio clock. Just wait and then return, to give the audio clock time
43445:       // to tick.  This should really wait for a specific signal from the audio
43445:       // thread rather than polling after a sleep.  See bug 568431 comment 4.
43445:       Wait(AUDIO_DURATION_MS);
40132:       return;
40132:     }
40132: 
40132:     // Determine the clock time. If we've got audio, and we've not reached
40132:     // the end of the audio, use the audio clock. However if we've finished
40132:     // audio, or don't have audio, use the system clock.
40132:     PRInt64 clock_time = -1;
63621:     if (!IsPlaying()) {
63621:       clock_time = DurationToMs(mPlayDuration) + mStartTime;
63621:     } else {
40132:       PRInt64 audio_time = GetAudioClock();
40132:       if (HasAudio() && !mAudioCompleted && audio_time != -1) {
40132:         clock_time = audio_time;
40132:         // Resync against the audio clock, while we're trusting the
40132:         // audio clock. This ensures no "drift", particularly on Linux.
63621:         mPlayDuration = MsToDuration(clock_time - mStartTime);
62888:         mPlayStartTime = TimeStamp::Now();
40132:       } else {
40132:         // Sound is disabled on this system. Sync to the system clock.
63621:         clock_time = DurationToMs(TimeStamp::Now() - mPlayStartTime + mPlayDuration);
40132:         // Ensure the clock can never go backwards.
40132:         NS_ASSERTION(mCurrentFrameTime <= clock_time, "Clock should go forwards");
40132:         clock_time = NS_MAX(mCurrentFrameTime, clock_time) + mStartTime;
40132:       }
63621:     }
40132: 
63621:     // Skip frames up to the frame at the playback position, and figure out
63621:     // the time remaining until it's time to display the next frame.
62888:     PRInt64 remainingTime = AUDIO_DURATION_MS;
40132:     NS_ASSERTION(clock_time >= mStartTime, "Should have positive clock time.");
62888:     nsAutoPtr<VideoData> currentFrame;
40132:     if (mReader->mVideoQueue.GetSize() > 0) {
62888:       VideoData* frame = mReader->mVideoQueue.PeekFront();
62888:       while (clock_time >= frame->mTime) {
62888:         mVideoFrameEndTime = frame->mEndTime;
62888:         currentFrame = frame;
40132:         mReader->mVideoQueue.PopFront();
62888:         mDecoder->UpdatePlaybackOffset(frame->mOffset);
40132:         if (mReader->mVideoQueue.GetSize() == 0)
40132:           break;
62888:         frame = mReader->mVideoQueue.PeekFront();
62888:       }
62888:       // Current frame has already been presented, wait until it's time to
62888:       // present the next frame.
62888:       if (frame && !currentFrame) {
63621:         PRInt64 now = IsPlaying()
63621:           ? DurationToMs(TimeStamp::Now() - mPlayStartTime + mPlayDuration)
63621:           : DurationToMs(mPlayDuration);
62888:         remainingTime = frame->mTime - mStartTime - now;
40132:       }
40132:     }
40132: 
63621:     // Check to see if we don't have enough data to play up to the next frame.
63621:     // If we don't, switch to buffering mode.
63621:     nsMediaStream* stream = mDecoder->GetCurrentStream();
63621:     if (mState == DECODER_STATE_DECODING &&
63621:         mDecoder->GetState() == nsBuiltinDecoder::PLAY_STATE_PLAYING &&
63621:         HasLowDecodedData(remainingTime + EXHAUSTED_DATA_MARGIN_MS) &&
63621:         !stream->IsDataCachedToEndOfStream(mDecoder->mDecoderPosition) &&
63622:         !stream->IsSuspended() &&
63623:         (JustExitedQuickBuffering() || HasLowUndecodedData()))
63621:     {
63621:       if (currentFrame) {
63621:         mReader->mVideoQueue.PushFront(currentFrame.forget());
63621:       }
63623:       StartBuffering();
63621:       return;
63621:     }
63621: 
63621:     // We've got enough data to keep playing until at least the next frame.
63621:     // Start playing now if need be.
63621:     if (!IsPlaying()) {
63621:       StartPlayback();
63621:       mDecoder->GetMonitor().NotifyAll();
63621:     }
63621: 
62888:     if (currentFrame) {
63621:       // Decode one frame and display it.
63612:       TimeStamp presTime = mPlayStartTime - mPlayDuration +
63624:                            MsToDuration(currentFrame->mTime - mStartTime);
62888:       NS_ASSERTION(currentFrame->mTime >= mStartTime, "Should have positive frame time");
40132:       {
63857:         nsIntSize display = mInfo.mDisplay;
63857:         float aspect = mInfo.mPixelAspectRatio;
63857:         {
40132:           MonitorAutoExit exitMon(mDecoder->GetMonitor());
40132:           // If we have video, we want to increment the clock in steps of the frame
40132:           // duration.
63857:           RenderVideoFrame(currentFrame, presTime, display, aspect);
63857:         }
40132:       }
63611:       mDecoder->GetFrameStatistics().NotifyPresentedFrame();
63621:       PRInt64 now = DurationToMs(TimeStamp::Now() - mPlayStartTime + mPlayDuration);
62888:       remainingTime = currentFrame->mEndTime - mStartTime - now;
62888:       currentFrame = nsnull;
40132:     }
40132: 
56888:     // Kick the decode thread in case it filled its buffers and put itself
56888:     // to sleep.
56888:     mDecoder->GetMonitor().NotifyAll();
56888: 
40132:     // Cap the current time to the larger of the audio and video end time.
40132:     // This ensures that if we're running off the system clock, we don't
40132:     // advance the clock to after the media end time.
43445:     if (mVideoFrameEndTime != -1 || mAudioEndTime != -1) {
40132:       // These will be non -1 if we've displayed a video frame, or played an audio sample.
43445:       clock_time = NS_MIN(clock_time, NS_MAX(mVideoFrameEndTime, mAudioEndTime));
54994:       if (clock_time > GetMediaTime()) {
40132:         // Only update the playback position if the clock time is greater
40132:         // than the previous playback position. The audio clock can
40132:         // sometimes report a time less than its previously reported in
40132:         // some situations, and we need to gracefully handle that.
40132:         UpdatePlaybackPosition(clock_time);
40132:       }
40132:     }
40132: 
40132:     // If the number of audio/video samples queued has changed, either by
40132:     // this function popping and playing a video sample, or by the audio
40132:     // thread popping and playing an audio sample, we may need to update our
40132:     // ready state. Post an update to do so.
40132:     UpdateReadyState();
40132: 
62888:     if (remainingTime > 0) {
62888:       Wait(remainingTime);
62888:     }
40132:   } else {
40132:     if (IsPlaying()) {
40132:       StopPlayback(AUDIO_PAUSE);
40132:       mDecoder->GetMonitor().NotifyAll();
40132:     }
40132: 
40132:     if (mState == DECODER_STATE_DECODING ||
40132:         mState == DECODER_STATE_COMPLETED) {
40132:       mDecoder->GetMonitor().Wait();
40132:     }
40132:   }
40132: }
40132: 
63624: void nsBuiltinDecoderStateMachine::Wait(PRInt64 aMs) {
40132:   mDecoder->GetMonitor().AssertCurrentThreadIn();
63624:   TimeStamp end = TimeStamp::Now() + MsToDuration(aMs);
40132:   TimeStamp now;
40132:   while ((now = TimeStamp::Now()) < end &&
40132:          mState != DECODER_STATE_SHUTDOWN &&
40132:          mState != DECODER_STATE_SEEKING)
40132:   {
63624:     PRInt64 ms = static_cast<PRInt64>(NS_round((end - now).ToSeconds() * 1000));
63624:     if (ms == 0 || ms > PR_UINT32_MAX) {
40132:       break;
40132:     }
40132:     NS_ASSERTION(ms <= aMs && ms > 0,
41954:                  "nsBuiltinDecoderStateMachine::Wait interval very wrong!");
63624:     mDecoder->GetMonitor().Wait(PR_MillisecondsToInterval(static_cast<PRUint32>(ms)));
40132:   }
40132: }
40132: 
41954: VideoData* nsBuiltinDecoderStateMachine::FindStartTime()
40132: {
41387:   NS_ASSERTION(IsCurrentThread(mDecoder->mStateMachineThread), "Should be on state machine thread.");
40132:   mDecoder->GetMonitor().AssertCurrentThreadIn();
40132:   PRInt64 startTime = 0;
40132:   mStartTime = 0;
40132:   VideoData* v = nsnull;
63857:   PRInt64 dataOffset = mInfo.mDataOffset;
40132:   {
40132:     MonitorAutoExit exitMon(mDecoder->GetMonitor());
63857:     v = mReader->FindStartTime(dataOffset, startTime);
40132:   }
40132:   if (startTime != 0) {
40132:     mStartTime = startTime;
54994:     if (mGotDurationFromMetaData) {
40132:       NS_ASSERTION(mEndTime != -1,
40132:                    "We should have mEndTime as supplied duration here");
40132:       // We were specified a duration from a Content-Duration HTTP header.
40132:       // Adjust mEndTime so that mEndTime-mStartTime matches the specified
40132:       // duration.
40132:       mEndTime = mStartTime + mEndTime;
40132:     }
40132:   }
50359:   // Set the audio start time to be start of media. If this lies before the
50359:   // first acutal audio sample we have, we'll inject silence during playback
50359:   // to ensure the audio starts at the correct time.
50359:   mAudioStartTime = mStartTime;
40132:   LOG(PR_LOG_DEBUG, ("%p Media start time is %lldms", mDecoder, mStartTime));
40132:   return v;
40132: }
40132: 
41954: void nsBuiltinDecoderStateMachine::FindEndTime() 
40132: {
40132:   NS_ASSERTION(OnStateMachineThread(), "Should be on state machine thread.");
40132:   mDecoder->GetMonitor().AssertCurrentThreadIn();
40132: 
41387:   nsMediaStream* stream = mDecoder->GetCurrentStream();
40132: 
40132:   // Seek to the end of file to find the length and duration.
40132:   PRInt64 length = stream->GetLength();
40132:   NS_ASSERTION(length > 0, "Must have a content length to get end time");
40132: 
40132:   mEndTime = 0;
40132:   PRInt64 endTime = 0;
40132:   {
40132:     MonitorAutoExit exitMon(mDecoder->GetMonitor());
40132:     endTime = mReader->FindEndTime(length);
40132:   }
40132:   if (endTime != -1) {
40132:     mEndTime = endTime;
40132:   }
40132: 
40132:   LOG(PR_LOG_DEBUG, ("%p Media end time is %lldms", mDecoder, mEndTime));   
40132: }
40132: 
41954: void nsBuiltinDecoderStateMachine::UpdateReadyState() {
40132:   mDecoder->GetMonitor().AssertCurrentThreadIn();
40132: 
40132:   nsCOMPtr<nsIRunnable> event;
40132:   switch (GetNextFrameStatus()) {
40132:     case nsHTMLMediaElement::NEXT_FRAME_UNAVAILABLE_BUFFERING:
41387:       event = NS_NewRunnableMethod(mDecoder, &nsBuiltinDecoder::NextFrameUnavailableBuffering);
40132:       break;
40132:     case nsHTMLMediaElement::NEXT_FRAME_AVAILABLE:
41387:       event = NS_NewRunnableMethod(mDecoder, &nsBuiltinDecoder::NextFrameAvailable);
40132:       break;
40132:     case nsHTMLMediaElement::NEXT_FRAME_UNAVAILABLE:
41387:       event = NS_NewRunnableMethod(mDecoder, &nsBuiltinDecoder::NextFrameUnavailable);
40132:       break;
40132:     default:
40132:       PR_NOT_REACHED("unhandled frame state");
40132:   }
40132: 
40132:   NS_DispatchToMainThread(event, NS_DISPATCH_NORMAL);
40132: }
40132: 
41954: void nsBuiltinDecoderStateMachine::LoadMetadata()
41954: {
41954:   NS_ASSERTION(IsCurrentThread(mDecoder->mStateMachineThread),
41954:                "Should be on state machine thread.");
41954:   mDecoder->GetMonitor().AssertCurrentThreadIn();
41954: 
41954:   LOG(PR_LOG_DEBUG, ("Loading Media Headers"));
55967:   nsresult res;
63857:   nsVideoInfo info;
41954:   {
41954:     MonitorAutoExit exitMon(mDecoder->GetMonitor());
63857:     res = mReader->ReadMetadata(&info);
41954:   }
63857:   mInfo = info;
41954: 
55967:   if (NS_FAILED(res) || (!info.mHasVideo && !info.mHasAudio)) {
41954:     mState = DECODER_STATE_SHUTDOWN;      
41954:     nsCOMPtr<nsIRunnable> event =
41954:       NS_NewRunnableMethod(mDecoder, &nsBuiltinDecoder::DecodeError);
41954:     NS_DispatchToMainThread(event, NS_DISPATCH_NORMAL);
41954:     return;
41954:   }
55967:   mDecoder->StartProgressUpdates();
55967:   mGotDurationFromMetaData = (GetDuration() != -1);
41954: }
48104: 
63623: PRBool nsBuiltinDecoderStateMachine::JustExitedQuickBuffering()
63623: {
63623:   return !mDecodeStartTime.IsNull() &&
63623:     mQuickBuffering &&
63623:     (TimeStamp::Now() - mDecodeStartTime) < TimeDuration::FromSeconds(QUICK_BUFFER_THRESHOLD_MS);
63623: }
63623: 
48104: void nsBuiltinDecoderStateMachine::StartBuffering()
48104: {
48104:   mDecoder->GetMonitor().AssertCurrentThreadIn();
48104: 
63623:   TimeDuration decodeDuration = TimeStamp::Now() - mDecodeStartTime;
63623:   // Go into quick buffering mode provided we've not just left buffering using
63623:   // a "quick exit". This stops us flip-flopping between playing and buffering
63623:   // when the download speed is similar to the decode speed.
63623:   mQuickBuffering =
63623:     !JustExitedQuickBuffering() &&
63623:     decodeDuration < TimeDuration::FromMilliseconds(QUICK_BUFFER_THRESHOLD_MS);
63623:   mBufferingStart = TimeStamp::Now();
63623: 
48104:   // We need to tell the element that buffering has started.
48104:   // We can't just directly send an asynchronous runnable that
48104:   // eventually fires the "waiting" event. The problem is that
48104:   // there might be pending main-thread events, such as "data
48104:   // received" notifications, that mean we're not actually still
48104:   // buffering by the time this runnable executes. So instead
48104:   // we just trigger UpdateReadyStateForData; when it runs, it
48104:   // will check the current state and decide whether to tell
48104:   // the element we're buffering or not.
48104:   UpdateReadyState();
48104:   mState = DECODER_STATE_BUFFERING;
63623:   LOG(PR_LOG_DEBUG, ("Changed state from DECODING to BUFFERING, decoded for %.3lfs",
63623:                      decodeDuration.ToSeconds()));
63623:   nsMediaDecoder::Statistics stats = mDecoder->GetStatistics();
63623:   LOG(PR_LOG_DEBUG, ("Playback rate: %.1lfKB/s%s download rate: %.1lfKB/s%s",
63623:     stats.mPlaybackRate/1024, stats.mPlaybackRateReliable ? "" : " (unreliable)",
63623:     stats.mDownloadRate/1024, stats.mDownloadRateReliable ? "" : " (unreliable)"));
48104: }
63627: 
63627: nsresult nsBuiltinDecoderStateMachine::GetBuffered(nsTimeRanges* aBuffered) {
63627:   nsMediaStream* stream = mDecoder->GetCurrentStream();
63627:   NS_ENSURE_TRUE(stream, NS_ERROR_FAILURE);
63627:   stream->Pin();
63627:   nsresult res = mReader->GetBuffered(aBuffered, mStartTime);
63627:   stream->Unpin();
63627:   return res;
63627: }
