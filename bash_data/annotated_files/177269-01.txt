110929: /* -*- Mode: C++; tab-width: 2; indent-tabs-mode: nil; c-basic-offset: 2 -*- */
110929: /* vim:set ts=2 sw=2 sts=2 et cindent: */
110929: /* This Source Code Form is subject to the terms of the Mozilla Public
110929:  * License, v. 2.0. If a copy of the MPL was not distributed with this
110929:  * file, You can obtain one at http://mozilla.org/MPL/2.0/. */
110929: 
110929: #include "AudioContext.h"
160078: 
136240: #include "nsPIDOMWindow.h"
110929: #include "mozilla/ErrorResult.h"
155439: #include "mozilla/dom/AnalyserNode.h"
144538: #include "mozilla/dom/AudioContextBinding.h"
155439: #include "mozilla/dom/HTMLMediaElement.h"
144538: #include "mozilla/dom/OfflineAudioContextBinding.h"
160078: #include "mozilla/dom/OwningNonNull.h"
131561: #include "MediaStreamGraph.h"
114592: #include "AudioDestinationNode.h"
114592: #include "AudioBufferSourceNode.h"
114937: #include "AudioBuffer.h"
120694: #include "GainNode.h"
155439: #include "MediaElementAudioSourceNode.h"
155437: #include "MediaStreamAudioSourceNode.h"
120775: #include "DelayNode.h"
121066: #include "PannerNode.h"
121021: #include "AudioListener.h"
121244: #include "DynamicsCompressorNode.h"
121333: #include "BiquadFilterNode.h"
141208: #include "ScriptProcessorNode.h"
142679: #include "ChannelMergerNode.h"
142678: #include "ChannelSplitterNode.h"
147552: #include "MediaStreamAudioDestinationNode.h"
144191: #include "WaveShaperNode.h"
148067: #include "PeriodicWave.h"
146939: #include "ConvolverNode.h"
156971: #include "OscillatorNode.h"
131294: #include "nsNetUtil.h"
177245: #include "AudioStream.h"
110929: 
110929: namespace mozilla {
111522: namespace dom {
110929: 
163172: NS_IMPL_CYCLE_COLLECTION_CLASS(AudioContext)
163172: 
163172: NS_IMPL_CYCLE_COLLECTION_UNLINK_BEGIN(AudioContext)
163172:   NS_IMPL_CYCLE_COLLECTION_UNLINK(mDestination)
163172:   NS_IMPL_CYCLE_COLLECTION_UNLINK(mListener)
163172:   if (!tmp->mIsStarted) {
163172:     NS_IMPL_CYCLE_COLLECTION_UNLINK(mActiveNodes)
163172:   }
163172: NS_IMPL_CYCLE_COLLECTION_UNLINK_END_INHERITED(nsDOMEventTargetHelper)
163172: 
163172: NS_IMPL_CYCLE_COLLECTION_TRAVERSE_BEGIN_INHERITED(AudioContext, nsDOMEventTargetHelper)
163172:   NS_IMPL_CYCLE_COLLECTION_TRAVERSE(mDestination)
163172:   NS_IMPL_CYCLE_COLLECTION_TRAVERSE(mListener)
163172:   if (!tmp->mIsStarted) {
163172:     MOZ_ASSERT(tmp->mIsOffline,
163172:                "Online AudioContexts should always be started");
163172:     NS_IMPL_CYCLE_COLLECTION_TRAVERSE(mActiveNodes)
163172:   }
163172: NS_IMPL_CYCLE_COLLECTION_TRAVERSE_END
124159: 
141760: NS_IMPL_ADDREF_INHERITED(AudioContext, nsDOMEventTargetHelper)
141760: NS_IMPL_RELEASE_INHERITED(AudioContext, nsDOMEventTargetHelper)
141760: NS_INTERFACE_MAP_BEGIN_CYCLE_COLLECTION_INHERITED(AudioContext)
141760: NS_INTERFACE_MAP_END_INHERITING(nsDOMEventTargetHelper)
110929: 
131561: static uint8_t gWebAudioOutputKey;
131561: 
177245: float GetSampleRateForAudioContext(bool aIsOffline, float aSampleRate)
177245: {
177245:   if (aIsOffline) {
177245:     return aSampleRate;
177245:   } else {
177245:     AudioStream::InitPreferredSampleRate();
177245:     return static_cast<float>(AudioStream::PreferredSampleRate());
177245:   }
177245: }
177245: 
144539: AudioContext::AudioContext(nsPIDOMWindow* aWindow,
144539:                            bool aIsOffline,
144539:                            uint32_t aNumberOfChannels,
144539:                            uint32_t aLength,
144539:                            float aSampleRate)
177245:   : mSampleRate(GetSampleRateForAudioContext(aIsOffline, aSampleRate))
146894:   , mNumberOfChannels(aNumberOfChannels)
144538:   , mIsOffline(aIsOffline)
162434:   , mIsStarted(!aIsOffline)
162437:   , mIsShutDown(false)
110929: {
141760:   nsDOMEventTargetHelper::BindToOwner(aWindow);
160583:   aWindow->AddAudioContext(this);
110929:   SetIsDOMBinding();
164641: 
164641:   // Note: AudioDestinationNode needs an AudioContext that must already be
164641:   // bound to the window.
164641:   mDestination = new AudioDestinationNode(this, aIsOffline, aNumberOfChannels,
164641:                                           aLength, aSampleRate);
164641:   mDestination->Stream()->AddAudioOutput(&gWebAudioOutputKey);
110929: }
110929: 
110929: AudioContext::~AudioContext()
110929: {
160583:   nsPIDOMWindow* window = GetOwner();
160583:   if (window) {
160583:     window->RemoveAudioContext(this);
160583:   }
110929: }
110929: 
110929: JSObject*
141672: AudioContext::WrapObject(JSContext* aCx, JS::Handle<JSObject*> aScope)
110929: {
144538:   if (mIsOffline) {
144538:     return OfflineAudioContextBinding::Wrap(aCx, aScope, this);
144538:   } else {
135651:     return AudioContextBinding::Wrap(aCx, aScope, this);
110929:   }
144538: }
110929: 
110929: /* static */ already_AddRefed<AudioContext>
157843: AudioContext::Constructor(const GlobalObject& aGlobal,
157843:                           ErrorResult& aRv)
110929: {
157843:   nsCOMPtr<nsPIDOMWindow> window = do_QueryInterface(aGlobal.GetAsSupports());
110929:   if (!window) {
110929:     aRv.Throw(NS_ERROR_FAILURE);
110929:     return nullptr;
110929:   }
110929: 
144538:   nsRefPtr<AudioContext> object = new AudioContext(window, false);
144538:   return object.forget();
144538: }
144538: 
144538: /* static */ already_AddRefed<AudioContext>
144538: AudioContext::Constructor(const GlobalObject& aGlobal,
144538:                           uint32_t aNumberOfChannels,
144538:                           uint32_t aLength,
144538:                           float aSampleRate,
144538:                           ErrorResult& aRv)
144538: {
157843:   nsCOMPtr<nsPIDOMWindow> window = do_QueryInterface(aGlobal.GetAsSupports());
144538:   if (!window) {
144538:     aRv.Throw(NS_ERROR_FAILURE);
144538:     return nullptr;
144538:   }
144538: 
145728:   if (aNumberOfChannels == 0 ||
145728:       aNumberOfChannels > WebAudioUtils::MaxChannelCount ||
145728:       aLength == 0 ||
145923:       aSampleRate <= 1.0f ||
145728:       aSampleRate >= TRACK_RATE_MAX) {
145284:     // The DOM binding protects us against infinity and NaN
145728:     aRv.Throw(NS_ERROR_DOM_NOT_SUPPORTED_ERR);
144538:     return nullptr;
144538:   }
144538: 
144539:   nsRefPtr<AudioContext> object = new AudioContext(window,
144539:                                                    true,
144539:                                                    aNumberOfChannels,
144539:                                                    aLength,
144539:                                                    aSampleRate);
136240:   return object.forget();
110929: }
110929: 
114592: already_AddRefed<AudioBufferSourceNode>
114592: AudioContext::CreateBufferSource()
114592: {
114592:   nsRefPtr<AudioBufferSourceNode> bufferNode =
114592:     new AudioBufferSourceNode(this);
114592:   return bufferNode.forget();
111522: }
110929: 
114937: already_AddRefed<AudioBuffer>
114937: AudioContext::CreateBuffer(JSContext* aJSContext, uint32_t aNumberOfChannels,
114937:                            uint32_t aLength, float aSampleRate,
114937:                            ErrorResult& aRv)
114937: {
177269:   if (aSampleRate < 8000 || aSampleRate > 96000 || !aLength) {
177269:     aRv.Throw(NS_ERROR_DOM_NOT_SUPPORTED_ERR);
135460:     return nullptr;
135460:   }
135460: 
131561:   if (aLength > INT32_MAX) {
131561:     aRv.Throw(NS_ERROR_OUT_OF_MEMORY);
131561:     return nullptr;
131561:   }
131561: 
131561:   nsRefPtr<AudioBuffer> buffer =
131561:     new AudioBuffer(this, int32_t(aLength), aSampleRate);
114937:   if (!buffer->InitializeBuffers(aNumberOfChannels, aJSContext)) {
114937:     aRv.Throw(NS_ERROR_OUT_OF_MEMORY);
114937:     return nullptr;
114592:   }
131561: 
114937:   return buffer.forget();
114592: }
114592: 
142597: already_AddRefed<AudioBuffer>
155256: AudioContext::CreateBuffer(JSContext* aJSContext, const ArrayBuffer& aBuffer,
142597:                           bool aMixToMono, ErrorResult& aRv)
142597: {
150616:   // Do not accept this method unless the legacy pref has been set.
150616:   if (!Preferences::GetBool("media.webaudio.legacy.AudioContext")) {
150616:     aRv.ThrowNotEnoughArgsError();
150616:     return nullptr;
150616:   }
150616: 
142597:   // Sniff the content of the media.
142597:   // Failed type sniffing will be handled by SyncDecodeMedia.
142597:   nsAutoCString contentType;
142597:   NS_SniffContent(NS_DATA_SNIFFER_CATEGORY, nullptr,
142597:                   aBuffer.Data(), aBuffer.Length(),
142597:                   contentType);
142597: 
151821:   nsRefPtr<WebAudioDecodeJob> job =
151821:     new WebAudioDecodeJob(contentType, this, aBuffer);
142597: 
142597:   if (mDecoder.SyncDecodeMedia(contentType.get(),
151821:                                aBuffer.Data(), aBuffer.Length(), *job) &&
151821:       job->mOutput) {
151821:     nsRefPtr<AudioBuffer> buffer = job->mOutput.forget();
142673:     if (aMixToMono) {
142673:       buffer->MixToMono(aJSContext);
142673:     }
142673:     return buffer.forget();
142597:   }
142597: 
142597:   return nullptr;
142597: }
142597: 
141208: namespace {
141208: 
141208: bool IsValidBufferSize(uint32_t aBufferSize) {
141208:   switch (aBufferSize) {
141208:   case 0:       // let the implementation choose the buffer size
141208:   case 256:
141208:   case 512:
141208:   case 1024:
141208:   case 2048:
141208:   case 4096:
141208:   case 8192:
141208:   case 16384:
141208:     return true;
141208:   default:
141208:     return false;
141208:   }
141208: }
141208: 
141208: }
141208: 
147552: already_AddRefed<MediaStreamAudioDestinationNode>
152212: AudioContext::CreateMediaStreamDestination(ErrorResult& aRv)
147552: {
152212:   if (mIsOffline) {
152212:     aRv.Throw(NS_ERROR_DOM_NOT_SUPPORTED_ERR);
152212:     return nullptr;
152212:   }
152212: 
147552:   nsRefPtr<MediaStreamAudioDestinationNode> node =
147552:       new MediaStreamAudioDestinationNode(this);
147552:   return node.forget();
147552: }
147552: 
141208: already_AddRefed<ScriptProcessorNode>
141208: AudioContext::CreateScriptProcessor(uint32_t aBufferSize,
141208:                                     uint32_t aNumberOfInputChannels,
141208:                                     uint32_t aNumberOfOutputChannels,
141208:                                     ErrorResult& aRv)
141208: {
145117:   if ((aNumberOfInputChannels == 0 && aNumberOfOutputChannels == 0) ||
145661:       aNumberOfInputChannels > WebAudioUtils::MaxChannelCount ||
145661:       aNumberOfOutputChannels > WebAudioUtils::MaxChannelCount ||
141208:       !IsValidBufferSize(aBufferSize)) {
141208:     aRv.Throw(NS_ERROR_DOM_INDEX_SIZE_ERR);
141208:     return nullptr;
141208:   }
141208: 
141208:   nsRefPtr<ScriptProcessorNode> scriptProcessor =
141208:     new ScriptProcessorNode(this, aBufferSize, aNumberOfInputChannels,
141208:                             aNumberOfOutputChannels);
141208:   return scriptProcessor.forget();
141208: }
141208: 
138690: already_AddRefed<AnalyserNode>
138690: AudioContext::CreateAnalyser()
138690: {
138690:   nsRefPtr<AnalyserNode> analyserNode = new AnalyserNode(this);
138690:   return analyserNode.forget();
138690: }
138690: 
155439: already_AddRefed<MediaElementAudioSourceNode>
155439: AudioContext::CreateMediaElementSource(HTMLMediaElement& aMediaElement,
155439:                                        ErrorResult& aRv)
155439: {
155439:   if (mIsOffline) {
155439:     aRv.Throw(NS_ERROR_DOM_NOT_SUPPORTED_ERR);
155439:     return nullptr;
155439:   }
155439:   nsRefPtr<DOMMediaStream> stream = aMediaElement.MozCaptureStream(aRv);
155439:   if (aRv.Failed()) {
155439:     return nullptr;
155439:   }
155439:   nsRefPtr<MediaElementAudioSourceNode> mediaElementAudioSourceNode =
155439:     new MediaElementAudioSourceNode(this, stream);
155439:   return mediaElementAudioSourceNode.forget();
155439: }
155439: 
155437: already_AddRefed<MediaStreamAudioSourceNode>
155438: AudioContext::CreateMediaStreamSource(DOMMediaStream& aMediaStream,
155437:                                       ErrorResult& aRv)
155437: {
155437:   if (mIsOffline) {
155437:     aRv.Throw(NS_ERROR_DOM_NOT_SUPPORTED_ERR);
155437:     return nullptr;
155437:   }
155439:   nsRefPtr<MediaStreamAudioSourceNode> mediaStreamAudioSourceNode =
155439:     new MediaStreamAudioSourceNode(this, &aMediaStream);
155437:   return mediaStreamAudioSourceNode.forget();
155437: }
155437: 
120694: already_AddRefed<GainNode>
120694: AudioContext::CreateGain()
120694: {
120694:   nsRefPtr<GainNode> gainNode = new GainNode(this);
120694:   return gainNode.forget();
114937: }
114937: 
144191: already_AddRefed<WaveShaperNode>
144191: AudioContext::CreateWaveShaper()
144191: {
144191:   nsRefPtr<WaveShaperNode> waveShaperNode = new WaveShaperNode(this);
144191:   return waveShaperNode.forget();
144191: }
144191: 
120775: already_AddRefed<DelayNode>
123572: AudioContext::CreateDelay(double aMaxDelayTime, ErrorResult& aRv)
120775: {
137409:   if (aMaxDelayTime > 0. && aMaxDelayTime < 180.) {
122108:     nsRefPtr<DelayNode> delayNode = new DelayNode(this, aMaxDelayTime);
122108:     return delayNode.forget();
122108:   }
121469:   aRv.Throw(NS_ERROR_DOM_NOT_SUPPORTED_ERR);
121469:   return nullptr;
121469: }
120694: 
121066: already_AddRefed<PannerNode>
121066: AudioContext::CreatePanner()
121066: {
121066:   nsRefPtr<PannerNode> pannerNode = new PannerNode(this);
141639:   mPannerNodes.PutEntry(pannerNode);
121066:   return pannerNode.forget();
121066: }
121066: 
146939: already_AddRefed<ConvolverNode>
146939: AudioContext::CreateConvolver()
146939: {
146939:   nsRefPtr<ConvolverNode> convolverNode = new ConvolverNode(this);
146939:   return convolverNode.forget();
146939: }
146939: 
142678: already_AddRefed<ChannelSplitterNode>
142678: AudioContext::CreateChannelSplitter(uint32_t aNumberOfOutputs, ErrorResult& aRv)
142678: {
142678:   if (aNumberOfOutputs == 0 ||
145661:       aNumberOfOutputs > WebAudioUtils::MaxChannelCount) {
142678:     aRv.Throw(NS_ERROR_DOM_INDEX_SIZE_ERR);
142678:     return nullptr;
142678:   }
142678: 
142678:   nsRefPtr<ChannelSplitterNode> splitterNode =
142678:     new ChannelSplitterNode(this, aNumberOfOutputs);
142678:   return splitterNode.forget();
142678: }
142678: 
142679: already_AddRefed<ChannelMergerNode>
142679: AudioContext::CreateChannelMerger(uint32_t aNumberOfInputs, ErrorResult& aRv)
142679: {
142679:   if (aNumberOfInputs == 0 ||
145661:       aNumberOfInputs > WebAudioUtils::MaxChannelCount) {
142679:     aRv.Throw(NS_ERROR_DOM_INDEX_SIZE_ERR);
142679:     return nullptr;
142679:   }
142679: 
142679:   nsRefPtr<ChannelMergerNode> mergerNode =
142679:     new ChannelMergerNode(this, aNumberOfInputs);
142679:   return mergerNode.forget();
142679: }
142679: 
121244: already_AddRefed<DynamicsCompressorNode>
121244: AudioContext::CreateDynamicsCompressor()
121244: {
121244:   nsRefPtr<DynamicsCompressorNode> compressorNode =
121244:     new DynamicsCompressorNode(this);
121244:   return compressorNode.forget();
121244: }
121244: 
121333: already_AddRefed<BiquadFilterNode>
121333: AudioContext::CreateBiquadFilter()
121333: {
121333:   nsRefPtr<BiquadFilterNode> filterNode =
121333:     new BiquadFilterNode(this);
121333:   return filterNode.forget();
121333: }
121333: 
156971: already_AddRefed<OscillatorNode>
156971: AudioContext::CreateOscillator()
156971: {
156971:   nsRefPtr<OscillatorNode> oscillatorNode =
156971:     new OscillatorNode(this);
156971:   return oscillatorNode.forget();
156971: }
156971: 
148067: already_AddRefed<PeriodicWave>
148067: AudioContext::CreatePeriodicWave(const Float32Array& aRealData,
145458:                                  const Float32Array& aImagData,
145458:                                  ErrorResult& aRv)
145458: {
145458:   if (aRealData.Length() != aImagData.Length() ||
145458:       aRealData.Length() == 0 ||
145458:       aRealData.Length() > 4096) {
145458:     aRv.Throw(NS_ERROR_DOM_NOT_SUPPORTED_ERR);
145458:     return nullptr;
145458:   }
145458: 
148067:   nsRefPtr<PeriodicWave> periodicWave =
162496:     new PeriodicWave(this, aRealData.Data(), aImagData.Data(),
162496:                      aImagData.Length(), aRv);
162496:   if (aRv.Failed()) {
162496:     return nullptr;
162496:   }
148067:   return periodicWave.forget();
145458: }
145458: 
121021: AudioListener*
121021: AudioContext::Listener()
121021: {
121021:   if (!mListener) {
121021:     mListener = new AudioListener(this);
120775:   }
121021:   return mListener;
120775: }
120775: 
131294: void
131294: AudioContext::DecodeAudioData(const ArrayBuffer& aBuffer,
131294:                               DecodeSuccessCallback& aSuccessCallback,
131294:                               const Optional<OwningNonNull<DecodeErrorCallback> >& aFailureCallback)
131294: {
131294:   // Sniff the content of the media.
131294:   // Failed type sniffing will be handled by AsyncDecodeMedia.
131294:   nsAutoCString contentType;
131294:   NS_SniffContent(NS_DATA_SNIFFER_CATEGORY, nullptr,
131294:                   aBuffer.Data(), aBuffer.Length(),
131294:                   contentType);
131294: 
131294:   nsCOMPtr<DecodeErrorCallback> failureCallback;
131294:   if (aFailureCallback.WasPassed()) {
148011:     failureCallback = &aFailureCallback.Value();
121021:   }
151821:   nsRefPtr<WebAudioDecodeJob> job(
151821:     new WebAudioDecodeJob(contentType, this, aBuffer,
131294:                           &aSuccessCallback, failureCallback));
131294:   mDecoder.AsyncDecodeMedia(contentType.get(),
144097:                             aBuffer.Data(), aBuffer.Length(), *job);
131294:   // Transfer the ownership to mDecodeJobs
131294:   mDecodeJobs.AppendElement(job.forget());
121021: }
121021: 
131294: void
131294: AudioContext::RemoveFromDecodeQueue(WebAudioDecodeJob* aDecodeJob)
131294: {
131294:   mDecodeJobs.RemoveElement(aDecodeJob);
131294: }
131294: 
140371: void
162435: AudioContext::RegisterActiveNode(AudioNode* aNode)
162435: {
162437:   if (!mIsShutDown) {
162435:     mActiveNodes.PutEntry(aNode);
162435:   }
162437: }
162435: 
162435: void
162435: AudioContext::UnregisterActiveNode(AudioNode* aNode)
162435: {
162435:   mActiveNodes.RemoveEntry(aNode);
162435: }
162435: 
162435: void
140371: AudioContext::UnregisterAudioBufferSourceNode(AudioBufferSourceNode* aNode)
140371: {
142523:   UpdatePannerSource();
140371: }
140371: 
140371: void
140371: AudioContext::UnregisterPannerNode(PannerNode* aNode)
140371: {
141639:   mPannerNodes.RemoveEntry(aNode);
152088:   if (mListener) {
152088:     mListener->UnregisterPannerNode(aNode);
152088:   }
140371: }
140371: 
141639: static PLDHashOperator
141639: FindConnectedSourcesOn(nsPtrHashKey<PannerNode>* aEntry, void* aData)
141639: {
141639:   aEntry->GetKey()->FindConnectedSources();
141639:   return PL_DHASH_NEXT;
141395: }
141395: 
141395: void
140371: AudioContext::UpdatePannerSource()
140371: {
141639:   mPannerNodes.EnumerateEntries(FindConnectedSourcesOn, nullptr);
140371: }
140371: 
146894: uint32_t
146894: AudioContext::MaxChannelCount() const
146894: {
146894:   return mIsOffline ? mNumberOfChannels : AudioStream::MaxNumberOfChannels();
146894: }
146894: 
131561: MediaStreamGraph*
131561: AudioContext::Graph() const
131561: {
131561:   return Destination()->Stream()->Graph();
131294: }
131294: 
131561: MediaStream*
131561: AudioContext::DestinationStream() const
131561: {
162586:   if (Destination()) {
131561:     return Destination()->Stream();
131561:   }
162586:   return nullptr;
162586: }
131561: 
136142: double
136142: AudioContext::CurrentTime() const
136142: {
136142:   return MediaTimeToSeconds(Destination()->Stream()->GetCurrentTime());
131561: }
136142: 
137148: void
141296: AudioContext::Shutdown()
141296: {
162437:   mIsShutDown = true;
162437: 
141296:   Suspend();
154322: 
169802:   mDecoder.Shutdown();
169802: 
162435:   // Release references to active nodes.
162435:   // Active AudioNodes don't unregister in destructors, at which point the
162435:   // Node is already unregistered.
162435:   mActiveNodes.Clear();
162435: 
144541:   // For offline contexts, we can destroy the MediaStreamGraph at this point.
162587:   if (mIsOffline && mDestination) {
160582:     mDestination->OfflineShutdown();
144541:   }
141296: }
141296: 
141296: void
137148: AudioContext::Suspend()
137148: {
140529:   MediaStream* ds = DestinationStream();
140529:   if (ds) {
140529:     ds->ChangeExplicitBlockerCount(1);
140529:   }
131561: }
137148: 
137148: void
137148: AudioContext::Resume()
137148: {
140529:   MediaStream* ds = DestinationStream();
140529:   if (ds) {
140529:     ds->ChangeExplicitBlockerCount(-1);
140529:   }
136142: }
137148: 
140672: JSContext*
140672: AudioContext::GetJSContext() const
140672: {
140672:   MOZ_ASSERT(NS_IsMainThread());
140672: 
140672:   nsCOMPtr<nsIScriptGlobalObject> scriptGlobal =
140672:     do_QueryInterface(GetParentObject());
141985:   if (!scriptGlobal) {
141985:     return nullptr;
141985:   }
140672:   nsIScriptContext* scriptContext = scriptGlobal->GetContext();
140672:   if (!scriptContext) {
140672:     return nullptr;
137148:   }
140672:   return scriptContext->GetNativeContext();
137148: }
140672: 
144539: void
162434: AudioContext::StartRendering(ErrorResult& aRv)
144539: {
144539:   MOZ_ASSERT(mIsOffline, "This should only be called on OfflineAudioContext");
162434:   if (mIsStarted) {
162434:     aRv.Throw(NS_ERROR_DOM_INVALID_STATE_ERR);
162434:     return;
162434:   }
144539: 
162434:   mIsStarted = true;
144539:   mDestination->StartRendering();
140672: }
144539: 
150590: void
150590: AudioContext::Mute() const
150590: {
150590:   MOZ_ASSERT(!mIsOffline);
150590:   mDestination->Mute();
140672: }
150590: 
150590: void
150590: AudioContext::Unmute() const
150590: {
150590:   MOZ_ASSERT(!mIsOffline);
150590:   mDestination->Unmute();
144539: }
150590: 
165212: AudioChannel
165212: AudioContext::MozAudioChannelType() const
165212: {
165212:   return mDestination->MozAudioChannelType();
150590: }
165212: 
165212: void
165212: AudioContext::SetMozAudioChannelType(AudioChannel aValue, ErrorResult& aRv)
165212: {
165212:   mDestination->SetMozAudioChannelType(aValue, aRv);
150590: }
165212: 
165212: }
165212: }
