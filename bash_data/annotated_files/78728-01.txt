52560: /* -*- Mode: C++; tab-width: 4; indent-tabs-mode: nil; c-basic-offset: 4 -*-
52560:  * vim: set ts=4 sw=4 et tw=99:
52560:  *
52560:  * ***** BEGIN LICENSE BLOCK *****
52560:  * Version: MPL 1.1/GPL 2.0/LGPL 2.1
52560:  *
52560:  * The contents of this file are subject to the Mozilla Public License Version
52560:  * 1.1 (the "License"); you may not use this file except in compliance with
52560:  * the License. You may obtain a copy of the License at
52560:  * http://www.mozilla.org/MPL/
52560:  *
52560:  * Software distributed under the License is distributed on an "AS IS" basis,
52560:  * WITHOUT WARRANTY OF ANY KIND, either express or implied. See the License
52560:  * for the specific language governing rights and limitations under the
52560:  * License.
52560:  *
52560:  * The Original Code is Mozilla SpiderMonkey JavaScript 1.9 code, released
52560:  * May 28, 2008.
52560:  *
52560:  * The Initial Developer of the Original Code is
52560:  *   Brendan Eich <brendan@mozilla.org>
52560:  *
52560:  * Contributor(s):
52560:  *   David Anderson <danderson@mozilla.com>
52560:  *
52560:  * Alternatively, the contents of this file may be used under the terms of
52560:  * either of the GNU General Public License Version 2 or later (the "GPL"),
52560:  * or the GNU Lesser General Public License Version 2.1 or later (the "LGPL"),
52560:  * in which case the provisions of the GPL or the LGPL are applicable instead
52560:  * of those above. If you wish to allow use of your version of this file only
52560:  * under the terms of either the GPL or the LGPL, and not to allow others to
52560:  * use your version of this file under the terms of the MPL, indicate your
52560:  * decision by deleting the provisions above and replace them with the notice
52560:  * and other provisions required by the GPL or the LGPL. If you do not delete
52560:  * the provisions above, a recipient may use your version of this file under
52560:  * the terms of any one of the MPL, the GPL or the LGPL.
52560:  *
52560:  * ***** END LICENSE BLOCK ***** */
52560: #include "jscntxt.h"
52560: #include "FrameState.h"
52618: #include "FrameState-inl.h"
77343: #include "StubCompiler.h"
52560: 
52560: using namespace js;
52560: using namespace js::mjit;
77343: using namespace js::analyze;
52560: 
52719: /* Because of Value alignment */
52719: JS_STATIC_ASSERT(sizeof(FrameEntry) % 8 == 0);
52719: 
77343: FrameState::FrameState(JSContext *cx, mjit::Compiler &cc,
77343:                        Assembler &masm, StubCompiler &stubcc)
77343:   : cx(cx),
77343:     masm(masm), cc(cc), stubcc(stubcc),
77343:     a(NULL), entries(NULL), nentries(0), freeRegs(Registers::AvailAnyRegs),
77343:     loop(NULL), inTryBlock(false)
52617: {
52617: }
52617: 
52617: FrameState::~FrameState()
52617: {
77343:     while (a) {
77343:         ActiveFrame *parent = a->parent;
77391:         a->script->analysis()->clearAllocations();
77343:         cx->free_(a);
77343:         a = parent;
77343:     }
64560:     cx->free_(entries);
52617: }
52617: 
77343: void
77343: FrameState::pruneDeadEntries()
77343: {
77343:     unsigned shift = 0;
77343:     for (unsigned i = 0; i < tracker.nentries; i++) {
77343:         FrameEntry *fe = tracker[i];
77343:         if (deadEntry(fe)) {
77343:             fe->untrack();
77343:             shift++;
77343:         } else if (shift) {
77343:             fe->index_ -= shift;
77343:             tracker.entries[fe->index_] = fe;
77343:         }
77343:     }
77343:     tracker.nentries -= shift;
77343: }
77343: 
76206: bool
77343: FrameState::pushActiveFrame(JSScript *script, uint32 argc)
75864: {
77343:     if (!a) {
77343:         this->nentries = analyze::TotalSlots(script) + (script->nslots - script->nfixed) +
77343:             StackSpace::STACK_JIT_EXTRA - VALUES_PER_STACK_FRAME;
77343:         size_t totalBytes = sizeof(FrameEntry) * nentries +       // entries[]
57787:                             sizeof(FrameEntry *) * nentries +     // tracker.entries
77343:                             sizeof(StackEntryExtra) * nentries;   // extraArray
64560:         uint8 *cursor = (uint8 *)cx->calloc_(totalBytes);
52617:         if (!cursor)
52560:             return false;
52560: 
77343:         this->entries = (FrameEntry *) cursor;
57787:         cursor += sizeof(FrameEntry) * nentries;
52560: 
77343:         this->tracker.entries = (FrameEntry **)cursor;
57787:         cursor += sizeof(FrameEntry *) * nentries;
52878: 
77343:         this->extraArray = (StackEntryExtra *)cursor;
77343:         cursor += sizeof(StackEntryExtra) * nentries;
77343: 
77343:         JS_ASSERT(reinterpret_cast<uint8 *>(this->entries) + totalBytes == cursor);
77343: 
77343: #if defined JS_NUNBOX32
77343:         if (!reifier.init(cx, *this, nentries))
77343:             return false;
77343: #endif
77343: 
77343:         this->temporaries = this->temporariesTop = this->entries + nentries - TEMPORARY_LIMIT;
76206:     }
77343: 
77343:     /* We should have already checked that argc == nargs */
77391:     JS_ASSERT_IF(a, argc == script->function()->nargs);
77343: 
77343:     ActiveFrame *newa = cx->new_<ActiveFrame>();
77343:     if (!newa)
77343:         return false;
77343: 
77343:     newa->parent = a;
77343:     newa->depth = a ? (totalDepth() + VALUES_PER_STACK_FRAME) : 0;
77343: 
77343:     newa->script = script;
77343:     newa->PC = script->code;
77391:     newa->analysis = script->analysis();
77343: 
77343:     /*
77343:      * The callee/this/args in the new frame reuse the same entries as are on
77343:      * the stack in the old frame.
77343:      */
77343:     FrameEntry *entriesStart = a ? a->sp - (argc + 2) : entries;
77343:     newa->callee_ = entriesStart + analyze::CalleeSlot();
77343:     newa->this_   = entriesStart + analyze::ThisSlot();
77343:     newa->args    = entriesStart + analyze::ArgSlot(0);
77343:     newa->locals  = entriesStart + analyze::LocalSlot(script, 0);
77343:     newa->spBase  = entriesStart + analyze::TotalSlots(script);
77343:     newa->sp      = newa->spBase;
77343: 
77343:     this->a = newa;
54719: 
52560:     return true;
52560: }
52560: 
52652: void
77343: FrameState::associateReg(FrameEntry *fe, RematInfo::RematType type, AnyRegisterID reg)
52652: {
77343:     freeRegs.takeReg(reg);
77343: 
77343:     if (type == RematInfo::TYPE)
77343:         fe->type.setRegister(reg.reg());
77343:     else if (reg.isReg())
77343:         fe->data.setRegister(reg.reg());
77343:     else
77343:         fe->data.setFPRegister(reg.fpreg());
77343:     regstate(reg).associate(fe, type);
77343: }
77343: 
77343: void
77343: FrameState::popActiveFrame()
77343: {
77343:     a->analysis->clearAllocations();
77343: 
77343:     if (a->parent) {
77343:         /* Clear registers and copies used by local variables and stack slots. */
77343:         for (FrameEntry *fe = a->sp - 1; fe >= a->locals; fe--) {
77343:             if (!fe->isTracked())
77343:                 continue;
77343:             forgetAllRegs(fe);
77343:             fe->clear();
77343:         }
77343:     }
77343: 
77343:     ActiveFrame *parent = a->parent;
77343:     cx->delete_(a);
77343:     a = parent;
77343: }
77343: 
77343: void
77343: FrameState::takeReg(AnyRegisterID reg)
77343: {
77343:     modifyReg(reg);
76206:     if (freeRegs.hasReg(reg)) {
76019:         freeRegs.takeReg(reg);
77343:         JS_ASSERT(!regstate(reg).usedBy());
76206:     } else {
77343:         JS_ASSERT(regstate(reg).fe());
76206:         evictReg(reg);
76206:     }
75864: }
75864: 
77343: #ifdef DEBUG
77343: const char *
77343: FrameState::entryName(const FrameEntry *fe) const
77343: {
77343:     static char bufs[4][50];
77343:     static unsigned which = 0;
77343:     which = (which + 1) & 3;
77343:     char *buf = bufs[which];
77343: 
77343:     if (isTemporary(fe)) {
77343:         JS_snprintf(buf, 50, "temp%d", fe - temporaries);
77343:         return buf;
77343:     }
77343: 
77343:     if (fe < a->callee_)
77343:         return "parent";
77343: 
77343:     JS_ASSERT(fe >= a->callee_ && fe < a->sp);
77343: 
77343:     if (fe == a->callee_)
77343:         return "callee";
77343:     if (fe == a->this_)
77343:         return "'this'";
77343: 
77343:     if (isArg(fe))
77343:         JS_snprintf(buf, 50, "arg%d", fe - a->args);
77343:     else if (isLocal(fe))
77343:         JS_snprintf(buf, 50, "local%d", fe - a->locals);
77343:     else
77343:         JS_snprintf(buf, 50, "slot%d", fe - a->spBase);
77343:     return buf;
77343: }
77343: #endif
77343: 
75864: void
77343: FrameState::evictReg(AnyRegisterID reg)
75864: {
77343:     FrameEntry *fe = regstate(reg).fe();
77343: 
77343:     JaegerSpew(JSpew_Regalloc, "evicting %s from %s\n", entryName(fe), reg.name());
77343: 
77343:     if (regstate(reg).type() == RematInfo::TYPE) {
77343:         syncType(fe);
76206:         fe->type.setMemory();
77343:     } else if (reg.isReg()) {
77343:         syncData(fe);
77343:         fe->data.setMemory();
76206:     } else {
77343:         syncFe(fe);
76206:         fe->data.setMemory();
76008:     }
77343: 
77343:     regstate(reg).forget();
76008: }
76008: 
77343: inline Lifetime *
77343: FrameState::variableLive(FrameEntry *fe, jsbytecode *pc) const
57787: {
77432:     /*
77432:      * Whether an argument, local or 'this' entry is live at pc. Note: this
77432:      * does not account for the 'this' entry when the script is used as a
77432:      * constructor, in which case it is live the entire frame.
77432:      */
77343:     JS_ASSERT(cx->typeInferenceEnabled());
77343:     JS_ASSERT(fe > a->callee_ && fe < a->spBase);
77343: 
77343:     uint32 offset = pc - a->script->code;
77343:     return a->analysis->liveness(entrySlot(fe)).live(offset);
77343: }
77343: 
77343: AnyRegisterID
77343: FrameState::bestEvictReg(uint32 mask, bool includePinned) const
77343: {
77343:     JS_ASSERT(cx->typeInferenceEnabled());
77343: 
77343:     /* Must be looking for a specific type of register. */
77343:     JS_ASSERT((mask & Registers::AvailRegs) != (mask & Registers::AvailFPRegs));
77343: 
77343:     AnyRegisterID fallback;
77343:     uint32 fallbackOffset = uint32(-1);
77343: 
77343:     JaegerSpew(JSpew_Regalloc, "picking best register to evict:\n");
77343: 
77343:     for (uint32 i = 0; i < Registers::TotalAnyRegisters; i++) {
77343:         AnyRegisterID reg = AnyRegisterID::fromRaw(i);
75899: 
75899:         /* Register is not allocatable, don't bother.  */
75899:         if (!(Registers::maskReg(reg) & mask))
75899:             continue;
75899: 
75899:         /* Register is not owned by the FrameState. */
77343:         FrameEntry *fe = includePinned ? regstate(reg).usedBy() : regstate(reg).fe();
75899:         if (!fe)
75899:             continue;
75899: 
77343:         /*
77343:          * Liveness is not tracked for the callee or for stack slot frame entries.
77343:          * The callee is evicted as early as needed, stack slots are evicted as
77343:          * late as possible. :XXX: This is unfortunate if the stack slot lives
77343:          * a long time (especially if it gets spilled anyways when we hit a branch).
77343:          */
77343: 
77343:         if (fe == a->callee_) {
77343:             JaegerSpew(JSpew_Regalloc, "result: %s is callee\n", reg.name());
77343:             return reg;
77343:         }
77343: 
77343:         if (fe >= a->spBase && !isTemporary(fe)) {
77343:             if (!fallback.isSet()) {
75899:                 fallback = reg;
77343:                 fallbackOffset = 0;
77343:             }
77343:             JaegerSpew(JSpew_Regalloc, "    %s is on stack\n", reg.name());
77343:             continue;
77343:         }
77343: 
77343:         /* Prioritize keeping copied entries in registers. */
77343:         if (fe->isCopied()) {
77343:             if (!fallback.isSet()) {
77343:                 fallback = reg;
77343:                 fallbackOffset = 0;
77343:             }
77343:             JaegerSpew(JSpew_Regalloc, "    %s has copies\n", reg.name());
77343:             continue;
77343:         }
77343: 
77343:         if (isTemporary(fe) || (a->parent && fe < a->locals)) {
77343:             /*
77343:              * All temporaries we currently generate are for loop invariants,
77343:              * which we treat as being live everywhere within the loop.
77343:              * Additionally, if this is an inlined frame then any entries
77343:              * belonging to parents are treated as live everywhere in the call.
77343:              */
77343:             uint32 offset = a->parent ? a->script->length : loop->backedgeOffset();
77343:             if (!fallback.isSet() || offset > fallbackOffset) {
77343:                 fallback = reg;
77343:                 fallbackOffset = offset;
77343:             }
77343:             JaegerSpew(JSpew_Regalloc, "    %s is a LICM or inline parent entry\n", reg.name());
77343:             continue;
77343:         }
77343: 
77432:         /*
77432:          * All entries still in registers should have a lifetime, except 'this'
77432:          * in constructors which are not accessed later on.
77432:          */
77343:         Lifetime *lifetime = variableLive(fe, a->PC);
77432: 
77432:         if (!lifetime) {
77432:             JS_ASSERT(isConstructorThis(fe));
77432:             fallback = reg;
77432:             fallbackOffset = a->script->length;
77432:             JaegerSpew(JSpew_Regalloc, "    %s is 'this' in a constructor\n", reg.name());
77432:             continue;
77432:         }
77343: 
77343:         /*
77343:          * Evict variables which are only live in future loop iterations, and are
77343:          * not carried around the loop in a register.
77343:          */
77343:         JS_ASSERT_IF(lifetime->loopTail, loop);
77343:         if (lifetime->loopTail && !loop->carriesLoopReg(fe)) {
77343:             JaegerSpew(JSpew_Regalloc, "result: %s (%s) only live in later iterations\n",
77343:                        entryName(fe), reg.name());
77343:             return reg;
77343:         }
77343: 
77343:         JaegerSpew(JSpew_Regalloc, "    %s (%s): %u\n", entryName(fe), reg.name(), lifetime->end);
77343: 
77343:         /*
77343:          * The best live register to evict is the one that will be live for the
77343:          * longest time. This may need tweaking for variables that are used in
77343:          * many places throughout their lifetime. Note that we don't pay attention
77343:          * to whether the register is synced or not --- it is more efficient to
77343:          * have things in registers when they're needed than to emit some extra
77343:          * writes for things that won't be used again for a while.
77343:          */
77343: 
77343:         if (!fallback.isSet() || lifetime->end > fallbackOffset) {
77343:             fallback = reg;
77343:             fallbackOffset = lifetime->end;
77343:         }
77343:     }
77343: 
77343:     JS_ASSERT(fallback.isSet());
77343: 
77343:     JaegerSpew(JSpew_Regalloc, "result %s\n", fallback.name());
76206:     return fallback;
75899: }
77343: 
77343: void
77343: FrameState::evictDeadEntries(bool includePinned)
77343: {
77343:     for (uint32 i = 0; i < Registers::TotalAnyRegisters; i++) {
77343:         AnyRegisterID reg = AnyRegisterID::fromRaw(i);
77343: 
77343:         /* Follow along with the same filters as bestEvictReg. */
77343: 
77343:         if (!(Registers::maskReg(reg) & Registers::AvailAnyRegs))
77343:             continue;
77343: 
77343:         FrameEntry *fe = includePinned ? regstate(reg).usedBy() : regstate(reg).fe();
77343:         if (!fe)
77343:             continue;
77343: 
77432:         if (fe == a->callee_ || isConstructorThis(fe) ||
77432:             fe >= a->spBase || fe->isCopied() || (a->parent && fe < a->locals)) {
77343:             continue;
77432:         }
77343: 
77343:         Lifetime *lifetime = variableLive(fe, a->PC);
77343:         if (lifetime)
77343:             continue;
77343: 
77343:         /*
77343:          * If we are about to fake sync for an entry with known type, reset
77343:          * that type. We don't want to regard it as correctly synced later.
77343:          */
77343:         if (!fe->type.synced() && fe->isTypeKnown())
77343:             fe->type.setMemory();
77343: 
77343:         /*
77343:          * Mark the entry as synced to avoid emitting a store, we don't need
77343:          * to keep this value around.
77343:          */
77343:         fakeSync(fe);
77343:         if (regstate(reg).type() == RematInfo::DATA)
68952:             fe->data.setMemory();
77343:         else
77343:             fe->type.setMemory();
77343:         forgetReg(reg);
68952:     }
68952: }
68952: 
77343: AnyRegisterID
77343: FrameState::evictSomeReg(uint32 mask)
77343: {
77343:     JS_ASSERT(!freeRegs.hasRegInMask(mask));
77343: 
77343:     if (cx->typeInferenceEnabled()) {
77343:         evictDeadEntries(false);
77343: 
77343:         if (freeRegs.hasRegInMask(mask)) {
77343:             /* There was a register in use by a dead local variable. */
77343:             AnyRegisterID reg = freeRegs.takeAnyReg(mask);
77343:             modifyReg(reg);
77343:             return reg;
76206:         }
76206: 
77343:         AnyRegisterID reg = bestEvictReg(mask, false);
77343:         evictReg(reg);
77343:         return reg;
77343:     }
77343: 
77343:     /* With inference disabled, only general purpose registers are managed. */
77343:     JS_ASSERT((mask & ~Registers::AvailRegs) == 0);
77343: 
77343:     MaybeRegisterID fallback;
77343: 
77343:     for (uint32 i = 0; i < JSC::MacroAssembler::TotalRegisters; i++) {
77343:         RegisterID reg = RegisterID(i);
77343: 
77343:         /* Register is not allocatable, don't bother.  */
77343:         if (!(Registers::maskReg(reg) & mask))
77343:             continue;
77343: 
77343:         /* Register is not owned by the FrameState. */
77343:         FrameEntry *fe = regstate(reg).fe();
77343:         if (!fe)
77343:             continue;
77343: 
77343:         /* Try to find a candidate... that doesn't need spilling. */
77343:         fallback = reg;
77343: 
77343:         if (regstate(reg).type() == RematInfo::TYPE && fe->type.synced()) {
77343:             fe->type.setMemory();
77343:             regstate(reg).forget();
77343:             return reg;
77343:         }
77343:         if (regstate(reg).type() == RematInfo::DATA && fe->data.synced()) {
77343:             fe->data.setMemory();
77343:             regstate(reg).forget();
77343:             return reg;
77343:         }
77343:     }
77343: 
77343:     evictReg(fallback.reg());
77343:     return fallback.reg();
52847: }
52847: 
52847: void
54719: FrameState::resetInternalState()
52847: {
52670:     for (uint32 i = 0; i < tracker.nentries; i++)
54719:         tracker[i]->untrack();
52617: 
52617:     tracker.reset();
77343:     freeRegs = Registers(Registers::AvailAnyRegs);
52617: }
52617: 
52608: void
54719: FrameState::discardFrame()
54719: {
54719:     resetInternalState();
77343:     PodArrayZero(regstate_);
77343: }
77343: 
77343: FrameEntry *
77343: FrameState::snapshotState()
77343: {
77343:     /* Everything can be recovered from a copy of the frame entries. */
77343:     FrameEntry *snapshot = cx->array_new<FrameEntry>(nentries);
77343:     if (!snapshot)
77343:         return NULL;
77343:     PodCopy(snapshot, entries, nentries);
77343:     return snapshot;
77343: }
77343: 
77343: void
77343: FrameState::restoreFromSnapshot(FrameEntry *snapshot)
77343: {
77343:     discardFrame();
77343:     PodCopy(entries, snapshot, nentries);
77343: 
77343:     for (unsigned i = 0; i < nentries; i++) {
77343:         FrameEntry *fe = entries + i;
77343:         if (!fe->isTracked())
77343:             continue;
77343:         tracker.entries[fe->index_] = fe;
77343:         tracker.nentries = Max(tracker.nentries, fe->index_ + 1);
77343:         if (fe->isCopy())
77343:             continue;
77343:         if (fe->type.inRegister()) {
77343:             freeRegs.takeReg(fe->type.reg());
77343:             regstate(fe->type.reg()).associate(fe, RematInfo::TYPE);
77343:         }
77343:         if (fe->data.inRegister()) {
77343:             freeRegs.takeReg(fe->data.reg());
77343:             regstate(fe->data.reg()).associate(fe, RematInfo::DATA);
77343:         }
77343:         if (fe->data.inFPRegister()) {
77343:             freeRegs.takeReg(fe->data.fpreg());
77343:             regstate(fe->data.fpreg()).associate(fe, RematInfo::DATA);
77343:         }
77343:     }
54719: }
54719: 
54719: void
54719: FrameState::forgetEverything()
54719: {
54719:     resetInternalState();
54719: 
54719: #ifdef DEBUG
77343:     for (uint32 i = 0; i < Registers::TotalAnyRegisters; i++) {
77343:         AnyRegisterID reg = AnyRegisterID::fromRaw(i);
77343:         JS_ASSERT(!regstate(reg).usedBy());
54719:     }
54719: #endif
54719: }
54719: 
77343: #ifdef DEBUG
77343: void
77343: FrameState::dumpAllocation(RegisterAllocation *alloc)
77343: {
77343:     JS_ASSERT(cx->typeInferenceEnabled());
77343:     for (unsigned i = 0; i < Registers::TotalAnyRegisters; i++) {
77343:         AnyRegisterID reg = AnyRegisterID::fromRaw(i);
77343:         if (alloc->assigned(reg)) {
77343:             printf(" (%s: %s%s)", reg.name(), entryName(entries + alloc->index(reg)),
77343:                    alloc->synced(reg) ? "" : " unsynced");
77343:         }
77343:     }
77343:     printf("\n");
77343: }
77343: #endif
77343: 
77343: RegisterAllocation *
77343: FrameState::computeAllocation(jsbytecode *target)
77343: {
77343:     JS_ASSERT(cx->typeInferenceEnabled());
77343:     RegisterAllocation *alloc = ArenaNew<RegisterAllocation>(cx->compartment->pool, false);
77343:     if (!alloc)
77343:         return NULL;
77343: 
77343:     if (a->analysis->getCode(target).exceptionEntry || a->analysis->getCode(target).switchTarget ||
77343:         JSOp(*target) == JSOP_TRAP) {
77343:         /* State must be synced at exception and switch targets, and at traps. */
77343: #ifdef DEBUG
77343:         if (IsJaegerSpewChannelActive(JSpew_Regalloc)) {
77530:             JaegerSpew(JSpew_Regalloc, "allocation at %u:", unsigned(target - a->script->code));
77343:             dumpAllocation(alloc);
77343:         }
77343: #endif
77343:         return alloc;
77343:     }
77343: 
77343:     /*
77343:      * The allocation to use at the target consists of all parent, temporary
77343:      * and non-stack entries currently in registers which are live at target.
77343:      */
77343:     Registers regs = Registers::AvailAnyRegs;
77343:     while (!regs.empty()) {
77343:         AnyRegisterID reg = regs.takeAnyReg();
77343:         if (freeRegs.hasReg(reg) || regstate(reg).type() == RematInfo::TYPE)
77343:             continue;
77343:         FrameEntry *fe = regstate(reg).fe();
77343:         if (fe < a->callee_ ||
77432:             isConstructorThis(fe) ||
77343:             (fe > a->callee_ && fe < a->spBase && variableLive(fe, target)) ||
77343:             (isTemporary(fe) && (a->parent || uint32(target - a->script->code) <= loop->backedgeOffset()))) {
77343:             /*
77343:              * For entries currently in floating point registers, check they
77343:              * are known to be doubles at the target. We don't need to do this
77343:              * for entries in normal registers, as fixDoubleTypes must have been
77343:              * called to convert them to floats.
77343:              */
77343:             if (!reg.isReg() && !isTemporary(fe) && fe >= a->callee_ && fe < a->spBase) {
77343:                 if (!a->analysis->trackSlot(entrySlot(fe)))
77343:                     continue;
77343:                 bool nonDoubleTarget = false;
77343:                 const SlotValue *newv = a->analysis->newValues(target);
77343:                 while (newv && newv->slot) {
77343:                     if (newv->value.kind() == SSAValue::PHI &&
77343:                         newv->value.phiOffset() == uint32(target - a->script->code) &&
77343:                         newv->slot == entrySlot(fe)) {
77343:                         types::TypeSet *types = a->analysis->getValueTypes(newv->value);
77343:                         if (types->getKnownTypeTag(cx) != JSVAL_TYPE_DOUBLE)
77343:                             nonDoubleTarget = true;
77343:                     }
77343:                     newv++;
77343:                 }
77343:                 if (nonDoubleTarget)
77343:                     continue;
77343:             }
77343:             alloc->set(reg, fe - entries, fe->data.synced());
77343:         }
77343:     }
77343: 
77343: #ifdef DEBUG
77343:     if (IsJaegerSpewChannelActive(JSpew_Regalloc)) {
77530:         JaegerSpew(JSpew_Regalloc, "allocation at %u:", unsigned(target - a->script->code));
77343:         dumpAllocation(alloc);
77343:     }
77343: #endif
77343: 
77343:     return alloc;
77343: }
77343: 
77343: void
77343: FrameState::relocateReg(AnyRegisterID reg, RegisterAllocation *alloc, Uses uses)
77343: {
77343:     JS_ASSERT(cx->typeInferenceEnabled());
77343: 
77343:     /*
77343:      * The reg needs to be freed to make room for a variable carried across
77343:      * a branch. Either evict its entry, or try to move it to a different
77343:      * register if it is needed to test the branch condition. :XXX: could also
77343:      * watch for variables which are carried across the branch but are in a
77343:      * the register for a different carried entry, we just spill these for now.
77343:      */
77343:     JS_ASSERT(!freeRegs.hasReg(reg));
77343: 
77343:     for (unsigned i = 0; i < uses.nuses; i++) {
77343:         FrameEntry *fe = peek(-1 - i);
77343:         if (fe->isCopy())
77343:             fe = fe->copyOf();
77343:         if (reg.isReg() && fe->data.inRegister() && fe->data.reg() == reg.reg()) {
77343:             pinReg(reg);
77343:             RegisterID nreg = allocReg();
77343:             unpinReg(reg);
77343: 
77343:             JaegerSpew(JSpew_Regalloc, "relocating %s\n", reg.name());
77343: 
77343:             masm.move(reg.reg(), nreg);
77343:             regstate(reg).forget();
77343:             regstate(nreg).associate(fe, RematInfo::DATA);
77343:             fe->data.setRegister(nreg);
77343:             freeRegs.putReg(reg);
77343:             return;
77343:         }
77343:     }
77343: 
77343:     JaegerSpew(JSpew_Regalloc, "could not relocate %s\n", reg.name());
77343: 
77343:     takeReg(reg);
77343:     freeRegs.putReg(reg);
77343: }
77343: 
77343: bool
77343: FrameState::syncForBranch(jsbytecode *target, Uses uses)
77343: {
77343:     /* There should be no unowned or pinned registers. */
77343: #ifdef DEBUG
77343:     Registers checkRegs(Registers::AvailAnyRegs);
77343:     while (!checkRegs.empty()) {
77343:         AnyRegisterID reg = checkRegs.takeAnyReg();
77343:         JS_ASSERT_IF(!freeRegs.hasReg(reg), regstate(reg).fe());
77343:     }
77343: #endif
77343: 
77343:     if (!cx->typeInferenceEnabled()) {
77343:         syncAndForgetEverything();
77343:         return true;
77343:     }
77343: 
77343:     RegisterAllocation *&alloc = a->analysis->getAllocation(target);
77343:     if (!alloc) {
77343:         alloc = computeAllocation(target);
77343:         if (!alloc)
77343:             return false;
77343:     }
77343: 
77343:     syncForAllocation(alloc, false, uses);
77343: 
77343:     return true;
77343: }
77343: 
77343: void
77343: FrameState::syncForAllocation(RegisterAllocation *alloc, bool inlineReturn, Uses uses)
77343: {
77343:     /*
77343:      * First pass. Sync all entries which will not be carried in a register,
77343:      * and uncopy everything except values popped by the branch or before the
77343:      * call returns.
77343:      */
77343: 
77343:     FrameEntry *topEntry = NULL;
77343:     if (inlineReturn)
77343:         topEntry = a->parent->sp - (GET_ARGC(a->parent->PC) + 2);
77343: 
77343:     for (uint32 i = tracker.nentries - 1; i < tracker.nentries; i--) {
77343:         FrameEntry *fe = tracker[i];
77343: 
77343:         if (deadEntry(fe, uses.nuses))
77343:             continue;
77343:         if (inlineReturn && fe >= topEntry && !isTemporary(fe)) {
77343:             /*
77343:              * The return value has already been stored, so there is no need to
77343:              * keep any of the entries for this frame or for values popped once
77343:              * the call returns intact. Forcibly evict any registers for these,
77343:              * so that we don't emit sync code for them if we need a register
77343:              * in syncFe below.
77343:              */
77343:             forgetAllRegs(fe);
77343:             fe->resetSynced();
77343:             continue;
77343:         }
77343: 
77343:         /* Force syncs for locals which are dead at the current PC. */
78728:         if (isLocal(fe) && !fe->copied && !a->analysis->slotEscapes(entrySlot(fe))) {
77343:             Lifetime *lifetime = a->analysis->liveness(entrySlot(fe)).live(a->PC - a->script->code);
77343:             if (!lifetime)
77343:                 fakeSync(fe);
77343:         }
77343: 
77343:         /* If returning from a script, fake syncs for dead locals in the immediate parent. */
77343:         if (inlineReturn && fe >= a->parent->locals &&
77343:             fe - a->parent->locals < a->parent->script->nfixed &&
77343:             !a->parent->analysis->slotEscapes(frameSlot(a->parent, fe))) {
77343:             const LifetimeVariable &var = a->parent->analysis->liveness(frameSlot(a->parent, fe));
77343:             Lifetime *lifetime = var.live(a->parent->PC - a->parent->script->code);
77343:             if (!lifetime)
77343:                 fakeSync(fe);
77343:         }
77343: 
77343:         if (!fe->isCopy() && alloc->hasAnyReg(fe - entries)) {
77343:             /* Types are always synced, except for known doubles. */
77343:             if (!fe->isType(JSVAL_TYPE_DOUBLE))
77343:                 syncType(fe);
77343:         } else {
77343:             syncFe(fe);
77343:             if (fe->isCopy())
77343:                 fe->resetSynced();
77343:         }
77343:     }
77343: 
77343:     /*
77343:      * Second pass. Move entries carried in registers to the right register
77343:      * provided no value used in the branch is evicted. After this pass,
77343:      * everything will either be in the right register or will be in memory.
77343:      */
77343: 
77343:     Registers regs = Registers(Registers::AvailAnyRegs);
77343:     while (!regs.empty()) {
77343:         AnyRegisterID reg = regs.takeAnyReg();
77343:         if (!alloc->assigned(reg))
77343:             continue;
77343:         FrameEntry *fe = getOrTrack(alloc->index(reg));
77343:         JS_ASSERT(!fe->isCopy());
77343: 
77343:         JS_ASSERT_IF(!fe->isType(JSVAL_TYPE_DOUBLE), fe->type.synced());
77343:         if (!fe->data.synced() && alloc->synced(reg))
77343:             syncFe(fe);
77343: 
77343:         if (fe->dataInRegister(reg))
77343:             continue;
77343: 
77343:         if (!freeRegs.hasReg(reg))
77343:             relocateReg(reg, alloc, uses);
77343: 
77343:         if (reg.isReg()) {
77343:             RegisterID nreg = reg.reg();
77459:             if (fe->isType(JSVAL_TYPE_DOUBLE)) {
77459:                 JS_ASSERT(!a->analysis->trackSlot(entrySlot(fe)));
77459:                 syncFe(fe);
77459:                 forgetAllRegs(fe);
77459:                 fe->resetSynced();
77459:             }
77343:             if (fe->data.inMemory()) {
77343:                 masm.loadPayload(addressOf(fe), nreg);
77343:             } else if (fe->isConstant()) {
77343:                 masm.loadValuePayload(fe->getValue(), nreg);
77343:             } else {
77343:                 JS_ASSERT(fe->data.inRegister() && fe->data.reg() != nreg);
77343:                 masm.move(fe->data.reg(), nreg);
77343:                 freeRegs.putReg(fe->data.reg());
77343:                 regstate(fe->data.reg()).forget();
77343:             }
77343:             fe->data.setRegister(nreg);
77343:         } else {
77343:             FPRegisterID nreg = reg.fpreg();
77457:             JS_ASSERT(!fe->isNotType(JSVAL_TYPE_DOUBLE));
77457:             if (!fe->isTypeKnown())
77457:                 learnType(fe, JSVAL_TYPE_DOUBLE, false);
77343:             if (fe->data.inMemory()) {
77343:                 masm.loadDouble(addressOf(fe), nreg);
77343:             } else if (fe->isConstant()) {
77343:                 masm.slowLoadConstantDouble(fe->getValue().toDouble(), nreg);
77343:             } else {
77343:                 JS_ASSERT(fe->data.inFPRegister() && fe->data.fpreg() != nreg);
77343:                 masm.moveDouble(fe->data.fpreg(), nreg);
77343:                 freeRegs.putReg(fe->data.fpreg());
77343:                 regstate(fe->data.fpreg()).forget();
77343:             }
77343:             fe->data.setFPRegister(nreg);
77343:         }
77343: 
77343:         freeRegs.takeReg(reg);
77343:         regstate(reg).associate(fe, RematInfo::DATA);
77343:     }
77343: }
77343: 
77343: bool
77343: FrameState::discardForJoin(RegisterAllocation *&alloc, uint32 stackDepth)
77343: {
77343:     if (!cx->typeInferenceEnabled()) {
77343:         resetInternalState();
77343:         PodArrayZero(regstate_);
77343:         a->sp = a->spBase + stackDepth;
77343:         return true;
77343:     }
77343: 
77343:     if (!alloc) {
77343:         /*
77343:          * This shows up for loop entries which are not reachable from the
77343:          * loop head, and for exception, switch target and trap safe points.
77343:          */
77343:         alloc = ArenaNew<RegisterAllocation>(cx->compartment->pool, false);
77343:         if (!alloc)
77343:             return false;
77343:     }
77343: 
77343:     resetInternalState();
77343:     PodArrayZero(regstate_);
77343: 
77343:     Registers regs(Registers::AvailAnyRegs);
77343:     while (!regs.empty()) {
77343:         AnyRegisterID reg = regs.takeAnyReg();
77343:         if (!alloc->assigned(reg))
77343:             continue;
77343:         FrameEntry *fe = getOrTrack(alloc->index(reg));
77343: 
77343:         freeRegs.takeReg(reg);
77343: 
77343:         /*
77343:          * We can't look at the type of the fe as we haven't restored analysis types yet,
77343:          * but if this is an FP reg it will be set to double type.
77343:          */
77343:         if (reg.isReg()) {
77343:             fe->data.setRegister(reg.reg());
77343:         } else {
77343:             fe->setType(JSVAL_TYPE_DOUBLE);
77343:             fe->data.setFPRegister(reg.fpreg());
77343:         }
77343: 
77343:         regstate(reg).associate(fe, RematInfo::DATA);
77343:         if (!alloc->synced(reg))
77343:             fe->data.unsync();
77343:     }
77343: 
77343:     a->sp = a->spBase + stackDepth;
77343: 
77343:     for (unsigned i = 0; i < stackDepth; i++)
77343:         extraArray[a->spBase + i - entries].reset();
77343: 
77343:     return true;
77343: }
77343: 
77343: bool
77343: FrameState::consistentRegisters(jsbytecode *target)
77343: {
77343:     if (!cx->typeInferenceEnabled()) {
77343:         JS_ASSERT(freeRegs.freeMask == Registers::AvailAnyRegs);
77343:         return true;
77343:     }
77343: 
77343:     /*
77343:      * Before calling this, either the entire state should have been synced or
77343:      * syncForBranch should have been called. These will ensure that any FE
77343:      * which is not consistent with the target's register state has already
77343:      * been synced, and no stores will need to be issued by prepareForJump.
77343:      */
77343:     RegisterAllocation *alloc = a->analysis->getAllocation(target);
77343:     JS_ASSERT(alloc);
77343: 
77343:     Registers regs(Registers::AvailAnyRegs);
77343:     while (!regs.empty()) {
77343:         AnyRegisterID reg = regs.takeAnyReg();
77343:         if (alloc->assigned(reg)) {
77343:             FrameEntry *needed = getOrTrack(alloc->index(reg));
77343:             if (!freeRegs.hasReg(reg)) {
77343:                 FrameEntry *fe = regstate(reg).fe();
77343:                 if (fe != needed)
77343:                     return false;
77343:             } else {
77343:                 return false;
77343:             }
77343:         }
77343:     }
77343: 
77343:     return true;
77343: }
77343: 
77343: void
77343: FrameState::prepareForJump(jsbytecode *target, Assembler &masm, bool synced)
77343: {
77343:     if (!cx->typeInferenceEnabled())
77343:         return;
77343: 
77343:     JS_ASSERT_IF(!synced, !consistentRegisters(target));
77343: 
77343:     RegisterAllocation *alloc = a->analysis->getAllocation(target);
77343:     JS_ASSERT(alloc);
77343: 
77343:     Registers regs = 0;
77343: 
77343:     regs = Registers(Registers::AvailAnyRegs);
77343:     while (!regs.empty()) {
77343:         AnyRegisterID reg = regs.takeAnyReg();
77343:         if (!alloc->assigned(reg))
77343:             continue;
77343: 
77343:         const FrameEntry *fe = getOrTrack(alloc->index(reg));
77343:         if (synced || !fe->backing()->dataInRegister(reg)) {
77343:             JS_ASSERT_IF(!synced, fe->data.synced());
77343:             if (reg.isReg())
77343:                 masm.loadPayload(addressOf(fe), reg.reg());
77343:             else
77343:                 masm.loadDouble(addressOf(fe), reg.fpreg());
77343:         }
77343:     }
77343: }
77343: 
54719: void
52617: FrameState::storeTo(FrameEntry *fe, Address address, bool popped)
52608: {
52617:     if (fe->isConstant()) {
52617:         masm.storeValue(fe->getValue(), address);
52617:         return;
52617:     }
52611: 
52670:     if (fe->isCopy())
52705:         fe = fe->copyOf();
52670: 
52622:     JS_ASSERT(!freeRegs.hasReg(address.base));
52622: 
54582:     /* If loading from memory, ensure destination differs. */
54582:     JS_ASSERT_IF((fe->type.inMemory() || fe->data.inMemory()),
54582:                  addressOf(fe).base != address.base ||
54582:                  addressOf(fe).offset != address.offset);
54582: 
77343:     if (fe->data.inFPRegister()) {
77343:         masm.storeDouble(fe->data.fpreg(), address);
77343:         return;
77343:     }
77343: 
77343:     if (fe->isType(JSVAL_TYPE_DOUBLE)) {
77343:         JS_ASSERT(fe->data.inMemory());
77343:         masm.loadDouble(addressOf(fe), Registers::FPConversionTemp);
77343:         masm.storeDouble(Registers::FPConversionTemp, address);
77343:         return;
77343:     }
77343: 
77343:     /* Don't clobber the address's register. */
77343:     bool pinAddressReg = !!regstate(address.base).fe();
77343:     if (pinAddressReg)
77343:         pinReg(address.base);
77343: 
54582: #if defined JS_PUNBOX64
54582:     if (fe->type.inMemory() && fe->data.inMemory()) {
54582:         /* Future optimization: track that the Value is in a register. */
54582:         RegisterID vreg = Registers::ValueReg;
54582:         masm.loadPtr(addressOf(fe), vreg);
54582:         masm.storePtr(vreg, address);
77343:         if (pinAddressReg)
77343:             unpinReg(address.base);
54582:         return;
54582:     }
54582: 
77343:     JS_ASSERT(!fe->isType(JSVAL_TYPE_DOUBLE));
77343: 
54751:     /*
54751:      * If dreg is obtained via allocReg(), then calling
54751:      * pinReg() trips an assertion. But in all other cases,
54751:      * calling pinReg() is necessary in the fe->type.inMemory() path.
54751:      * Remember whether pinReg() can be safely called.
54751:      */
54751:     bool canPinDreg = true;
54751:     bool wasInRegister = fe->data.inRegister();
54751: 
54582:     /* Get a register for the payload. */
54582:     MaybeRegisterID dreg;
54582:     if (fe->data.inRegister()) {
54582:         dreg = fe->data.reg();
54582:     } else {
54582:         JS_ASSERT(fe->data.inMemory());
54751:         if (popped) {
54751:             dreg = allocReg();
77343:             masm.loadPayload(addressOf(fe), dreg.reg());
54751:             canPinDreg = false;
54751:         } else {
77343:             dreg = allocAndLoadReg(fe, false, RematInfo::DATA).reg();
54751:             fe->data.setRegister(dreg.reg());
54751:         }
54582:     }
54582:     
54582:     /* Store the Value. */
54582:     if (fe->type.inRegister()) {
54582:         masm.storeValueFromComponents(fe->type.reg(), dreg.reg(), address);
54582:     } else if (fe->isTypeKnown()) {
54582:         masm.storeValueFromComponents(ImmType(fe->getKnownType()), dreg.reg(), address);
54582:     } else {
54751:         JS_ASSERT(fe->type.inMemory());
54751:         if (canPinDreg)
54582:             pinReg(dreg.reg());
54751: 
77343:         RegisterID treg;
77343:         if (popped) {
77343:             treg = allocReg();
54582:             masm.loadTypeTag(addressOf(fe), treg);
77343:         } else {
77343:             treg = allocAndLoadReg(fe, false, RematInfo::TYPE).reg();
77343:         }
54582:         masm.storeValueFromComponents(treg, dreg.reg(), address);
54751: 
54582:         if (popped)
54582:             freeReg(treg);
54582:         else
54582:             fe->type.setRegister(treg);
54751: 
54751:         if (canPinDreg)
54582:             unpinReg(dreg.reg());
54582:     }
54582: 
54582:     /* If register is untracked, free it. */
54582:     if (!wasInRegister && popped)
54582:         freeReg(dreg.reg());
54582: 
54582: #elif defined JS_NUNBOX32
54582: 
52617:     if (fe->data.inRegister()) {
53144:         masm.storePayload(fe->data.reg(), address);
52617:     } else {
52670:         JS_ASSERT(fe->data.inMemory());
77343:         RegisterID reg;
77343:         if (popped) {
77343:             reg = allocReg();
53144:             masm.loadPayload(addressOf(fe), reg);
77343:         } else {
77343:             reg = allocAndLoadReg(fe, false, RematInfo::DATA).reg();
77343:         }
53144:         masm.storePayload(reg, address);
52617:         if (popped)
52617:             freeReg(reg);
52611:         else
52617:             fe->data.setRegister(reg);
52611:     }
52617: 
52617:     if (fe->isTypeKnown()) {
53144:         masm.storeTypeTag(ImmType(fe->getKnownType()), address);
52617:     } else if (fe->type.inRegister()) {
52623:         masm.storeTypeTag(fe->type.reg(), address);
52617:     } else {
52670:         JS_ASSERT(fe->type.inMemory());
77343:         RegisterID reg;
77343:         if (popped) {
77343:             reg = allocReg();
52617:             masm.loadTypeTag(addressOf(fe), reg);
77343:         } else {
77343:             reg = allocAndLoadReg(fe, false, RematInfo::TYPE).reg();
77343:         }
52623:         masm.storeTypeTag(reg, address);
52617:         if (popped)
52617:             freeReg(reg);
52617:         else
52617:             fe->type.setRegister(reg);
52617:     }
54582: #endif
77343:     if (pinAddressReg)
77343:         unpinReg(address.base);
52617: }
52617: 
57787: void
57787: FrameState::loadThisForReturn(RegisterID typeReg, RegisterID dataReg, RegisterID tempReg)
57787: {
57787:     return loadForReturn(getThis(), typeReg, dataReg, tempReg);
57787: }
57787: 
56572: void FrameState::loadForReturn(FrameEntry *fe, RegisterID typeReg, RegisterID dataReg, RegisterID tempReg)
54832: {
54832:     JS_ASSERT(dataReg != typeReg && dataReg != tempReg && typeReg != tempReg);
54832: 
54832:     if (fe->isConstant()) {
54832:         masm.loadValueAsComponents(fe->getValue(), typeReg, dataReg);
54832:         return;
54832:     }
54832: 
77343:     if (fe->isType(JSVAL_TYPE_DOUBLE)) {
77343:         FPRegisterID fpreg = tempFPRegForData(fe);
77343:         masm.breakDouble(fpreg, typeReg, dataReg);
77343:         return;
77343:     }
77343: 
54832:     if (fe->isCopy())
54832:         fe = fe->copyOf();
54832: 
56572:     MaybeRegisterID maybeType = maybePinType(fe);
56572:     MaybeRegisterID maybeData = maybePinData(fe);
56572: 
54832:     if (fe->isTypeKnown()) {
56572:         // If the data is in memory, or in the wrong reg, load/move it.
56572:         if (!maybeData.isSet())
56572:             masm.loadPayload(addressOf(fe), dataReg);
56572:         else if (maybeData.reg() != dataReg)
56572:             masm.move(maybeData.reg(), dataReg);
54832:         masm.move(ImmType(fe->getKnownType()), typeReg);
54832:         return;
54832:     }
54832: 
56572:     // If both halves of the value are in memory, make this easier and load
56572:     // both pieces into their respective registers.
55503:     if (fe->type.inMemory() && fe->data.inMemory()) {
55503:         masm.loadValueAsComponents(addressOf(fe), typeReg, dataReg);
55503:         return;
55503:     }
55503: 
56572:     // Now, we should be guaranteed that at least one part is in a register.
56572:     JS_ASSERT(maybeType.isSet() || maybeData.isSet());
56572: 
56572:     // Make sure we have two registers while making sure not clobber either half.
56572:     // Here we are allowed to mess up the FrameState invariants, because this
56572:     // is specialized code for a path that is about to discard the entire frame.
56572:     if (!maybeType.isSet()) {
56572:         JS_ASSERT(maybeData.isSet());
56572:         if (maybeData.reg() != typeReg)
56572:             maybeType = typeReg;
56572:         else
56572:             maybeType = tempReg;
56572:         masm.loadTypeTag(addressOf(fe), maybeType.reg());
56572:     } else if (!maybeData.isSet()) {
56572:         JS_ASSERT(maybeType.isSet());
56572:         if (maybeType.reg() != dataReg)
56572:             maybeData = dataReg;
56572:         else
56572:             maybeData = tempReg;
56572:         masm.loadPayload(addressOf(fe), maybeData.reg());
56572:     }
56572: 
56572:     RegisterID type = maybeType.reg();
56572:     RegisterID data = maybeData.reg();
56572: 
54832:     if (data == typeReg && type == dataReg) {
54832:         masm.move(type, tempReg);
54832:         masm.move(data, dataReg);
54832:         masm.move(tempReg, typeReg);
54832:     } else if (data != dataReg) {
54832:         if (type == typeReg) {
54832:             masm.move(data, dataReg);
54832:         } else if (type != dataReg) {
54832:             masm.move(data, dataReg);
54832:             if (type != typeReg)
54832:                 masm.move(type, typeReg);
54832:         } else {
54832:             JS_ASSERT(data != typeReg);
54832:             masm.move(type, typeReg);
54832:             masm.move(data, dataReg);
54832:         }
54832:     } else if (type != typeReg) {
54832:         masm.move(type, typeReg);
54832:     }
54832: }
54832: 
52618: #ifdef DEBUG
52608: void
52617: FrameState::assertValidRegisterState() const
52608: {
77343:     Registers checkedFreeRegs(Registers::AvailAnyRegs);
77343: 
77343:     /* Check that copied and copy info balance out. */
77343:     int32 copyCount = 0;
52617: 
52617:     for (uint32 i = 0; i < tracker.nentries; i++) {
52705:         FrameEntry *fe = tracker[i];
77343:         if (deadEntry(fe))
52617:             continue;
52617: 
52708:         JS_ASSERT(i == fe->trackerIndex());
77343: 
77343:         if (fe->isCopy()) {
77343:             JS_ASSERT_IF(!fe->copyOf()->temporary, fe > fe->copyOf());
77343:             JS_ASSERT(fe->trackerIndex() > fe->copyOf()->trackerIndex());
77343:             JS_ASSERT(!deadEntry(fe->copyOf()));
77343:             JS_ASSERT(fe->copyOf()->isCopied());
77343:             JS_ASSERT(!fe->isCopied());
77343:             copyCount--;
52670:             continue;
77343:         }
77343: 
77343:         copyCount += fe->copied;
77343: 
52617:         if (fe->type.inRegister()) {
52617:             checkedFreeRegs.takeReg(fe->type.reg());
77343:             JS_ASSERT(regstate(fe->type.reg()).fe() == fe);
77343:             JS_ASSERT(!fe->isType(JSVAL_TYPE_DOUBLE));
52617:         }
52617:         if (fe->data.inRegister()) {
52617:             checkedFreeRegs.takeReg(fe->data.reg());
77343:             JS_ASSERT(regstate(fe->data.reg()).fe() == fe);
77343:             JS_ASSERT(!fe->isType(JSVAL_TYPE_DOUBLE));
52617:         }
77343:         if (fe->data.inFPRegister()) {
77343:             JS_ASSERT(fe->isType(JSVAL_TYPE_DOUBLE));
77343:             checkedFreeRegs.takeReg(fe->data.fpreg());
77343:             JS_ASSERT(regstate(fe->data.fpreg()).fe() == fe);
57787:         }
77343:     }
77343: 
77343:     JS_ASSERT(copyCount == 0);
52617:     JS_ASSERT(checkedFreeRegs == freeRegs);
54719: 
77343:     for (uint32 i = 0; i < Registers::TotalRegisters; i++) {
77343:         AnyRegisterID reg = (RegisterID) i;
77343:         JS_ASSERT(!regstate(reg).isPinned());
77343:         JS_ASSERT_IF(regstate(reg).fe(), !freeRegs.hasReg(reg));
77343:         JS_ASSERT_IF(regstate(reg).fe(), regstate(reg).fe()->isTracked());
77343:     }
77343: 
77343:     for (uint32 i = 0; i < Registers::TotalFPRegisters; i++) {
77343:         AnyRegisterID reg = (FPRegisterID) i;
77343:         JS_ASSERT(!regstate(reg).isPinned());
77343:         JS_ASSERT_IF(regstate(reg).fe(), !freeRegs.hasReg(reg));
77343:         JS_ASSERT_IF(regstate(reg).fe(), regstate(reg).fe()->isTracked());
77343:         JS_ASSERT_IF(regstate(reg).fe(), regstate(reg).type() == RematInfo::DATA);
54719:     }
52618: }
52617: #endif
52611: 
56005: #if defined JS_NUNBOX32
52791: void
54719: FrameState::syncFancy(Assembler &masm, Registers avail, FrameEntry *resumeAt,
53113:                       FrameEntry *bottom) const
52791: {
54719:     reifier.reset(&masm, avail, resumeAt, bottom);
52791: 
54719:     for (FrameEntry *fe = resumeAt; fe >= bottom; fe--) {
54719:         if (!fe->isTracked())
52791:             continue;
52791: 
52839:         reifier.sync(fe);
52791:     }
52791: }
77343: 
76206: #endif
52608: void
53088: FrameState::sync(Assembler &masm, Uses uses) const
52619: {
54719:     if (!entries)
54719:         return;
54719: 
54719:     /* Sync all registers up-front. */
77343:     Registers allRegs(Registers::AvailAnyRegs);
56004:     while (!allRegs.empty()) {
77343:         AnyRegisterID reg = allRegs.takeAnyReg();
77343:         FrameEntry *fe = regstate(reg).usedBy();
54719:         if (!fe)
54719:             continue;
54719: 
54719:         JS_ASSERT(fe->isTracked());
54719: 
56004: #if defined JS_PUNBOX64
56004:         /* Sync entire FE to prevent loads. */
56004:         ensureFeSynced(fe, masm);
56004: 
56004:         /* Take the other register in the pair, if one exists. */
77343:         if (regstate(reg).type() == RematInfo::DATA && fe->type.inRegister())
56004:             allRegs.takeReg(fe->type.reg());
77343:         else if (regstate(reg).type() == RematInfo::TYPE && fe->data.inRegister())
56004:             allRegs.takeReg(fe->data.reg());
56004: #elif defined JS_NUNBOX32
56004:         /* Sync register if unsynced. */
77343:         if (fe->isType(JSVAL_TYPE_DOUBLE)) {
77343:             ensureFeSynced(fe, masm);
77343:         } else if (regstate(reg).type() == RematInfo::DATA) {
77343:             JS_ASSERT(fe->data.reg() == reg.reg());
56004:             ensureDataSynced(fe, masm);
54719:         } else {
77343:             JS_ASSERT(fe->type.reg() == reg.reg());
56004:             ensureTypeSynced(fe, masm);
54719:         }
56004: #endif
54719:     }
54719: 
52791:     /*
52791:      * Keep track of free registers using a bitmask. If we have to drop into
52791:      * syncFancy(), then this mask will help avoid eviction.
52791:      */
77343:     Registers avail(freeRegs.freeMask & Registers::AvailRegs);
77343:     Registers temp(Registers::TempAnyRegs);
77343: 
78413:     FrameEntry *bottom = (cx->typeInferenceEnabled() || cx->compartment->debugMode())
78413:         ? entries
78413:         : a->sp - uses.nuses;
78413: 
78413:     for (FrameEntry *fe = a->sp - 1; fe >= bottom; fe--) {
54719:         if (!fe->isTracked())
52619:             continue;
52619: 
77343:         if (fe->isType(JSVAL_TYPE_DOUBLE)) {
77343:             /* Copies of in-memory doubles can be synced without spilling. */
77343:             if (fe->isCopy() || !fe->data.inFPRegister())
77343:                 ensureFeSynced(fe, masm);
77343:             continue;
77343:         }
77343: 
56004:         FrameEntry *backing = fe;
52670: 
52670:         if (!fe->isCopy()) {
55514:             if (fe->data.inRegister())
52670:                 avail.putReg(fe->data.reg());
54719:             if (fe->type.inRegister())
54719:                 avail.putReg(fe->type.reg());
54719:         } else {
56004:             backing = fe->copyOf();
52670:             JS_ASSERT(!backing->isConstant() && !fe->isConstant());
52670: 
56005: #if defined JS_PUNBOX64
56005:             if ((!fe->type.synced() && backing->type.inMemory()) ||
56005:                 (!fe->data.synced() && backing->data.inMemory())) {
56005:     
56005:                 RegisterID syncReg = Registers::ValueReg;
56005: 
56005:                 /* Load the entire Value into syncReg. */
56005:                 if (backing->type.synced() && backing->data.synced()) {
56005:                     masm.loadValue(addressOf(backing), syncReg);
56005:                 } else if (backing->type.inMemory()) {
56005:                     masm.loadTypeTag(addressOf(backing), syncReg);
56005:                     masm.orPtr(backing->data.reg(), syncReg);
56005:                 } else {
56005:                     JS_ASSERT(backing->data.inMemory());
56005:                     masm.loadPayload(addressOf(backing), syncReg);
56005:                     if (backing->isTypeKnown())
56005:                         masm.orPtr(ImmType(backing->getKnownType()), syncReg);
56005:                     else
56005:                         masm.orPtr(backing->type.reg(), syncReg);
56005:                 }
56005: 
56005:                 masm.storeValue(syncReg, addressOf(fe));
56005:                 continue;
56005:             }
56005: #elif defined JS_NUNBOX32
56004:             /* Fall back to a slower sync algorithm if load required. */
56004:             if ((!fe->type.synced() && backing->type.inMemory()) ||
56004:                 (!fe->data.synced() && backing->data.inMemory())) {
78413:                 syncFancy(masm, avail, fe, bottom);
52791:                 return;
52670:             }
56005: #endif
52670:         }
52670: 
77343:         bool copy = fe->isCopy();
77343: 
56004:         /* If a part still needs syncing, it is either a copy or constant. */
56004: #if defined JS_PUNBOX64
56004:         /* All register-backed FEs have been entirely synced up-front. */
77343:         if (copy || (!fe->type.inRegister() && !fe->data.inRegister()))
56004:             ensureFeSynced(fe, masm);
56004: #elif defined JS_NUNBOX32
56004:         /* All components held in registers have been already synced. */
77343:         if (copy || !fe->data.inRegister())
56004:             ensureDataSynced(fe, masm);
77343:         if (copy || !fe->type.inRegister())
56004:             ensureTypeSynced(fe, masm);
56004: #endif
52619:     }
52619: }
52619: 
52619: void
54160: FrameState::syncAndKill(Registers kill, Uses uses, Uses ignore)
52878: {
77343:     if (loop) {
77343:         /*
77343:          * Drop any remaining loop registers so we don't do any more after-the-fact
77343:          * allocation of the initial register state.
77343:          */
77343:         loop->clearLoopRegisters();
77343:     }
53087: 
54719:     /* Sync all kill-registers up-front. */
54719:     Registers search(kill.freeMask & ~freeRegs.freeMask);
54719:     while (!search.empty()) {
77343:         AnyRegisterID reg = search.takeAnyReg();
77343:         FrameEntry *fe = regstate(reg).usedBy();
77343:         if (!fe || deadEntry(fe, ignore.nuses))
54719:             continue;
54160: 
54719:         JS_ASSERT(fe->isTracked());
53113: 
56004: #if defined JS_PUNBOX64
56004:         /* Don't use syncFe(), since that may clobber more registers. */
56004:         ensureFeSynced(fe, masm);
56004: 
56004:         if (!fe->type.synced())
56004:             fe->type.sync();
56004:         if (!fe->data.synced())
56004:             fe->data.sync();
56004: 
56004:         /* Take the other register in the pair, if one exists. */
77343:         if (regstate(reg).type() == RematInfo::DATA) {
77343:             if (!fe->isType(JSVAL_TYPE_DOUBLE)) {
77343:                 JS_ASSERT(fe->data.reg() == reg.reg());
56004:                 if (fe->type.inRegister() && search.hasReg(fe->type.reg()))
56004:                     search.takeReg(fe->type.reg());
77343:             }
54719:         } else {
77343:             JS_ASSERT(fe->type.reg() == reg.reg());
56004:             if (fe->data.inRegister() && search.hasReg(fe->data.reg()))
56004:                 search.takeReg(fe->data.reg());
54719:         }
56004: #elif defined JS_NUNBOX32
56004:         /* Sync this register. */
77343:         if (fe->isType(JSVAL_TYPE_DOUBLE)) {
77343:             syncFe(fe);
77343:         } else if (regstate(reg).type() == RematInfo::DATA) {
77343:             JS_ASSERT(fe->data.reg() == reg.reg());
56004:             syncData(fe);
56004:         } else {
77343:             JS_ASSERT(fe->type.reg() == reg.reg());
56004:             syncType(fe);
54719:         }
56004: #endif
54719:     }
54719: 
54719:     uint32 maxvisits = tracker.nentries;
77466: 
78413:     FrameEntry *bottom = (cx->typeInferenceEnabled() || cx->compartment->debugMode())
78413:         ? entries
78413:         : a->sp - uses.nuses;
78413: 
78413:     for (FrameEntry *fe = a->sp - 1; fe >= bottom && maxvisits; fe--) {
54719:         if (!fe->isTracked())
54719:             continue;
54719: 
54719:         maxvisits--;
54719: 
77343:         if (deadEntry(fe, ignore.nuses))
52608:             continue;
52611: 
56004:         syncFe(fe);
54719: 
77343:         if (fe->isCopy())
77343:             continue;
77343: 
56004:         /* Forget registers. */
77343:         if (fe->data.inRegister() && !regstate(fe->data.reg()).isPinned()) {
52617:             forgetReg(fe->data.reg());
52617:             fe->data.setMemory();
52617:         }
77343:         if (fe->data.inFPRegister() && !regstate(fe->data.fpreg()).isPinned()) {
77343:             forgetReg(fe->data.fpreg());
77343:             fe->data.setMemory();
77343:         }
77343:         if (fe->type.inRegister() && !regstate(fe->type.reg()).isPinned()) {
52617:             forgetReg(fe->type.reg());
52617:             fe->type.setMemory();
52611:         }
52611:     }
52608: 
54719:     /*
54719:      * Anything still alive at this point is guaranteed to be synced. However,
54719:      * it is necessary to evict temporary registers.
54719:      */
54719:     search = Registers(kill.freeMask & ~freeRegs.freeMask);
54719:     while (!search.empty()) {
77343:         AnyRegisterID reg = search.takeAnyReg();
77343:         FrameEntry *fe = regstate(reg).usedBy();
77343:         if (!fe || deadEntry(fe, ignore.nuses))
54719:             continue;
54719: 
77343:         JS_ASSERT(fe->isTracked() && !fe->isType(JSVAL_TYPE_DOUBLE));
77343: 
77343:         if (regstate(reg).type() == RematInfo::DATA) {
77343:             JS_ASSERT(fe->data.reg() == reg.reg());
54719:             JS_ASSERT(fe->data.synced());
54719:             fe->data.setMemory();
54719:         } else {
77343:             JS_ASSERT(fe->type.reg() == reg.reg());
54719:             JS_ASSERT(fe->type.synced());
54719:             fe->type.setMemory();
54719:         }
54719: 
54719:         forgetReg(reg);
54719:     }
53087: }
53087: 
53087: void
53088: FrameState::merge(Assembler &masm, Changes changes) const
52620: {
77343:     /*
77343:      * Note: this should only be called by StubCompiler::rejoin, which will notify
77343:      * this FrameState about the jump to patch up in case a new loop register is
77343:      * allocated later.
77343:      */
77343: 
77343:     /*
77343:      * For any changed values we are merging back which we consider to be doubles,
77343:      * ensure they actually are doubles.  They must be doubles or ints, but we
77343:      * do not require stub paths to always generate a double when needed.
77343:      * :FIXME: we check this on OOL stub calls, but not inline stub calls.
77343:      */
77343:     for (unsigned i = 0; i < changes.nchanges; i++) {
77343:         FrameEntry *fe = a->sp - 1 - i;
77343:         if (fe->isTracked() && fe->isType(JSVAL_TYPE_DOUBLE))
77343:             masm.ensureInMemoryDouble(addressOf(fe));
77343:     }
77343: 
77343:     uint32 mask = Registers::AvailAnyRegs & ~freeRegs.freeMask;
77343:     Registers search(mask);
77343: 
77343:     while (!search.empty(mask)) {
77343:         AnyRegisterID reg = search.peekReg(mask);
77343:         FrameEntry *fe = regstate(reg).usedBy();
52620: 
54719:         if (!fe) {
54719:             search.takeReg(reg);
52673:             continue;
52673:         }
52670: 
77343:         if (fe->isType(JSVAL_TYPE_DOUBLE)) {
77343:             JS_ASSERT(fe->data.fpreg() == reg.fpreg());
77343:             search.takeReg(fe->data.fpreg());
77343:             masm.loadDouble(addressOf(fe), fe->data.fpreg());
77343:         } else if (fe->data.inRegister() && fe->type.inRegister()) {
54719:             search.takeReg(fe->data.reg());
54719:             search.takeReg(fe->type.reg());
53386:             masm.loadValueAsComponents(addressOf(fe), fe->type.reg(), fe->data.reg());
54719:         } else {
54719:             if (fe->data.inRegister()) {
54719:                 search.takeReg(fe->data.reg());
53144:                 masm.loadPayload(addressOf(fe), fe->data.reg());
54719:             }
54719:             if (fe->type.inRegister()) {
54719:                 search.takeReg(fe->type.reg());
52620:                 masm.loadTypeTag(addressOf(fe), fe->type.reg());
52620:             }
52620:         }
54719:     }
54719: }
52620: 
52623: JSC::MacroAssembler::RegisterID
52846: FrameState::copyDataIntoReg(FrameEntry *fe)
52623: {
52962:     return copyDataIntoReg(this->masm, fe);
52962: }
52962: 
53156: void
53156: FrameState::copyDataIntoReg(FrameEntry *fe, RegisterID hint)
53156: {
77343:     JS_ASSERT(!fe->isConstant());
77343:     JS_ASSERT(!fe->isType(JSVAL_TYPE_DOUBLE));
53156: 
53156:     if (fe->isCopy())
53156:         fe = fe->copyOf();
53156: 
53156:     if (!fe->data.inRegister())
53156:         tempRegForData(fe);
53156: 
53156:     RegisterID reg = fe->data.reg();
53156:     if (reg == hint) {
77343:         if (freeRegs.empty(Registers::AvailRegs)) {
56004:             ensureDataSynced(fe, masm);
53156:             fe->data.setMemory();
53156:         } else {
53156:             reg = allocReg();
53156:             masm.move(hint, reg);
53156:             fe->data.setRegister(reg);
77343:             regstate(reg).associate(regstate(hint).fe(), RematInfo::DATA);
53156:         }
77343:         regstate(hint).forget();
53156:     } else {
53156:         pinReg(reg);
53156:         takeReg(hint);
53156:         unpinReg(reg);
53156:         masm.move(reg, hint);
53156:     }
77343: 
77343:     modifyReg(hint);
53156: }
53156: 
52962: JSC::MacroAssembler::RegisterID
52962: FrameState::copyDataIntoReg(Assembler &masm, FrameEntry *fe)
52962: {
77343:     JS_ASSERT(!fe->isConstant());
52822: 
52822:     if (fe->isCopy())
52822:         fe = fe->copyOf();
52623: 
52623:     if (fe->data.inRegister()) {
52623:         RegisterID reg = fe->data.reg();
77343:         if (freeRegs.empty(Registers::AvailRegs)) {
56004:             ensureDataSynced(fe, masm);
52623:             fe->data.setMemory();
77343:             regstate(reg).forget();
77343:             modifyReg(reg);
52623:         } else {
52827:             RegisterID newReg = allocReg();
52623:             masm.move(reg, newReg);
52623:             reg = newReg;
52623:         }
52623:         return reg;
52623:     }
52623: 
52827:     RegisterID reg = allocReg();
52623: 
77343:     if (!freeRegs.empty(Registers::AvailRegs))
52623:         masm.move(tempRegForData(fe), reg);
52623:     else
53144:         masm.loadPayload(addressOf(fe),reg);
52623: 
52623:     return reg;
52623: }
52623: 
52623: JSC::MacroAssembler::RegisterID
52906: FrameState::copyTypeIntoReg(FrameEntry *fe)
52906: {
52906:     if (fe->isCopy())
52906:         fe = fe->copyOf();
52906: 
77343:     JS_ASSERT(!fe->type.isConstant());
77343: 
52906:     if (fe->type.inRegister()) {
52906:         RegisterID reg = fe->type.reg();
77343:         if (freeRegs.empty(Registers::AvailRegs)) {
56004:             ensureTypeSynced(fe, masm);
52906:             fe->type.setMemory();
77343:             regstate(reg).forget();
77343:             modifyReg(reg);
52906:         } else {
52906:             RegisterID newReg = allocReg();
52906:             masm.move(reg, newReg);
52906:             reg = newReg;
52906:         }
52906:         return reg;
52906:     }
52906: 
52906:     RegisterID reg = allocReg();
52906: 
77343:     if (!freeRegs.empty(Registers::AvailRegs))
52906:         masm.move(tempRegForType(fe), reg);
52906:     else
52906:         masm.loadTypeTag(addressOf(fe), reg);
52906: 
52906:     return reg;
52906: }
52906: 
53031: JSC::MacroAssembler::RegisterID
53032: FrameState::copyInt32ConstantIntoReg(FrameEntry *fe)
53031: {
53032:     return copyInt32ConstantIntoReg(masm, fe);
53031: }
53031: 
53031: JSC::MacroAssembler::RegisterID
53032: FrameState::copyInt32ConstantIntoReg(Assembler &masm, FrameEntry *fe)
53031: {
53031:     JS_ASSERT(fe->data.isConstant());
53031: 
53031:     if (fe->isCopy())
53031:         fe = fe->copyOf();
53031: 
53031:     RegisterID reg = allocReg();
53081:     masm.move(Imm32(fe->getValue().toInt32()), reg);
53031:     return reg;
53031: }
53031: 
52906: JSC::MacroAssembler::RegisterID
52831: FrameState::ownRegForType(FrameEntry *fe)
52831: {
77343:     JS_ASSERT(!fe->isTypeKnown());
52831: 
52831:     RegisterID reg;
52831:     if (fe->isCopy()) {
52831:         /* For now, just do an extra move. The reg must be mutable. */
52831:         FrameEntry *backing = fe->copyOf();
52831:         if (!backing->type.inRegister()) {
52831:             JS_ASSERT(backing->type.inMemory());
52831:             tempRegForType(backing);
52831:         }
52831: 
77343:         if (freeRegs.empty(Registers::AvailRegs)) {
52831:             /* For now... just steal the register that already exists. */
56004:             ensureTypeSynced(backing, masm);
52831:             reg = backing->type.reg();
52831:             backing->type.setMemory();
77343:             regstate(reg).forget();
77343:             modifyReg(reg);
52831:         } else {
52835:             reg = allocReg();
52831:             masm.move(backing->type.reg(), reg);
52831:         }
52831:         return reg;
52831:     }
52831: 
52831:     if (fe->type.inRegister()) {
52831:         reg = fe->type.reg();
54719: 
52831:         /* Remove ownership of this register. */
77343:         JS_ASSERT(regstate(reg).fe() == fe);
77343:         JS_ASSERT(regstate(reg).type() == RematInfo::TYPE);
77343:         regstate(reg).forget();
77343:         fe->type.setMemory();
77343:         modifyReg(reg);
52831:     } else {
52831:         JS_ASSERT(fe->type.inMemory());
52835:         reg = allocReg();
52831:         masm.loadTypeTag(addressOf(fe), reg);
52831:     }
52831:     return reg;
52831: }
52831: 
52831: JSC::MacroAssembler::RegisterID
52623: FrameState::ownRegForData(FrameEntry *fe)
52623: {
77343:     JS_ASSERT(!fe->isConstant());
77343:     JS_ASSERT(!fe->isType(JSVAL_TYPE_DOUBLE));
52623: 
52670:     RegisterID reg;
52670:     if (fe->isCopy()) {
52670:         /* For now, just do an extra move. The reg must be mutable. */
52705:         FrameEntry *backing = fe->copyOf();
52670:         if (!backing->data.inRegister()) {
52670:             JS_ASSERT(backing->data.inMemory());
52670:             tempRegForData(backing);
52670:         }
52623: 
77343:         if (freeRegs.empty(Registers::AvailRegs)) {
52670:             /* For now... just steal the register that already exists. */
56004:             ensureDataSynced(backing, masm);
52670:             reg = backing->data.reg();
52670:             backing->data.setMemory();
77343:             regstate(reg).forget();
77343:             modifyReg(reg);
52670:         } else {
52827:             reg = allocReg();
52670:             masm.move(backing->data.reg(), reg);
52670:         }
52808:         return reg;
52808:     }
52808: 
77343:     if (fe->isCopied())
77343:         uncopy(fe);
52808: 
52808:     if (fe->data.inRegister()) {
52670:         reg = fe->data.reg();
52623:         /* Remove ownership of this register. */
77343:         JS_ASSERT(regstate(reg).fe() == fe);
77343:         JS_ASSERT(regstate(reg).type() == RematInfo::DATA);
77343:         regstate(reg).forget();
77343:         fe->data.setMemory();
77343:         modifyReg(reg);
52670:     } else {
52670:         JS_ASSERT(fe->data.inMemory());
52827:         reg = allocReg();
53144:         masm.loadPayload(addressOf(fe), reg);
52670:     }
52623:     return reg;
52623: }
52623: 
52670: void
55503: FrameState::discardFe(FrameEntry *fe)
55503: {
55503:     forgetEntry(fe);
55503:     fe->type.setMemory();
55503:     fe->data.setMemory();
77343:     fe->clear();
55503: }
55503: 
55503: void
77343: FrameState::pushDouble(FPRegisterID fpreg)
52670: {
77343:     FrameEntry *fe = rawPush();
77343:     fe->resetUnsynced();
77343:     fe->setType(JSVAL_TYPE_DOUBLE);
77343:     fe->data.setFPRegister(fpreg);
77343:     regstate(fpreg).associate(fe, RematInfo::DATA);
77343: }
77343: 
77343: void
77343: FrameState::pushDouble(Address address)
77343: {
77343:     FPRegisterID fpreg = allocFPReg();
77343:     masm.loadDouble(address, fpreg);
77343:     pushDouble(fpreg);
77343: }
77343: 
77343: void
77343: FrameState::ensureDouble(FrameEntry *fe)
77343: {
77343:     if (fe->isType(JSVAL_TYPE_DOUBLE))
77343:         return;
77343: 
77343:     if (fe->isConstant()) {
77343:         JS_ASSERT(fe->getValue().isInt32());
77343:         Value newValue = DoubleValue(double(fe->getValue().toInt32()));
78614:         fe->setConstant(newValue);
77343:         return;
77343:     }
77343: 
77343:     FrameEntry *backing = fe;
77343:     if (fe->isCopy()) {
77343:         /* Forget this entry is a copy.  We are converting this entry, not the backing. */
77343:         backing = fe->copyOf();
77343:         fe->clear();
77343:     } else if (fe->isCopied()) {
77343:         /* Sync and forget any copies of this entry. */
77343:         for (uint32 i = fe->trackerIndex() + 1; i < tracker.nentries; i++) {
77343:             FrameEntry *nfe = tracker[i];
77343:             if (!deadEntry(nfe) && nfe->isCopy() && nfe->copyOf() == fe) {
77343:                 syncFe(nfe);
77343:                 nfe->resetSynced();
77343:             }
77343:         }
77343:     }
77343: 
77343:     FPRegisterID fpreg = allocFPReg();
77343: 
77343:     if (backing->isType(JSVAL_TYPE_INT32)) {
77343:         RegisterID data = tempRegForData(backing);
77343:         masm.convertInt32ToDouble(data, fpreg);
77343:     } else {
77343:         syncFe(backing);
77343:         masm.moveInt32OrDouble(addressOf(backing), fpreg);
77343:     }
77343: 
77343:     if (fe == backing)
77343:         forgetAllRegs(fe);
77343:     fe->resetUnsynced();
77343:     fe->setType(JSVAL_TYPE_DOUBLE);
77343:     fe->data.setFPRegister(fpreg);
77343:     regstate(fpreg).associate(fe, RematInfo::DATA);
77343: 
77343:     fe->data.unsync();
77343:     fe->type.unsync();
77343: }
77343: 
77343: void
77343: FrameState::ensureInteger(FrameEntry *fe)
77343: {
77343:     /*
77343:      * This method is used to revert a previous ensureDouble call made for a
77343:      * branch. The entry is definitely a double, and has had no copies made.
77343:      */
77343: 
77343:     if (fe->isConstant()) {
77343:         Value newValue = Int32Value(int32(fe->getValue().toDouble()));
78614:         fe->setConstant(newValue);
77343:         return;
77343:     }
77343: 
77343:     JS_ASSERT(!fe->isCopy() && !fe->isCopied());
77343:     JS_ASSERT_IF(fe->isTypeKnown(), fe->isType(JSVAL_TYPE_DOUBLE));
77343: 
77343:     if (!fe->isType(JSVAL_TYPE_DOUBLE)) {
77343:         /*
77343:          * A normal register may have been allocated after calling
77343:          * syncAndForgetEverything.
77343:          */
77343:         if (fe->data.inRegister()) {
77343:             syncFe(fe);
77343:             forgetReg(fe->data.reg());
77343:             fe->data.setMemory();
77343:         }
77343:         learnType(fe, JSVAL_TYPE_DOUBLE, false);
77343:     }
77343: 
77343:     RegisterID reg = allocReg();
77343:     FPRegisterID fpreg = tempFPRegForData(fe);
77343:     Jump j = masm.branchTruncateDoubleToInt32(fpreg, reg);
77343:     j.linkTo(masm.label(), &masm);
77343: 
77343:     forgetAllRegs(fe);
77343:     fe->resetUnsynced();
77343:     fe->setType(JSVAL_TYPE_INT32);
77343:     fe->data.setRegister(reg);
77343:     regstate(reg).associate(fe, RematInfo::DATA);
77343: 
77343:     fe->data.unsync();
77343:     fe->type.unsync();
77343: }
77343: 
77343: void
77343: FrameState::ensureInMemoryDoubles(Assembler &masm)
77343: {
77343:     JS_ASSERT(!a->parent);
77343:     for (uint32 i = 0; i < tracker.nentries; i++) {
77343:         FrameEntry *fe = tracker[i];
77343:         if (!deadEntry(fe) && fe->isType(JSVAL_TYPE_DOUBLE) &&
77343:             !fe->isCopy() && !fe->isConstant()) {
77343:             masm.ensureInMemoryDouble(addressOf(fe));
77343:         }
77343:     }
77343: }
77343: 
77343: void
77343: FrameState::pushCopyOf(FrameEntry *backing)
77343: {
77343:     JS_ASSERT(backing->isTracked());
52670:     FrameEntry *fe = rawPush();
52670:     fe->resetUnsynced();
52714:     if (backing->isConstant()) {
78614:         fe->setConstant(backing->getValue());
52670:     } else {
77343:         if (backing->isCopy())
52714:             backing = backing->copyOf();
52714:         fe->setCopyOf(backing);
52708: 
52708:         /* Maintain tracker ordering guarantees for copies. */
52714:         JS_ASSERT(backing->isCopied());
52714:         if (fe->trackerIndex() < backing->trackerIndex())
52714:             swapInTracker(fe, backing);
52670:     }
52691: }
52623: 
53243: FrameEntry *
54719: FrameState::walkTrackerForUncopy(FrameEntry *original)
52670: {
52691:     uint32 firstCopy = InvalidIndex;
53272:     FrameEntry *bestFe = NULL;
53272:     uint32 ncopies = 0;
54719:     for (uint32 i = original->trackerIndex() + 1; i < tracker.nentries; i++) {
52705:         FrameEntry *fe = tracker[i];
77343:         if (deadEntry(fe))
52691:             continue;
52705:         if (fe->isCopy() && fe->copyOf() == original) {
53272:             if (firstCopy == InvalidIndex) {
52691:                 firstCopy = i;
53272:                 bestFe = fe;
53272:             } else if (fe < bestFe) {
53272:                 bestFe = fe;
53272:             }
53272:             ncopies++;
52691:         }
52691:     }
52691: 
53272:     if (!ncopies) {
53272:         JS_ASSERT(firstCopy == InvalidIndex);
53272:         JS_ASSERT(!bestFe);
53243:         return NULL;
52691:     }
52691: 
53272:     JS_ASSERT(firstCopy != InvalidIndex);
53272:     JS_ASSERT(bestFe);
77896:     JS_ASSERT_IF(!isTemporary(original), bestFe > original);
53272: 
52691:     /* Mark all extra copies as copies of the new backing index. */
53272:     bestFe->setCopyOf(NULL);
53272:     if (ncopies > 1) {
53272:         for (uint32 i = firstCopy; i < tracker.nentries; i++) {
52705:             FrameEntry *other = tracker[i];
77343:             if (deadEntry(other) || other == bestFe)
52691:                 continue;
52691: 
52691:             /* The original must be tracked before copies. */
52691:             JS_ASSERT(other != original);
52691: 
52705:             if (!other->isCopy() || other->copyOf() != original)
52691:                 continue;
52691: 
53272:             other->setCopyOf(bestFe);
53272: 
53272:             /*
53272:              * This is safe even though we're mutating during iteration. There
53272:              * are two cases. The first is that both indexes are <= i, and :.
53272:              * will never be observed. The other case is we're placing the
53272:              * other FE such that it will be observed later. Luckily, copyOf()
53272:              * will return != original, so nothing will happen.
53272:              */
53272:             if (other->trackerIndex() < bestFe->trackerIndex())
53272:                 swapInTracker(bestFe, other);
52691:         }
53272:     }
53272: 
54719:     return bestFe;
54719: }
54719: 
54719: FrameEntry *
54719: FrameState::walkFrameForUncopy(FrameEntry *original)
54719: {
54719:     FrameEntry *bestFe = NULL;
54719:     uint32 ncopies = 0;
54719: 
54719:     /* It's only necessary to visit as many FEs are being tracked. */
54719:     uint32 maxvisits = tracker.nentries;
54719: 
77343:     for (FrameEntry *fe = original + 1; fe < a->sp && maxvisits; fe++) {
54719:         if (!fe->isTracked())
54719:             continue;
54719: 
54719:         maxvisits--;
54719: 
54719:         if (fe->isCopy() && fe->copyOf() == original) {
54719:             if (!bestFe) {
54719:                 bestFe = fe;
54719:                 bestFe->setCopyOf(NULL);
54719:             } else {
54719:                 fe->setCopyOf(bestFe);
54719:                 if (fe->trackerIndex() < bestFe->trackerIndex())
54719:                     swapInTracker(bestFe, fe);
54719:             }
54719:             ncopies++;
54719:         }
54719:     }
54719: 
54719:     return bestFe;
54719: }
54719: 
54719: FrameEntry *
54719: FrameState::uncopy(FrameEntry *original)
54719: {
54719:     JS_ASSERT(original->isCopied());
54719: 
54719:     /*
54719:      * Copies have three critical invariants:
54719:      *  1) The backing store precedes all copies in the tracker.
54719:      *  2) The backing store precedes all copies in the FrameState.
54719:      *  3) The backing store of a copy cannot be popped from the stack
54719:      *     while the copy is still live.
54719:      *
54719:      * Maintaining this invariant iteratively is kind of hard, so we choose
54719:      * the "lowest" copy in the frame up-front.
54719:      *
54719:      * For example, if the stack is:
54719:      *    [A, B, C, D]
54719:      * And the tracker has:
54719:      *    [A, D, C, B]
54719:      *
54719:      * If B, C, and D are copies of A - we will walk the tracker to the end
54719:      * and select B, not D (see bug 583684).
54719:      *
54719:      * Note: |tracker.nentries <= (nslots + nargs)|. However, this walk is
54719:      * sub-optimal if |tracker.nentries - original->trackerIndex() > sp - original|.
54719:      * With large scripts this may be a problem worth investigating. Note that
54719:      * the tracker is walked twice, so we multiply by 2 for pessimism.
54719:      */
54719:     FrameEntry *fe;
77343:     if ((tracker.nentries - original->trackerIndex()) * 2 > uint32(a->sp - original))
54719:         fe = walkFrameForUncopy(original);
54719:     else
54719:         fe = walkTrackerForUncopy(original);
77343:     JS_ASSERT(fe);
52691: 
52691:     /*
52691:      * Switch the new backing store to the old backing store. During
52691:      * this process we also necessarily make sure the copy can be
52691:      * synced.
52691:      */
52691:     if (!original->isTypeKnown()) {
52691:         /*
52691:          * If the copy is unsynced, and the original is in memory,
52691:          * give the original a register. We do this below too; it's
52691:          * okay if it's spilled.
52691:          */
52691:         if (original->type.inMemory() && !fe->type.synced())
52691:             tempRegForType(original);
52691:         fe->type.inherit(original->type);
52691:         if (fe->type.inRegister())
77343:             regstate(fe->type.reg()).reassociate(fe);
52691:     } else {
77343:         fe->setType(original->getKnownType());
52691:     }
77343:     if (original->isType(JSVAL_TYPE_DOUBLE)) {
77343:         if (original->data.inMemory() && !fe->data.synced())
77343:             tempFPRegForData(original);
77343:         fe->data.inherit(original->data);
77343:         if (fe->data.inFPRegister())
77343:             regstate(fe->data.fpreg()).reassociate(fe);
77343:     } else {
77343:         if (fe->type.inRegister())
77343:             pinReg(fe->type.reg());
52691:         if (original->data.inMemory() && !fe->data.synced())
52691:             tempRegForData(original);
77343:         if (fe->type.inRegister())
77343:             unpinReg(fe->type.reg());
52691:         fe->data.inherit(original->data);
52691:         if (fe->data.inRegister())
77343:             regstate(fe->data.reg()).reassociate(fe);
77343:     }
53243: 
53243:     return fe;
52691: }
52691: 
77343: bool
77343: FrameState::hasOnlyCopy(FrameEntry *backing, FrameEntry *fe)
77343: {
77343:     JS_ASSERT(backing->isCopied() && fe->copyOf() == backing);
77343: 
77343:     for (uint32 i = backing->trackerIndex() + 1; i < tracker.nentries; i++) {
77343:         FrameEntry *nfe = tracker[i];
77343:         if (nfe != fe && !deadEntry(nfe) && nfe->isCopy() && nfe->copyOf() == backing)
77343:             return false;
77343:     }
77343: 
77343:     return true;
77343: }
77343: 
76206: void
77343: FrameState::separateBinaryEntries(FrameEntry *lhs, FrameEntry *rhs)
57787: {
77343:     JS_ASSERT(lhs == a->sp - 2 && rhs == a->sp - 1);
77343:     if (rhs->isCopy() && rhs->copyOf() == lhs) {
77343:         syncAndForgetFe(rhs);
77343:         syncAndForgetFe(lhs);
77343:         uncopy(lhs);
57787:     }
57787: }
57787: 
52691: void
77343: FrameState::storeLocal(uint32 n, bool popGuaranteed)
52691: {
54719:     FrameEntry *local = getLocal(n);
77343: 
77343:     if (a->analysis->slotEscapes(entrySlot(local))) {
77343:         JS_ASSERT(local->data.inMemory());
77343:         storeTo(peek(-1), addressOf(local), popGuaranteed);
55514:         return;
77343:     }
77343: 
77343:     storeTop(local);
77343: 
77343:     if (loop)
77343:         local->lastLoop = loop->headOffset();
77343: 
77343:     if (inTryBlock)
77343:         syncFe(local);
57787: }
56004: 
57787: void
57787: FrameState::storeArg(uint32 n, bool popGuaranteed)
57787: {
57787:     // Note that args are always immediately synced, because they can be
57787:     // aliased (but not written to) via f.arguments.
57787:     FrameEntry *arg = getArg(n);
77343: 
77343:     if (a->analysis->slotEscapes(entrySlot(arg))) {
77343:         JS_ASSERT(arg->data.inMemory());
77343:         storeTo(peek(-1), addressOf(arg), popGuaranteed);
77343:         return;
77343:     }
77343: 
77343:     storeTop(arg);
77343: 
77343:     if (loop)
77343:         arg->lastLoop = loop->headOffset();
77343: 
77343:     syncFe(arg);
54719: }
52961: 
54719: void
54719: FrameState::forgetEntry(FrameEntry *fe)
54719: {
54719:     if (fe->isCopied()) {
54719:         uncopy(fe);
77343:         fe->resetUnsynced();
54719:     } else {
54719:         forgetAllRegs(fe);
54719:     }
77343: 
77343:     extraArray[fe - entries].reset();
54719: }
54719: 
54719: void
77343: FrameState::storeTop(FrameEntry *target)
54719: {
77343:     JS_ASSERT(!isTemporary(target));
77343: 
52691:     /* Detect something like (x = x) which is a no-op. */
52691:     FrameEntry *top = peek(-1);
54719:     if (top->isCopy() && top->copyOf() == target) {
54719:         JS_ASSERT(target->isCopied());
52670:         return;
52670:     }
52670: 
77343:     /*
77343:      * If this is overwriting a known non-double type with another value of the
77343:      * same type, then make sure we keep the type marked as synced after doing
77343:      * the copy.
77343:      */
77343:     bool wasSynced = target->type.synced();
77343:     JSValueType oldType = target->isTypeKnown() ? target->getKnownType() : JSVAL_TYPE_UNKNOWN;
77343:     bool trySyncType = wasSynced && oldType != JSVAL_TYPE_UNKNOWN && oldType != JSVAL_TYPE_DOUBLE;
77343: 
52691:     /* Completely invalidate the local variable. */
54719:     forgetEntry(target);
54719:     target->resetUnsynced();
52691: 
52691:     /* Constants are easy to propagate. */
52691:     if (top->isConstant()) {
77343:         target->clear();
78614:         target->setConstant(top->getValue());
77343:         if (trySyncType && target->isType(oldType))
77343:             target->type.sync();
52691:         return;
52691:     }
52691: 
52691:     /*
54719:      * When dealing with copies, there are three important invariants:
52691:      *
52708:      * 1) The backing store precedes all copies in the tracker.
54719:      * 2) The backing store precedes all copies in the FrameState.
52785:      * 2) The backing store of a local is never a stack slot, UNLESS the local
53272:      *    variable itself is a stack slot (blocks) that precedes the stack
52785:      *    slot.
52708:      *
52708:      * If the top is a copy, and the second condition holds true, the local
52708:      * can be rewritten as a copy of the original backing slot. If the first
52708:      * condition does not hold, force it to hold by swapping in-place.
52691:      */
52708:     FrameEntry *backing = top;
52691:     if (top->isCopy()) {
52705:         backing = top->copyOf();
52708:         JS_ASSERT(backing->trackerIndex() < top->trackerIndex());
52691: 
77343:         if (backing < target || isTemporary(backing)) {
52708:             /* local.idx < backing.idx means local cannot be a copy yet */
54719:             if (target->trackerIndex() < backing->trackerIndex())
54719:                 swapInTracker(backing, target);
54719:             target->setCopyOf(backing);
77343:             if (trySyncType && target->isType(oldType))
77343:                 target->type.sync();
52691:             return;
52691:         }
52670: 
52785:         /*
52785:          * If control flow lands here, then there was a bytecode sequence like
52785:          *
52785:          *  ENTERBLOCK 2
52785:          *  GETLOCAL 1
52785:          *  SETLOCAL 0
52785:          *
52785:          * The problem is slot N can't be backed by M if M could be popped
52785:          * before N. We want a guarantee that when we pop M, even if it was
52785:          * copied, it has no outstanding copies.
52785:          * 
52785:          * Because of |let| expressions, it's kind of hard to really know
52785:          * whether a region on the stack will be popped all at once. Bleh!
52785:          *
52785:          * This should be rare except in browser code (and maybe even then),
52785:          * but even so there's a quick workaround. We take all copies of the
52785:          * backing fe, and redirect them to be copies of the destination.
52785:          */
52785:         for (uint32 i = backing->trackerIndex() + 1; i < tracker.nentries; i++) {
52785:             FrameEntry *fe = tracker[i];
77343:             if (deadEntry(fe))
52785:                 continue;
77343:             if (fe->isCopy() && fe->copyOf() == backing)
54719:                 fe->setCopyOf(target);
52691:         }
52785:     }
52785:     
52785:     /*
52785:      * This is valid from the top->isCopy() path because we're guaranteed a
52785:      * consistent ordering - all copies of |backing| are tracked after 
52785:      * |backing|. Transitively, only one swap is needed.
52785:      */
54719:     if (backing->trackerIndex() < target->trackerIndex())
54719:         swapInTracker(backing, target);
52691: 
77343:     if (backing->isType(JSVAL_TYPE_DOUBLE)) {
77343:         FPRegisterID fpreg = tempFPRegForData(backing);
77343:         target->setType(JSVAL_TYPE_DOUBLE);
77343:         target->data.setFPRegister(fpreg);
77343:         regstate(fpreg).reassociate(target);
77343:     } else {
52691:         /*
52691:          * Move the backing store down - we spill registers here, but we could be
77343:          * smarter and re-use the type reg. If we need registers for both the type
77343:          * and data in the backing, make sure we keep the other components pinned.
77343:          * There is nothing else to keep us from evicting the backing's registers.
52691:          */
77343:         if (backing->type.inRegister())
77343:             pinReg(backing->type.reg());
52691:         RegisterID reg = tempRegForData(backing);
77343:         if (backing->type.inRegister())
77343:             unpinReg(backing->type.reg());
54719:         target->data.setRegister(reg);
77343:         regstate(reg).reassociate(target);
77343: 
52691:         if (backing->isTypeKnown()) {
54719:             target->setType(backing->getKnownType());
52670:         } else {
77343:             pinReg(reg);
77343:             RegisterID typeReg = tempRegForType(backing);
77343:             unpinReg(reg);
77343:             target->type.setRegister(typeReg);
77343:             regstate(typeReg).reassociate(target);
52670:         }
52961:     }
52691: 
54719:     backing->setCopyOf(target);
54719:     JS_ASSERT(top->copyOf() == target);
53309: 
77343:     if (trySyncType && target->isType(oldType))
77343:         target->type.sync();
52623: }
52623: 
52838: void
52838: FrameState::shimmy(uint32 n)
52838: {
77343:     JS_ASSERT(a->sp - n >= a->spBase);
52838:     int32 depth = 0 - int32(n);
77343:     storeTop(peek(depth - 1));
52838:     popn(n);
52838: }
52664: 
52896: void
52896: FrameState::shift(int32 n)
52896: {
52896:     JS_ASSERT(n < 0);
77343:     JS_ASSERT(a->sp + n - 1 >= a->spBase);
77343:     storeTop(peek(n - 1));
52896:     pop();
52896: }
52896: 
54160: void
77343: FrameState::swap()
54160: {
77343:     // A B
77343: 
77343:     dupAt(-2);
77343:     // A B A
77343: 
77343:     dupAt(-2);
77343:     // A B A B
77343: 
77343:     shift(-3);
77343:     // B B A
77343: 
77343:     shimmy(1);
77343:     // B A
77343: }
77343: 
77343: void
77343: FrameState::forgetKnownDouble(FrameEntry *fe)
77343: {
77343:     /*
77343:      * Forget all information indicating fe is a double, so we can use GPRs for its
77343:      * contents.  We currently need to do this in order to use the entry in MICs/PICs
77343:      * or to construct its ValueRemat. :FIXME: this needs to get fixed.
77343:      */
77343:     JS_ASSERT(!fe->isConstant() && fe->isType(JSVAL_TYPE_DOUBLE));
77343: 
77343:     RegisterID typeReg = allocReg();
77343:     RegisterID dataReg = allocReg();
77343: 
77343:     /* Copy into a different FP register, as breakDouble can modify fpreg. */
77343:     FPRegisterID fpreg = allocFPReg();
77343:     masm.moveDouble(tempFPRegForData(fe), fpreg);
77343:     masm.breakDouble(fpreg, typeReg, dataReg);
77343: 
77343:     forgetAllRegs(fe);
77343:     fe->resetUnsynced();
77343:     fe->clear();
77343: 
77343:     regstate(typeReg).associate(fe, RematInfo::TYPE);
77343:     regstate(dataReg).associate(fe, RematInfo::DATA);
77343:     fe->type.setRegister(typeReg);
77343:     fe->data.setRegister(dataReg);
77343:     freeReg(fpreg);
77343: }
77343: 
77343: void
77343: FrameState::pinEntry(FrameEntry *fe, ValueRemat &vr, bool breakDouble)
77343: {
77343:     if (breakDouble && !fe->isConstant() && fe->isType(JSVAL_TYPE_DOUBLE))
77343:         forgetKnownDouble(fe);
77343: 
56575:     if (fe->isConstant()) {
56575:         vr = ValueRemat::FromConstant(fe->getValue());
77343:     } else if (fe->isType(JSVAL_TYPE_DOUBLE)) {
77343:         FPRegisterID fpreg = tempFPRegForData(fe);
77343:         pinReg(fpreg);
77343:         vr = ValueRemat::FromFPRegister(fpreg);
56575:     } else {
56575:         // Pin the type register so it can't spill.
56575:         MaybeRegisterID maybePinnedType = maybePinType(fe);
56575: 
56575:         // Get and pin the data register.
56575:         RegisterID dataReg = tempRegForData(fe);
56575:         pinReg(dataReg);
56575: 
56575:         if (fe->isTypeKnown()) {
56575:             vr = ValueRemat::FromKnownType(fe->getKnownType(), dataReg);
56575:         } else {
56575:             // The type might not be loaded yet, so unpin for simplicity.
56575:             maybeUnpinReg(maybePinnedType);
56575: 
56575:             vr = ValueRemat::FromRegisters(tempRegForType(fe), dataReg);
56575:             pinReg(vr.typeReg());
56575:         }
56575:     }
56575: 
56575:     // Set these bits last, since allocation could have caused a sync.
54160:     vr.isDataSynced = fe->data.synced();
54160:     vr.isTypeSynced = fe->type.synced();
54160: }
54160: 
54160: void
54160: FrameState::unpinEntry(const ValueRemat &vr)
54160: {
77343:     if (vr.isFPRegister()) {
77343:         unpinReg(vr.fpReg());
77343:     } else if (!vr.isConstant()) {
56575:         if (!vr.isTypeKnown())
56575:             unpinReg(vr.typeReg());
56575:         unpinReg(vr.dataReg());
54160:     }
54160: }
54160: 
54160: void
56004: FrameState::ensureValueSynced(Assembler &masm, FrameEntry *fe, const ValueRemat &vr)
54160: {
54582: #if defined JS_PUNBOX64
54582:     if (!vr.isDataSynced || !vr.isTypeSynced)
54582:         masm.storeValue(vr, addressOf(fe));
54582: #elif defined JS_NUNBOX32
77343:     if (vr.isConstant() || vr.isFPRegister()) {
54160:         if (!vr.isDataSynced || !vr.isTypeSynced)
56575:             masm.storeValue(vr.value(), addressOf(fe));
54160:     } else {
54160:         if (!vr.isDataSynced)
56575:             masm.storePayload(vr.dataReg(), addressOf(fe));
54160:         if (!vr.isTypeSynced) {
56575:             if (vr.isTypeKnown())
56575:                 masm.storeTypeTag(ImmType(vr.knownType()), addressOf(fe));
54160:             else
56575:                 masm.storeTypeTag(vr.typeReg(), addressOf(fe));
54160:         }
54160:     }
54582: #endif
54160: }
54160: 
53152: static inline bool
53152: AllocHelper(RematInfo &info, MaybeRegisterID &maybe)
53152: {
53152:     if (info.inRegister()) {
53152:         maybe = info.reg();
53152:         return true;
53152:     }
53152:     return false;
53152: }
53152: 
53152: void
53152: FrameState::allocForSameBinary(FrameEntry *fe, JSOp op, BinaryAlloc &alloc)
53152: {
77343:     alloc.rhsNeedsRemat = false;
77343: 
53152:     if (!fe->isTypeKnown()) {
53152:         alloc.lhsType = tempRegForType(fe);
53152:         pinReg(alloc.lhsType.reg());
53152:     }
53152: 
53152:     alloc.lhsData = tempRegForData(fe);
53152: 
77343:     if (!freeRegs.empty(Registers::AvailRegs)) {
53152:         alloc.result = allocReg();
53152:         masm.move(alloc.lhsData.reg(), alloc.result);
53152:         alloc.lhsNeedsRemat = false;
53152:     } else {
53152:         alloc.result = alloc.lhsData.reg();
53152:         takeReg(alloc.result);
53152:         alloc.lhsNeedsRemat = true;
53152:     }
53152: 
53152:     if (alloc.lhsType.isSet())
53152:         unpinReg(alloc.lhsType.reg());
77343: 
77343:     alloc.lhsFP = alloc.rhsFP = allocFPReg();
53152: }
53152: 
53152: void
56219: FrameState::ensureFullRegs(FrameEntry *fe, MaybeRegisterID *type, MaybeRegisterID *data)
53590: {
56219:     fe = fe->isCopy() ? fe->copyOf() : fe;
53590: 
56219:     JS_ASSERT(!data->isSet() && !type->isSet());
53590:     if (!fe->type.inMemory()) {
56219:         if (fe->type.inRegister())
56219:             *type = fe->type.reg();
56219:         if (fe->data.isConstant())
53590:             return;
56219:         if (fe->data.inRegister()) {
56219:             *data = fe->data.reg();
56219:             return;
56219:         }
53590:         if (fe->type.inRegister())
53590:             pinReg(fe->type.reg());
56219:         *data = tempRegForData(fe);
53590:         if (fe->type.inRegister())
53590:             unpinReg(fe->type.reg());
53590:     } else if (!fe->data.inMemory()) {
56219:         if (fe->data.inRegister())
56219:             *data = fe->data.reg();
56219:         if (fe->type.isConstant())
53590:             return;
56219:         if (fe->type.inRegister()) {
56219:             *type = fe->type.reg();
56219:             return;
56219:         }
53590:         if (fe->data.inRegister())
53590:             pinReg(fe->data.reg());
56219:         *type = tempRegForType(fe);
53590:         if (fe->data.inRegister())
53590:             unpinReg(fe->data.reg());
56219:     } else {
56219:         *data = tempRegForData(fe);
56219:         pinReg(data->reg());
56219:         *type = tempRegForType(fe);
56219:         unpinReg(data->reg());
53590:     }
53590: }
53590: 
77343: inline bool
77343: FrameState::binaryEntryLive(FrameEntry *fe) const
77343: {
77343:     /*
77343:      * Compute whether fe is live after the binary operation performed at the current
77343:      * bytecode. This is similar to variableLive except that it returns false for the
77343:      * top two stack entries and special cases LOCALINC/ARGINC and friends, which fuse
77343:      * a binary operation before writing over the local/arg.
77343:      */
77343:     JS_ASSERT(cx->typeInferenceEnabled());
77343: 
77343:     if (deadEntry(fe, 2))
77343:         return false;
77343: 
77343:     switch (JSOp(*a->PC)) {
77343:       case JSOP_INCLOCAL:
77343:       case JSOP_DECLOCAL:
77343:       case JSOP_LOCALINC:
77343:       case JSOP_LOCALDEC:
77343:         if (fe - a->locals == (int) GET_SLOTNO(a->PC))
77343:             return false;
77343:       case JSOP_INCARG:
77343:       case JSOP_DECARG:
77343:       case JSOP_ARGINC:
77343:       case JSOP_ARGDEC:
77343:         if (fe - a->args == (int) GET_SLOTNO(a->PC))
77343:             return false;
77343:       default:;
77343:     }
77343: 
77343:     JS_ASSERT(fe != a->callee_);
77343: 
77343:     /* Arguments are always treated as live within inline frames, see bestEvictReg. */
77343:     if (a->parent && fe < a->locals)
77343:         return true;
77343: 
77343:     /* Caller must check that no copies are invalidated by rewriting the entry. */
77343:     return fe >= a->spBase || variableLive(fe, a->PC);
77343: }
77343: 
53590: void
53201: FrameState::allocForBinary(FrameEntry *lhs, FrameEntry *rhs, JSOp op, BinaryAlloc &alloc,
53201:                            bool needsResult)
53152: {
53152:     FrameEntry *backingLeft = lhs;
53152:     FrameEntry *backingRight = rhs;
53152: 
53152:     if (backingLeft->isCopy())
53152:         backingLeft = backingLeft->copyOf();
53152:     if (backingRight->isCopy())
53152:         backingRight = backingRight->copyOf();
53152: 
53152:     /*
53152:      * For each remat piece of both FEs, if a register is assigned, get it now
53152:      * and pin it. This is safe - constants and known types will be avoided.
53152:      */
53152:     if (AllocHelper(backingLeft->type, alloc.lhsType))
53152:         pinReg(alloc.lhsType.reg());
53152:     if (AllocHelper(backingLeft->data, alloc.lhsData))
53152:         pinReg(alloc.lhsData.reg());
53152:     if (AllocHelper(backingRight->type, alloc.rhsType))
53152:         pinReg(alloc.rhsType.reg());
53152:     if (AllocHelper(backingRight->data, alloc.rhsData))
53152:         pinReg(alloc.rhsData.reg());
53152: 
53152:     /* For each type without a register, give it a register if needed. */
53152:     if (!alloc.lhsType.isSet() && backingLeft->type.inMemory()) {
53152:         alloc.lhsType = tempRegForType(lhs);
53152:         pinReg(alloc.lhsType.reg());
53152:     }
53152:     if (!alloc.rhsType.isSet() && backingRight->type.inMemory()) {
53152:         alloc.rhsType = tempRegForType(rhs);
53152:         pinReg(alloc.rhsType.reg());
53152:     }
53152: 
77343:     /*
77343:      * Allocate floating point registers.  These are temporaries with no pre-existing data;
77343:      * floating point registers are only allocated for known doubles, and BinaryAlloc is not
77343:      * used for such operations.
77343:      */
77343:     JS_ASSERT(!backingLeft->isType(JSVAL_TYPE_DOUBLE));
77343:     JS_ASSERT(!backingRight->isType(JSVAL_TYPE_DOUBLE));
77343:     alloc.lhsFP = allocFPReg();
77343:     alloc.rhsFP = allocFPReg();
77343: 
53152:     bool commu;
53152:     switch (op) {
54160:       case JSOP_EQ:
53201:       case JSOP_GT:
53201:       case JSOP_GE:
53201:       case JSOP_LT:
53201:       case JSOP_LE:
53201:         /* fall through */
53152:       case JSOP_ADD:
53152:       case JSOP_MUL:
53152:       case JSOP_SUB:
53152:         commu = true;
53152:         break;
53152: 
53152:       case JSOP_DIV:
53152:         commu = false;
53152:         break;
53152: 
53152:       default:
53152:         JS_NOT_REACHED("unknown op");
53152:         return;
53152:     }
53152: 
53152:     /*
78205:      * Allocate data registers. If the op is not commutative, the LHS
78205:      * _must_ be in a register.
53152:      */
53152:     JS_ASSERT_IF(lhs->isConstant(), !rhs->isConstant());
53152:     JS_ASSERT_IF(rhs->isConstant(), !lhs->isConstant());
53152: 
53152:     if (!alloc.lhsData.isSet()) {
53152:         if (backingLeft->data.inMemory()) {
53152:             alloc.lhsData = tempRegForData(lhs);
53152:             pinReg(alloc.lhsData.reg());
78205:         } else if (!commu) {
53152:             JS_ASSERT(lhs->isConstant());
53152:             alloc.lhsData = allocReg();
53152:             alloc.extraFree = alloc.lhsData;
53152:             masm.move(Imm32(lhs->getValue().toInt32()), alloc.lhsData.reg());
53152:         }
53152:     }
78205:     if (!alloc.rhsData.isSet() && backingRight->data.inMemory()) {
53152:         alloc.rhsData = tempRegForData(rhs);
53152:         pinReg(alloc.rhsData.reg());
53152:     }
53152: 
53152:     alloc.lhsNeedsRemat = false;
53152:     alloc.rhsNeedsRemat = false;
77343:     alloc.resultHasRhs = false;
77343:     alloc.undoResult = false;
53152: 
53201:     if (!needsResult)
53201:         goto skip;
53201: 
53152:     /*
53152:      * Now a result register is needed. It must contain a mutable copy of the
53152:      * LHS. For commutative operations, we can opt to use the RHS instead. At
53152:      * this point, if for some reason either must be in a register, that has
53152:      * already been guaranteed at this point.
53152:      */
77343: 
77343:     /*
77343:      * Try to reuse operand registers without syncing for ADD and constant SUB,
77343:      * so long as the backing for the operand is dead.
77343:      */
77343:     if (cx->typeInferenceEnabled() &&
77343:         backingLeft->data.inRegister() && !binaryEntryLive(backingLeft) &&
77343:         (op == JSOP_ADD || (op == JSOP_SUB && backingRight->isConstant())) &&
77343:         (lhs == backingLeft || hasOnlyCopy(backingLeft, lhs))) {
77343:         alloc.result = backingLeft->data.reg();
77343:         alloc.undoResult = true;
77343:         alloc.resultHasRhs = false;
77343:         goto skip;
77343:     }
77343: 
77343:     if (cx->typeInferenceEnabled())
77343:         evictDeadEntries(true);
77343: 
77343:     if (!freeRegs.empty(Registers::AvailRegs)) {
53152:         /* Free reg - just grab it. */
53152:         alloc.result = allocReg();
53152:         if (!alloc.lhsData.isSet()) {
53152:             JS_ASSERT(alloc.rhsData.isSet());
53152:             JS_ASSERT(commu);
53152:             masm.move(alloc.rhsData.reg(), alloc.result);
53152:             alloc.resultHasRhs = true;
53152:         } else {
53152:             masm.move(alloc.lhsData.reg(), alloc.result);
53152:             alloc.resultHasRhs = false;
53152:         }
77343:     } else if (cx->typeInferenceEnabled()) {
77343:         /* No free regs. Evict a register or reuse one of the operands. */
77343:         bool leftInReg = backingLeft->data.inRegister();
77343:         bool rightInReg = backingRight->data.inRegister();
77343: 
77343:         /* If the LHS/RHS types are in registers, don't use them for the result. */
77343:         uint32 mask = Registers::AvailRegs;
77343:         if (backingLeft->type.inRegister())
77343:             mask &= ~Registers::maskReg(backingLeft->type.reg());
77343:         if (backingRight->type.inRegister())
77343:             mask &= ~Registers::maskReg(backingRight->type.reg());
77343: 
77343:         RegisterID result = bestEvictReg(mask, true).reg();
77343:         if (!commu && rightInReg && backingRight->data.reg() == result) {
77343:             /* Can't put the result in the RHS for non-commutative operations. */
77343:             alloc.result = allocReg();
77343:             masm.move(alloc.lhsData.reg(), alloc.result);
77343:         } else {
77343:             alloc.result = result;
77343:             if (leftInReg && result == backingLeft->data.reg()) {
77343:                 alloc.lhsNeedsRemat = true;
77343:                 unpinReg(result);
77343:                 takeReg(result);
77343:             } else if (rightInReg && result == backingRight->data.reg()) {
77343:                 alloc.rhsNeedsRemat = true;
77343:                 alloc.resultHasRhs = true;
77343:                 unpinReg(result);
77343:                 takeReg(result);
77343:             } else {
77343:                 JS_ASSERT(!regstate(result).isPinned());
77343:                 takeReg(result);
77343:                 if (leftInReg) {
77343:                     masm.move(alloc.lhsData.reg(), result);
77343:                 } else {
77343:                     masm.move(alloc.rhsData.reg(), result);
77343:                     alloc.resultHasRhs = true;
77343:                 }
77343:             }
77343:         }
53152:     } else {
53152:         /*
53152:          * No free regs. Find a good candidate to re-use. Best candidates don't
53152:          * require syncs on the inline path.
53152:          */
53152:         bool leftInReg = backingLeft->data.inRegister();
53152:         bool rightInReg = backingRight->data.inRegister();
53152:         bool leftSynced = backingLeft->data.synced();
53152:         bool rightSynced = backingRight->data.synced();
53152:         if (!commu || (leftInReg && (leftSynced || (!rightInReg || !rightSynced)))) {
53152:             JS_ASSERT(backingLeft->data.inRegister() || !commu);
53152:             JS_ASSERT_IF(backingLeft->data.inRegister(),
53152:                          backingLeft->data.reg() == alloc.lhsData.reg());
53152:             if (backingLeft->data.inRegister()) {
53152:                 alloc.result = backingLeft->data.reg();
53152:                 unpinReg(alloc.result);
53152:                 takeReg(alloc.result);
53152:                 alloc.lhsNeedsRemat = true;
53152:             } else {
53152:                 /* For now, just spill... */
53152:                 alloc.result = allocReg();
53152:                 masm.move(alloc.lhsData.reg(), alloc.result);
53152:             }
53152:             alloc.resultHasRhs = false;
53152:         } else {
53152:             JS_ASSERT(commu);
53152:             JS_ASSERT(!leftInReg || (rightInReg && rightSynced));
53152:             alloc.result = backingRight->data.reg();
53152:             unpinReg(alloc.result);
53152:             takeReg(alloc.result);
53152:             alloc.resultHasRhs = true;
53152:             alloc.rhsNeedsRemat = true;
53152:         }
53152:     }
53152: 
53201:   skip:
53152:     /* Unpin everything that was pinned. */
53152:     if (backingLeft->type.inRegister())
53152:         unpinReg(backingLeft->type.reg());
53152:     if (backingRight->type.inRegister())
53152:         unpinReg(backingRight->type.reg());
53152:     if (backingLeft->data.inRegister())
53152:         unpinReg(backingLeft->data.reg());
53152:     if (backingRight->data.inRegister())
53152:         unpinReg(backingRight->data.reg());
53152: }
53152: 
77343: void
77343: FrameState::rematBinary(FrameEntry *lhs, FrameEntry *rhs, const BinaryAlloc &alloc, Assembler &masm)
77343: {
77343:     if (alloc.rhsNeedsRemat)
77343:         masm.loadPayload(addressForDataRemat(rhs), alloc.rhsData.reg());
77343:     if (alloc.lhsNeedsRemat)
77343:         masm.loadPayload(addressForDataRemat(lhs), alloc.lhsData.reg());
77343: }
77343: 
56572: MaybeRegisterID
56572: FrameState::maybePinData(FrameEntry *fe)
56572: {
56572:     fe = fe->isCopy() ? fe->copyOf() : fe;
56572:     if (fe->data.inRegister()) {
56572:         pinReg(fe->data.reg());
56572:         return fe->data.reg();
56572:     }
56572:     return MaybeRegisterID();
56572: }
56572: 
56572: MaybeRegisterID
56572: FrameState::maybePinType(FrameEntry *fe)
56572: {
56572:     fe = fe->isCopy() ? fe->copyOf() : fe;
56572:     if (fe->type.inRegister()) {
56572:         pinReg(fe->type.reg());
56572:         return fe->type.reg();
56572:     }
56572:     return MaybeRegisterID();
56572: }
56572: 
56572: void
56572: FrameState::maybeUnpinReg(MaybeRegisterID reg)
56572: {
56572:     if (reg.isSet())
56572:         unpinReg(reg.reg());
56572: }
56572: 
77343: uint32
77343: FrameState::allocTemporary()
77343: {
77343:     if (temporariesTop == temporaries + TEMPORARY_LIMIT)
77343:         return uint32(-1);
77343:     FrameEntry *fe = temporariesTop++;
77343:     fe->lastLoop = 0;
77343:     fe->temporary = true;
77343:     return fe - temporaries;
77343: }
77343: 
77343: void
77343: FrameState::clearTemporaries()
77343: {
77343:     JS_ASSERT(!a->parent);
77343: 
77343:     for (FrameEntry *fe = temporaries; fe < temporariesTop; fe++) {
77343:         if (!fe->isTracked())
77343:             continue;
77896:         if (fe->isCopied())
77896:             uncopy(fe);
77343:         forgetAllRegs(fe);
77343:         fe->resetSynced();
77343:     }
77343: 
77343:     temporariesTop = temporaries;
77343: }
77343: 
77343: Vector<TemporaryCopy> *
78454: FrameState::getTemporaryCopies(Uses uses)
77343: {
77343:     /* :XXX: handle OOM */
77343:     Vector<TemporaryCopy> *res = NULL;
77343: 
77343:     for (FrameEntry *fe = temporaries; fe < temporariesTop; fe++) {
77343:         if (!fe->isTracked())
77343:             continue;
77343:         if (fe->isCopied()) {
77343:             for (uint32 i = fe->trackerIndex() + 1; i < tracker.nentries; i++) {
77343:                 FrameEntry *nfe = tracker[i];
78454:                 if (!deadEntry(nfe, uses.nuses) && nfe->isCopy() && nfe->copyOf() == fe) {
77343:                     if (!res)
77343:                         res = cx->new_< Vector<TemporaryCopy> >(cx);
77343:                     res->append(TemporaryCopy(addressOf(nfe), addressOf(fe)));
77343:                 }
77343:             }
77343:         }
77343:     }
77343: 
77343:     return res;
77343: }
