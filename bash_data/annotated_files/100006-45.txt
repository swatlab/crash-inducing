 52557: /* -*- Mode: C++; tab-width: 4; indent-tabs-mode: nil; c-basic-offset: 4 -*-
 52557:  * vim: set ts=4 sw=4 et tw=99:
 52557:  *
 98983:  * This Source Code Form is subject to the terms of the Mozilla Public
 98983:  * License, v. 2.0. If a copy of the MPL was not distributed with this
 98983:  * file, You can obtain one at http://mozilla.org/MPL/2.0/. */
 52557: 
 52557: #if !defined jsjaeger_h__ && defined JS_METHODJIT
 52557: #define jsjaeger_h__
 52557: 
 82129: #ifdef JSGC_INCREMENTAL
 82129: #define JSGC_INCREMENTAL_MJ
 82129: #endif
 82129: 
 52557: #include "jscntxt.h"
 76185: #include "jscompartment.h"
 52557: 
 52557: #include "assembler/assembler/MacroAssemblerCodeRef.h"
 76185: #include "assembler/assembler/CodeLocation.h"
 52557: 
 52557: #if !defined JS_CPU_X64 && \
 52557:     !defined JS_CPU_X86 && \
 68931:     !defined JS_CPU_SPARC && \
 87250:     !defined JS_CPU_ARM && \
 87250:     !defined JS_CPU_MIPS
 52557: # error "Oh no, you should define a platform so this compiles."
 52557: #endif
 52557: 
 53224: #if !defined(JS_NUNBOX32) && !defined(JS_PUNBOX64)
 53224: # error "No boxing format selected."
 52560: #endif
 52560: 
 52557: namespace js {
 52557: 
 87654: namespace mjit {
 87654:     struct JITChunk;
 87654:     struct JITScript;
 87654: }
 58063: 
 52557: struct VMFrame
 52557: {
 68931: #if defined(JS_CPU_SPARC)
 68931:     void *savedL0;
 68931:     void *savedL1;
 68931:     void *savedL2;
 68931:     void *savedL3;
 68931:     void *savedL4;
 68931:     void *savedL5;
 68931:     void *savedL6;
 68931:     void *savedL7;
 68931:     void *savedI0;
 68931:     void *savedI1;
 68931:     void *savedI2;
 68931:     void *savedI3;
 68931:     void *savedI4;
 68931:     void *savedI5;
 68931:     void *savedI6;
 68931:     void *savedI7;
 68931: 
 68931:     void *str_p;
 68931: 
 68931:     void *outgoing_p0;
 68931:     void *outgoing_p1;
 68931:     void *outgoing_p2;
 68931:     void *outgoing_p3;
 68931:     void *outgoing_p4;
 68931:     void *outgoing_p5;
 68931: 
 68931:     void *outgoing_p6;
 68931: 
 68931:     void *reserve_0;
 68931:     void *reserve_1;
 87250: 
 87250: #elif defined(JS_CPU_MIPS)
 87250:     /* Reserved 16 bytes for a0-a3 space in MIPS O32 ABI */
 87250:     void         *unused0;
 87250:     void         *unused1;
 87250:     void         *unused2;
 87250:     void         *unused3;
 68931: #endif
 68931: 
 52557:     union Arguments {
 52825:         struct {
 52825:             void *ptr;
 52825:             void *ptr2;
 52825:         } x;
 57717:         struct {
 84755:             uint32_t dynamicArgc;
 57717:         } call;
 52557:     } u;
 52557: 
 82150:     static size_t offsetOfDynamicArgc() {
 82150:         return offsetof(VMFrame, u.call.dynamicArgc);
 82150:     }
 82150: 
 53168:     VMFrame      *previous;
 76185:     void         *scratch;
 69223:     FrameRegs    regs;
 82150: 
 82150:     static size_t offsetOfRegsSp() {
 82150:         return offsetof(VMFrame, regs.sp);
 82150:     }
 82150: 
 82150:     static size_t offsetOfRegsPc() {
 82150:         return offsetof(VMFrame, regs.pc);
 82150:     }
 82150: 
 52557:     JSContext    *cx;
 53422:     Value        *stackLimit;
 69223:     StackFrame   *entryfp;
 77341:     FrameRegs    *oldregs;
100006:     JSRejoinState stubRejoin;  /* How to rejoin if inside a call from an IC stub. */
 76185: 
 76185: #if defined(JS_CPU_X86)
 76185:     void         *unused0, *unused1;  /* For 16 byte alignment */
 76185: #endif
 52557: 
 52557: #if defined(JS_CPU_X86)
 52557:     void *savedEBX;
 52557:     void *savedEDI;
 52557:     void *savedESI;
 52557:     void *savedEBP;
 52557:     void *savedEIP;
 52557: 
 53012: # ifdef JS_NO_FASTCALL
 53168:     inline void** returnAddressLocation() {
 58684:         return reinterpret_cast<void**>(this) - 5;
 53012:     }
 53012: # else
 53168:     inline void** returnAddressLocation() {
 53168:         return reinterpret_cast<void**>(this) - 1;
 52557:     }
 53012: # endif
 76185: 
 76185:     /* The gap between ebp and esp in JaegerTrampoline frames on X86 platforms. */
 84755:     static const uint32_t STACK_BASE_DIFFERENCE = 0x38;
 76185: 
 52557: #elif defined(JS_CPU_X64)
 52557:     void *savedRBX;
 53477: # ifdef _WIN64
 52557:     void *savedRSI;
 52557:     void *savedRDI;
 52557: # endif
 52557:     void *savedR15;
 52557:     void *savedR14;
 52557:     void *savedR13;
 52557:     void *savedR12;
 52557:     void *savedRBP;
 52557:     void *savedRIP;
 52557: 
 53477: # ifdef _WIN64
 53168:     inline void** returnAddressLocation() {
 53168:         return reinterpret_cast<void**>(this) - 5;
 52557:     }
 52557: # else
 53168:     inline void** returnAddressLocation() {
 53168:         return reinterpret_cast<void**>(this) - 1;
 52557:     }
 52557: # endif
 52557: 
 52557: #elif defined(JS_CPU_ARM)
 52557:     void *savedR4;
 52557:     void *savedR5;
 52557:     void *savedR6;
 52557:     void *savedR7;
 52557:     void *savedR8;
 52557:     void *savedR9;
 52557:     void *savedR10;
 52557:     void *savedR11;
 52557:     void *savedLR;
 52557: 
 53168:     inline void** returnAddressLocation() {
 53361:         return reinterpret_cast<void**>(this) - 1;
 52557:     }
 68931: #elif defined(JS_CPU_SPARC)
 68931:     JSStackFrame *topRetrunAddr;
 68931:     void* veneerReturn;
 68931:     void* _align;
 68931:     inline void** returnAddressLocation() {
 68931:         return reinterpret_cast<void**>(&this->veneerReturn);
 68931:     }
 87250: #elif defined(JS_CPU_MIPS)
 87250:     void *savedS0;
 87250:     void *savedS1;
 87250:     void *savedS2;
 87250:     void *savedS3;
 87250:     void *savedS4;
 87250:     void *savedS5;
 87250:     void *savedS6;
 87250:     void *savedS7;
 87250:     void *savedGP;
 87250:     void *savedRA;
 87250:     void *unused4;  // For alignment.
 87250: 
 87250:     inline void** returnAddressLocation() {
 87250:         return reinterpret_cast<void**>(this) - 1;
 87250:     }
 52557: #else
 52557: # error "The VMFrame layout isn't defined for your processor architecture!"
 52557: #endif
 52557: 
 52557:     JSRuntime *runtime() { return cx->runtime; }
 53422: 
 76185:     /*
 76185:      * Get the current frame and JIT. Note that these are NOT stable in case
 76185:      * of recompilations; all code which expects these to be stable should
 76185:      * check that cx->recompilations() has not changed across a call that could
 76185:      * trigger recompilation (pretty much any time the VM is called into).
 76185:      */
 69223:     StackFrame *fp() { return regs.fp(); }
 58063:     mjit::JITScript *jit() { return fp()->jit(); }
 69223: 
 87654:     inline mjit::JITChunk *chunk();
 87654:     inline unsigned chunkIndex();
 87654: 
 76185:     /* Get the inner script/PC in case of inlining. */
 76185:     inline JSScript *script();
 76185:     inline jsbytecode *pc();
 76185: 
 69844: #if defined(JS_CPU_SPARC)
 76185:     static const size_t offsetOfFp = 30 * sizeof(void *) + FrameRegs::offsetOfFp;
 76185:     static const size_t offsetOfInlined = 30 * sizeof(void *) + FrameRegs::offsetOfInlined;
 87250: #elif defined(JS_CPU_MIPS)
 87250:     static const size_t offsetOfFp = 8 * sizeof(void *) + FrameRegs::offsetOfFp;
 87250:     static const size_t offsetOfInlined = 8 * sizeof(void *) + FrameRegs::offsetOfInlined;
 69844: #else
 76185:     static const size_t offsetOfFp = 4 * sizeof(void *) + FrameRegs::offsetOfFp;
 76185:     static const size_t offsetOfInlined = 4 * sizeof(void *) + FrameRegs::offsetOfInlined;
 69844: #endif
 76185: 
 69223:     static void staticAssert() {
 69223:         JS_STATIC_ASSERT(offsetOfFp == offsetof(VMFrame, regs) + FrameRegs::offsetOfFp);
 76185:         JS_STATIC_ASSERT(offsetOfInlined == offsetof(VMFrame, regs) + FrameRegs::offsetOfInlined);
 69223:     }
 52557: };
 52557: 
 87250: #if defined(JS_CPU_ARM) || defined(JS_CPU_SPARC) || defined(JS_CPU_MIPS)
 53361: // WARNING: Do not call this function directly from C(++) code because it is not ABI-compliant.
 52557: extern "C" void JaegerStubVeneer(void);
 52557: #endif
 52557: 
 55503: namespace mjit {
 56773: 
 56773: /*
 76185:  * For a C++ or scripted call made from JIT code, indicates properties of the
 79434:  * register and stack state after the call finishes, which js_InternalInterpret
 76185:  * must use to construct a coherent state for rejoining into the interpreter.
 76185:  */
 76185: enum RejoinState {
 76185:     /*
 76185:      * Return value of call at this bytecode is held in ReturnReg_{Data,Type}
 76185:      * and needs to be restored before starting the next bytecode. f.regs.pc
 76185:      * is *not* intact when rejoining from a scripted call (unlike all other
 76185:      * rejoin states). The pc's offset into the script is stored in the upper
 76185:      * 31 bits of the rejoin state, and the remaining values for RejoinState
 76185:      * are shifted left by one in stack frames to leave the lower bit set only
 76185:      * for scripted calls.
 76185:      */
 76185:     REJOIN_SCRIPTED = 1,
 76185: 
 76185:     /* Recompilations and frame expansion are impossible for this call. */
 76185:     REJOIN_NONE,
 76185: 
 76185:     /* State is coherent for the start of the current bytecode. */
 76185:     REJOIN_RESUME,
 76185: 
 76185:     /*
 76185:      * State is coherent for the start of the current bytecode, which is a TRAP
 76185:      * that has already been invoked and should not be invoked again.
 76185:      */
 76185:     REJOIN_TRAP,
 76185: 
 76185:     /* State is coherent for the start of the next (fallthrough) bytecode. */
 76185:     REJOIN_FALLTHROUGH,
 76185: 
 76185:     /*
 76185:      * As for REJOIN_FALLTHROUGH, but holds a reference on the compartment's
 76185:      * orphaned native pools which needs to be reclaimed by InternalInterpret.
 78454:      * The return value needs to be adjusted if REJOIN_NATIVE_LOWERED, and
 78454:      * REJOIN_NATIVE_GETTER is for ABI calls made for property accesses.
 76185:      */
 76185:     REJOIN_NATIVE,
 76185:     REJOIN_NATIVE_LOWERED,
 78454:     REJOIN_NATIVE_GETTER,
 76185: 
 76185:     /*
 76185:      * Dummy rejoin stored in VMFrames to indicate they return into a native
 76185:      * stub (and their FASTCALL return address should not be observed) but
 76185:      * that they have already been patched and can be ignored.
 76185:      */
 76185:     REJOIN_NATIVE_PATCHED,
 76185: 
 76185:     /* Call returns a payload, which should be pushed before starting next bytecode. */
 76185:     REJOIN_PUSH_BOOLEAN,
 76185:     REJOIN_PUSH_OBJECT,
 76185: 
100006:     /* Call returns an object, which should be assigned to a local per the current bytecode. */
100006:     REJOIN_DEFLOCALFUN,
100006: 
 76185:     /*
 76185:      * During the prologue of constructing scripts, after the function's
 76185:      * .prototype property has been fetched.
 76185:      */
 76185:     REJOIN_THIS_PROTOTYPE,
 76185: 
 76185:     /*
 76185:      * Type check on arguments failed during prologue, need stack check and
 77884:      * the rest of the JIT prologue before the script can execute.
 76185:      */
 76185:     REJOIN_CHECK_ARGUMENTS,
 76185: 
 77884:     /*
100006:      * The script's jitcode was discarded after marking an outer function as
100006:      * reentrant or due to a GC while creating a call object.
 77884:      */
 77884:     REJOIN_FUNCTION_PROLOGUE,
 77356: 
 76185:     /*
 76185:      * State after calling a stub which returns a JIT code pointer for a call
 76185:      * or NULL for an already-completed call.
 76185:      */
 76185:     REJOIN_CALL_PROLOGUE,
 76185:     REJOIN_CALL_PROLOGUE_LOWERED_CALL,
 76185:     REJOIN_CALL_PROLOGUE_LOWERED_APPLY,
 76185: 
 76185:     /* Triggered a recompilation while placing the arguments to an apply on the stack. */
 76185:     REJOIN_CALL_SPLAT,
 76185: 
 76185:     /* FALLTHROUGH ops which can be implemented as part of an IncOp. */
 76185:     REJOIN_GETTER,
 76185:     REJOIN_POS,
 76185:     REJOIN_BINARY,
 76185: 
 76185:     /*
 76185:      * For an opcode fused with IFEQ/IFNE, call returns a boolean indicating
 76185:      * the result of the comparison and whether to take or not take the branch.
 76185:      */
 78389:     REJOIN_BRANCH
 76185: };
 76185: 
 87654: /* Get the rejoin state for a StackFrame after returning from a scripted call. */
100006: static inline JSRejoinState
 87654: ScriptedRejoin(uint32_t pcOffset)
 87654: {
 87654:     return REJOIN_SCRIPTED | (pcOffset << 1);
 87654: }
 87654: 
 87654: /* Get the rejoin state for a StackFrame after returning from a stub call. */
100006: static inline JSRejoinState
 87654: StubRejoin(RejoinState rejoin)
 87654: {
 87654:     return rejoin << 1;
 87654: }
 87654: 
 76185: /* Helper to watch for recompilation and frame expansion activity on a compartment. */
 76185: struct RecompilationMonitor
 76185: {
 76185:     JSContext *cx;
 76185: 
 76185:     /*
 76185:      * If either inline frame expansion or recompilation occurs, then ICs and
 76185:      * stubs should not depend on the frame or JITs being intact. The two are
 76185:      * separated for logging.
 76185:      */
 76185:     unsigned recompilations;
 76185:     unsigned frameExpansions;
 76185: 
 77367:     /* If a GC occurs it may discard jit code on the stack. */
 90410:     uint64_t gcNumber;
 77367: 
 76185:     RecompilationMonitor(JSContext *cx)
 76185:         : cx(cx),
 76185:           recompilations(cx->compartment->types.recompilations),
 77367:           frameExpansions(cx->compartment->types.frameExpansions),
 77367:           gcNumber(cx->runtime->gcNumber)
 76185:     {}
 76185: 
 76185:     bool recompiled() {
 76185:         return cx->compartment->types.recompilations != recompilations
 77367:             || cx->compartment->types.frameExpansions != frameExpansions
 77367:             || cx->runtime->gcNumber != gcNumber;
 76185:     }
 76185: };
 76185: 
 76185: /*
 56773:  * Trampolines to force returns from jit code.
 56773:  * See also TrampolineCompiler::generateForceReturn(Fast).
 56773:  */
 56773: struct Trampolines {
 56773:     typedef void (*TrampolinePtr)();
 56773: 
 56773:     TrampolinePtr       forceReturn;
 56773:     JSC::ExecutablePool *forceReturnPool;
 56773: 
 56773: #if (defined(JS_NO_FASTCALL) && defined(JS_CPU_X86)) || defined(_WIN64)
 56773:     TrampolinePtr       forceReturnFast;
 56773:     JSC::ExecutablePool *forceReturnFastPool;
 56773: #endif
 56773: };
 56773: 
 77341: /* Result status of executing mjit code on a frame. */
 77341: enum JaegerStatus
 77341: {
 77341:     /* Entry frame finished, and is throwing an exception. */
 77341:     Jaeger_Throwing = 0,
 77341: 
 77341:     /* Entry frame finished, and is returning. */
 77341:     Jaeger_Returned = 1,
 77341: 
 77341:     /*
 77341:      * Entry frame did not finish. cx->regs reflects where to resume execution.
 77341:      * This result is only possible if 'partial' is passed as true below.
 77341:      */
 77341:     Jaeger_Unfinished = 2,
 77341: 
 77341:     /*
 77341:      * As for Unfinished, but stopped after a TRAP triggered recompilation.
 77341:      * The trap has been reinstalled, but should not execute again when
 77341:      * resuming execution.
 77341:      */
 93359:     Jaeger_UnfinishedAtTrap = 3,
 93359: 
 93359:     /*
 93359:      * An exception was thrown before entering jit code, so the caller should
 93359:      * 'goto error'.
 93359:      */
 93359:     Jaeger_ThrowBeforeEnter = 4
 77341: };
 77341: 
 93359: static inline bool
 93359: JaegerStatusToSuccess(JaegerStatus status)
 93359: {
 93359:     JS_ASSERT(status != Jaeger_Unfinished);
 93359:     JS_ASSERT(status != Jaeger_UnfinishedAtTrap);
 93359:     return status == Jaeger_Returned;
 93359: }
 93359: 
 97464: /* Method JIT data associated with the JSRuntime. */
 97464: class JaegerRuntime
 97464: {
 56773:     Trampolines              trampolines;    // force-return trampolines
 56773:     VMFrame                  *activeFrame_;  // current active VMFrame
 77341:     JaegerStatus             lastUnfinished_;// result status of last VM frame,
 77341:                                              // if unfinished
 56773: 
 97464:     void finish();
 56773: 
 56773:   public:
 97464:     bool init(JSContext *cx);
 56773: 
 97464:     JaegerRuntime();
 97464:     ~JaegerRuntime() { finish(); }
 56773: 
 56773:     VMFrame *activeFrame() {
 56773:         return activeFrame_;
 56773:     }
 56773: 
 56773:     void pushActiveFrame(VMFrame *f) {
 77341:         JS_ASSERT(!lastUnfinished_);
 56773:         f->previous = activeFrame_;
 76185:         f->scratch = NULL;
 56773:         activeFrame_ = f;
 56773:     }
 56773: 
 56773:     void popActiveFrame() {
 56773:         JS_ASSERT(activeFrame_);
 56773:         activeFrame_ = activeFrame_->previous;
 56773:     }
 56773: 
 77341:     void setLastUnfinished(JaegerStatus status) {
 77341:         JS_ASSERT(!lastUnfinished_);
 77341:         lastUnfinished_ = status;
 77341:     }
 77341: 
 77341:     JaegerStatus lastUnfinished() {
 77341:         JaegerStatus result = lastUnfinished_;
 77341:         lastUnfinished_ = (JaegerStatus) 0;
 77341:         return result;
 77341:     }
 77341: 
 84068:     /*
 84068:      * To force the top StackFrame in a VMFrame to return, when that VMFrame
 84068:      * has called an extern "C" function (say, js_InternalThrow or
 84068:      * js_InternalInterpret), change the extern "C" function's return address
 84068:      * to the value this method returns.
 84068:      */
 67899:     void *forceReturnFromExternC() const {
 67899:         return JS_FUNC_TO_DATA_PTR(void *, trampolines.forceReturn);
 56773:     }
 56773: 
 84068:     /*
 84068:      * To force the top StackFrame in a VMFrame to return, when that VMFrame has
 84068:      * called a fastcall function (say, most stubs:: functions), change the
 84068:      * fastcall function's return address to the value this method returns.
 84068:      */
 67899:     void *forceReturnFromFastCall() const {
 56773: #if (defined(JS_NO_FASTCALL) && defined(JS_CPU_X86)) || defined(_WIN64)
 67899:         return JS_FUNC_TO_DATA_PTR(void *, trampolines.forceReturnFast);
 67899: #else
 67899:         return JS_FUNC_TO_DATA_PTR(void *, trampolines.forceReturn);
 67899: #endif
 56773:     }
 76185: 
 76185:     /*
 76185:      * References held on pools created for native ICs, where the IC was
 76185:      * destroyed and we are waiting for the pool to finish use and jump
 76185:      * into the interpoline.
 76185:      */
 76185:     Vector<StackFrame *, 8, SystemAllocPolicy> orphanedNativeFrames;
 76185:     Vector<JSC::ExecutablePool *, 8, SystemAllocPolicy> orphanedNativePools;
 56773: };
 56773: 
 57679: /*
 57679:  * Allocation policy for compiler jstl objects. The goal is to free the
 57679:  * compiler from having to check and propagate OOM after every time we
 57679:  * append to a vector. We do this by reporting OOM to the engine and
 57679:  * setting a flag on the compiler when OOM occurs. The compiler is required
 57679:  * to check for OOM only before trying to use the contents of the list.
 57679:  */
 72091: class CompilerAllocPolicy : public TempAllocPolicy
 57679: {
 57679:     bool *oomFlag;
 57679: 
 57679:     void *checkAlloc(void *p) {
 57679:         if (!p)
 57679:             *oomFlag = true;
 57679:         return p;
 57679:     }
 57679: 
 57679:   public:
 57679:     CompilerAllocPolicy(JSContext *cx, bool *oomFlag)
 72091:     : TempAllocPolicy(cx), oomFlag(oomFlag) {}
 57679:     CompilerAllocPolicy(JSContext *cx, Compiler &compiler);
 57679: 
 72091:     void *malloc_(size_t bytes) { return checkAlloc(TempAllocPolicy::malloc_(bytes)); }
 72070:     void *realloc_(void *p, size_t oldBytes, size_t bytes) {
 72091:         return checkAlloc(TempAllocPolicy::realloc_(p, oldBytes, bytes));
 57679:     }
 57679: };
 57679: 
 55503: namespace ic {
 55503: # if defined JS_POLYIC
 55503:     struct PICInfo;
 56738:     struct GetElementIC;
 57671:     struct SetElementIC;
 55503: # endif
 55503: # if defined JS_MONOIC
 62386:     struct GetGlobalNameIC;
 62386:     struct SetGlobalNameIC;
 56192:     struct EqualityICInfo;
 68952:     struct CallICInfo;
 55503: # endif
 55503: }
 55503: }
 55503: 
 52557: typedef void (JS_FASTCALL *VoidStub)(VMFrame &);
 52623: typedef void (JS_FASTCALL *VoidVpStub)(VMFrame &, Value *);
 84755: typedef void (JS_FASTCALL *VoidStubUInt32)(VMFrame &, uint32_t);
 84755: typedef void (JS_FASTCALL *VoidStubInt32)(VMFrame &, int32_t);
 52557: typedef JSBool (JS_FASTCALL *BoolStub)(VMFrame &);
 52557: typedef void * (JS_FASTCALL *VoidPtrStub)(VMFrame &);
 52557: typedef void * (JS_FASTCALL *VoidPtrStubPC)(VMFrame &, jsbytecode *);
 84755: typedef void * (JS_FASTCALL *VoidPtrStubUInt32)(VMFrame &, uint32_t);
 52557: typedef JSObject * (JS_FASTCALL *JSObjStub)(VMFrame &);
 84755: typedef JSObject * (JS_FASTCALL *JSObjStubUInt32)(VMFrame &, uint32_t);
 52727: typedef JSObject * (JS_FASTCALL *JSObjStubFun)(VMFrame &, JSFunction *);
 53591: typedef void (JS_FASTCALL *VoidStubFun)(VMFrame &, JSFunction *);
 52738: typedef JSObject * (JS_FASTCALL *JSObjStubJSObj)(VMFrame &, JSObject *);
 86542: typedef void (JS_FASTCALL *VoidStubName)(VMFrame &, PropertyName *);
 52738: typedef JSString * (JS_FASTCALL *JSStrStub)(VMFrame &);
 84755: typedef JSString * (JS_FASTCALL *JSStrStubUInt32)(VMFrame &, uint32_t);
 52785: typedef void (JS_FASTCALL *VoidStubJSObj)(VMFrame &, JSObject *);
 53168: typedef void (JS_FASTCALL *VoidStubPC)(VMFrame &, jsbytecode *);
 84755: typedef JSBool (JS_FASTCALL *BoolStubUInt32)(VMFrame &f, uint32_t);
 55503: #ifdef JS_MONOIC
 68952: typedef void (JS_FASTCALL *VoidStubCallIC)(VMFrame &, js::mjit::ic::CallICInfo *);
 68952: typedef void * (JS_FASTCALL *VoidPtrStubCallIC)(VMFrame &, js::mjit::ic::CallICInfo *);
 62386: typedef void (JS_FASTCALL *VoidStubGetGlobal)(VMFrame &, js::mjit::ic::GetGlobalNameIC *);
 62386: typedef void (JS_FASTCALL *VoidStubSetGlobal)(VMFrame &, js::mjit::ic::SetGlobalNameIC *);
 56192: typedef JSBool (JS_FASTCALL *BoolStubEqualityIC)(VMFrame &, js::mjit::ic::EqualityICInfo *);
 55503: #endif
 55503: #ifdef JS_POLYIC
 55503: typedef void (JS_FASTCALL *VoidStubPIC)(VMFrame &, js::mjit::ic::PICInfo *);
 56738: typedef void (JS_FASTCALL *VoidStubGetElemIC)(VMFrame &, js::mjit::ic::GetElementIC *);
 57671: typedef void (JS_FASTCALL *VoidStubSetElemIC)(VMFrame &f, js::mjit::ic::SetElementIC *);
 55503: #endif
 52557: 
 52557: namespace mjit {
 52557: 
 76185: struct InlineFrame;
 55503: struct CallSite;
 55503: 
 58993: struct NativeMapEntry {
 58993:     size_t          bcOff;  /* bytecode offset in script */
 58993:     void            *ncode; /* pointer to native code */
 58993: };
 58993: 
 77407: /* Per-op counts of performance metrics. */
 77407: struct PCLengthEntry {
 77407:     double          codeLength; /* amount of inline code generated */
 77407:     double          picsLength; /* amount of PIC stub code generated */
 77407: };
 77407: 
 78454: /*
 78454:  * Pools and patch locations for managing stubs for non-FASTCALL C++ calls made
 78454:  * from native call and PropertyOp stubs. Ownership of these may be transferred
 78454:  * into the orphanedNativePools for the compartment.
 78454:  */
 78454: struct NativeCallStub {
 78454:     /* PC for the stub. Native call stubs cannot be added for inline frames. */
 78454:     jsbytecode *pc;
 78454: 
 78454:     /* Pool for the stub, NULL if it has been removed from the script. */
 78454:     JSC::ExecutablePool *pool;
 78454: 
 78454:     /*
 78454:      * Fallthrough jump returning to jitcode which may be patched during
 78454:      * recompilation. On x64 this is an indirect jump to avoid issues with far
 78454:      * jumps on relative branches.
 78454:      */
 78454: #ifdef JS_CPU_X64
 78454:     JSC::CodeLocationDataLabelPtr jump;
 78454: #else
 78454:     JSC::CodeLocationJump jump;
 78454: #endif
 78454: };
 78454: 
 87654: struct JITChunk
 87654: {
 55503:     typedef JSC::MacroAssemblerCodeRef CodeRef;
 55503:     CodeRef         code;       /* pool & code addresses */
 58993: 
 77407:     PCLengthEntry   *pcLengths;         /* lengths for outer and inline frames */
 59899: 
 62075:     /*
 62075:      * This struct has several variable-length sections that are allocated on
 62075:      * the end:  nmaps, MICs, callICs, etc.  To save space -- worthwhile
 62075:      * because JITScripts are common -- we only record their lengths.  We can
 62075:      * find any of the sections from the lengths because we know their order.
 62075:      * Therefore, do not change the section ordering in finishThisUp() without
 62075:      * changing nMICs() et al as well.
 62075:      */
 98147:     uint32_t        nNmapPairs : 31;    /* The NativeMapEntrys are sorted by .bcOff.
 62075:                                            .ncode values may not be NULL. */
 84755:     uint32_t        nInlineFrames;
 84755:     uint32_t        nCallSites;
 98147:     uint32_t        nRootedTemplates;
 98147:     uint32_t        nRootedRegExps;
 59899: #ifdef JS_MONOIC
 84755:     uint32_t        nGetGlobalNames;
 84755:     uint32_t        nSetGlobalNames;
 84755:     uint32_t        nCallICs;
 84755:     uint32_t        nEqualityICs;
 59899: #endif
 59899: #ifdef JS_POLYIC
 84755:     uint32_t        nGetElems;
 84755:     uint32_t        nSetElems;
 84755:     uint32_t        nPICs;
 59899: #endif
 76185: 
 76185: #ifdef JS_MONOIC
 56192:     // Additional ExecutablePools that IC stubs were generated into.
 56192:     typedef Vector<JSC::ExecutablePool *, 0, SystemAllocPolicy> ExecPoolVector;
 56192:     ExecPoolVector execPools;
 53498: #endif
 55503: 
 78454:     // Additional ExecutablePools for native call and getter stubs.
 78454:     Vector<NativeCallStub, 0, SystemAllocPolicy> nativeCallStubs;
 78454: 
 62075:     NativeMapEntry *nmap() const;
 76185:     js::mjit::InlineFrame *inlineFrames() const;
 76185:     js::mjit::CallSite *callSites() const;
 98147:     JSObject **rootedTemplates() const;
 98147:     RegExpShared **rootedRegExps() const;
 62075: #ifdef JS_MONOIC
 62386:     ic::GetGlobalNameIC *getGlobalNames() const;
 62386:     ic::SetGlobalNameIC *setGlobalNames() const;
 68952:     ic::CallICInfo *callICs() const;
 62075:     ic::EqualityICInfo *equalityICs() const;
 62075: #endif
 62075: #ifdef JS_POLYIC
 62075:     ic::GetElementIC *getElems() const;
 62075:     ic::SetElementIC *setElems() const;
 62075:     ic::PICInfo     *pics() const;
 62075: #endif
 62075: 
 55503:     bool isValidCode(void *ptr) {
 55503:         char *jitcode = (char *)code.m_code.executableAddress();
 55503:         char *jcheck = (char *)ptr;
 55503:         return jcheck >= jitcode && jcheck < jitcode + code.m_size;
 55503:     }
 55503: 
 88145:     size_t computedSizeOfIncludingThis();
 88145:     size_t sizeOfIncludingThis(JSMallocSizeOfFun mallocSizeOf);
 76185: 
 87654:     ~JITChunk();
 62075: 
 98147:     void trace(JSTracer *trc);
 98147:     void purgeCaches();
 98147: 
 62075:   private:
 62075:     /* Helpers used to navigate the variable-length sections. */
 76185:     char *commonSectionLimit() const;
 62075:     char *monoICSectionsLimit() const;
 62075:     char *polyICSectionsLimit() const;
 53498: };
 53498: 
 87654: void
 87654: SetChunkLimit(uint32_t limit);
 87654: 
 87654: /* Information about a compilation chunk within a script. */
 87654: struct ChunkDescriptor
 87654: {
 87654:     /* Bytecode range of the chunk: [begin,end) */
 87654:     uint32_t begin;
 87654:     uint32_t end;
 87654: 
 87654:     /* Use counter for the chunk. */
 87654:     uint32_t counter;
 87654: 
 87654:     /* Optional compiled code for the chunk. */
 87654:     JITChunk *chunk;
 87671: 
 87671:     ChunkDescriptor() { PodZero(this); }
 87654: };
 87654: 
 87654: /* Jump or fallthrough edge in the bytecode which crosses a chunk boundary. */
 87654: struct CrossChunkEdge
 87654: {
 87654:     /* Bytecode offsets of the source and target of the edge. */
 87654:     uint32_t source;
 87654:     uint32_t target;
 87654: 
 87654:     /* Locations of the jump(s) for the source, NULL if not compiled. */
 87654:     void *sourceJump1;
 87654:     void *sourceJump2;
 87654: 
 90435: #ifdef JS_CPU_X64
 90435:     /*
 90435:      * Location of a trampoline for the edge to perform an indirect jump if
 90435:      * out of range, NULL if the source is not compiled.
 90435:      */
 90435:     void *sourceTrampoline;
 90435: #endif
 90435: 
 87654:     /* Any jump table entries along this edge. */
 87654:     typedef Vector<void**,4,SystemAllocPolicy> JumpTableEntryVector;
 87654:     JumpTableEntryVector *jumpTableEntries;
 87654: 
 87654:     /* Location of the label for the target, NULL if not compiled. */
 87654:     void *targetLabel;
 87654: 
 87654:     /*
 87654:      * Location of a shim which will transfer control to the interpreter at the
 87654:      * target bytecode. The source jumps are patched to jump to this label if
 87654:      * the source is compiled but not the target.
 87654:      */
 87654:     void *shimLabel;
 87671: 
 87671:     CrossChunkEdge() { PodZero(this); }
 87654: };
 87654: 
 87654: struct JITScript
 87654: {
 87654:     JSScript        *script;
 87654: 
 87654:     void            *invokeEntry;       /* invoke address */
 87654:     void            *fastEntry;         /* cached entry, fastest */
 94626:     void            *arityCheckEntry;   /* arity check address */
 87654:     void            *argsCheckEntry;    /* arguments check address */
 87654: 
 87654:     /* List of inline caches jumping to the fastEntry. */
 87654:     JSCList         callers;
 87654: 
 87654:     uint32_t        nchunks;
 87654:     uint32_t        nedges;
 87654: 
 87654:     /*
 87654:      * Pool for shims which transfer control to the interpreter on cross chunk
 87654:      * edges to chunks which do not have compiled code.
 87654:      */
 87654:     JSC::ExecutablePool *shimPool;
 87654: 
 87654: #ifdef JS_MONOIC
 87654:     /* Inline cache at function entry for checking this/argument types. */
 87654:     JSC::CodeLocationLabel argsCheckStub;
 87654:     JSC::CodeLocationLabel argsCheckFallthrough;
 87654:     JSC::CodeLocationJump  argsCheckJump;
 87654:     JSC::ExecutablePool *argsCheckPool;
 87654:     void resetArgsCheck();
 87654: #endif
 87654: 
 87654:     ChunkDescriptor &chunkDescriptor(unsigned i) {
 87654:         JS_ASSERT(i < nchunks);
 87654:         ChunkDescriptor *descs = (ChunkDescriptor *) ((char *) this + sizeof(JITScript));
 87654:         return descs[i];
 87654:     }
 87654: 
 87654:     unsigned chunkIndex(jsbytecode *pc) {
 87654:         unsigned offset = pc - script->code;
 87654:         JS_ASSERT(offset < script->length);
 87654:         for (unsigned i = 0; i < nchunks; i++) {
 87654:             const ChunkDescriptor &desc = chunkDescriptor(i);
 87654:             JS_ASSERT(desc.begin <= offset);
 87654:             if (offset < desc.end)
 87654:                 return i;
 87654:         }
 87654:         JS_NOT_REACHED("Bad chunk layout");
 87654:         return 0;
 87654:     }
 87654: 
 87654:     JITChunk *chunk(jsbytecode *pc) {
 87654:         return chunkDescriptor(chunkIndex(pc)).chunk;
 87654:     }
 87654: 
 87654:     JITChunk *findCodeChunk(void *addr);
 87654: 
 87654:     CrossChunkEdge *edges() {
 87654:         return (CrossChunkEdge *) (&chunkDescriptor(0) + nchunks);
 87654:     }
 87654: 
 87654:     /* Patch any compiled sources in edge to jump to label. */
 87654:     void patchEdge(const CrossChunkEdge &edge, void *label);
 87654: 
 87654:     jsbytecode *nativeToPC(void *returnAddress, CallSite **pinline);
 87654: 
 88145:     size_t sizeOfIncludingThis(JSMallocSizeOfFun mallocSizeOf);
 87654: 
 94740:     void destroy(FreeOp *fop);
 94740:     void destroyChunk(FreeOp *fop, unsigned chunkIndex, bool resetUses = true);
 98147: 
 98147:     void trace(JSTracer *trc);
 98147:     void purgeCaches();
 87654: };
 87654: 
 55565: /*
 55565:  * Execute the given mjit code. This is a low-level call and callers must
 55565:  * provide the same guarantees as JaegerShot/CheckStackAndEnterMethodJIT.
 55565:  */
 77341: JaegerStatus EnterMethodJIT(JSContext *cx, StackFrame *fp, void *code, Value *stackLimit,
 77341:                             bool partial);
 55565: 
 53471: /* Execute a method that has been JIT compiled. */
 77341: JaegerStatus JaegerShot(JSContext *cx, bool partial);
 53471: 
 53471: /* Drop into the middle of a method at an arbitrary point, and execute. */
 77341: JaegerStatus JaegerShotAtSafePoint(JSContext *cx, void *safePoint, bool partial);
 52557: 
 52557: enum CompileStatus
 52557: {
 52557:     Compile_Okay,
 76185:     Compile_Abort,        // abort compilation
 76185:     Compile_InlineAbort,  // inlining attempt failed, continue compilation
 76185:     Compile_Retry,        // static overflow or failed inline, try to recompile
 76185:     Compile_Error,        // OOM
 62574:     Compile_Skipped
 52557: };
 52557: 
 52853: void JS_FASTCALL
 52853: ProfileStubCall(VMFrame &f);
 52853: 
 87654: enum CompileRequest
 87654: {
 87654:     CompileRequest_Interpreter,
 87654:     CompileRequest_JIT
 87654: };
 87654: 
 87654: CompileStatus
 87654: CanMethodJIT(JSContext *cx, JSScript *script, jsbytecode *pc,
 87654:              bool construct, CompileRequest request);
 52557: 
 77434: inline void
 94740: ReleaseScriptCode(FreeOp *fop, JSScript *script)
 77434: {
 99476:     if (!script->hasJITInfo())
 99476:         return;
 99476: 
 98147:     for (int constructing = 0; constructing <= 1; constructing++) {
 98147:         for (int barriers = 0; barriers <= 1; barriers++) {
 98147:             JSScript::JITScriptHandle *jith = script->jitHandle((bool) constructing, (bool) barriers);
 98147:             if (jith && jith->isValid())
 98147:                 JSScript::ReleaseCode(fop, jith);
 98147:         }
 98147:     }
 99476: 
 99476:     script->destroyJITInfo(fop);
 77434: }
 77434: 
 77398: // Expand all stack frames inlined by the JIT within a compartment.
 74731: void
 77398: ExpandInlineFrames(JSCompartment *compartment);
 77353: 
 77353: // Return all VMFrames in a compartment to the interpreter. This must be
 77353: // followed by destroying all JIT code in the compartment.
 77353: void
 77353: ClearAllFrames(JSCompartment *compartment);
 76185: 
 76185: // Information about a frame inlined during compilation.
 76185: struct InlineFrame
 76185: {
 76185:     InlineFrame *parent;
 76185:     jsbytecode *parentpc;
 82129:     HeapPtrFunction fun;
 76185: 
 76185:     // Total distance between the start of the outer JSStackFrame and the start
 76185:     // of this frame, in multiples of sizeof(Value).
 84755:     uint32_t depth;
 76185: };
 74731: 
 53498: struct CallSite
 53168: {
 84755:     uint32_t codeOffset;
 84755:     uint32_t inlineIndex;
 84755:     uint32_t pcOffset;
 76185:     RejoinState rejoin;
 57766: 
 84755:     void initialize(uint32_t codeOffset, uint32_t inlineIndex, uint32_t pcOffset,
 84755:                     RejoinState rejoin) {
 57766:         this->codeOffset = codeOffset;
 76185:         this->inlineIndex = inlineIndex;
 57766:         this->pcOffset = pcOffset;
 76185:         this->rejoin = rejoin;
 57766:     }
 57766: 
 57766:     bool isTrap() const {
 76185:         return rejoin == REJOIN_TRAP;
 57766:     }
 53168: };
 53168: 
 69852: void
 69852: DumpAllProfiles(JSContext *cx);
 69852: 
 58993: inline void * bsearch_nmap(NativeMapEntry *nmap, size_t nPairs, size_t bcOff)
 58993: {
 58993:     size_t lo = 1, hi = nPairs;
 58993:     while (1) {
 58993:         /* current unsearched space is from lo-1 to hi-1, inclusive. */
 58993:         if (lo > hi)
 58993:             return NULL; /* not found */
 58993:         size_t mid       = (lo + hi) / 2;
 58993:         size_t bcOff_mid = nmap[mid-1].bcOff;
 58993:         if (bcOff < bcOff_mid) {
 58993:             hi = mid-1;
 58993:             continue;
 58993:         }
 58993:         if (bcOff > bcOff_mid) {
 58993:             lo = mid+1;
 58993:             continue;
 58993:         }
 58993:         return nmap[mid-1].ncode;
 58993:     }
 58993: }
 58993: 
 95100: static inline bool
 95100: IsLowerableFunCallOrApply(jsbytecode *pc)
 95100: {
 95100: #ifdef JS_MONOIC
 95100:     return (*pc == JSOP_FUNCALL && GET_ARGC(pc) >= 1) ||
 95100:            (*pc == JSOP_FUNAPPLY && GET_ARGC(pc) == 2);
 95100: #else
 95100:     return false;
 95100: #endif
 95100: }
 95100: 
 52557: } /* namespace mjit */
 52557: 
 87654: inline mjit::JITChunk *
 87654: VMFrame::chunk()
 87654: {
 87654:     return jit()->chunk(regs.pc);
 87654: }
 87654: 
 87654: inline unsigned
 87654: VMFrame::chunkIndex()
 87654: {
 87654:     return jit()->chunkIndex(regs.pc);
 87654: }
 87654: 
 76185: inline JSScript *
 76185: VMFrame::script()
 76185: {
 76185:     if (regs.inlined())
 87654:         return chunk()->inlineFrames()[regs.inlined()->inlineIndex].fun->script();
 76185:     return fp()->script();
 76185: }
 76185: 
 76185: inline jsbytecode *
 76185: VMFrame::pc()
 76185: {
 76185:     if (regs.inlined())
 76185:         return script()->code + regs.inlined()->pcOffset;
 76185:     return regs.pc;
 76185: }
 76185: 
 52557: } /* namespace js */
 52557: 
 55687: inline void *
 87654: JSScript::nativeCodeForPC(bool constructing, jsbytecode *pc)
 55687: {
 98147:     js::mjit::JITScript *jit = getJIT(constructing, compartment()->needsBarrier());
 55687:     if (!jit)
 55687:         return NULL;
 87654:     js::mjit::JITChunk *chunk = jit->chunk(pc);
 87654:     if (!chunk)
 87654:         return NULL;
 87654:     return bsearch_nmap(chunk->nmap(), chunk->nNmapPairs, (size_t)(pc - code));
 55687: }
 55687: 
 76185: extern "C" void JaegerTrampolineReturn();
 76185: extern "C" void JaegerInterpoline();
 76185: extern "C" void JaegerInterpolineScripted();
 76185: 
 64272: #if defined(_MSC_VER) || defined(_WIN64)
 52557: extern "C" void *JaegerThrowpoline(js::VMFrame *vmFrame);
 52557: #else
 52557: extern "C" void JaegerThrowpoline();
 52557: #endif
 52557: 
 77389: #if (defined(JS_NO_FASTCALL) && defined(JS_CPU_X86)) || defined(_WIN64)
 76185: extern "C" void JaegerInterpolinePatched();
 76185: #endif
 76185: 
 52557: #endif /* jsjaeger_h__ */
 52880: 
