52826: /* -*- Mode: C++; tab-width: 4; indent-tabs-mode: nil; c-basic-offset: 4 -*-
52826:  * vim: set ts=4 sw=4 et tw=99:
52826:  *
52826:  * ***** BEGIN LICENSE BLOCK *****
52826:  * Version: MPL 1.1/GPL 2.0/LGPL 2.1
52826:  *
52826:  * The contents of this file are subject to the Mozilla Public License Version
52826:  * 1.1 (the "License"); you may not use this file except in compliance with
52826:  * the License. You may obtain a copy of the License at
52826:  * http://www.mozilla.org/MPL/
52826:  *
52826:  * Software distributed under the License is distributed on an "AS IS" basis,
52826:  * WITHOUT WARRANTY OF ANY KIND, either express or implied. See the License
52826:  * for the specific language governing rights and limitations under the
52826:  * License.
52826:  *
52826:  * The Original Code is Mozilla SpiderMonkey JavaScript 1.9 code, released
52826:  * May 28, 2008.
52826:  *
52826:  * The Initial Developer of the Original Code is
52826:  *   Brendan Eich <brendan@mozilla.org>
52826:  *
52826:  * Contributor(s):
52826:  *   David Anderson <danderson@mozilla.com>
52826:  *   David Mandelin <dmandelin@mozilla.com>
52826:  *
52826:  * Alternatively, the contents of this file may be used under the terms of
52826:  * either of the GNU General Public License Version 2 or later (the "GPL"),
52826:  * or the GNU Lesser General Public License Version 2.1 or later (the "LGPL"),
52826:  * in which case the provisions of the GPL or the LGPL are applicable instead
52826:  * of those above. If you wish to allow use of your version of this file only
52826:  * under the terms of either the GPL or the LGPL, and not to allow others to
52826:  * use your version of this file under the terms of the MPL, indicate your
52826:  * decision by deleting the provisions above and replace them with the notice
52826:  * and other provisions required by the GPL or the LGPL. If you do not delete
52826:  * the provisions above, a recipient may use your version of this file under
52826:  * the terms of any one of the MPL, the GPL or the LGPL.
52826:  *
52826:  * ***** END LICENSE BLOCK ***** */
52826: #include "jsscope.h"
52826: #include "jsnum.h"
52826: #include "MonoIC.h"
52826: #include "StubCalls.h"
53590: #include "StubCalls-inl.h"
53301: #include "assembler/assembler/LinkBuffer.h"
52826: #include "assembler/assembler/RepatchBuffer.h"
53301: #include "assembler/assembler/MacroAssembler.h"
53590: #include "assembler/assembler/CodeLocation.h"
53301: #include "CodeGenIncludes.h"
53590: #include "methodjit/Compiler.h"
53590: #include "InlineFrameAssembler.h"
53263: #include "jsobj.h"
53840: 
53840: #include "jsinterpinlines.h"
53263: #include "jsobjinlines.h"
52826: #include "jsscopeinlines.h"
53590: #include "jsscriptinlines.h"
52826: 
52826: using namespace js;
52826: using namespace js::mjit;
52826: using namespace js::mjit::ic;
52826: 
53590: typedef JSC::MacroAssembler::RegisterID RegisterID;
53590: typedef JSC::MacroAssembler::Address Address;
53590: typedef JSC::MacroAssembler::Jump Jump;
53590: typedef JSC::MacroAssembler::Imm32 Imm32;
53590: typedef JSC::MacroAssembler::ImmPtr ImmPtr;
53590: typedef JSC::MacroAssembler::Call Call;
53590: 
53119: #if defined JS_MONOIC
53119: 
52826: static void
52831: PatchGetFallback(VMFrame &f, ic::MICInfo &mic)
52826: {
52826:     JSC::RepatchBuffer repatch(mic.stubEntry.executableAddress(), 64);
52826:     JSC::FunctionPtr fptr(JS_FUNC_TO_DATA_PTR(void *, stubs::GetGlobalName));
52826:     repatch.relink(mic.stubCall, fptr);
52826: }
52826: 
52826: void JS_FASTCALL
52826: ic::GetGlobalName(VMFrame &f, uint32 index)
52826: {
53840:     JSObject *obj = f.fp()->scopeChain().getGlobal();
53840:     ic::MICInfo &mic = f.fp()->script()->mics[index];
53840:     JSAtom *atom = f.fp()->script()->getAtom(GET_INDEX(f.regs.pc));
52826:     jsid id = ATOM_TO_JSID(atom);
52826: 
53116:     JS_ASSERT(mic.kind == ic::MICInfo::GET);
53116: 
52826:     JS_LOCK_OBJ(f.cx, obj);
53531:     const Shape *shape = obj->nativeLookup(id);
53531:     if (!shape ||
53531:         !shape->hasDefaultGetterOrIsMethod() ||
53531:         !shape->hasSlot())
52826:     {
53531:         JS_UNLOCK_OBJ(f.cx, obj);
53531:         if (shape)
52831:             PatchGetFallback(f, mic);
52826:         stubs::GetGlobalName(f);
52826:         return;
52826:     }
53531:     uint32 slot = shape->slot;
53531:     JS_UNLOCK_OBJ(f.cx, obj);
52826: 
53133:     mic.u.name.touched = true;
52826: 
52826:     /* Patch shape guard. */
52826:     JSC::RepatchBuffer repatch(mic.entry.executableAddress(), 50);
53531:     repatch.repatch(mic.shape, obj->shape());
52826: 
52826:     /* Patch loads. */
53117:     JS_ASSERT(slot >= JS_INITIAL_NSLOTS);
52826:     slot -= JS_INITIAL_NSLOTS;
52826:     slot *= sizeof(Value);
52826:     JSC::RepatchBuffer loads(mic.load.executableAddress(), 32, false);
53451: #if defined JS_CPU_X86
53269:     loads.repatch(mic.load.dataLabel32AtOffset(MICInfo::GET_DATA_OFFSET), slot);
52831:     loads.repatch(mic.load.dataLabel32AtOffset(MICInfo::GET_TYPE_OFFSET), slot + 4);
53451: #elif defined JS_CPU_ARM
53451:     // mic.load actually points to the LDR instruction which fetches the offset, but 'repatch'
53451:     // knows how to dereference it to find the integer value.
53451:     loads.repatch(mic.load.dataLabel32AtOffset(0), slot);
53269: #elif defined JS_PUNBOX64
53269:     loads.repatch(mic.load.dataLabel32AtOffset(mic.patchValueOffset), slot);
53269: #endif
52826: 
52826:     /* Do load anyway... this time. */
52826:     stubs::GetGlobalName(f);
52826: }
52826: 
52831: static void JS_FASTCALL
52831: SetGlobalNameSlow(VMFrame &f, uint32 index)
52831: {
53840:     JSAtom *atom = f.fp()->script()->getAtom(GET_INDEX(f.regs.pc));
52831:     stubs::SetGlobalName(f, atom);
52831: }
52831: 
52831: static void
52831: PatchSetFallback(VMFrame &f, ic::MICInfo &mic)
52831: {
52831:     JSC::RepatchBuffer repatch(mic.stubEntry.executableAddress(), 64);
52831:     JSC::FunctionPtr fptr(JS_FUNC_TO_DATA_PTR(void *, SetGlobalNameSlow));
52831:     repatch.relink(mic.stubCall, fptr);
52831: }
52831: 
53512: static VoidStubAtom
53512: GetStubForSetGlobalName(VMFrame &f)
53512: {
53512:     // The property cache doesn't like inc ops, so we use a simpler
53512:     // stub for that case.
53512:     return js_CodeSpec[*f.regs.pc].format & (JOF_INC | JOF_DEC)
53512:          ? stubs::SetGlobalNameDumb
53512:          : stubs::SetGlobalName;
53512: }
53512: 
52831: void JS_FASTCALL
52831: ic::SetGlobalName(VMFrame &f, uint32 index)
52831: {
53840:     JSObject *obj = f.fp()->scopeChain().getGlobal();
53840:     ic::MICInfo &mic = f.fp()->script()->mics[index];
53840:     JSAtom *atom = f.fp()->script()->getAtom(GET_INDEX(f.regs.pc));
52831:     jsid id = ATOM_TO_JSID(atom);
52831: 
53116:     JS_ASSERT(mic.kind == ic::MICInfo::SET);
53116: 
52831:     JS_LOCK_OBJ(f.cx, obj);
53531:     const Shape *shape = obj->nativeLookup(id);
53531:     if (!shape ||
53531:         !shape->hasDefaultGetterOrIsMethod() ||
53531:         !shape->writable() ||
53531:         !shape->hasSlot())
52831:     {
53531:         JS_UNLOCK_OBJ(f.cx, obj);
53531:         if (shape)
52831:             PatchSetFallback(f, mic);
53512:         GetStubForSetGlobalName(f)(f, atom);
52831:         return;
52831:     }
53531:     uint32 slot = shape->slot;
53531:     JS_UNLOCK_OBJ(f.cx, obj);
52831: 
53133:     mic.u.name.touched = true;
52831: 
52831:     /* Patch shape guard. */
52831:     JSC::RepatchBuffer repatch(mic.entry.executableAddress(), 50);
53531:     repatch.repatch(mic.shape, obj->shape());
52831: 
52831:     /* Patch loads. */
53117:     JS_ASSERT(slot >= JS_INITIAL_NSLOTS);
52831:     slot -= JS_INITIAL_NSLOTS;
52831:     slot *= sizeof(Value);
52831: 
52831:     JSC::RepatchBuffer stores(mic.load.executableAddress(), 32, false);
53451: #if defined JS_CPU_X86
52831:     stores.repatch(mic.load.dataLabel32AtOffset(MICInfo::SET_TYPE_OFFSET), slot + 4);
52831: 
52831:     uint32 dataOffset;
53133:     if (mic.u.name.typeConst)
52831:         dataOffset = MICInfo::SET_DATA_CONST_TYPE_OFFSET;
52831:     else
52831:         dataOffset = MICInfo::SET_DATA_TYPE_OFFSET;
52831:     stores.repatch(mic.load.dataLabel32AtOffset(dataOffset), slot);
53451: #elif defined JS_CPU_ARM
53451:     // mic.load actually points to the LDR instruction which fetches the offset, but 'repatch'
53451:     // knows how to dereference it to find the integer value.
53451:     stores.repatch(mic.load.dataLabel32AtOffset(0), slot);
53269: #elif defined JS_PUNBOX64
53269:     stores.repatch(mic.load.dataLabel32AtOffset(mic.patchValueOffset), slot);
53269: #endif
52831: 
53511:     // Actually implement the op the slow way.
53512:     GetStubForSetGlobalName(f)(f, atom);
52831: }
52831: 
53590: static void * JS_FASTCALL
53590: SlowCallFromIC(VMFrame &f, uint32 index)
53590: {
53840:     JSScript *oldscript = f.fp()->script();
53590:     CallICInfo &ic= oldscript->callICs[index];
53301: 
53590:     stubs::SlowCall(f, ic.argc);
53523: 
53590:     return NULL;
53301: }
53301: 
53590: static void * JS_FASTCALL
53590: SlowNewFromIC(VMFrame &f, uint32 index)
53301: {
53840:     JSScript *oldscript = f.fp()->script();
53590:     CallICInfo &ic = oldscript->callICs[index];
53590: 
53590:     stubs::SlowNew(f, ic.argc);
53590: 
53590:     return NULL;
53523: }
53522: 
53590: /*
53590:  * Calls have an inline path and an out-of-line path. The inline path is used
53590:  * in the fastest case: the method has JIT'd code, and |argc == nargs|.
53590:  * 
53590:  * The inline path and OOL path are separated by a guard on the identity of
53590:  * the callee object. This guard starts as NULL and always fails on the first
53590:  * hit. On the OOL path, the callee is verified to be both a function and a
53590:  * scripted function. If these conditions hold, |ic::Call| is invoked.
53590:  *
53590:  * |ic::Call| first ensures that the callee has JIT code. If it doesn't, the
53590:  * call to |ic::Call| is patched to a slow path. If it does have JIT'd code,
53590:  * the following cases can occur:
53590:  *
53590:  *   1) args != nargs: The call to |ic::Call| is patched with a dynamically
53590:  *      generated stub. This stub inlines a path that looks like:
53590:  *      ----
53590:  *      push frame
53590:  *      if (callee is not compiled) {
53590:  *          Compile(callee);
53590:  *      }
53590:  *      call callee->arityLabel
53590:  *
53590:  *      The arity label is a special entry point for correcting frames for
53590:  *      arity mismatches.
53590:  *
53590:  *   2) args == nargs, and the inline call site was not patched yet.
53590:  *      The guard dividing the two paths is patched to guard on the given
53590:  *      function object identity, and the proceeding call is patched to
53590:  *      directly call the JIT code.
53590:  *
53590:  *   3) args == nargs, and the inline call site was patched already.
53590:  *      A small stub is created which extends the original guard to also
53590:  *      guard on the JSFunction lying underneath the function object.
53590:  *
53590:  * If the OOL path does not have a scripted function, but does have a
53590:  * scripted native, then a small stub is generated which inlines the native
53590:  * invocation.
53590:  */
53590: class CallCompiler
53590: {
53590:     VMFrame &f;
53590:     JSContext *cx;
53590:     CallICInfo &ic;
53590:     Value *vp;
53590:     bool callingNew;
53306: 
53590:   public:
53590:     CallCompiler(VMFrame &f, CallICInfo &ic, bool callingNew)
53590:       : f(f), cx(f.cx), ic(ic), vp(f.regs.sp - (ic.argc + 2)), callingNew(callingNew)
53590:     {
53590:     }
53301: 
53590:     JSC::ExecutablePool *poolForSize(size_t size, CallICInfo::PoolIndex index)
53590:     {
53590:         mjit::ThreadData *jm = &JS_METHODJIT_DATA(cx);
53590:         JSC::ExecutablePool *ep = jm->execPool->poolForSize(size);
53590:         if (!ep) {
53590:             js_ReportOutOfMemory(f.cx);
53590:             return NULL;
53590:         }
53590:         JS_ASSERT(!ic.pools[index]);
53590:         ic.pools[index] = ep;
53590:         return ep;
53590:     }
53301: 
53590:     bool generateFullCallStub(JSScript *script, uint32 flags)
53590:     {
53590:         /*
53590:          * Create a stub that works with arity mismatches. Like the fast-path,
53590:          * this allocates a frame on the caller side, but also performs extra
53590:          * checks for compilability. Perhaps this should be a separate, shared
53590:          * trampoline, but for now we generate it dynamically.
53590:          */
53590:         Assembler masm;
54163:         InlineFrameAssembler inlFrame(masm, ic, flags);
53590:         RegisterID t0 = inlFrame.tempRegs.takeAnyReg();
53301: 
53590:         /* Generate the inline frame creation. */
53590:         inlFrame.assemble();
53301: 
53590:         /* funPtrReg is still valid. Check if a compilation is needed. */
53590:         Address scriptAddr(ic.funPtrReg, offsetof(JSFunction, u) +
53590:                            offsetof(JSFunction::U::Scripted, script));
53590:         masm.loadPtr(scriptAddr, t0);
53301: 
53590:         /*
53590:          * Test if script->nmap is NULL - same as checking ncode, but faster
53590:          * here since ncode has two failure modes and we need to load out of
53590:          * nmap anyway.
53590:          */
53590:         masm.loadPtr(Address(t0, offsetof(JSScript, jit)), t0);
53590:         Jump hasCode = masm.branchTestPtr(Assembler::NonZero, t0, t0);
53523: 
53590:         /* Try and compile. On success we get back the nmap pointer. */
53590:         masm.storePtr(JSFrameReg, FrameAddress(offsetof(VMFrame, regs.fp)));
53840:         masm.move(Imm32(ic.argc), Registers::ArgReg1);
53590:         JSC::MacroAssembler::Call tryCompile =
53590:             masm.stubCall(JS_FUNC_TO_DATA_PTR(void *, stubs::CompileFunction),
53590:                           script->code, ic.frameDepth);
53590: 
53590:         Jump notCompiled = masm.branchTestPtr(Assembler::Zero, Registers::ReturnReg,
53590:                                               Registers::ReturnReg);
53590: 
53590:         masm.call(Registers::ReturnReg);
53590:         Jump done = masm.jump();
53590: 
53590:         hasCode.linkTo(masm.label(), &masm);
53590: 
53590:         /* Get nmap[ARITY], set argc, call. */
53590:         masm.move(Imm32(ic.argc), JSParamReg_Argc);
53590:         masm.loadPtr(Address(t0, offsetof(JITScript, arityCheck)), t0);
53590:         masm.call(t0);
53590: 
53590:         /* Rejoin with the fast path. */
53590:         Jump rejoin = masm.jump();
53590: 
53590:         /* Worst case - function didn't compile. */
53590:         notCompiled.linkTo(masm.label(), &masm);
53590:         masm.loadPtr(FrameAddress(offsetof(VMFrame, regs.fp)), JSFrameReg);
53590:         notCompiled = masm.jump();
53590: 
53590:         JSC::ExecutablePool *ep = poolForSize(masm.size(), CallICInfo::Pool_ScriptStub);
53590:         if (!ep)
53590:             return false;
53590: 
53590:         JSC::LinkBuffer buffer(&masm, ep);
53590:         buffer.link(rejoin, ic.funGuard.labelAtOffset(ic.joinPointOffset));
53590:         buffer.link(done, ic.funGuard.labelAtOffset(ic.joinPointOffset));
53590:         buffer.link(notCompiled, ic.slowPathStart.labelAtOffset(ic.slowJoinOffset));
53590:         buffer.link(tryCompile,
53590:                     JSC::FunctionPtr(JS_FUNC_TO_DATA_PTR(void *, stubs::CompileFunction)));
53590:         JSC::CodeLocationLabel cs = buffer.finalizeCodeAddendum();
53590: 
53590:         JaegerSpew(JSpew_PICs, "generated CALL stub %p (%d bytes)\n", cs.executableAddress(),
53590:                    masm.size());
53590: 
53590:         JSC::CodeLocationJump oolJump = ic.slowPathStart.jumpAtOffset(ic.oolJumpOffset);
53590:         uint8 *start = (uint8 *)oolJump.executableAddress();
53590:         JSC::RepatchBuffer repatch(start - 32, 64);
53590:         repatch.relink(oolJump, cs);
53590: 
53590:         return true;
53590:     }
53590: 
53590:     void patchInlinePath(JSScript *script, JSObject *obj)
53590:     {
53590:         /* Very fast path. */
53590:         uint8 *start = (uint8 *)ic.funGuard.executableAddress();
53590:         JSC::RepatchBuffer repatch(start - 32, 64);
53590: 
53590:         ic.fastGuardedObject = obj;
53590: 
53590:         repatch.repatch(ic.funGuard, obj);
53590:         repatch.relink(ic.funGuard.callAtOffset(ic.hotCallOffset),
53590:                        JSC::FunctionPtr(script->ncode));
53590: 
53590:         JaegerSpew(JSpew_PICs, "patched CALL path %p (obj: %p)\n", start, ic.fastGuardedObject);
53590:     }
53590: 
53590:     bool generateStubForClosures(JSObject *obj)
53590:     {
53590:         /* Slightly less fast path - guard on fun->getFunctionPrivate() instead. */
53590:         Assembler masm;
53590: 
53590:         Registers tempRegs;
53590:         tempRegs.takeReg(ic.funObjReg);
53590: 
53590:         RegisterID t0 = tempRegs.takeAnyReg();
53590: 
53590:         /* Guard that it's actually a function object. */
53590:         Jump claspGuard = masm.branchPtr(Assembler::NotEqual,
53590:                                          Address(ic.funObjReg, offsetof(JSObject, clasp)),
53590:                                          ImmPtr(&js_FunctionClass));
53590: 
53590:         /* Guard that it's the same function. */
53590:         JSFunction *fun = obj->getFunctionPrivate();
53590:         masm.loadFunctionPrivate(ic.funObjReg, t0);
53590:         Jump funGuard = masm.branchPtr(Assembler::NotEqual, t0, ImmPtr(fun));
53590:         Jump done = masm.jump();
53590: 
53590:         JSC::ExecutablePool *ep = poolForSize(masm.size(), CallICInfo::Pool_ClosureStub);
53590:         if (!ep)
53590:             return false;
53590: 
53590:         JSC::LinkBuffer buffer(&masm, ep);
53590:         buffer.link(claspGuard, ic.slowPathStart);
53590:         buffer.link(funGuard, ic.slowPathStart);
53590:         buffer.link(done, ic.funGuard.labelAtOffset(ic.hotPathOffset));
53590:         JSC::CodeLocationLabel cs = buffer.finalizeCodeAddendum();
53590: 
53590:         JaegerSpew(JSpew_PICs, "generated CALL closure stub %p (%d bytes)\n",
53590:                    cs.executableAddress(), masm.size());
53590: 
53590:         uint8 *start = (uint8 *)ic.funJump.executableAddress();
53590:         JSC::RepatchBuffer repatch(start - 32, 64);
53590:         repatch.relink(ic.funJump, cs);
53590: 
53590:         ic.hasJsFunCheck = true;
53590: 
53590:         return true;
53590:     }
53590: 
53590:     bool generateNativeStub()
53590:     {
53590:         Value *vp = f.regs.sp - (ic.argc + 2);
53590: 
53590:         JSObject *obj;
53590:         if (!IsFunctionObject(*vp, &obj))
53590:             return false;
53590: 
53590:         JSFunction *fun = obj->getFunctionPrivate();
53590:         if ((!callingNew && !fun->isNative()) || (callingNew && !fun->isConstructor()))
53590:             return false;
53590: 
53590:         if (callingNew)
53590:             vp[1].setMagicWithObjectOrNullPayload(NULL);
53590: 
53590:         Native fn = fun->u.n.native;
53590:         if (!fn(cx, ic.argc, vp))
53590:             THROWV(true);
53590: 
53590:         /* Right now, take slow-path for IC misses or multiple stubs. */
53590:         if (ic.fastGuardedNative || ic.hasJsFunCheck)
53590:             return true;
53590: 
53590:         /* Native MIC needs to warm up first. */
53590:         if (!ic.hit) {
53590:             ic.hit = true;
53590:             return true;
53590:         }
53590: 
53590:         /* Generate fast-path for calling this native. */
53590:         Assembler masm;
53590: 
53590:         /* Guard on the function object identity, for now. */
53590:         Jump funGuard = masm.branchPtr(Assembler::NotEqual, ic.funObjReg, ImmPtr(obj));
53590: 
53590:         Registers tempRegs;
53590: #ifndef JS_CPU_X86
53590:         tempRegs.takeReg(Registers::ArgReg0);
53590:         tempRegs.takeReg(Registers::ArgReg1);
53590:         tempRegs.takeReg(Registers::ArgReg2);
53590: #endif
53590:         RegisterID t0 = tempRegs.takeAnyReg();
53590: 
53590:         /* Store pc. */
53590:         masm.storePtr(ImmPtr(cx->regs->pc),
53301:                        FrameAddress(offsetof(VMFrame, regs) + offsetof(JSFrameRegs, pc)));
53301: 
53301:         /* Store sp. */
53590:         uint32 spOffset = sizeof(JSStackFrame) + ic.frameDepth * sizeof(Value);
53590:         masm.addPtr(Imm32(spOffset), JSFrameReg, t0);
53590:         masm.storePtr(t0, FrameAddress(offsetof(VMFrame, regs) + offsetof(JSFrameRegs, sp)));
53301: 
53590:         /* Grab cx early on to avoid stack mucking on x86. */
53590: #ifdef JS_CPU_X86
53590:         RegisterID cxReg = tempRegs.takeAnyReg();
53590: #else
53590:         RegisterID cxReg = Registers::ArgReg0;
53590: #endif
53590:         masm.loadPtr(FrameAddress(offsetof(VMFrame, cx)), cxReg);
53301: 
53590: #ifdef JS_CPU_X86
53590:         /* x86's stack should be 16-byte aligned. */
53590:         masm.subPtr(Imm32(16), Assembler::stackPointerRegister);
53590: #endif
53301: 
53590:         /* Compute vp. */
53590: #ifdef JS_CPU_X86
53590:         RegisterID vpReg = t0;
53590: #else
53590:         RegisterID vpReg = Registers::ArgReg2;
53590: #endif
53590:         
53590:         uint32 vpOffset = sizeof(JSStackFrame) + (ic.frameDepth - ic.argc - 2) * sizeof(Value);
53590:         masm.addPtr(Imm32(vpOffset), JSFrameReg, vpReg);
53590: 
53590:         /* Mark vp[1] as magic for |new|. */
53590:         if (callingNew) {
53590:             Value v;
53590:             v.setMagicWithObjectOrNullPayload(NULL);
53590:             masm.storeValue(v, Address(vpReg, sizeof(Value)));
53523:         }
53306: 
53590: #ifdef JS_CPU_X86
53590:         masm.storePtr(vpReg, Address(Assembler::stackPointerRegister, 8));
53590: #endif
53301: 
53590:         /* Push argc. */
53590: #ifdef JS_CPU_X86
53590:         masm.store32(Imm32(ic.argc), Address(Assembler::stackPointerRegister, 4));
53590: #else
53590:         masm.move(Imm32(ic.argc), Registers::ArgReg1);
53590: #endif
53301: 
53590:         /* Push cx. */
53590: #ifdef JS_CPU_X86
53590:         masm.storePtr(cxReg, Address(Assembler::stackPointerRegister, 0));
53590: #endif
53301: 
53862: #ifdef _WIN64
53862:         /* x64 needs to pad the stack */
53862:         masm.subPtr(Imm32(32), Assembler::stackPointerRegister);
53862: #endif
53590:         /* Make the call. */
53590:         Assembler::Call call = masm.call();
53590: 
53590: #ifdef JS_CPU_X86
53590:         masm.addPtr(Imm32(16), Assembler::stackPointerRegister);
53590: #endif
53590: #if defined(JS_NO_FASTCALL) && defined(JS_CPU_X86)
53590:         // Usually JaegerThrowpoline got called from return address.
53590:         // So in JaegerThrowpoline without fastcall, esp was added by 8.
53590:         // If we just want to jump there, we need to sub esp by 8 first.
53590:         masm.subPtr(Imm32(8), Assembler::stackPointerRegister);
53590: #endif
53590: 
53590:         Jump hasException = masm.branchTest32(Assembler::Zero, Registers::ReturnReg,
53590:                                               Registers::ReturnReg);
53590:         
53301: 
53326: #if defined(JS_NO_FASTCALL) && defined(JS_CPU_X86)
53326:         // Usually JaegerThrowpoline got called from return address.
53326:         // So in JaegerThrowpoline without fastcall, esp was added by 8.
53326:         // If we just want to jump there, we need to sub esp by 8 first.
53590:         masm.addPtr(Imm32(8), Assembler::stackPointerRegister);
53862: #elif defined(_WIN64)
53862:         /* JaegerThrowpoline expcets that stack is added by 32 for padding */
53862:         masm.addPtr(Imm32(32), Assembler::stackPointerRegister);
53326: #endif
53326: 
53590:         Jump done = masm.jump();
53301: 
53590:         /* Move JaegerThrowpoline into register for very far jump on x64. */
53590:         hasException.linkTo(masm.label(), &masm);
53590:         masm.move(ImmPtr(JS_FUNC_TO_DATA_PTR(void *, JaegerThrowpoline)), Registers::ReturnReg);
53590:         masm.jump(Registers::ReturnReg);
53326: 
53590:         JSC::ExecutablePool *ep = poolForSize(masm.size(), CallICInfo::Pool_NativeStub);
53590:         if (!ep)
53590:             THROWV(true);
53301: 
53590:         JSC::LinkBuffer buffer(&masm, ep);
53590:         buffer.link(done, ic.slowPathStart.labelAtOffset(ic.slowJoinOffset));
53590:         buffer.link(call, JSC::FunctionPtr(JS_FUNC_TO_DATA_PTR(void *, fun->u.n.native)));
53590:         buffer.link(funGuard, ic.slowPathStart);
53590:         
53590:         JSC::CodeLocationLabel cs = buffer.finalizeCodeAddendum();
53590: 
53590:         JaegerSpew(JSpew_PICs, "generated native CALL stub %p (%d bytes)\n",
53590:                    cs.executableAddress(), masm.size());
53590: 
53590:         uint8 *start = (uint8 *)ic.funJump.executableAddress();
53590:         JSC::RepatchBuffer repatch(start - 32, 64);
53590:         repatch.relink(ic.funJump, cs);
53590: 
53590:         ic.fastGuardedNative = obj;
53590: 
53590:         return true;
53301:     }
53301: 
53590:     void *update()
53590:     {
54163:         stubs::UncachedCallResult ucr;
53590:         if (callingNew)
54163:             stubs::UncachedNewHelper(f, ic.argc, &ucr);
53590:         else
54163:             stubs::UncachedCallHelper(f, ic.argc, &ucr);
53590: 
54163:         // If the function cannot be jitted (generally unjittable or empty script),
54163:         // patch this site to go to a slow path always.
54163:         if (!ucr.codeAddr) {
53590:             JSC::CodeLocationCall oolCall = ic.slowPathStart.callAtOffset(ic.oolCallOffset);
53590:             uint8 *start = (uint8 *)oolCall.executableAddress();
53590:             JSC::RepatchBuffer repatch(start - 32, 64);
53590:             JSC::FunctionPtr fptr = callingNew
53590:                                     ? JSC::FunctionPtr(JS_FUNC_TO_DATA_PTR(void *, SlowNewFromIC))
53590:                                     : JSC::FunctionPtr(JS_FUNC_TO_DATA_PTR(void *, SlowCallFromIC));
53590:             repatch.relink(oolCall, fptr);
53590:             return NULL;
53590:         }
53590:             
54163:         JSFunction *fun = ucr.fun;
54163:         JS_ASSERT(fun);
54163:         JSScript *script = fun->script();
54163:         JS_ASSERT(script);
54163:         JSObject *callee = ucr.callee;
54163:         JS_ASSERT(callee);
54163: 
53590:         uint32 flags = callingNew ? JSFRAME_CONSTRUCTING : 0;
53590: 
53590:         if (!ic.hit) {
54163:             ic.hit = true;
54163:             return ucr.codeAddr;
54163:         }
54163: 
53840:         if (ic.argc != fun->nargs) {
53590:             if (!generateFullCallStub(script, flags))
53590:                 THROWV(NULL);
53590:         } else {
53590:             if (!ic.fastGuardedObject) {
54163:                 patchInlinePath(script, callee);
53590:             } else if (!ic.hasJsFunCheck &&
53590:                        !ic.fastGuardedNative &&
53590:                        ic.fastGuardedObject->getFunctionPrivate() == fun) {
53590:                 /*
53590:                  * Note: Multiple "function guard" stubs are not yet
53590:                  * supported, thus the fastGuardedNative check.
53590:                  */
54163:                 if (!generateStubForClosures(callee))
53590:                     THROWV(NULL);
53590:             } else {
53590:                 if (!generateFullCallStub(script, flags))
53590:                     THROWV(NULL);
53590:             }
53590:         }
53590: 
54163:         return ucr.codeAddr;
53590:     }
53590: };
53590: 
53590: void * JS_FASTCALL
53590: ic::Call(VMFrame &f, uint32 index)
53590: {
53840:     JSScript *oldscript = f.fp()->script();
53590:     CallICInfo &ic = oldscript->callICs[index];
53590:     CallCompiler cc(f, ic, false);
53590:     return cc.update();
53590: }
53590: 
53590: void * JS_FASTCALL
53590: ic::New(VMFrame &f, uint32 index)
53590: {
53840:     JSScript *oldscript = f.fp()->script();
53590:     CallICInfo &ic = oldscript->callICs[index];
53590:     CallCompiler cc(f, ic, true);
53590:     return cc.update();
53590: }
53590: 
53590: void JS_FASTCALL
53590: ic::NativeCall(VMFrame &f, uint32 index)
53590: {
53840:     JSScript *oldscript = f.fp()->script();
53590:     CallICInfo &ic = oldscript->callICs[index];
53590:     CallCompiler cc(f, ic, false);
53590:     if (!cc.generateNativeStub())
53590:         stubs::SlowCall(f, ic.argc);
53590: }
53590: 
53590: void JS_FASTCALL
53590: ic::NativeNew(VMFrame &f, uint32 index)
53590: {
53840:     JSScript *oldscript = f.fp()->script();
53590:     CallICInfo &ic = oldscript->callICs[index];
53590:     CallCompiler cc(f, ic, true);
53590:     if (!cc.generateNativeStub())
53590:         stubs::SlowNew(f, ic.argc);
53590: }
53301: 
53405: void
53405: ic::PurgeMICs(JSContext *cx, JSScript *script)
53405: {
53405:     /* MICs are purged during GC to handle changing shapes. */
53405:     JS_ASSERT(cx->runtime->gcRegenShapes);
53405: 
53498:     uint32 nmics = script->jit->nMICs;
53405:     for (uint32 i = 0; i < nmics; i++) {
53405:         ic::MICInfo &mic = script->mics[i];
53405:         switch (mic.kind) {
53405:           case ic::MICInfo::SET:
53405:           case ic::MICInfo::GET:
53405:           {
53405:             /* Patch shape guard. */
53405:             JSC::RepatchBuffer repatch(mic.entry.executableAddress(), 50);
53409:             repatch.repatch(mic.shape, int(JSObjectMap::INVALID_SHAPE));
53405: 
53405:             /* 
53405:              * If the stub call was patched, leave it alone -- it probably will
53405:              * just be invalidated again.
53405:              */
53405:             break;
53405:           }
53405:           case ic::MICInfo::TRACER:
53405:             /* Nothing to patch! */
53405:             break;
53405:           default:
53405:             JS_NOT_REACHED("Unknown MIC type during purge");
53405:             break;
53405:         }
53405:     }
53405: }
53405: 
53590: void
53590: ic::SweepCallICs(JSContext *cx, JSScript *script)
53590: {
53590:     for (uint32 i = 0; i < script->jit->nCallICs; i++) {
53590:         ic::CallICInfo &ic = script->callICs[i];
53590: 
53590:         /*
53590:          * If the object is unreachable, we're guaranteed not to be currently
53590:          * executing a stub generated by a guard on that object. This lets us
53590:          * precisely GC call ICs while keeping the identity guard safe.
53590:          */
53590:         bool fastFunDead = ic.fastGuardedObject && js_IsAboutToBeFinalized(ic.fastGuardedObject);
53590:         bool nativeDead = ic.fastGuardedNative && js_IsAboutToBeFinalized(ic.fastGuardedNative);
53590: 
53590:         if (!fastFunDead && !nativeDead)
53590:             continue;
53590: 
53590:         uint8 *start = (uint8 *)ic.funGuard.executableAddress();
53590:         JSC::RepatchBuffer repatch(start - 32, 64);
53590: 
53590:         if (fastFunDead) {
53590:             repatch.repatch(ic.funGuard, NULL);
53590:             ic.releasePool(CallICInfo::Pool_ClosureStub);
53590:             ic.hasJsFunCheck = false;
53590:             ic.fastGuardedObject = NULL;
53590:         }
53590: 
53590:         if (nativeDead) {
53590:             ic.releasePool(CallICInfo::Pool_NativeStub);
53590:             ic.fastGuardedNative = NULL;
53590:         }
53590: 
53590:         repatch.relink(ic.funJump, ic.slowPathStart);
53590: 
53590:         ic.hit = false;
53590:     }
53590: }
53590: 
53119: #endif /* JS_MONOIC */
53405: 
