29366: /* -*- Mode: C++; tab-width: 8; indent-tabs-mode: nil; c-basic-offset: 4 -*-
    1:  * vim: set ts=8 sw=4 et tw=78:
    1:  *
    1:  * ***** BEGIN LICENSE BLOCK *****
    1:  * Version: MPL 1.1/GPL 2.0/LGPL 2.1
    1:  *
    1:  * The contents of this file are subject to the Mozilla Public License Version
    1:  * 1.1 (the "License"); you may not use this file except in compliance with
    1:  * the License. You may obtain a copy of the License at
    1:  * http://www.mozilla.org/MPL/
    1:  *
    1:  * Software distributed under the License is distributed on an "AS IS" basis,
    1:  * WITHOUT WARRANTY OF ANY KIND, either express or implied. See the License
    1:  * for the specific language governing rights and limitations under the
    1:  * License.
    1:  *
    1:  * The Original Code is Mozilla Communicator client code, released
    1:  * March 31, 1998.
    1:  *
    1:  * The Initial Developer of the Original Code is
    1:  * Netscape Communications Corporation.
    1:  * Portions created by the Initial Developer are Copyright (C) 1998
    1:  * the Initial Developer. All Rights Reserved.
    1:  *
    1:  * Contributor(s):
    1:  *
    1:  * Alternatively, the contents of this file may be used under the terms of
    1:  * either of the GNU General Public License Version 2 or later (the "GPL"),
    1:  * or the GNU Lesser General Public License Version 2.1 or later (the "LGPL"),
    1:  * in which case the provisions of the GPL or the LGPL are applicable instead
    1:  * of those above. If you wish to allow use of your version of this file only
    1:  * under the terms of either the GPL or the LGPL, and not to allow others to
    1:  * use your version of this file under the terms of the MPL, indicate your
    1:  * decision by deleting the provisions above and replace them with the notice
    1:  * and other provisions required by the GPL or the LGPL. If you do not delete
    1:  * the provisions above, a recipient may use your version of this file under
    1:  * the terms of any one of the MPL, the GPL or the LGPL.
    1:  *
    1:  * ***** END LICENSE BLOCK ***** */
    1: 
    1: #ifndef jscntxt_h___
    1: #define jscntxt_h___
    1: /*
    1:  * JS execution context.
    1:  */
38604: #include <string.h>
38604: 
43110: /* Gross special case for Gecko, which defines malloc/calloc/free. */
43110: #ifdef mozilla_mozalloc_macro_wrappers_h
43110: #  define JS_UNDEFD_MOZALLOC_WRAPPERS
43110: /* The "anti-header" */
43110: #  include "mozilla/mozalloc_undef_macro_wrappers.h"
43110: #endif
43110: 
48594: #include "jsprvtd.h"
55477: #include "jsarena.h"
    1: #include "jsclist.h"
    1: #include "jslong.h"
    1: #include "jsatom.h"
    1: #include "jsdhash.h"
40339: #include "jsdtoa.h"
52503: #include "jsfun.h"
    1: #include "jsgc.h"
47400: #include "jsgcchunk.h"
40327: #include "jshashtable.h"
    1: #include "jsinterp.h"
55569: #include "jsmath.h"
    1: #include "jsobj.h"
40359: #include "jspropertycache.h"
40327: #include "jspropertytree.h"
53858: #include "jsstaticcheck.h"
    1: #include "jsutil.h"
30023: #include "jsarray.h"
34299: #include "jsvector.h"
43191: #include "prmjtime.h"
    1: 
39928: #ifdef _MSC_VER
39928: #pragma warning(push)
39928: #pragma warning(disable:4100) /* Silence unreferenced formal parameter warnings */
39928: #pragma warning(push)
39928: #pragma warning(disable:4355) /* Silence warning about "this" used in base member initializer list */
39928: #endif
39928: 
    1: /*
    1:  * js_GetSrcNote cache to avoid O(n^2) growth in finding a source note for a
15530:  * given pc in a script. We use the script->code pointer to tag the cache,
15530:  * instead of the script address itself, so that source notes are always found
15530:  * by offset from the bytecode with which they were generated.
    1:  */
    1: typedef struct JSGSNCache {
15530:     jsbytecode      *code;
    1:     JSDHashTable    table;
    1: #ifdef JS_GSNMETER
    1:     uint32          hits;
    1:     uint32          misses;
    1:     uint32          fills;
26569:     uint32          purges;
    1: # define GSN_CACHE_METER(cache,cnt) (++(cache)->cnt)
    1: #else
    1: # define GSN_CACHE_METER(cache,cnt) /* nothing */
    1: #endif
    1: } JSGSNCache;
    1: 
26569: #define js_FinishGSNCache(cache) js_PurgeGSNCache(cache)
26569: 
26569: extern void
26569: js_PurgeGSNCache(JSGSNCache *cache);
    1: 
    1: /* These helper macros take a cx as parameter and operate on its GSN cache. */
26569: #define JS_PURGE_GSN_CACHE(cx)      js_PurgeGSNCache(&JS_GSN_CACHE(cx))
    1: #define JS_METER_GSN_CACHE(cx,cnt)  GSN_CACHE_METER(&JS_GSN_CACHE(cx), cnt)
    1: 
34572: /* Forward declarations of nanojit types. */
37741: namespace nanojit {
37741: 
31475: class Assembler;
31475: class CodeAlloc;
17937: class Fragment;
33166: template<typename K> struct DefaultHash;
32784: template<typename K, typename V, typename H> class HashMap;
32784: template<typename T> class Seq;
37741: 
37741: }  /* namespace nanojit */
37741: 
50491: namespace JSC {
50491:     class ExecutableAllocator;
50491: }
50491: 
37741: namespace js {
34572: 
34572: /* Tracer constants. */
34572: static const size_t MONITOR_N_GLOBAL_STATES = 4;
34572: static const size_t FRAGMENT_TABLE_SIZE = 512;
34572: static const size_t MAX_NATIVE_STACK_SLOTS = 4096;
34572: static const size_t MAX_CALL_STACK_ENTRIES = 500;
34572: static const size_t MAX_GLOBAL_SLOTS = 4096;
34572: static const size_t GLOBAL_SLOTS_BUFFER_SIZE = MAX_GLOBAL_SLOTS + 1;
42714: static const size_t MAX_SLOW_NATIVE_EXTRA_SLOTS = 16;
34572: 
34572: /* Forward declarations of tracer types. */
34572: class VMAllocator;
34572: class FrameInfoCache;
34572: struct REHashFn;
34572: struct REHashKey;
34572: struct FrameInfo;
34572: struct VMSideExit;
35044: struct TreeFragment;
41276: struct TracerState;
34572: template<typename T> class Queue;
34572: typedef Queue<uint16> SlotList;
39928: class TypeMap;
35044: struct REFragment;
35044: typedef nanojit::HashMap<REHashKey, REFragment*, REHashFn> REHashMap;
56551: class LoopProfile;
34572: 
32784: #if defined(JS_JIT_SPEW) || defined(DEBUG)
32784: struct FragPI;
32788: typedef nanojit::HashMap<uint32, FragPI, nanojit::DefaultHash<uint32> > FragStatsMap;
32784: #endif
17583: 
53382: namespace mjit {
56773: class JaegerCompartment;
53382: }
53382: 
38568: /*
38568:  * Allocation policy that calls JSContext memory functions and reports errors
38568:  * to the context. Since the JSContext given on construction is stored for
38568:  * the lifetime of the container, this policy may only be used for containers
38568:  * whose lifetime is a shorter than the given JSContext.
38568:  */
38568: class ContextAllocPolicy
38568: {
38568:     JSContext *cx;
38568: 
38568:   public:
38568:     ContextAllocPolicy(JSContext *cx) : cx(cx) {}
38568:     JSContext *context() const { return cx; }
38568: 
38568:     /* Inline definitions below. */
38568:     void *malloc(size_t bytes);
38568:     void free(void *p);
38568:     void *realloc(void *p, size_t bytes);
38568:     void reportAllocOverflow() const;
38568: };
38568: 
34572: /* Holds the execution state during trace execution. */
41276: struct TracerState
34572: {
35083:     JSContext*     cx;                  // current VM context handle
35083:     double*        stackBase;           // native stack base
34572:     double*        sp;                  // native stack pointer, stack[0] is spbase[0]
35083:     double*        eos;                 // first unusable word after the native stack / begin of globals
35083:     FrameInfo**    callstackBase;       // call stack base
35083:     void*          sor;                 // start of rp stack
34572:     FrameInfo**    rp;                  // call stack pointer
34572:     void*          eor;                 // first unusable word after the call stack
34572:     VMSideExit*    lastTreeExitGuard;   // guard we exited on during a tree call
34572:     VMSideExit*    lastTreeCallGuard;   // guard we want to grow from if the tree
34572:                                         // call exit guard mismatched
34572:     void*          rpAtLastTreeCall;    // value of rp at innermost tree call guard
34572:     VMSideExit*    outermostTreeExitGuard; // the last side exit returned by js_CallTree
36361:     TreeFragment*  outermostTree;       // the outermost tree we initially invoked
34572:     uintN*         inlineCallCountp;    // inline call count counter
34572:     VMSideExit**   innermostNestedGuardp;
34572:     VMSideExit*    innermost;
34572:     uint64         startTime;
41276:     TracerState*   prev;
24307: 
34572:     // Used by _FAIL builtins; see jsbuiltins.h. The builtin sets the
34572:     // JSBUILTIN_BAILED bit if it bails off trace and the JSBUILTIN_ERROR bit
34572:     // if an error or exception occurred.
34572:     uint32         builtinStatus;
31918: 
34572:     // Used to communicate the location of the return value in case of a deep bail.
34572:     double*        deepBailSp;
34572: 
34572:     // Used when calling natives from trace to root the vp vector.
34572:     uintN          nativeVpLen;
48470:     js::Value*     nativeVp;
35083: 
41276:     TracerState(JSContext *cx, TraceMonitor *tm, TreeFragment *ti,
35083:                 uintN &inlineCallCountp, VMSideExit** innermostNestedGuardp);
41276:     ~TracerState();
34572: };
34572: 
34572: /*
34572:  * Storage for the execution state and store during trace execution. Generated
34572:  * code depends on the fact that the globals begin |MAX_NATIVE_STACK_SLOTS|
41276:  * doubles after the stack begins. Thus, on trace, |TracerState::eos| holds a
34572:  * pointer to the first global.
34572:  */
34572: struct TraceNativeStorage
34572: {
34572:     double stack_global_buf[MAX_NATIVE_STACK_SLOTS + GLOBAL_SLOTS_BUFFER_SIZE];
34572:     FrameInfo *callstack_buf[MAX_CALL_STACK_ENTRIES];
34572: 
34572:     double *stack() { return stack_global_buf; }
34572:     double *global() { return stack_global_buf + MAX_NATIVE_STACK_SLOTS; }
34572:     FrameInfo **callstack() { return callstack_buf; }
34572: };
34572: 
34572: /* Holds data to track a single globa. */
24491: struct GlobalState {
26819:     JSObject*               globalObj;
24491:     uint32                  globalShape;
34299:     SlotList*               globalSlots;
24491: };
24491: 
17583: /*
53840:  * A StackSegment (referred to as just a 'segment') contains a prev-linked set
50467:  * of stack frames and the slots associated with each frame. A segment and its
50467:  * contained frames/slots also have a precise memory layout that is described
50467:  * in the js::StackSpace comment. A key layout invariant for segments is that
53840:  * prev-linked frames are adjacent in memory, separated only by the values that
53840:  * constitute the locals and expression stack of the prev-frame.
37777:  *
48531:  * The set of stack frames in a non-empty segment start at the segment's
48531:  * "current frame", which is the most recently pushed frame, and ends at the
48531:  * segment's "initial frame". Note that, while all stack frames in a segment
53840:  * are prev-linked, not all prev-linked frames are in the same segment. Hence,
53840:  * for a segment |ss|, |ss->getInitialFrame()->prev| may be non-null and in a
50467:  * different segment. This occurs when the VM reenters itself (via Invoke or
50467:  * Execute). In full generality, a single context may contain a forest of trees
50467:  * of stack frames. With respect to this forest, a segment contains a linear
50467:  * path along a single tree, not necessarily to the root.
42714:  *
50467:  * The frames of a non-empty segment must all be in the same context and thus
50467:  * each non-empty segment is referred to as being "in" a context. Segments in a
50467:  * context have an additional state of being either "active" or "suspended". A
51446:  * suspended segment |ss| has a "suspended frame" which is snapshot of |cx->regs|
50467:  * when the segment was suspended and serves as the current frame of |ss|.
50467:  * There is at most one active segment in a given context. Segments in a
50467:  * context execute LIFO and are maintained in a stack.  The top of this stack
50467:  * is the context's "current segment". If a context |cx| has an active segment
50467:  * |ss|, then:
50467:  *   1. |ss| is |cx|'s current segment,
51446:  *   2. |cx->regs != NULL|, and
51446:  *   3. |ss|'s current frame is |cx->regs->fp|.
51446:  * Moreover, |cx->regs != NULL| iff |cx| has an active segment.
42714:  *
50467:  * An empty segment is not associated with any context. Empty segments are
50467:  * created when there is not an active segment for a context at the top of the
50467:  * stack and claim space for the arguments of an Invoke before the Invoke's
50467:  * stack frame is pushed. During the intervals when the arguments have been
50467:  * pushed, but not the stack frame, the segment cannot be pushed onto the
50467:  * context, since that would require some hack to deal with cx->fp not being
50467:  * the current frame of cx->currentSegment.
50467:  *
42714:  * Finally, (to support JS_SaveFrameChain/JS_RestoreFrameChain) a suspended
48531:  * segment may or may not be "saved". Normally, when the active segment is
48531:  * popped, the previous segment (which is necessarily suspended) becomes
48531:  * active. If the previous segment was saved, however, then it stays suspended
48531:  * until it is made active by a call to JS_RestoreFrameChain. This is why a
48531:  * context may have a current segment, but not an active segment.
37777:  */
50466: class StackSegment
37777: {
48531:     /* The context to which this segment belongs. */
37777:     JSContext           *cx;
42714: 
48531:     /* Link for JSContext segment stack mentioned in big comment above. */
50466:     StackSegment        *previousInContext;
48531: 
48531:     /* Link for StackSpace segment stack mentioned in StackSpace comment. */
50466:     StackSegment        *previousInMemory;
48531: 
48531:     /* The first frame executed in this segment. null iff cx is null */
42714:     JSStackFrame        *initialFrame;
37777: 
50467:     /* If this segment is suspended, |cx->regs| when it was suspended. */
50467:     JSFrameRegs         *suspendedRegs;
37777: 
37777:     /* The varobj on entry to initialFrame. */
37777:     JSObject            *initialVarObj;
37777: 
50467:     /* Whether this segment was suspended by JS_SaveFrameChain. */
50467:     bool                saved;
50467: 
51446:     /* Align at 8 bytes on all platforms. */
51446: #if JS_BITS_PER_WORD == 32
51446:     void                *padding;
51446: #endif
51446: 
50467:     /*
50467:      * To make isActive a single null-ness check, this non-null constant is
51446:      * assigned to suspendedRegs when !inContext.
50467:      */
51446: #define NON_NULL_SUSPENDED_REGS ((JSFrameRegs *)0x1)
50467: 
37777:   public:
50466:     StackSegment()
48531:       : cx(NULL), previousInContext(NULL), previousInMemory(NULL),
51446:         initialFrame(NULL), suspendedRegs(NON_NULL_SUSPENDED_REGS),
51446:         initialVarObj(NULL), saved(false)
50467:     {
50467:         JS_ASSERT(!inContext());
50467:     }
37777: 
42714:     /* Safe casts guaranteed by the contiguous-stack layout. */
42714: 
53840:     Value *valueRangeBegin() const {
48470:         return (Value *)(this + 1);
37777:     }
37777: 
42714:     /*
48531:      * As described in the comment at the beginning of the class, a segment
42714:      * is in one of three states:
42714:      *
48531:      *  !inContext:  the segment has been created to root arguments for a
50467:      *               future call to Invoke.
48531:      *  isActive:    the segment describes a set of stack frames in a context,
42714:      *               where the top frame currently executing.
42714:      *  isSuspended: like isActive, but the top frame has been suspended.
42714:      */
42714: 
42714:     bool inContext() const {
42714:         JS_ASSERT(!!cx == !!initialFrame);
51446:         JS_ASSERT_IF(!cx, suspendedRegs == NON_NULL_SUSPENDED_REGS && !saved);
50467:         return cx;
42714:     }
42714: 
42714:     bool isActive() const {
51446:         JS_ASSERT_IF(!suspendedRegs, cx && !saved);
51446:         JS_ASSERT_IF(!cx, suspendedRegs == NON_NULL_SUSPENDED_REGS);
51446:         return !suspendedRegs;
42714:     }
42714: 
42714:     bool isSuspended() const {
51446:         JS_ASSERT_IF(!cx || !suspendedRegs, !saved);
51446:         JS_ASSERT_IF(!cx, suspendedRegs == NON_NULL_SUSPENDED_REGS);
51446:         return cx && suspendedRegs;
37777:     }
37777: 
42714:     /* Substate of suspended, queryable in any state. */
50466: 
37777:     bool isSaved() const {
50467:         JS_ASSERT_IF(saved, isSuspended());
50467:         return saved;
37777:     }
42714: 
42714:     /* Transitioning between inContext <--> isActive */
42714: 
42714:     void joinContext(JSContext *cx, JSStackFrame *f) {
42714:         JS_ASSERT(!inContext());
42714:         this->cx = cx;
42714:         initialFrame = f;
51446:         suspendedRegs = NULL;
42714:         JS_ASSERT(isActive());
42714:     }
42714: 
42714:     void leaveContext() {
42714:         JS_ASSERT(isActive());
42714:         this->cx = NULL;
42714:         initialFrame = NULL;
51446:         suspendedRegs = NON_NULL_SUSPENDED_REGS;
42714:         JS_ASSERT(!inContext());
42714:     }
42714: 
42714:     JSContext *maybeContext() const {
42714:         return cx;
42714:     }
42714: 
51446: #undef NON_NULL_SUSPENDED_REGS
50467: 
42714:     /* Transitioning between isActive <--> isSuspended */
42714: 
51446:     void suspend(JSFrameRegs *regs) {
42714:         JS_ASSERT(isActive());
51446:         JS_ASSERT(regs && regs->fp && contains(regs->fp));
51446:         suspendedRegs = regs;
42714:         JS_ASSERT(isSuspended());
42714:     }
42714: 
42714:     void resume() {
42714:         JS_ASSERT(isSuspended());
51446:         suspendedRegs = NULL;
42714:         JS_ASSERT(isActive());
42714:     }
42714: 
42714:     /* When isSuspended, transitioning isSaved <--> !isSaved */
42714: 
51446:     void save(JSFrameRegs *regs) {
50467:         JS_ASSERT(!isSuspended());
51446:         suspend(regs);
50467:         saved = true;
42714:         JS_ASSERT(isSaved());
42714:     }
42714: 
42714:     void restore() {
42714:         JS_ASSERT(isSaved());
50467:         saved = false;
42714:         resume();
50467:         JS_ASSERT(!isSuspended());
42714:     }
42714: 
42714:     /* Data available when inContext */
42714: 
42714:     JSStackFrame *getInitialFrame() const {
42714:         JS_ASSERT(inContext());
42714:         return initialFrame;
42714:     }
42714: 
51446:     inline JSFrameRegs *getCurrentRegs() const;
42714:     inline JSStackFrame *getCurrentFrame() const;
42714: 
42714:     /* Data available when isSuspended. */
42714: 
42717:     JSFrameRegs *getSuspendedRegs() const {
42717:         JS_ASSERT(isSuspended());
50467:         return suspendedRegs;
42717:     }
42717: 
51446:     JSStackFrame *getSuspendedFrame() const {
51446:         return suspendedRegs->fp;
51446:     }
51446: 
42714:     /* JSContext / js::StackSpace bookkeeping. */
42714: 
50466:     void setPreviousInContext(StackSegment *seg) {
50466:         previousInContext = seg;
42714:     }
42714: 
50466:     StackSegment *getPreviousInContext() const  {
42714:         return previousInContext;
42714:     }
42714: 
50466:     void setPreviousInMemory(StackSegment *seg) {
50466:         previousInMemory = seg;
42714:     }
42714: 
50466:     StackSegment *getPreviousInMemory() const  {
48531:         return previousInMemory;
42714:     }
42714: 
42714:     void setInitialVarObj(JSObject *obj) {
42714:         JS_ASSERT(inContext());
42714:         initialVarObj = obj;
42714:     }
42714: 
53840:     bool hasInitialVarObj() {
42714:         JS_ASSERT(inContext());
53840:         return initialVarObj != NULL;
53840:     }
53840: 
53840:     JSObject &getInitialVarObj() const {
53840:         JS_ASSERT(inContext() && initialVarObj);
53840:         return *initialVarObj;
42714:     }
42714: 
42714: #ifdef DEBUG
42714:     JS_REQUIRES_STACK bool contains(const JSStackFrame *fp) const;
42714: #endif
37777: };
37777: 
50466: static const size_t VALUES_PER_STACK_SEGMENT = sizeof(StackSegment) / sizeof(Value);
50466: JS_STATIC_ASSERT(sizeof(StackSegment) % sizeof(Value) == 0);
42714: 
50468: /* See StackSpace::pushInvokeArgs. */
50468: class InvokeArgsGuard : public CallArgs
42714: {
42714:     friend class StackSpace;
50467:     JSContext        *cx;  /* null implies nothing pushed */
50467:     StackSegment     *seg;
50467:     Value            *prevInvokeArgEnd;
50467: #ifdef DEBUG
50467:     StackSegment     *prevInvokeSegment;
50467:     JSStackFrame     *prevInvokeFrame;
50467: #endif
42714:   public:
55565:     InvokeArgsGuard() : cx(NULL), seg(NULL) {}
55565:     ~InvokeArgsGuard();
50467:     bool pushed() const { return cx != NULL; }
50468: };
50468: 
50468: /*
50468:  * This type can be used to call Invoke when the arguments have already been
50468:  * pushed onto the stack as part of normal execution.
50468:  */
50468: struct InvokeArgsAlreadyOnTheStack : CallArgs
50468: {
50468:     InvokeArgsAlreadyOnTheStack(Value *vp, uintN argc) : CallArgs(vp + 2, argc) {}
42714: };
42714: 
42714: /* See StackSpace::pushInvokeFrame. */
42714: class InvokeFrameGuard
42714: {
42714:     friend class StackSpace;
53840:     JSContext        *cx_;  /* null implies nothing pushed */
53840:     JSFrameRegs      regs_;
53840:     JSFrameRegs      *prevRegs_;
42714:   public:
53840:     InvokeFrameGuard() : cx_(NULL) {}
55565:     ~InvokeFrameGuard() { if (pushed()) pop(); }
53840:     bool pushed() const { return cx_ != NULL; }
55565:     void pop();
53840:     JSStackFrame *fp() const { return regs_.fp; }
42714: };
42714: 
53840: /* Reusable base; not for direct use. */
51471: class FrameGuard
42714: {
42714:     friend class StackSpace;
53840:     JSContext        *cx_;  /* null implies nothing pushed */
53840:     StackSegment     *seg_;
53840:     Value            *vp_;
53840:     JSStackFrame     *fp_;
42714:   public:
53840:     FrameGuard() : cx_(NULL), vp_(NULL), fp_(NULL) {}
51471:     JS_REQUIRES_STACK ~FrameGuard();
53840:     bool pushed() const { return cx_ != NULL; }
53840:     StackSegment *segment() const { return seg_; }
53840:     Value *vp() const { return vp_; }
53840:     JSStackFrame *fp() const { return fp_; }
42714: };
42714: 
53840: /* See StackSpace::pushExecuteFrame. */
53840: class ExecuteFrameGuard : public FrameGuard
53840: {
53840:     friend class StackSpace;
53840:     JSFrameRegs      regs_;
53840: };
53840: 
53840: /* See StackSpace::pushDummyFrame. */
53840: class DummyFrameGuard : public FrameGuard
53840: {
53840:     friend class StackSpace;
53840:     JSFrameRegs      regs_;
53840: };
53840: 
53840: /* See StackSpace::pushGeneratorFrame. */
53840: class GeneratorFrameGuard : public FrameGuard
53840: {};
53840: 
42714: /*
50467:  * Stack layout
42714:  *
42714:  * Each JSThreadData has one associated StackSpace object which allocates all
48531:  * segments for the thread. StackSpace performs all such allocations in a
42714:  * single, fixed-size buffer using a specific layout scheme that allows some
48531:  * associations between segments, frames, and slots to be implicit, rather
42714:  * than explicitly stored as pointers. To maintain useful invariants, stack
42714:  * space is not given out arbitrarily, but rather allocated/deallocated for
42714:  * specific purposes. The use cases currently supported are: calling a function
51471:  * with arguments (e.g. Invoke), executing a script (e.g. Execute), inline
51471:  * interpreter calls, and pushing "dummy" frames for bookkeeping purposes. See
51471:  * associated member functions below.
42714:  *
48531:  * First, we consider the layout of individual segments. (See the
50466:  * js::StackSegment comment for terminology.) A non-empty segment (i.e., a
48531:  * segment in a context) has the following layout:
42714:  *
50467:  *           initial frame                 current frame ------.  if regs,
42714:  *          .------------.                           |         |  regs->sp
42714:  *          |            V                           V         V
48531:  *   |segment| slots |frame| slots |frame| slots |frame| slots |
42714:  *                       |  ^          |  ^          |
42714:  *          ? <----------'  `----------'  `----------'
53840:  *                prev          prev          prev
42714:  *
42714:  * Moreover, the bytes in the following ranges form a contiguous array of
48470:  * Values that are marked during GC:
48531:  *   1. between a segment and its first frame
48531:  *   2. between two adjacent frames in a segment
48531:  *   3. between a segment's current frame and (if fp->regs) fp->regs->sp
48470:  * Thus, the VM must ensure that all such Values are safe to be marked.
42714:  *
50467:  * An empty segment is followed by arguments that are rooted by the
50467:  * StackSpace::invokeArgEnd pointer:
42714:  *
50467:  *              invokeArgEnd
50467:  *                   |
50467:  *                   V
48531:  *   |segment| slots |
42714:  *
48531:  * Above the level of segments, a StackSpace is simply a contiguous sequence
48531:  * of segments kept in a linked list:
42714:  *
48531:  *   base                       currentSegment  firstUnused            end
42714:  *    |                               |             |                   |
42714:  *    V                               V             V                   V
48531:  *    |segment| --- |segment| --- |segment| ------- |                   |
42714:  *         | ^           | ^           |
48531:  *   0 <---' `-----------' `-----------'
42714:  *   previous    previous       previous
42714:  *
48531:  * Both js::StackSpace and JSContext maintain a stack of segments, the top of
48531:  * which is the "current segment" for that thread or context, respectively.
42714:  * Since different contexts can arbitrarily interleave execution in a single
48531:  * thread, these stacks are different enough that a segment needs both
48531:  * "previousInMemory" and "previousInContext".
42714:  *
50467:  * For example, in a single thread, a function in segment S1 in a context CX1
42714:  * may call out into C++ code that reenters the VM in a context CX2, which
50467:  * creates a new segment S2 in CX2, and CX1 may or may not equal CX2.
42714:  *
48531:  * Note that there is some structure to this interleaving of segments:
48531:  *   1. the inclusion from segments in a context to segments in a thread
48531:  *      preserves order (in terms of previousInContext and previousInMemory,
42714:  *      respectively).
48531:  *   2. the mapping from stack frames to their containing segment preserves
53840:  *      order (in terms of prev and previousInContext, respectively).
42714:  */
42714: class StackSpace
42714: {
48470:     Value *base;
42714: #ifdef XP_WIN
48470:     mutable Value *commitEnd;
42714: #endif
48470:     Value *end;
50466:     StackSegment *currentSegment;
50467: #ifdef DEBUG
50467:     /*
50467:      * Keep track of which segment/frame bumped invokeArgEnd so that
50467:      * firstUnused() can assert that, when invokeArgEnd is used as the top of
50467:      * the stack, it is being used appropriately.
50467:      */
50467:     StackSegment *invokeSegment;
50467:     JSStackFrame *invokeFrame;
50467: #endif
50467:     Value        *invokeArgEnd;
50467: 
42714:     friend class InvokeArgsGuard;
42714:     friend class InvokeFrameGuard;
51471:     friend class FrameGuard;
53840: 
53840:     bool pushSegmentForInvoke(JSContext *cx, uintN argc, InvokeArgsGuard *ag);
53840:     void popSegmentForInvoke(const InvokeArgsGuard &ag);
53840: 
53840:     bool pushInvokeFrameSlow(JSContext *cx, const InvokeArgsGuard &ag,
53840:                              InvokeFrameGuard *fg);
53840:     void popInvokeFrameSlow(const CallArgs &args);
53840: 
53840:     bool getSegmentAndFrame(JSContext *cx, uintN vplen, uintN nfixed,
53840:                             FrameGuard *fg) const;
53840:     void pushSegmentAndFrame(JSContext *cx, JSObject *initialVarObj,
53840:                              JSFrameRegs *regs, FrameGuard *fg);
53840:     void popSegmentAndFrame(JSContext *cx);
53840: 
53840:     struct EnsureSpaceCheck {
53840:         inline bool operator()(const StackSpace &, JSContext *, Value *, uintN);
53840:     };
53840: 
53840:     struct LimitCheck {
53840:         JSStackFrame *base;
53840:         Value **limit;
53840:         LimitCheck(JSStackFrame *base, Value **limit) : base(base), limit(limit) {}
53840:         inline bool operator()(const StackSpace &, JSContext *, Value *, uintN);
53840:     };
53840: 
53840:     template <class Check>
53840:     inline JSStackFrame *getCallFrame(JSContext *cx, Value *sp, uintN nactual,
53840:                                       JSFunction *fun, JSScript *script,
53840:                                       uint32 *pflags, Check check) const;
53840: 
53840:     inline void popInvokeArgs(const InvokeArgsGuard &args);
53840:     inline void popInvokeFrame(const InvokeFrameGuard &ag);
53840: 
48470:     inline Value *firstUnused() const;
42714: 
50467:     inline bool isCurrentAndActive(JSContext *cx) const;
53391:     friend class AllFramesIter;
50466:     StackSegment *getCurrentSegment() const { return currentSegment; }
42714: 
42714: #ifdef XP_WIN
42714:     /* Commit more memory from the reserved stack space. */
48470:     JS_FRIEND_API(bool) bumpCommit(Value *from, ptrdiff_t nvals) const;
42714: #endif
42714: 
42714:   public:
42714:     static const size_t CAPACITY_VALS   = 512 * 1024;
48470:     static const size_t CAPACITY_BYTES  = CAPACITY_VALS * sizeof(Value);
42714:     static const size_t COMMIT_VALS     = 16 * 1024;
48470:     static const size_t COMMIT_BYTES    = COMMIT_VALS * sizeof(Value);
42714: 
53840:     /*
53840:      * SunSpider and v8bench have roughly an average of 9 slots per script.
53840:      * Our heuristic for a quick over-recursion check uses a generous slot
53840:      * count based on this estimate. We take this frame size and multiply it
53840:      * by the old recursion limit from the interpreter.
53840:      *
53840:      * Worst case, if an average size script (<=9 slots) over recurses, it'll
53840:      * effectively be the same as having increased the old inline call count
53840:      * to <= 5,000.
53840:      */
53840:     static const size_t STACK_QUOTA    = (VALUES_PER_STACK_FRAME + 18) *
53840:                                          JS_MAX_INLINE_CALL_COUNT;
53840: 
42714:     /* Kept as a member of JSThreadData; cannot use constructor/destructor. */
42714:     bool init();
42714:     void finish();
42714: 
42714: #ifdef DEBUG
42714:     template <class T>
42714:     bool contains(T *t) const {
42714:         char *v = (char *)t;
42714:         JS_ASSERT(size_t(-1) - uintptr_t(t) >= sizeof(T));
42714:         return v >= (char *)base && v + sizeof(T) <= (char *)end;
42714:     }
42714: #endif
42714: 
42714:     /*
42714:      * When we LeaveTree, we need to rebuild the stack, which requires stack
42714:      * allocation. There is no good way to handle an OOM for these allocations,
42714:      * so this function checks that they cannot occur using the size of the
42714:      * TraceNativeStorage as a conservative upper bound.
42714:      */
42714:     inline bool ensureEnoughSpaceToEnterTrace();
42714: 
42714:     /* +1 for slow native's stack frame. */
42714:     static const ptrdiff_t MAX_TRACE_SPACE_VALS =
42714:       MAX_NATIVE_STACK_SLOTS + MAX_CALL_STACK_ENTRIES * VALUES_PER_STACK_FRAME +
50466:       (VALUES_PER_STACK_SEGMENT + VALUES_PER_STACK_FRAME /* synthesized slow native */);
42714: 
48531:     /* Mark all segments, frames, and slots on the stack. */
42714:     JS_REQUIRES_STACK void mark(JSTracer *trc);
42714: 
42714:     /*
53840:      * For all five use cases below:
42714:      *  - The boolean-valued functions call js_ReportOutOfScriptQuota on OOM.
42714:      *  - The "get*Frame" functions do not change any global state, they just
42714:      *    check OOM and return pointers to an uninitialized frame with the
42714:      *    requested missing arguments/slots. Only once the "push*Frame"
42714:      *    function has been called is global state updated. Thus, between
42714:      *    "get*Frame" and "push*Frame", the frame and slots are unrooted.
53840:      *  - The "push*Frame" functions will set fp->prev; the caller needn't.
42714:      *  - Functions taking "*Guard" arguments will use the guard's destructor
42714:      *    to pop the allocation. The caller must ensure the guard has the
42714:      *    appropriate lifetime.
42714:      *  - The get*Frame functions put the 'nmissing' slots contiguously after
42714:      *    the arguments.
42714:      */
42714: 
42714:     /*
42714:      * pushInvokeArgs allocates |argc + 2| rooted values that will be passed as
50467:      * the arguments to Invoke. A single allocation can be used for multiple
50467:      * Invoke calls. The InvokeArgumentsGuard passed to Invoke must come from
50467:      * an immediately-enclosing (stack-wise) call to pushInvokeArgs.
42714:      */
53840:     bool pushInvokeArgs(JSContext *cx, uintN argc, InvokeArgsGuard *ag);
42714: 
50467:     /* These functions are called inside Invoke, not Invoke clients. */
53840:     bool getInvokeFrame(JSContext *cx, const CallArgs &args, JSFunction *fun,
53840:                         JSScript *script, uint32 *flags, InvokeFrameGuard *fg) const;
53840: 
53840:     void pushInvokeFrame(JSContext *cx, const CallArgs &args, InvokeFrameGuard *fg);
53840: 
53840:     /* These functions are called inside Execute, not Execute clients. */
53840:     bool getExecuteFrame(JSContext *cx, JSScript *script, ExecuteFrameGuard *fg) const;
53840:     void pushExecuteFrame(JSContext *cx, JSObject *initialVarObj, ExecuteFrameGuard *fg);
42714: 
42714:     /*
42714:      * Since RAII cannot be used for inline frames, callers must manually
42714:      * call pushInlineFrame/popInlineFrame.
42714:      */
53840:     inline JSStackFrame *getInlineFrame(JSContext *cx, Value *sp, uintN nactual,
53840:                                         JSFunction *fun, JSScript *script,
53840:                                         uint32 *flags) const;
53840:     inline void pushInlineFrame(JSContext *cx, JSScript *script, JSStackFrame *fp,
53840:                                 JSFrameRegs *regs);
53840:     inline void popInlineFrame(JSContext *cx, JSStackFrame *prev, js::Value *newsp);
53840: 
53840:     /* These functions are called inside SendToGenerator. */
53840:     bool getGeneratorFrame(JSContext *cx, uintN vplen, uintN nfixed,
53840:                            GeneratorFrameGuard *fg);
53840:     void pushGeneratorFrame(JSContext *cx, JSFrameRegs *regs, GeneratorFrameGuard *fg);
53840: 
53840:     /* Pushes a JSStackFrame::isDummyFrame. */
53840:     bool pushDummyFrame(JSContext *cx, JSObject &scopeChain, DummyFrameGuard *fg);
53840: 
53840:     /* Check and bump the given stack limit. */
53840:     inline JSStackFrame *getInlineFrameWithinLimit(JSContext *cx, Value *sp, uintN nactual,
53840:                                                    JSFunction *fun, JSScript *script, uint32 *flags,
53840:                                                    JSStackFrame *base, Value **limit) const;
42714: 
42714:     /*
53840:      * Compute a stack limit for entering method jit code which allows the
53840:      * method jit to check for end-of-stack and over-recursion with a single
53840:      * comparison. See STACK_QUOTA above.
51471:      */
53840:     inline Value *getStackLimit(JSContext *cx);
53501: 
53501:     /*
53840:      * Try to bump the given 'limit' by bumping the commit limit. Return false
53840:      * if fully committed or if 'limit' exceeds 'base' + STACK_QUOTA.
53422:      */
53840:     bool bumpCommitAndLimit(JSStackFrame *base, Value *from, uintN nvals, Value **limit) const;
57717: 
57717:     /*
57717:      * Allocate nvals on the top of the stack, report error on failure.
57717:      * N.B. the caller must ensure |from >= firstUnused()|.
57717:      */
57717:     inline bool ensureSpace(JSContext *maybecx, Value *from, ptrdiff_t nvals) const;
42714: };
42714: 
42714: JS_STATIC_ASSERT(StackSpace::CAPACITY_VALS % StackSpace::COMMIT_VALS == 0);
42714: 
42717: /*
42717:  * While |cx->fp|'s pc/sp are available in |cx->regs|, to compute the saved
42717:  * value of pc/sp for any other frame, it is necessary to know about that
53840:  * frame's next-frame. This iterator maintains this information when walking
42717:  * a chain of stack frames starting at |cx->fp|.
42717:  *
42717:  * Usage:
42717:  *   for (FrameRegsIter i(cx); !i.done(); ++i)
42717:  *     ... i.fp() ... i.sp() ... i.pc()
42717:  */
42717: class FrameRegsIter
42717: {
54832:     JSContext         *cx;
50466:     StackSegment      *curseg;
42717:     JSStackFrame      *curfp;
48470:     Value             *cursp;
42717:     jsbytecode        *curpc;
42717: 
50467:     void initSlow();
53840:     void incSlow(JSStackFrame *fp, JSStackFrame *prev);
50467: 
42717:   public:
50467:     JS_REQUIRES_STACK inline FrameRegsIter(JSContext *cx);
42717: 
42717:     bool done() const { return curfp == NULL; }
50467:     inline FrameRegsIter &operator++();
42717: 
42717:     JSStackFrame *fp() const { return curfp; }
48470:     Value *sp() const { return cursp; }
42717:     jsbytecode *pc() const { return curpc; }
42717: };
42717: 
53391: /*
53391:  * Utility class for iteration over all active stack frames.
53391:  */
53391: class AllFramesIter
53391: {
53391: public:
53391:     AllFramesIter(JSContext *cx);
53391: 
53391:     bool done() const { return curfp == NULL; }
53391:     AllFramesIter& operator++();
53391: 
53391:     JSStackFrame *fp() const { return curfp; }
53391: 
53391: private:
53391:     StackSegment *curcs;
53391:     JSStackFrame *curfp;
53391: };
53391: 
38568: /* Holds the number of recording attemps for an address. */
38568: typedef HashMap<jsbytecode*,
38568:                 size_t,
38568:                 DefaultHasher<jsbytecode*>,
38568:                 SystemAllocPolicy> RecordAttemptMap;
38568: 
56551: /* Holds the profile data for loops. */
56551: typedef HashMap<jsbytecode*,
56551:                 LoopProfile*,
56551:                 DefaultHasher<jsbytecode*>,
56551:                 SystemAllocPolicy> LoopProfileMap;
56551: 
41802: class Oracle;
41802: 
58041: typedef HashSet<JSScript *,
58041:                 DefaultHasher<JSScript *>,
58041:                 SystemAllocPolicy> TracedScriptSet;
58041: 
37777: /*
17583:  * Trace monitor. Every JSThread (if JS_THREADSAFE) or JSRuntime (if not
17583:  * JS_THREADSAFE) has an associated trace monitor that keeps track of loop
17583:  * frequencies for all JavaScript code loaded into that runtime.
17583:  */
37741: struct TraceMonitor {
18782:     /*
27882:      * The context currently executing JIT-compiled code on this thread, or
27882:      * NULL if none. Among other things, this can in certain cases prevent
27882:      * last-ditch GC and suppress calls to JS_ReportOutOfMemory.
24613:      *
27882:      * !tracecx && !recorder: not on trace
33172:      * !tracecx && recorder: recording
27882:      * tracecx && !recorder: executing a trace
27882:      * tracecx && recorder: executing inner loop, recording outer loop
18782:      */
27882:     JSContext               *tracecx;
24598: 
33545:     /*
34572:      * Cached storage to use when executing on trace. While we may enter nested
34572:      * traces, we always reuse the outer trace's storage, so never need more
34572:      * than of these.
34572:      */
37037:     TraceNativeStorage      *storage;
34572: 
34572:     /*
36377:      * There are 5 allocators here.  This might seem like overkill, but they
33545:      * have different lifecycles, and by keeping them separate we keep the
36377:      * amount of retained memory down significantly.  They are flushed (ie.
36377:      * all the allocated memory is freed) periodically.
33545:      *
36377:      * - dataAlloc has the lifecycle of the monitor.  It's flushed only when
36377:      *   the monitor is flushed.  It's used for fragments.
33545:      *
36377:      * - traceAlloc has the same flush lifecycle as the dataAlloc, but it is
36377:      *   also *marked* when a recording starts and rewinds to the mark point
36377:      *   if recording aborts.  So you can put things in it that are only
36377:      *   reachable on a successful record/compile cycle like GuardRecords and
36377:      *   SideExits.
33545:      *
36377:      * - tempAlloc is flushed after each recording, successful or not.  It's
36377:      *   used to store LIR code and for all other elements in the LIR
36377:      *   pipeline.
36377:      *
36377:      * - reTempAlloc is just like tempAlloc, but is used for regexp
36377:      *   compilation in RegExpNativeCompiler rather than normal compilation in
36377:      *   TraceRecorder.
36377:      *
36377:      * - codeAlloc has the same lifetime as dataAlloc, but its API is
36377:      *   different (CodeAlloc vs. VMAllocator).  It's used for native code.
36377:      *   It's also a good idea to keep code and data separate to avoid I-cache
36377:      *   vs. D-cache issues.
33545:      */
36377:     VMAllocator*            dataAlloc;
36377:     VMAllocator*            traceAlloc;
36377:     VMAllocator*            tempAlloc;
36377:     VMAllocator*            reTempAlloc;
36377:     nanojit::CodeAlloc*     codeAlloc;
34299:     nanojit::Assembler*     assembler;
34299:     FrameInfoCache*         frameCache;
31920: 
56551:     /* This gets incremented every time the monitor is flushed. */
56551:     uintN                   flushEpoch;
56551: 
41802:     Oracle*                 oracle;
34299:     TraceRecorder*          recorder;
21491: 
56551:     /* If we are profiling a loop, this tracks the current profile. Otherwise NULL. */
56551:     LoopProfile*            profile;
56551: 
37741:     GlobalState             globalStates[MONITOR_N_GLOBAL_STATES];
37741:     TreeFragment*           vmfragments[FRAGMENT_TABLE_SIZE];
38568:     RecordAttemptMap*       recordAttempts;
27379: 
56551:     /* A hashtable mapping PC values to loop profiles for those loops. */
56551:     LoopProfileMap*         loopProfiles;
56551: 
27379:     /*
27884:      * Maximum size of the code cache before we start flushing. 1/16 of this
27884:      * size is used as threshold for the regular expression code cache.
27884:      */
27884:     uint32                  maxCodeCacheBytes;
27884: 
27884:     /*
28312:      * If nonzero, do not flush the JIT cache after a deep bail. That would
28312:      * free JITted code pages that we will later return to. Instead, set the
28312:      * needFlush flag so that it can be flushed later.
28312:      */
31526:     JSBool                  needFlush;
28312: 
28312:     /*
32767:      * Fragment map for the regular expression compiler.
32767:      */
34299:     REHashMap*              reFragments;
21723: 
37694:     // Cached temporary typemap to avoid realloc'ing every time we create one.
37694:     // This must be used in only one place at a given time. It must be cleared
37694:     // before use.
37694:     TypeMap*                cachedTempTypeMap;
37694: 
58041:     /* Scripts with recorded fragments. */
58041:     TracedScriptSet         tracedScripts;
58041: 
32784: #ifdef DEBUG
32784:     /* Fields needed for fragment/guard profiling. */
34299:     nanojit::Seq<nanojit::Fragment*>* branches;
32788:     uint32                  lastFragID;
32784:     /*
32784:      * profAlloc has a lifetime which spans exactly from js_InitJIT to
32784:      * js_FinishJIT.
32784:      */
34299:     VMAllocator*            profAlloc;
34299:     FragStatsMap*           profTab;
32784: #endif
32784: 
54718:     bool ontrace() const {
54718:         return !!tracecx;
54718:     }
54718: 
31843:     /* Flush the JIT cache. */
31843:     void flush();
31843: 
54718:     /* Sweep any cache entry pointing to dead GC things. */
54718:     void sweep();
35083: 
35083:     bool outOfMemory() const;
26569: };
17583: 
37741: } /* namespace js */
24612: 
27577: /*
27577:  * N.B. JS_ON_TRACE(cx) is true if JIT code is on the stack in the current
27577:  * thread, regardless of whether cx is the context in which that trace is
27577:  * executing.  cx must be a context on the current thread.
27577:  */
18782: #ifdef JS_TRACER
54718: # define JS_ON_TRACE(cx)            (JS_TRACE_MONITOR(cx).ontrace())
18782: #else
54718: # define JS_ON_TRACE(cx)            false
18782: #endif
18782: 
24375: /* Number of potentially reusable scriptsToGC to search for the eval cache. */
24375: #ifndef JS_EVAL_CACHE_SHIFT
24375: # define JS_EVAL_CACHE_SHIFT        6
24375: #endif
24375: #define JS_EVAL_CACHE_SIZE          JS_BIT(JS_EVAL_CACHE_SHIFT)
24375: 
48676: #ifdef DEBUG
24375: # define EVAL_CACHE_METER_LIST(_)   _(probe), _(hit), _(step), _(noscope)
27012: # define identity(x)                x
24375: 
29923: struct JSEvalCacheMeter {
27012:     uint64 EVAL_CACHE_METER_LIST(identity);
29923: };
24375: 
27012: # undef identity
27012: #endif
27012: 
48676: #ifdef DEBUG
27012: # define FUNCTION_KIND_METER_LIST(_)                                          \
27012:                         _(allfun), _(heavy), _(nofreeupvar), _(onlyfreevar),  \
48676:                         _(display), _(flat), _(setupvar), _(badfunarg),       \
48676:                         _(joinedsetmethod), _(joinedinitmethod),              \
48676:                         _(joinedreplace), _(joinedsort), _(joinedmodulepat),  \
48676:                         _(mreadbarrier), _(mwritebarrier), _(mwslotbarrier),  \
48676:                         _(unjoined)
27012: # define identity(x)    x
27012: 
35075: struct JSFunctionMeter {
27012:     int32 FUNCTION_KIND_METER_LIST(identity);
35075: };
27012: 
27012: # undef identity
48676: 
48676: # define JS_FUNCTION_METER(cx,x) JS_RUNTIME_METER((cx)->runtime, functionMeter.x)
48676: #else
48676: # define JS_FUNCTION_METER(cx,x) ((void)0)
24375: #endif
24375: 
48676: 
42641: #define NATIVE_ITER_CACHE_LOG2  8
42641: #define NATIVE_ITER_CACHE_MASK  JS_BITMASK(NATIVE_ITER_CACHE_LOG2)
42641: #define NATIVE_ITER_CACHE_SIZE  JS_BIT(NATIVE_ITER_CACHE_LOG2)
42641: 
43279: struct JSPendingProxyOperation {
43279:     JSPendingProxyOperation *next;
43279:     JSObject *object;
43279: };
43279: 
26569: struct JSThreadData {
56559: #ifdef JS_THREADSAFE
56559:     /* The request depth for this thread. */
56559:     unsigned            requestDepth;
56559: #endif
56559: 
48538:     /*
56559:      * If non-zero, we were been asked to call the operation callback as soon
56559:      * as possible.  If the thread has an active request, this contributes
56559:      * towards rt->interruptCounter.
48538:      */
56573:     volatile int32      interruptFlags;
48538: 
42714:     /* Keeper of the contiguous stack used by all contexts in this thread. */
42714:     js::StackSpace      stackSpace;
42714: 
26569:     /*
48619:      * Flag indicating that we are waiving any soft limits on the GC heap
56023:      * because we want allocations to be infallible (except when we hit OOM).
48619:      */
48619:     bool                waiveGCQuota;
48619: 
48619:     /*
26569:      * The GSN cache is per thread since even multi-cx-per-thread embeddings
26569:      * do not interleave js_GetSrcNote calls.
26569:      */
26569:     JSGSNCache          gsnCache;
26569: 
26569:     /* Property cache for faster call/get/set invocation. */
40362:     js::PropertyCache   propertyCache;
31898: 
26569: #ifdef JS_TRACER
26569:     /* Trace-tree JIT recorder/interpreter state. */
37741:     js::TraceMonitor    traceMonitor;
53578: 
53578:     /* Counts the number of iterations run by a trace. */
53578:     unsigned            iterationCounter;
26569: #endif
26569: 
26569:     /* Lock-free hashed lists of scripts created by eval to garbage-collect. */
26569:     JSScript            *scriptsToGC[JS_EVAL_CACHE_SIZE];
26569: 
48676: #ifdef DEBUG
26569:     JSEvalCacheMeter    evalCacheMeter;
26569: #endif
30453: 
40339:     /* State used by dtoa.c. */
40339:     DtoaState           *dtoaState;
40339: 
32553:     /*
53852:      * A single-entry cache for some base-10 double-to-string conversions.
53852:      * This helps date-format-xparb.js.  It also avoids skewing the results
53852:      * for v8-splay.js when measured by the SunSpider harness, where the splay
53852:      * tree initialization (which includes many repeated double-to-string
53852:      * conversions) is erroneously included in the measurement; see bug
53852:      * 562553.
41847:      */
41847:     struct {
41847:         jsdouble d;
41847:         jsint    base;
41847:         JSString *s;        // if s==NULL, d and base are not valid
41847:     } dtoaCache;
41847: 
42641:     /* Cached native iterators. */
42641:     JSObject            *cachedNativeIterators[NATIVE_ITER_CACHE_SIZE];
40844: 
53404:     /* Native iterator most recently started. */
53404:     JSObject            *lastNativeIterator;
53404: 
42740:     /* Base address of the native stack for the current thread. */
42740:     jsuword             *nativeStackBase;
42740: 
43279:     /* List of currently pending operations on proxies. */
43279:     JSPendingProxyOperation *pendingProxyOperation;
43279: 
47439:     js::ConservativeGCThreadData conservativeGC;
47439: 
55569:   private:
55569:     js::MathCache       *mathCache;
55569: 
55569:     js::MathCache *allocMathCache(JSContext *cx);
55569:   public:
55569: 
55569:     js::MathCache *getMathCache(JSContext *cx) {
55569:         return mathCache ? mathCache : allocMathCache(cx);
55569:     }
55569: 
40339:     bool init();
35075:     void finish();
35075:     void mark(JSTracer *trc);
35075:     void purge(JSContext *cx);
48538: 
56559:     /* This must be called with the GC lock held. */
56559:     inline void triggerOperationCallback(JSRuntime *rt);
26569: };
26569: 
    1: #ifdef JS_THREADSAFE
    1: 
    1: /*
    1:  * Structure uniquely representing a thread.  It holds thread-private data
    1:  * that can be accessed without a global lock.
    1:  */
    1: struct JSThread {
42712:     typedef js::HashMap<void *,
42712:                         JSThread *,
42712:                         js::DefaultHasher<void *>,
42712:                         js::SystemAllocPolicy> Map;
42712: 
28312:     /* Linked list of all contexts in use on this thread. */
    1:     JSCList             contextList;
    1: 
    1:     /* Opaque thread-id, from NSPR's PR_GetCurrentThread(). */
42712:     void                *id;
    1: 
53548:     /* Number of JS_SuspendRequest calls withot JS_ResumeRequest. */
53548:     unsigned            suspendCount;
53548: 
53548: # ifdef DEBUG
53548:     unsigned            checkRequestDepth;
53548: # endif
53548: 
28312:     /* Factored out of JSThread for !JS_THREADSAFE embedding in JSRuntime. */
26569:     JSThreadData        data;
    1: };
    1: 
26569: #define JS_THREAD_DATA(cx)      (&(cx)->thread->data)
    1: 
34365: extern JSThread *
34365: js_CurrentThread(JSRuntime *rt);
34365: 
26569: /*
26569:  * The function takes the GC lock and does not release in successful return.
26569:  * On error (out of memory) the function releases the lock but delegates
26569:  * the error reporting to the caller.
26569:  */
26569: extern JSBool
26569: js_InitContextThread(JSContext *cx);
26569: 
26569: /*
26569:  * On entrance the GC lock must be held and it will be held on exit.
26569:  */
26561: extern void
26569: js_ClearContextThread(JSContext *cx);
    1: 
    1: #endif /* JS_THREADSAFE */
    1: 
    1: typedef enum JSDestroyContextMode {
    1:     JSDCM_NO_GC,
    1:     JSDCM_MAYBE_GC,
    1:     JSDCM_FORCE_GC,
    1:     JSDCM_NEW_FAILED
    1: } JSDestroyContextMode;
    1: 
    1: typedef enum JSRuntimeState {
    1:     JSRTS_DOWN,
    1:     JSRTS_LAUNCHING,
    1:     JSRTS_UP,
    1:     JSRTS_LANDING
    1: } JSRuntimeState;
    1: 
    1: typedef struct JSPropertyTreeEntry {
    1:     JSDHashEntryHdr     hdr;
52503:     js::Shape           *child;
    1: } JSPropertyTreeEntry;
    1: 
50462: typedef void
50462: (* JSActivityCallback)(void *arg, JSBool active);
50462: 
55574: namespace js {
55574: 
55574: typedef js::Vector<JSCompartment *, 0, js::SystemAllocPolicy> WrapperVector;
55574: 
55574: }
55574: 
    1: struct JSRuntime {
43286:     /* Default compartment. */
43286:     JSCompartment       *defaultCompartment;
54707: #ifdef JS_THREADSAFE
54707:     bool                defaultCompartmentIsLocked;
54707: #endif
43286: 
43286:     /* List of compartments (protected by the GC lock). */
55574:     js::WrapperVector compartments;
43286: 
    1:     /* Runtime state, synchronized by the stateChange/gcLock condvar/lock. */
    1:     JSRuntimeState      state;
    1: 
    1:     /* Context create/destroy callback. */
    1:     JSContextCallback   cxCallback;
    1: 
48503:     /* Compartment create/destroy callback. */
48503:     JSCompartmentCallback compartmentCallback;
48503: 
28312:     /*
50462:      * Sets a callback that is run whenever the runtime goes idle - the
50462:      * last active request ceases - and begins activity - when it was
50462:      * idle and a request begins. Note: The callback is called under the
50462:      * GC lock.
50462:      */
50462:     void setActivityCallback(JSActivityCallback cb, void *arg) {
50462:         activityCallback = cb;
50462:         activityCallbackArg = arg;
50462:     }
50462: 
50462:     JSActivityCallback    activityCallback;
50462:     void                 *activityCallbackArg;
50462: 
50462:     /*
28312:      * Shape regenerated whenever a prototype implicated by an "add property"
28312:      * property cache fill and induced trace guard has a readonly property or a
28312:      * setter defined on it. This number proxies for the shapes of all objects
28312:      * along the prototype chain of all objects in the runtime on which such an
28312:      * add-property result has been cached/traced.
28312:      *
28312:      * See bug 492355 for more details.
28312:      *
28312:      * This comes early in JSRuntime to minimize the immediate format used by
28312:      * trace-JITted code that reads it.
28312:      */
28312:     uint32              protoHazardShape;
28312: 
    1:     /* Garbage collector state, used by jsgc.c. */
49085:     js::GCChunkSet      gcChunkSet;
49085: 
48470:     js::RootedValueMap  gcRootsHash;
42755:     js::GCLocks         gcLocksHash;
    1:     jsrefcount          gcKeepAtoms;
32553:     size_t              gcBytes;
56023:     size_t              gcTriggerBytes;
32553:     size_t              gcLastBytes;
32553:     size_t              gcMaxBytes;
32553:     size_t              gcMaxMallocBytes;
19196:     uint32              gcEmptyArenaPoolLifespan;
    1:     uint32              gcNumber;
48583:     js::GCMarker        *gcMarkingTracer;
32553:     uint32              gcTriggerFactor;
27546:     volatile JSBool     gcIsNeeded;
    1: 
    1:     /*
56023:      * We can pack these flags as only the GC thread writes to them. Atomic
56023:      * updates to packed bytes are not guaranteed, so stores issued by one
56023:      * thread may be lost due to unsynchronized read-modify-write cycles on
56023:      * other threads.
    1:      */
53548:     bool                gcPoke;
53548:     bool                gcMarkAndSweep;
53548:     bool                gcRunning;
53548:     bool                gcRegenShapes;
30845: 
 1492: #ifdef JS_GC_ZEAL
 7944:     jsrefcount          gcZeal;
 1492: #endif
    1: 
    1:     JSGCCallback        gcCallback;
34288: 
53592:   private:
34288:     /*
34288:      * Malloc counter to measure memory pressure for GC scheduling. It runs
34288:      * from gcMaxMallocBytes down to zero.
34288:      */
53592:     volatile ptrdiff_t  gcMallocBytes;
53592: 
53592:   public:
47400:     js::GCChunkAllocator    *gcChunkAllocator;
47400: 
47400:     void setCustomGCChunkAllocator(js::GCChunkAllocator *allocator) {
47400:         JS_ASSERT(allocator);
47400:         JS_ASSERT(state == JSRTS_DOWN);
47400:         gcChunkAllocator = allocator;
47400:     }
47400: 
    1:     /*
  958:      * The trace operation and its data argument to trace embedding-specific
  958:      * GC roots.
  958:      */
  958:     JSTraceDataOp       gcExtraRootsTraceOp;
  958:     void                *gcExtraRootsData;
  958: 
    1:     /* Well-known numbers held for use by this runtime's contexts. */
48470:     js::Value           NaNValue;
48470:     js::Value           negativeInfinityValue;
48470:     js::Value           positiveInfinityValue;
    1: 
56578:     js::DeflatedStringCache *deflatedStringCache;
56578: 
    1:     JSString            *emptyString;
    1: 
    1:     /* List of active contexts sharing this runtime; protected by gcLock. */
    1:     JSCList             contextList;
    1: 
 2433:     /* Per runtime debug hooks -- see jsprvtd.h and jsdbgapi.h. */
 2433:     JSDebugHooks        globalDebugHooks;
    1: 
56783:     /*
56783:      * Right now, we only support runtime-wide debugging.
56783:      */
56783:     JSBool              debugMode;
56783: 
35331: #ifdef JS_TRACER
35331:     /* True if any debug hooks not supported by the JIT are enabled. */
35331:     bool debuggerInhibitsJIT() const {
41863:         return (globalDebugHooks.interruptHook ||
48556:                 globalDebugHooks.callHook);
35331:     }
35331: #endif
35331: 
    1:     /* More debugging state, see jsdbgapi.c. */
    1:     JSCList             trapList;
    1:     JSCList             watchPointList;
    1: 
20312:     /* Client opaque pointers */
    1:     void                *data;
    1: 
    1: #ifdef JS_THREADSAFE
    1:     /* These combine to interlock the GC and new requests. */
    1:     PRLock              *gcLock;
    1:     PRCondVar           *gcDone;
    1:     PRCondVar           *requestDone;
    1:     uint32              requestCount;
    1:     JSThread            *gcThread;
    1: 
53592:     js::GCHelperThread  gcHelperThread;
53592: 
    1:     /* Lock and owning thread pointer for JS_LOCK_RUNTIME. */
    1:     PRLock              *rtLock;
    1: #ifdef DEBUG
42712:     void *              rtLockOwner;
    1: #endif
    1: 
    1:     /* Used to synchronize down/up state change; protected by gcLock. */
    1:     PRCondVar           *stateChange;
    1: 
    1:     /*
    1:      * Lock serializing trapList and watchPointList accesses, and count of all
    1:      * mutations to trapList and watchPointList made by debugger threads.  To
    1:      * keep the code simple, we define debuggerMutations for the thread-unsafe
    1:      * case too.
    1:      */
    1:     PRLock              *debuggerLock;
26569: 
42712:     JSThread::Map       threads;
    1: #endif /* JS_THREADSAFE */
    1:     uint32              debuggerMutations;
    1: 
    1:     /*
18870:      * Security callbacks set on the runtime are used by each context unless
18870:      * an override is set on the context.
    1:      */
18870:     JSSecurityCallbacks *securityCallbacks;
    1: 
54863:     /* Structured data callbacks are runtime-wide. */
54863:     const JSStructuredCloneCallbacks *structuredCloneCallbacks;
54863: 
    1:     /*
    1:      * Shared scope property tree, and arena-pool for allocating its nodes.
40327:      * This really should be free of all locking overhead and allocated in
40327:      * thread-local storage, hence the JS_PROPERTY_TREE(cx) macro.
40327:      */
40327:     js::PropertyTree    propertyTree;
40327: 
40327: #define JS_PROPERTY_TREE(cx) ((cx)->runtime->propertyTree)
40327: 
40327:     /*
52503:      * The propertyRemovals counter is incremented for every JSObject::clear,
52503:      * and for each JSObject::remove method call that frees a slot in the given
52503:      * object. See js_NativeGet and js_NativeSet in jsobj.cpp.
    1:      */
    1:     int32               propertyRemovals;
    1: 
    1:     /* Script filename table. */
    1:     struct JSHashTable  *scriptFilenameTable;
    1:     JSCList             scriptFilenamePrefixes;
    1: #ifdef JS_THREADSAFE
    1:     PRLock              *scriptFilenameTableLock;
    1: #endif
    1: 
    1:     /* Number localization, used by jsnum.c */
    1:     const char          *thousandsSeparator;
    1:     const char          *decimalSeparator;
    1:     const char          *numGrouping;
    1: 
    1:     /*
    1:      * Weak references to lazily-created, well-known XML singletons.
    1:      *
    1:      * NB: Singleton objects must be carefully disconnected from the rest of
    1:      * the object graph usually associated with a JSContext's global object,
    1:      * including the set of standard class objects.  See jsxml.c for details.
    1:      */
    1:     JSObject            *anynameObject;
    1:     JSObject            *functionNamespaceObject;
    1: 
56559: #ifdef JS_THREADSAFE
56559:     /* Number of threads with active requests and unhandled interrupts. */
56573:     volatile int32      interruptCounter;
56559: #else
26569:     JSThreadData        threadData;
    1: 
26569: #define JS_THREAD_DATA(cx)      (&(cx)->runtime->threadData)
    1: #endif
    1: 
11377:     /*
11377:      * Object shape (property cache structural type) identifier generator.
11377:      *
11377:      * Type 0 stands for the empty scope, and must not be regenerated due to
27546:      * uint32 wrap-around. Since js_GenerateShape (in jsinterp.cpp) uses
27546:      * atomic pre-increment, the initial value for the first typed non-empty
27546:      * scope will be 1.
11377:      *
11377:      * If this counter overflows into SHAPE_OVERFLOW_BIT (in jsinterp.h), the
27546:      * cache is disabled, to avoid aliasing two different types. It stays
27546:      * disabled until a triggered GC at some later moment compresses live
27546:      * types, minimizing rt->shapeGen in the process.
11377:      */
27546:     volatile uint32     shapeGen;
11377: 
 4342:     /* Literal table maintained by jsatom.c functions. */
 4342:     JSAtomState         atomState;
 4342: 
47497:     /*
47497:      * Runtime-shared empty scopes for well-known built-in objects that lack
52503:      * class prototypes (the usual locus of an emptyShape). Mnemonic: ABCDEW
47497:      */
52503:     js::EmptyShape      *emptyArgumentsShape;
52503:     js::EmptyShape      *emptyBlockShape;
52503:     js::EmptyShape      *emptyCallShape;
52503:     js::EmptyShape      *emptyDeclEnvShape;
52503:     js::EmptyShape      *emptyEnumeratorShape;
52503:     js::EmptyShape      *emptyWithShape;
37766: 
10954:     /*
10954:      * Various metering fields are defined at the end of JSRuntime. In this
10954:      * way there is no need to recompile all the code that refers to other
10954:      * fields of JSRuntime after enabling the corresponding metering macro.
10954:      */
17049: #ifdef JS_DUMP_ENUM_CACHE_STATS
17049:     int32               nativeEnumProbes;
17049:     int32               nativeEnumMisses;
17049: # define ENUM_CACHE_METER(name)     JS_ATOMIC_INCREMENT(&cx->runtime->name)
17049: #else
17049: # define ENUM_CACHE_METER(name)     ((void) 0)
17049: #endif
10954: 
17182: #ifdef JS_DUMP_LOOP_STATS
17182:     /* Loop statistics, to trigger trace recording and compiling. */
17182:     JSBasicStats        loopStats;
17182: #endif
17182: 
35453: #ifdef DEBUG
    1:     /* Function invocation metering. */
    1:     jsrefcount          inlineCalls;
    1:     jsrefcount          nativeCalls;
    1:     jsrefcount          nonInlineCalls;
    1:     jsrefcount          constructs;
    1: 
56568:     /* Property metering. */
52503:     jsrefcount          liveObjectProps;
52503:     jsrefcount          liveObjectPropsPreSweep;
52503:     jsrefcount          totalObjectProps;
    1:     jsrefcount          livePropTreeNodes;
    1:     jsrefcount          duplicatePropTreeNodes;
    1:     jsrefcount          totalPropTreeNodes;
    1:     jsrefcount          propTreeKidsChunks;
52503:     jsrefcount          liveDictModeNodes;
52503: 
52503:     /*
52503:      * NB: emptyShapes is init'ed iff at least one of these envars is set:
52503:      *
52503:      *  JS_PROPTREE_STATFILE  statistics on the property tree forest
52503:      *  JS_PROPTREE_DUMPFILE  all paths in the property tree forest
52503:      */
52503:     const char          *propTreeStatFilename;
52503:     const char          *propTreeDumpFilename;
52503: 
52503:     bool meterEmptyShapes() const { return propTreeStatFilename || propTreeDumpFilename; }
52503: 
52503:     typedef js::HashSet<js::EmptyShape *,
52503:                         js::DefaultHasher<js::EmptyShape *>,
52503:                         js::SystemAllocPolicy> EmptyShapeSet;
52503: 
52503:     EmptyShapeSet       emptyShapes;
    1: 
    1:     /* String instrumentation. */
    1:     jsrefcount          liveStrings;
    1:     jsrefcount          totalStrings;
    1:     jsrefcount          liveDependentStrings;
    1:     jsrefcount          totalDependentStrings;
10217:     jsrefcount          badUndependStrings;
    1:     double              lengthSum;
    1:     double              lengthSquaredSum;
    1:     double              strdepLengthSum;
    1:     double              strdepLengthSquaredSum;
34290: 
34290:     /* Script instrumentation. */
34290:     jsrefcount          liveScripts;
34290:     jsrefcount          totalScripts;
34290:     jsrefcount          liveEmptyScripts;
34290:     jsrefcount          totalEmptyScripts;
35453: #endif /* DEBUG */
10217: 
10217: #ifdef JS_SCOPE_DEPTH_METER
10217:     /*
10217:      * Stats on runtime prototype chain lookups and scope chain depths, i.e.,
10217:      * counts of objects traversed on a chain until the wanted id is found.
10217:      */
10217:     JSBasicStats        protoLookupDepthStats;
10217:     JSBasicStats        scopeSearchDepthStats;
10217: 
10217:     /*
10217:      * Stats on compile-time host environment and lexical scope chain lengths
10217:      * (maximum depths).
10217:      */
10217:     JSBasicStats        hostenvScopeDepthStats;
10217:     JSBasicStats        lexicalScopeDepthStats;
    1: #endif
10954: 
10954: #ifdef JS_GCMETER
54707:     js::gc::JSGCStats           gcStats;
54707:     js::gc::JSGCArenaStats      globalArenaStats[js::gc::FINALIZE_LIMIT];
10954: #endif
27012: 
48676: #ifdef DEBUG
48676:     /*
48676:      * If functionMeterFilename, set from an envariable in JSRuntime's ctor, is
48676:      * null, the remaining members in this ifdef'ed group are not initialized.
48676:      */
48676:     const char          *functionMeterFilename;
27012:     JSFunctionMeter     functionMeter;
27012:     char                lastScriptFilename[1024];
48676: 
48676:     typedef js::HashMap<JSFunction *,
48676:                         int32,
48676:                         js::DefaultHasher<JSFunction *>,
48676:                         js::SystemAllocPolicy> FunctionCountMap;
48676: 
48676:     FunctionCountMap    methodReadBarrierCountMap;
48676:     FunctionCountMap    unjoinedFunctionCountMap;
27012: #endif
30438: 
47516:     JSWrapObjectCallback wrapObjectCallback;
55628:     JSPreWrapCallback    preWrapObjectCallback;
47516: 
50491:     JSC::ExecutableAllocator *regExpAllocator;
50491: 
34299:     JSRuntime();
34299:     ~JSRuntime();
34299: 
34299:     bool init(uint32 maxbytes);
34299: 
32553:     void setGCTriggerFactor(uint32 factor);
32553:     void setGCLastBytes(size_t lastBytes);
32553: 
53592:     /*
53592:      * Call the system malloc while checking for GC memory pressure and
53592:      * reporting OOM error when cx is not null.
53592:      */
53592:     void* malloc(size_t bytes, JSContext *cx = NULL) {
53592:         updateMallocCounter(bytes);
53592:         void *p = ::js_malloc(bytes);
53592:         return JS_LIKELY(!!p) ? p : onOutOfMemory(NULL, bytes, cx);
53592:     }
53592: 
53592:     /*
53592:      * Call the system calloc while checking for GC memory pressure and
53592:      * reporting OOM error when cx is not null.
53592:      */
53592:     void* calloc(size_t bytes, JSContext *cx = NULL) {
53592:         updateMallocCounter(bytes);
53592:         void *p = ::js_calloc(bytes);
53592:         return JS_LIKELY(!!p) ? p : onOutOfMemory(reinterpret_cast<void *>(1), bytes, cx);
53592:     }
53592: 
53592:     void* realloc(void* p, size_t bytes, JSContext *cx = NULL) {
53592:         /*
53592:          * For compatibility we do not account for realloc that increases
53592:          * previously allocated memory.
53592:          */
53592:         if (!p)
53592:             updateMallocCounter(bytes);
53592:         void *p2 = ::js_realloc(p, bytes);
53592:         return JS_LIKELY(!!p2) ? p2 : onOutOfMemory(p, bytes, cx);
53592:     }
34288: 
34288:     void free(void* p) { ::js_free(p); }
34288: 
48619:     bool isGCMallocLimitReached() const { return gcMallocBytes <= 0; }
48619: 
34288:     void resetGCMallocBytes() { gcMallocBytes = ptrdiff_t(gcMaxMallocBytes); }
34288: 
34288:     void setGCMaxMallocBytes(size_t value) {
34288:         /*
34288:          * For compatibility treat any value that exceeds PTRDIFF_T_MAX to
34288:          * mean that value.
34288:          */
34288:         gcMaxMallocBytes = (ptrdiff_t(value) >= 0) ? value : size_t(-1) >> 1;
34288:         resetGCMallocBytes();
30851:     }
53592: 
53592:     /*
53592:      * Call this after allocating memory held by GC things, to update memory
53592:      * pressure counters or report the OOM error if necessary. If oomError and
53592:      * cx is not null the function also reports OOM error.
53592:      *
53592:      * The function must be called outside the GC lock and in case of OOM error
53592:      * the caller must ensure that no deadlock possible during OOM reporting.
53592:      */
53592:     void updateMallocCounter(size_t nbytes) {
53592:         /* We tolerate any thread races when updating gcMallocBytes. */
53592:         ptrdiff_t newCount = gcMallocBytes - ptrdiff_t(nbytes);
53592:         gcMallocBytes = newCount;
53592:         if (JS_UNLIKELY(newCount <= 0))
53592:             onTooMuchMalloc();
53592:     }
53592: 
53592:   private:
53592:     /*
53592:      * The function must be called outside the GC lock.
53592:      */
53592:     JS_FRIEND_API(void) onTooMuchMalloc();
53592: 
53592:     /*
53592:      * This should be called after system malloc/realloc returns NULL to try
53592:      * to recove some memory or to report an error. Failures in malloc and
53592:      * calloc are signaled by p == null and p == reinterpret_cast<void *>(1).
53592:      * Other values of p mean a realloc failure.
53592:      *
53592:      * The function must be called outside the GC lock.
53592:      */
53592:     JS_FRIEND_API(void *) onOutOfMemory(void *p, size_t nbytes, JSContext *cx);
    1: };
    1: 
24375: /* Common macros to access thread-local caches in JSThread or JSRuntime. */
26569: #define JS_GSN_CACHE(cx)        (JS_THREAD_DATA(cx)->gsnCache)
26569: #define JS_PROPERTY_CACHE(cx)   (JS_THREAD_DATA(cx)->propertyCache)
26569: #define JS_TRACE_MONITOR(cx)    (JS_THREAD_DATA(cx)->traceMonitor)
26569: #define JS_SCRIPTS_TO_GC(cx)    (JS_THREAD_DATA(cx)->scriptsToGC)
24375: 
48676: #ifdef DEBUG
26569: # define EVAL_CACHE_METER(x)    (JS_THREAD_DATA(cx)->evalCacheMeter.x++)
24375: #else
24375: # define EVAL_CACHE_METER(x)    ((void) 0)
24375: #endif
24375: 
    1: #ifdef DEBUG
    1: # define JS_RUNTIME_METER(rt, which)    JS_ATOMIC_INCREMENT(&(rt)->which)
    1: # define JS_RUNTIME_UNMETER(rt, which)  JS_ATOMIC_DECREMENT(&(rt)->which)
    1: #else
    1: # define JS_RUNTIME_METER(rt, which)    /* nothing */
    1: # define JS_RUNTIME_UNMETER(rt, which)  /* nothing */
    1: #endif
    1: 
    1: #define JS_KEEP_ATOMS(rt)   JS_ATOMIC_INCREMENT(&(rt)->gcKeepAtoms);
    1: #define JS_UNKEEP_ATOMS(rt) JS_ATOMIC_DECREMENT(&(rt)->gcKeepAtoms);
    1: 
    1: #ifdef JS_ARGUMENT_FORMATTER_DEFINED
    1: /*
    1:  * Linked list mapping format strings for JS_{Convert,Push}Arguments{,VA} to
    1:  * formatter functions.  Elements are sorted in non-increasing format string
    1:  * length order.
    1:  */
    1: struct JSArgumentFormatMap {
    1:     const char          *format;
    1:     size_t              length;
    1:     JSArgumentFormatter formatter;
    1:     JSArgumentFormatMap *next;
    1: };
    1: #endif
    1: 
    1: /*
    1:  * Key and entry types for the JSContext.resolvingTable hash table, typedef'd
    1:  * here because all consumers need to see these declarations (and not just the
    1:  * typedef names, as would be the case for an opaque pointer-to-typedef'd-type
    1:  * declaration), along with cx->resolvingTable.
    1:  */
    1: typedef struct JSResolvingKey {
    1:     JSObject            *obj;
    1:     jsid                id;
    1: } JSResolvingKey;
    1: 
    1: typedef struct JSResolvingEntry {
    1:     JSDHashEntryHdr     hdr;
    1:     JSResolvingKey      key;
    1:     uint32              flags;
    1: } JSResolvingEntry;
    1: 
    1: #define JSRESFLAG_LOOKUP        0x1     /* resolving id from lookup */
    1: #define JSRESFLAG_WATCH         0x2     /* resolving id from watch */
40221: #define JSRESOLVE_INFER         0xffff  /* infer bits from current bytecode */
40378: 
37717: extern const JSDebugHooks js_NullDebugHooks;  /* defined in jsdbgapi.cpp */
37717: 
40221: namespace js {
52503: 
40221: class AutoGCRooter;
50491: 
53848: #define JS_HAS_OPTION(cx,option)        (((cx)->options & (option)) != 0)
53848: #define JS_HAS_STRICT_OPTION(cx)        JS_HAS_OPTION(cx, JSOPTION_STRICT)
53848: #define JS_HAS_WERROR_OPTION(cx)        JS_HAS_OPTION(cx, JSOPTION_WERROR)
53848: #define JS_HAS_COMPILE_N_GO_OPTION(cx)  JS_HAS_OPTION(cx, JSOPTION_COMPILE_N_GO)
53848: #define JS_HAS_ATLINE_OPTION(cx)        JS_HAS_OPTION(cx, JSOPTION_ATLINE)
53848: 
53848: static inline bool
53848: OptionsHasXML(uint32 options)
53848: {
53848:     return !!(options & JSOPTION_XML);
53848: }
53848: 
53848: static inline bool
53848: OptionsHasAnonFunFix(uint32 options)
53848: {
53848:     return !!(options & JSOPTION_ANONFUNFIX);
53848: }
53848: 
53848: static inline bool
53848: OptionsSameVersionFlags(uint32 self, uint32 other)
53848: {
53848:     static const uint32 mask = JSOPTION_XML | JSOPTION_ANONFUNFIX;
53848:     return !((self & mask) ^ (other & mask));
53848: }
53848: 
57816: /*
57816:  * Flags accompany script version data so that a) dynamically created scripts
57816:  * can inherit their caller's compile-time properties and b) scripts can be
57816:  * appropriately compared in the eval cache across global option changes. An
57816:  * example of the latter is enabling the top-level-anonymous-function-is-error
57816:  * option: subsequent evals of the same, previously-valid script text may have
57816:  * become invalid.
57816:  */
53848: namespace VersionFlags {
53848: static const uint32 MASK        = 0x0FFF; /* see JSVersion in jspubtd.h */
53848: static const uint32 HAS_XML     = 0x1000; /* flag induced by XML option */
53848: static const uint32 ANONFUNFIX  = 0x2000; /* see jsapi.h comment on JSOPTION_ANONFUNFIX */
53848: }
53848: 
54417: static inline JSVersion
54417: VersionNumber(JSVersion version)
54417: {
54417:     return JSVersion(uint32(version) & VersionFlags::MASK);
54417: }
54417: 
53848: static inline bool
53848: VersionHasXML(JSVersion version)
53848: {
53848:     return !!(version & VersionFlags::HAS_XML);
53848: }
53848: 
54417: /* @warning This is a distinct condition from having the XML flag set. */
54417: static inline bool
54417: VersionShouldParseXML(JSVersion version)
54417: {
54417:     return VersionHasXML(version) || VersionNumber(version) >= JSVERSION_1_6;
54417: }
54417: 
53848: static inline bool
53848: VersionHasAnonFunFix(JSVersion version)
53848: {
53848:     return !!(version & VersionFlags::ANONFUNFIX);
53848: }
53848: 
53848: static inline void
53848: VersionSetXML(JSVersion *version, bool enable)
53848: {
53848:     if (enable)
53848:         *version = JSVersion(uint32(*version) | VersionFlags::HAS_XML);
53848:     else
53848:         *version = JSVersion(uint32(*version) & ~VersionFlags::HAS_XML);
53848: }
53848: 
53848: static inline void
53848: VersionSetAnonFunFix(JSVersion *version, bool enable)
53848: {
53848:     if (enable)
53848:         *version = JSVersion(uint32(*version) | VersionFlags::ANONFUNFIX);
53848:     else
53848:         *version = JSVersion(uint32(*version) & ~VersionFlags::ANONFUNFIX);
53848: }
53848: 
53848: static inline JSVersion
53848: VersionExtractFlags(JSVersion version)
53848: {
53848:     return JSVersion(uint32(version) & ~VersionFlags::MASK);
53848: }
53848: 
53848: static inline bool
53848: VersionHasFlags(JSVersion version)
53848: {
53848:     return !!VersionExtractFlags(version);
53848: }
53848: 
53848: static inline bool
53848: VersionIsKnown(JSVersion version)
53848: {
53848:     return VersionNumber(version) != JSVERSION_UNKNOWN;
53848: }
53848: 
52503: } /* namespace js */
50491: 
38568: struct JSContext
38568: {
42714:     explicit JSContext(JSRuntime *rt);
38568: 
23092:     /* JSRuntime contextList linkage. */
23092:     JSCList             link;
23092: 
53848:   private:
53848:     /* See JSContext::findVersion. */
53848:     JSVersion           defaultVersion;      /* script compilation version */
53848:     JSVersion           versionOverride;     /* supercedes defaultVersion when valid */
53848:     bool                hasVersionOverride;
53848: 
53848:   public:
    1:     /* Per-context options. */
    1:     uint32              options;            /* see jsapi.h for JSOPTION_* */
    1: 
    1:     /* Locale specific callbacks for string conversion. */
    1:     JSLocaleCallbacks   *localeCallbacks;
    1: 
    1:     /*
    1:      * cx->resolvingTable is non-null and non-empty if we are initializing
    1:      * standard classes lazily, or if we are otherwise recursing indirectly
48470:      * from js_LookupProperty through a Class.resolve hook.  It is used to
    1:      * limit runaway recursion (see jsapi.c and jsobj.c).
    1:      */
    1:     JSDHashTable        *resolvingTable;
    1: 
    1:     /*
    1:      * True if generating an error, to prevent runaway recursion.
48479:      * NB: generatingError packs with throwing below.
    1:      */
    1:     JSPackedBool        generatingError;
    1: 
    1:     /* Exception state -- the exception member is a GC root by definition. */
52786:     JSBool              throwing;           /* is there a pending exception? */
48470:     js::Value           exception;          /* most-recently-thrown exception */
    1: 
 5344:     /* Limit pointer for checking native stack consumption during recursion. */
    1:     jsuword             stackLimit;
    1: 
 5344:     /* Quota on the size of arenas used to compile and execute scripts. */
 5344:     size_t              scriptStackQuota;
 5344: 
    1:     /* Data shared by threads in an address space. */
32777:     JSRuntime *const    runtime;
32777: 
43286:     /* GC heap compartment. */
43286:     JSCompartment       *compartment;
43286: 
51446:     /* Currently executing frame and regs, set by stack operations. */
42717:     JS_REQUIRES_STACK
42717:     JSFrameRegs         *regs;
42717: 
51446:     /* Current frame accessors. */
51446: 
51446:     JSStackFrame* fp() {
51446:         JS_ASSERT(regs && regs->fp);
51446:         return regs->fp;
51446:     }
51446: 
51446:     JSStackFrame* maybefp() {
51446:         JS_ASSERT_IF(regs, regs->fp);
51446:         return regs ? regs->fp : NULL;
51446:     }
51446: 
51446:     bool hasfp() {
51446:         JS_ASSERT_IF(regs, regs->fp);
51446:         return !!regs;
51446:     }
51446: 
52557:   public:
42714:     friend class js::StackSpace;
56201:     friend bool js::Interpret(JSContext *, JSStackFrame *, uintN, JSInterpMode);
54427: 
55607:     void resetCompartment();
42717: 
51446:     /* 'regs' must only be changed by calling this function. */
42717:     void setCurrentRegs(JSFrameRegs *regs) {
55607:         JS_ASSERT_IF(regs, regs->fp);
42717:         this->regs = regs;
55607:         if (!regs)
55607:             resetCompartment();
42717:     }
42717: 
    1:     /* Temporary arena pool used while compiling and decompiling. */
    1:     JSArenaPool         tempPool;
    1: 
50491:     /* Temporary arena pool used while evaluate regular expressions. */
50491:     JSArenaPool         regExpPool;
50491: 
    1:     /* Top-level object and pointer to top stack frame's scope chain. */
    1:     JSObject            *globalObject;
    1: 
    1:     /* State for object and array toSource conversion. */
    1:     JSSharpObjectMap    sharpObjectMap;
38568:     js::HashSet<JSObject *> busyArrays;
    1: 
    1:     /* Argument formatter support for JS_{Convert,Push}Arguments{,VA}. */
    1:     JSArgumentFormatMap *argumentFormatMap;
    1: 
56604:     /* Last message string and log file for debugging. */
    1:     char                *lastMessage;
    1: #ifdef DEBUG
56604:     void                *logfp;
56604:     jsbytecode          *logPrevPc;
    1: #endif
    1: 
 9780:     /* Per-context optional error reporter. */
    1:     JSErrorReporter     errorReporter;
    1: 
25087:     /* Branch callback. */
 9780:     JSOperationCallback operationCallback;
 9780: 
    1:     /* Interpreter activation count. */
    1:     uintN               interpLevel;
    1: 
20312:     /* Client opaque pointers. */
    1:     void                *data;
20312:     void                *data2;
    1: 
37777:   private:
50466:     /* Linked list of segments. See StackSegment. */
50466:     js::StackSegment *currentSegment;
37777: 
37777:   public:
48531:     void assertSegmentsInSync() const {
42714: #ifdef DEBUG
51446:         if (regs) {
48531:             JS_ASSERT(currentSegment->isActive());
50466:             if (js::StackSegment *prev = currentSegment->getPreviousInContext())
42714:                 JS_ASSERT(!prev->isActive());
42714:         } else {
48531:             JS_ASSERT_IF(currentSegment, !currentSegment->isActive());
42714:         }
42714: #endif
42714:     }
42714: 
48531:     /* Return whether this context has an active segment. */
48531:     bool hasActiveSegment() const {
48531:         assertSegmentsInSync();
51446:         return !!regs;
42714:     }
42714: 
48531:     /* Assuming there is an active segment, return it. */
50466:     js::StackSegment *activeSegment() const {
48531:         JS_ASSERT(hasActiveSegment());
48531:         return currentSegment;
37777:     }
37777: 
48531:     /* Return the current segment, which may or may not be active. */
50466:     js::StackSegment *getCurrentSegment() const {
48531:         assertSegmentsInSync();
48531:         return currentSegment;
42714:     }
42714: 
53858:     inline js::RegExpStatics *regExpStatics();
53858: 
48531:     /* Add the given segment to the list as the new active segment. */
51446:     void pushSegmentAndFrame(js::StackSegment *newseg, JSFrameRegs &regs);
42708: 
48531:     /* Remove the active segment and make the next segment active. */
48531:     void popSegmentAndFrame();
48531: 
48531:     /* Mark the top segment as suspended, without pushing a new one. */
48531:     void saveActiveSegment();
48531: 
48531:     /* Undoes calls to suspendActiveSegment. */
48531:     void restoreSegment();
37777: 
54832:     /* Get the frame whose prev() is fp, which may be in any segment. */
54832:     inline JSStackFrame *computeNextFrame(JSStackFrame *fp);
54832: 
40276:     /*
48531:      * Perform a linear search of all frames in all segments in the given context
48531:      * for the given frame, returning the segment, if found, and null otherwise.
40276:      */
50466:     js::StackSegment *containingSegment(const JSStackFrame *target);
40276: 
53848:     /* Search the call stack for the nearest frame with static level targetLevel. */
53848:     JSStackFrame *findFrameAtLevel(uintN targetLevel) const {
53848:         JSStackFrame *fp = regs->fp;
48582:         while (true) {
53840:             JS_ASSERT(fp && fp->isScriptFrame());
53840:             if (fp->script()->staticLevel == targetLevel)
48582:                 break;
53840:             fp = fp->prev();
48582:         }
48582:         return fp;
48582:     }
48582: 
53848:   private:
53848:     /*
53848:      * The default script compilation version can be set iff there is no code running.
53848:      * This typically occurs via the JSAPI right after a context is constructed.
53848:      */
57819:     bool canSetDefaultVersion() const {
57819:         return !regs && !hasVersionOverride;
57819:     }
53848: 
53848:     /* Force a version for future script compilation. */
53848:     void overrideVersion(JSVersion newVersion) {
53848:         JS_ASSERT(!canSetDefaultVersion());
53848:         versionOverride = newVersion;
53848:         hasVersionOverride = true;
53848:     }
53848: 
53848:   public:
57819:     void clearVersionOverride() {
57819:         hasVersionOverride = false;
57819:     }
57819:     
57819:     bool isVersionOverridden() const {
57819:         return hasVersionOverride;
57819:     }
53848: 
53848:     /* Set the default script compilation version. */
57819:     void setDefaultVersion(JSVersion version) {
57819:         defaultVersion = version;
57819:     }
53848: 
53848:     /*
53848:      * Set the default version if possible; otherwise, force the version.
53848:      * Return whether an override occurred.
53848:      */
53848:     bool maybeOverrideVersion(JSVersion newVersion) {
53848:         if (canSetDefaultVersion()) {
53848:             setDefaultVersion(newVersion);
53848:             return false;
53848:         }
53848:         overrideVersion(newVersion);
53848:         return true;
53848:     }
53848: 
53848:     /*
53848:      * Return:
53848:      * - The override version, if there is an override version.
53848:      * - The newest scripted frame's version, if there is such a frame. 
53848:      * - The default verion.
53848:      *
53848:      * @note    If this ever shows up in a profile, just add caching!
53848:      */
53848:     JSVersion findVersion() const {
53848:         if (hasVersionOverride)
53848:             return versionOverride;
53848: 
53848:         if (regs) {
53848:             /* There may be a scripted function somewhere on the stack! */
53848:             JSStackFrame *fp = regs->fp;
53848:             while (fp && !fp->isScriptFrame())
53848:                 fp = fp->prev();
53848:             if (fp)
53848:                 return fp->script()->getVersion();
53848:         }
53848: 
53848:         return defaultVersion;
53848:     }
53848: 
57819:     void optionFlagsToVersion(JSVersion *version) const {
57819:         js::VersionSetXML(version, js::OptionsHasXML(options));
57819:         js::VersionSetAnonFunFix(version, js::OptionsHasAnonFunFix(options));
57819:     }
57819: 
57819:     void checkOptionVersionSync() const {
57819: #ifdef DEBUG
57819:         JSVersion version = findVersion();
57819:         JS_ASSERT(js::VersionHasXML(version) == js::OptionsHasXML(options));
57819:         JS_ASSERT(js::VersionHasAnonFunFix(version) == js::OptionsHasAnonFunFix(options));
57819: #endif
57819:     }
57819: 
57819:     /* Note: may override the version. */
57819:     void syncOptionsToVersion() {
57819:         JSVersion version = findVersion();
57819:         if (js::OptionsHasXML(options) == js::VersionHasXML(version) &&
57819:             js::OptionsHasAnonFunFix(options) == js::VersionHasAnonFunFix(version))
57819:             return;
57819:         js::VersionSetXML(&version, js::OptionsHasXML(options));
57819:         js::VersionSetAnonFunFix(&version, js::OptionsHasAnonFunFix(options));
57819:         maybeOverrideVersion(version);
57819:     }
57819: 
    1: #ifdef JS_THREADSAFE
    1:     JSThread            *thread;
53548:     unsigned            outstandingRequests;/* number of JS_BeginRequest calls
53548:                                                without the corresponding
53548:                                                JS_EndRequest. */
    1:     JSCList             threadLinks;        /* JSThread contextList linkage */
    1: 
    1: #define CX_FROM_THREAD_LINKS(tl) \
    1:     ((JSContext *)((char *)(tl) - offsetof(JSContext, threadLinks)))
    1: #endif
    1: 
40221:     /* Stack of thread-stack-allocated GC roots. */
40221:     js::AutoGCRooter   *autoGCRooters;
40221: 
 2433:     /* Debug hooks associated with the current context. */
35331:     const JSDebugHooks  *debugHooks;
18870: 
18870:     /* Security callbacks that override any defined on the runtime. */
18870:     JSSecurityCallbacks *securityCallbacks;
19196: 
19712:     /* Stored here to avoid passing it around as a parameter. */
19712:     uintN               resolveFlags;
24598: 
40306:     /* Random number generator state, used by jsmath.cpp. */
40306:     int64               rngSeed;
40306: 
42641:     /* Location to stash the iteration value between JSOP_MOREITER and JSOP_FOR*. */
48470:     js::Value           iterValue;
42641: 
24612: #ifdef JS_TRACER
24612:     /*
24612:      * State for the current tree execution.  bailExit is valid if the tree has
24612:      * called back into native code via a _FAIL builtin and has not yet bailed,
24612:      * else garbage (NULL in debug builds).
24612:      */
41276:     js::TracerState     *tracerState;
37741:     js::VMSideExit      *bailExit;
35331: 
35331:     /*
54175:      * True if traces may be executed. Invariant: The value of traceJitenabled
54175:      * is always equal to the expression in updateJITEnabled below.
35331:      *
35331:      * This flag and the fields accessed by updateJITEnabled are written only
35331:      * in runtime->gcLock, to avoid race conditions that would leave the wrong
54175:      * value in traceJitEnabled. (But the interpreter reads this without
35331:      * locking. That can race against another thread setting debug hooks, but
35331:      * we always read cx->debugHooks without locking anyway.)
35331:      */
54175:     bool                 traceJitEnabled;
24612: #endif
30453: 
54175: #ifdef JS_METHODJIT
54175:     bool                 methodJitEnabled;
56551:     bool                 profilingEnabled;
54175: #endif
54175: 
35331:     /* Caller must be holding runtime->gcLock. */
54175:     void updateJITEnabled();
35331: 
50455: #ifdef MOZ_TRACE_JSCALLS
50455:     /* Function entry/exit debugging callback. */
50455:     JSFunctionCallback    functionCallback;
50455: 
50455:     void doFunctionCallback(const JSFunction *fun,
50455:                             const JSScript *scr,
57757:                             int entering) const
50455:     {
50455:         if (functionCallback)
50455:             functionCallback(fun, scr, this, entering);
50455:     }
50455: #endif
50455: 
43191:     DSTOffsetCache dstOffsetCache;
43191: 
43281:     /* List of currently active non-escaping enumerators (for-in). */
43281:     JSObject *enumerators;
41796: 
42714:   private:
42714:     /*
42714:      * To go from a live generator frame (on the stack) to its generator object
42714:      * (see comment js_FloatingFrameIfGenerator), we maintain a stack of active
42714:      * generators, pushing and popping when entering and leaving generator
42714:      * frames, respectively.
42714:      */
42714:     js::Vector<JSGenerator *, 2, js::SystemAllocPolicy> genStack;
42714: 
42714:   public:
56773: #ifdef JS_METHODJIT
56773:     inline js::mjit::JaegerCompartment *jaegerCompartment();
56773: #endif
56773: 
42714:     /* Return the generator object for the given generator frame. */
42714:     JSGenerator *generatorFor(JSStackFrame *fp) const;
42714: 
42714:     /* Early OOM-check. */
42717:     inline bool ensureGeneratorStackSpace();
42714: 
42714:     bool enterGenerator(JSGenerator *gen) {
42714:         return genStack.append(gen);
42714:     }
42714: 
42714:     void leaveGenerator(JSGenerator *gen) {
42714:         JS_ASSERT(genStack.back() == gen);
42714:         genStack.popBack();
42714:     }
42714: 
30851: #ifdef JS_THREADSAFE
41796:     /*
53592:      * When non-null JSContext::free delegates the job to the background
53592:      * thread.
41796:      */
53592:     js::GCHelperThread *gcBackgroundFree;
30851: #endif
30851: 
48619:     inline void* malloc(size_t bytes) {
53592:         return runtime->malloc(bytes, this);
34288:     }
32553: 
33128:     inline void* mallocNoReport(size_t bytes) {
33128:         JS_ASSERT(bytes != 0);
53592:         return runtime->malloc(bytes, NULL);
33128:     }
33128: 
30851:     inline void* calloc(size_t bytes) {
30851:         JS_ASSERT(bytes != 0);
53592:         return runtime->calloc(bytes, this);
30851:     }
30851: 
30851:     inline void* realloc(void* p, size_t bytes) {
53592:         return runtime->realloc(p, bytes, this);
30851:     }
30851: 
41796:     inline void free(void* p) {
30851: #ifdef JS_THREADSAFE
53592:         if (gcBackgroundFree) {
53592:             gcBackgroundFree->freeLater(p);
30851:             return;
30851:         }
41796: #endif
30851:         runtime->free(p);
30851:     }
32651: 
32651:     /*
32651:      * In the common case that we'd like to allocate the memory for an object
32651:      * with cx->malloc/free, we cannot use overloaded C++ operators (no
32651:      * placement delete).  Factor the common workaround into one place.
32651:      */
32651: #define CREATE_BODY(parms)                                                    \
32651:     void *memory = this->malloc(sizeof(T));                                   \
34288:     if (!memory)                                                              \
32651:         return NULL;                                                          \
32651:     return new(memory) T parms;
32651: 
32651:     template <class T>
32651:     JS_ALWAYS_INLINE T *create() {
32651:         CREATE_BODY(())
32651:     }
32651: 
32651:     template <class T, class P1>
32651:     JS_ALWAYS_INLINE T *create(const P1 &p1) {
32651:         CREATE_BODY((p1))
32651:     }
32651: 
32651:     template <class T, class P1, class P2>
32651:     JS_ALWAYS_INLINE T *create(const P1 &p1, const P2 &p2) {
32651:         CREATE_BODY((p1, p2))
32651:     }
32651: 
32651:     template <class T, class P1, class P2, class P3>
32651:     JS_ALWAYS_INLINE T *create(const P1 &p1, const P2 &p2, const P3 &p3) {
32651:         CREATE_BODY((p1, p2, p3))
32651:     }
32651: #undef CREATE_BODY
32651: 
32651:     template <class T>
32651:     JS_ALWAYS_INLINE void destroy(T *p) {
32651:         p->~T();
32651:         this->free(p);
32651:     }
34288: 
38604:     void purge();
38604: 
42714:     js::StackSpace &stack() const {
42714:         return JS_THREAD_DATA(this)->stackSpace;
42714:     }
42714: 
42717: #ifdef DEBUG
42717:     void assertValidStackDepth(uintN depth) {
51446:         JS_ASSERT(0 <= regs->sp - regs->fp->base());
51446:         JS_ASSERT(depth <= uintptr_t(regs->sp - regs->fp->base()));
42717:     }
42717: #else
42717:     void assertValidStackDepth(uintN /*depth*/) {}
42717: #endif
48619: 
57585:     enum DollarPath {
57585:         DOLLAR_LITERAL = 1,
57585:         DOLLAR_AMP,
57585:         DOLLAR_PLUS,
57585:         DOLLAR_TICK,
58511:         DOLLAR_QUOT,
58511:         DOLLAR_EMPTY,
58511:         DOLLAR_1,
58511:         DOLLAR_2,
58511:         DOLLAR_3,
58511:         DOLLAR_4,
58511:         DOLLAR_5,
58511:         DOLLAR_OTHER
57585:     };
58511: #ifdef XP_WIN
57585:     volatile DollarPath *dollarPath;
58511:     volatile JSSubString *sub;
57585:     volatile jschar *blackBox;
58511:     volatile jschar **repstrChars;
58511:     volatile jschar **repstrDollar;
58511:     volatile jschar **repstrDollarEnd;
58511:     volatile size_t *peekLen;
58511: #endif
57585: 
48619: private:
48619: 
48619:     /*
48619:      * The allocation code calls the function to indicate either OOM failure
48619:      * when p is null or that a memory pressure counter has reached some
48619:      * threshold when p is not null. The function takes the pointer and not
48619:      * a boolean flag to minimize the amount of code in its inlined callers.
48619:      */
48619:     JS_FRIEND_API(void) checkMallocGCPressure(void *p);
56018: 
56018:     /* To silence MSVC warning about using 'this' in a member initializer. */
56018:     JSContext *thisInInitializer() { return this; }
57585: }; /* struct JSContext */
    1: 
    1: #ifdef JS_THREADSAFE
    1: # define JS_THREAD_ID(cx)       ((cx)->thread ? (cx)->thread->id : 0)
47439: #endif
47439: 
47439: #if defined JS_THREADSAFE && defined DEBUG
47439: 
47439: namespace js {
47439: 
47439: class AutoCheckRequestDepth {
47439:     JSContext *cx;
47439:   public:
53548:     AutoCheckRequestDepth(JSContext *cx) : cx(cx) { cx->thread->checkRequestDepth++; }
47439: 
47439:     ~AutoCheckRequestDepth() {
53548:         JS_ASSERT(cx->thread->checkRequestDepth != 0);
53548:         cx->thread->checkRequestDepth--;
47439:     }
47439: };
47439: 
47439: }
47439: 
43230: # define CHECK_REQUEST(cx)                                                    \
53548:     JS_ASSERT((cx)->thread);                                                  \
56559:     JS_ASSERT((cx)->thread->data.requestDepth || (cx)->thread == (cx)->runtime->gcThread); \
47439:     AutoCheckRequestDepth _autoCheckRequestDepth(cx);
47439: 
43230: #else
43230: # define CHECK_REQUEST(cx)          ((void) 0)
53548: # define CHECK_REQUEST_THREAD(cx)   ((void) 0)
    1: #endif
    1: 
42717: static inline uintN
42717: FramePCOffset(JSContext *cx, JSStackFrame* fp)
42717: {
53840:     jsbytecode *pc = fp->hasImacropc() ? fp->imacropc() : fp->pc(cx);
53840:     return uintN(pc - fp->script()->code);
42717: }
24293: 
24293: static inline JSAtom **
24293: FrameAtomBase(JSContext *cx, JSStackFrame *fp)
24293: {
53840:     return fp->hasImacropc()
24293:            ? COMMON_ATOMS_START(&cx->runtime->atomState)
53840:            : fp->script()->atomMap.vector;
24293: }
24293: 
40221: namespace js {
40221: 
40221: class AutoGCRooter {
40221:   public:
40221:     AutoGCRooter(JSContext *cx, ptrdiff_t tag)
40221:       : down(cx->autoGCRooters), tag(tag), context(cx)
40221:     {
40221:         JS_ASSERT(this != cx->autoGCRooters);
53548:         CHECK_REQUEST(cx);
40221:         cx->autoGCRooters = this;
40221:     }
40221: 
40221:     ~AutoGCRooter() {
40221:         JS_ASSERT(this == context->autoGCRooters);
53548:         CHECK_REQUEST(context);
40221:         context->autoGCRooters = down;
40221:     }
40221: 
47447:     /* Implemented in jsgc.cpp. */
40221:     inline void trace(JSTracer *trc);
40221: 
40431: #ifdef __GNUC__
40431: # pragma GCC visibility push(default)
40431: #endif
53548:     friend void MarkContext(JSTracer *trc, JSContext *acx);
53548:     friend void MarkRuntime(JSTracer *trc);
40431: #ifdef __GNUC__
40431: # pragma GCC visibility pop
40431: #endif
40221: 
40221:   protected:
40221:     AutoGCRooter * const down;
40221: 
40221:     /*
40221:      * Discriminates actual subclass of this being used.  If non-negative, the
48470:      * subclass roots an array of values of the length stored in this field.
40221:      * If negative, meaning is indicated by the corresponding value in the enum
40221:      * below.  Any other negative value indicates some deeper problem such as
40221:      * memory corruption.
40221:      */
40221:     ptrdiff_t tag;
40221: 
40221:     JSContext * const context;
40221: 
40221:     enum {
40221:         JSVAL =        -1, /* js::AutoValueRooter */
52503:         SHAPE =        -2, /* js::AutoShapeRooter */
51109:         PARSER =       -3, /* js::Parser */
51109:         SCRIPT =       -4, /* js::AutoScriptRooter */
51109:         ENUMERATOR =   -5, /* js::AutoEnumStateRooter */
51109:         IDARRAY =      -6, /* js::AutoIdArray */
51109:         DESCRIPTORS =  -7, /* js::AutoPropDescArrayRooter */
51109:         NAMESPACES =   -8, /* js::AutoNamespaceArray */
51109:         XML =          -9, /* js::AutoXMLRooter */
51109:         OBJECT =      -10, /* js::AutoObjectRooter */
51109:         ID =          -11, /* js::AutoIdRooter */
51109:         VALVECTOR =   -12, /* js::AutoValueVector */
51109:         DESCRIPTOR =  -13, /* js::AutoPropertyDescriptorRooter */
51109:         STRING =      -14, /* js::AutoStringRooter */
51109:         IDVECTOR =    -15  /* js::AutoIdVector */
40221:     };
41103: 
41103:     private:
41103:     /* No copy or assignment semantics. */
41103:     AutoGCRooter(AutoGCRooter &ida);
41103:     void operator=(AutoGCRooter &ida);
40221: };
40221: 
40221: /* FIXME(bug 332648): Move this into a public header. */
40221: class AutoValueRooter : private AutoGCRooter
40221: {
40221:   public:
48470:     explicit AutoValueRooter(JSContext *cx
48470:                              JS_GUARD_OBJECT_NOTIFIER_PARAM)
48470:       : AutoGCRooter(cx, JSVAL), val(js::NullValue())
48470:     {
48470:         JS_GUARD_OBJECT_NOTIFIER_INIT;
48470:     }
48470: 
48470:     AutoValueRooter(JSContext *cx, const Value &v
40221:                     JS_GUARD_OBJECT_NOTIFIER_PARAM)
40221:       : AutoGCRooter(cx, JSVAL), val(v)
40221:     {
40221:         JS_GUARD_OBJECT_NOTIFIER_INIT;
40221:     }
48470: 
48470:     AutoValueRooter(JSContext *cx, jsval v
40221:                     JS_GUARD_OBJECT_NOTIFIER_PARAM)
48470:       : AutoGCRooter(cx, JSVAL), val(js::Valueify(v))
40221:     {
40221:         JS_GUARD_OBJECT_NOTIFIER_INIT;
40221:     }
48470: 
48470:     /*
48470:      * If you are looking for Object* overloads, use AutoObjectRooter instead;
48470:      * rooting Object*s as a js::Value requires discerning whether or not it is
48470:      * a function object. Also, AutoObjectRooter is smaller.
48470:      */
48470: 
48470:     void set(Value v) {
42834:         JS_ASSERT(tag == JSVAL);
42834:         val = v;
42834:     }
42834: 
48470:     void set(jsval v) {
40221:         JS_ASSERT(tag == JSVAL);
48470:         val = js::Valueify(v);
40221:     }
40221: 
48470:     const Value &value() const {
40221:         JS_ASSERT(tag == JSVAL);
40221:         return val;
40221:     }
40221: 
48470:     Value *addr() {
40221:         JS_ASSERT(tag == JSVAL);
40221:         return &val;
40221:     }
40221: 
48470:     const jsval &jsval_value() const {
48470:         JS_ASSERT(tag == JSVAL);
48470:         return Jsvalify(val);
48470:     }
48470: 
48470:     jsval *jsval_addr() {
48470:         JS_ASSERT(tag == JSVAL);
48470:         return Jsvalify(&val);
48470:     }
48470: 
40221:     friend void AutoGCRooter::trace(JSTracer *trc);
53548:     friend void MarkRuntime(JSTracer *trc);
40221: 
40221:   private:
48470:     Value val;
40221:     JS_DECL_USE_GUARD_OBJECT_NOTIFIER
40221: };
40221: 
40221: class AutoObjectRooter : private AutoGCRooter {
40221:   public:
40221:     AutoObjectRooter(JSContext *cx, JSObject *obj = NULL
40221:                      JS_GUARD_OBJECT_NOTIFIER_PARAM)
40221:       : AutoGCRooter(cx, OBJECT), obj(obj)
40221:     {
40221:         JS_GUARD_OBJECT_NOTIFIER_INIT;
40221:     }
40221: 
40221:     void setObject(JSObject *obj) {
40221:         this->obj = obj;
40221:     }
40221: 
40221:     JSObject * object() const {
40221:         return obj;
40221:     }
40221: 
40221:     JSObject ** addr() {
40221:         return &obj;
40221:     }
40221: 
40221:     friend void AutoGCRooter::trace(JSTracer *trc);
53548:     friend void MarkRuntime(JSTracer *trc);
40221: 
40221:   private:
40221:     JSObject *obj;
40221:     JS_DECL_USE_GUARD_OBJECT_NOTIFIER
40221: };
40221: 
48470: class AutoStringRooter : private AutoGCRooter {
48470:   public:
48470:     AutoStringRooter(JSContext *cx, JSString *str = NULL
48470:                      JS_GUARD_OBJECT_NOTIFIER_PARAM)
48470:       : AutoGCRooter(cx, STRING), str(str)
48470:     {
48470:         JS_GUARD_OBJECT_NOTIFIER_INIT;
48470:     }
48470: 
48470:     void setString(JSString *str) {
48470:         this->str = str;
48470:     }
48470: 
48470:     JSString * string() const {
48470:         return str;
48470:     }
48470: 
48470:     JSString ** addr() {
48470:         return &str;
48470:     }
48470: 
48470:     friend void AutoGCRooter::trace(JSTracer *trc);
48470: 
48470:   private:
48470:     JSString *str;
48470:     JS_DECL_USE_GUARD_OBJECT_NOTIFIER
48470: };
48470: 
40221: class AutoArrayRooter : private AutoGCRooter {
40221:   public:
48470:     AutoArrayRooter(JSContext *cx, size_t len, Value *vec
40221:                     JS_GUARD_OBJECT_NOTIFIER_PARAM)
40221:       : AutoGCRooter(cx, len), array(vec)
40221:     {
40221:         JS_GUARD_OBJECT_NOTIFIER_INIT;
40221:         JS_ASSERT(tag >= 0);
40221:     }
40221: 
48470:     AutoArrayRooter(JSContext *cx, size_t len, jsval *vec
48470:                     JS_GUARD_OBJECT_NOTIFIER_PARAM)
48470:       : AutoGCRooter(cx, len), array(Valueify(vec))
48470:     {
48470:         JS_GUARD_OBJECT_NOTIFIER_INIT;
48470:         JS_ASSERT(tag >= 0);
48470:     }
48470: 
40221:     void changeLength(size_t newLength) {
40221:         tag = ptrdiff_t(newLength);
40221:         JS_ASSERT(tag >= 0);
40221:     }
40221: 
48470:     void changeArray(Value *newArray, size_t newLength) {
40221:         changeLength(newLength);
40221:         array = newArray;
40221:     }
40221: 
48470:     Value *array;
40221: 
40221:     friend void AutoGCRooter::trace(JSTracer *trc);
40221: 
40221:   private:
40221:     JS_DECL_USE_GUARD_OBJECT_NOTIFIER
40221: };
40221: 
52503: class AutoShapeRooter : private AutoGCRooter {
40221:   public:
52503:     AutoShapeRooter(JSContext *cx, const js::Shape *shape
40221:                     JS_GUARD_OBJECT_NOTIFIER_PARAM)
52503:       : AutoGCRooter(cx, SHAPE), shape(shape)
40221:     {
40221:         JS_GUARD_OBJECT_NOTIFIER_INIT;
40221:     }
40221: 
40221:     friend void AutoGCRooter::trace(JSTracer *trc);
53548:     friend void MarkRuntime(JSTracer *trc);
40221: 
40221:   private:
52503:     const js::Shape * const shape;
40221:     JS_DECL_USE_GUARD_OBJECT_NOTIFIER
40221: };
40221: 
40221: class AutoScriptRooter : private AutoGCRooter {
40221:   public:
40221:     AutoScriptRooter(JSContext *cx, JSScript *script
40221:                      JS_GUARD_OBJECT_NOTIFIER_PARAM)
40221:       : AutoGCRooter(cx, SCRIPT), script(script)
40221:     {
40221:         JS_GUARD_OBJECT_NOTIFIER_INIT;
40221:     }
40221: 
40221:     void setScript(JSScript *script) {
40221:         this->script = script;
40221:     }
40221: 
40221:     friend void AutoGCRooter::trace(JSTracer *trc);
40221: 
40221:   private:
40221:     JSScript *script;
40221:     JS_DECL_USE_GUARD_OBJECT_NOTIFIER
40221: };
40221: 
40221: class AutoIdRooter : private AutoGCRooter
40221: {
40221:   public:
40221:     explicit AutoIdRooter(JSContext *cx, jsid id = INT_TO_JSID(0)
40221:                           JS_GUARD_OBJECT_NOTIFIER_PARAM)
48470:       : AutoGCRooter(cx, ID), id_(id)
40221:     {
40221:         JS_GUARD_OBJECT_NOTIFIER_INIT;
40221:     }
40221: 
40221:     jsid id() {
48470:         return id_;
40221:     }
40221: 
40221:     jsid * addr() {
48470:         return &id_;
40221:     }
40221: 
40221:     friend void AutoGCRooter::trace(JSTracer *trc);
53548:     friend void MarkRuntime(JSTracer *trc);
40221: 
40221:   private:
48470:     jsid id_;
40221:     JS_DECL_USE_GUARD_OBJECT_NOTIFIER
40221: };
40221: 
40221: class AutoIdArray : private AutoGCRooter {
40221:   public:
40685:     AutoIdArray(JSContext *cx, JSIdArray *ida JS_GUARD_OBJECT_NOTIFIER_PARAM)
40685:       : AutoGCRooter(cx, IDARRAY), idArray(ida)
40221:     {
40221:         JS_GUARD_OBJECT_NOTIFIER_INIT;
40221:     }
40221:     ~AutoIdArray() {
40221:         if (idArray)
40221:             JS_DestroyIdArray(context, idArray);
40221:     }
40221:     bool operator!() {
40221:         return idArray == NULL;
40221:     }
40221:     jsid operator[](size_t i) const {
40221:         JS_ASSERT(idArray);
40221:         JS_ASSERT(i < size_t(idArray->length));
40221:         return idArray->vector[i];
40221:     }
40221:     size_t length() const {
40221:          return idArray->length;
40221:     }
40221: 
40221:     friend void AutoGCRooter::trace(JSTracer *trc);
40221: 
42733:     JSIdArray *steal() {
42733:         JSIdArray *copy = idArray;
42733:         idArray = NULL;
42733:         return copy;
42733:     }
42733: 
40221:   protected:
40221:     inline void trace(JSTracer *trc);
40221: 
40221:   private:
42733:     JSIdArray * idArray;
40221:     JS_DECL_USE_GUARD_OBJECT_NOTIFIER
40221: 
40221:     /* No copy or assignment semantics. */
40221:     AutoIdArray(AutoIdArray &ida);
40221:     void operator=(AutoIdArray &ida);
40221: };
40221: 
40221: /* The auto-root for enumeration object and its state. */
40221: class AutoEnumStateRooter : private AutoGCRooter
40221: {
40221:   public:
40221:     AutoEnumStateRooter(JSContext *cx, JSObject *obj
40221:                         JS_GUARD_OBJECT_NOTIFIER_PARAM)
48470:       : AutoGCRooter(cx, ENUMERATOR), obj(obj), stateValue()
40221:     {
40221:         JS_GUARD_OBJECT_NOTIFIER_INIT;
40221:         JS_ASSERT(obj);
40221:     }
40221: 
40221:     ~AutoEnumStateRooter() {
48470:         if (!stateValue.isNull()) {
40221: #ifdef DEBUG
40221:             JSBool ok =
40221: #endif
40221:             obj->enumerate(context, JSENUMERATE_DESTROY, &stateValue, 0);
40221:             JS_ASSERT(ok);
40221:         }
40221:     }
40221: 
40221:     friend void AutoGCRooter::trace(JSTracer *trc);
40221: 
48470:     const Value &state() const { return stateValue; }
48470:     Value *addr() { return &stateValue; }
40221: 
40221:   protected:
54707:     void trace(JSTracer *trc);
40221: 
40221:     JSObject * const obj;
40221: 
40221:   private:
48470:     Value stateValue;
40221:     JS_DECL_USE_GUARD_OBJECT_NOTIFIER
40221: };
40221: 
40221: #ifdef JS_HAS_XML_SUPPORT
40221: class AutoXMLRooter : private AutoGCRooter {
40221:   public:
40221:     AutoXMLRooter(JSContext *cx, JSXML *xml)
40221:       : AutoGCRooter(cx, XML), xml(xml)
40221:     {
40221:         JS_ASSERT(xml);
40221:     }
40221: 
40221:     friend void AutoGCRooter::trace(JSTracer *trc);
53548:     friend void MarkRuntime(JSTracer *trc);
40221: 
40221:   private:
40221:     JSXML * const xml;
40221: };
40221: #endif /* JS_HAS_XML_SUPPORT */
40221: 
40840: class AutoLockGC {
40840: private:
40840:     JSRuntime *rt;
40840: public:
40840:     explicit AutoLockGC(JSRuntime *rt) : rt(rt) { JS_LOCK_GC(rt); }
40840:     ~AutoLockGC() { JS_UNLOCK_GC(rt); }
40840: };
40840: 
40840: class AutoUnlockGC {
40840: private:
40840:     JSRuntime *rt;
40840: public:
40840:     explicit AutoUnlockGC(JSRuntime *rt) : rt(rt) { JS_UNLOCK_GC(rt); }
40840:     ~AutoUnlockGC() { JS_LOCK_GC(rt); }
40840: };
40840: 
54707: class AutoLockDefaultCompartment {
54707:   private:
54707:       JSContext *cx;
54707:   public:
54707:     AutoLockDefaultCompartment(JSContext *cx) : cx(cx) {
54707:         JS_LOCK(cx, &cx->runtime->atomState.lock);
54707: #ifdef JS_THREADSAFE
54707:         cx->runtime->defaultCompartmentIsLocked = true;
54707: #endif
54707:     }
54707:     ~AutoLockDefaultCompartment() {
54707:         JS_UNLOCK(cx, &cx->runtime->atomState.lock);
54707: #ifdef JS_THREADSAFE
54707:         cx->runtime->defaultCompartmentIsLocked = false;
54707: #endif
54707:     }
54707: };
54707: 
54707: class AutoUnlockDefaultCompartment {
54707:   private:
54707:       JSContext *cx;
54707:   public:
54707:     AutoUnlockDefaultCompartment(JSContext *cx) : cx(cx) {
54707:         JS_UNLOCK(cx, &cx->runtime->atomState.lock);
54707: #ifdef JS_THREADSAFE
54707:         cx->runtime->defaultCompartmentIsLocked = false;
54707: #endif
54707:     }
54707:     ~AutoUnlockDefaultCompartment() {
54707:         JS_LOCK(cx, &cx->runtime->atomState.lock);
54707: #ifdef JS_THREADSAFE
54707:         cx->runtime->defaultCompartmentIsLocked = true;
54707: #endif
54707:     }
54707: };
54707: 
40840: class AutoKeepAtoms {
40840:     JSRuntime *rt;
40840:   public:
40840:     explicit AutoKeepAtoms(JSRuntime *rt) : rt(rt) { JS_KEEP_ATOMS(rt); }
40840:     ~AutoKeepAtoms() { JS_UNKEEP_ATOMS(rt); }
40840: };
40840: 
50491: class AutoArenaAllocator {
50491:     JSArenaPool *pool;
50491:     void        *mark;
50491:   public:
50491:     explicit AutoArenaAllocator(JSArenaPool *pool) : pool(pool) { mark = JS_ARENA_MARK(pool); }
50491:     ~AutoArenaAllocator() { JS_ARENA_RELEASE(pool, mark); }
50491: 
50491:     template <typename T>
50491:     T *alloc(size_t elems) {
50491:         void *ptr;
50491:         JS_ARENA_ALLOCATE(ptr, pool, elems * sizeof(T));
50491:         return static_cast<T *>(ptr);
50491:     }
50491: };
50491: 
50491: class AutoReleasePtr {
50491:     JSContext   *cx;
50491:     void        *ptr;
50491:     AutoReleasePtr operator=(const AutoReleasePtr &other);
50491:   public:
50491:     explicit AutoReleasePtr(JSContext *cx, void *ptr) : cx(cx), ptr(ptr) {}
50491:     ~AutoReleasePtr() { cx->free(ptr); }
50491: };
50491: 
56211: /*
56211:  * FIXME: bug 602774: cleaner API for AutoReleaseNullablePtr
56211:  */
56211: class AutoReleaseNullablePtr {
56211:     JSContext   *cx;
56211:     void        *ptr;
56211:     AutoReleaseNullablePtr operator=(const AutoReleaseNullablePtr &other);
56211:   public:
56211:     explicit AutoReleaseNullablePtr(JSContext *cx, void *ptr) : cx(cx), ptr(ptr) {}
56211:     void reset(void *ptr2) {
56211:         if (ptr)
56211:             cx->free(ptr);
56211:         ptr = ptr2;
56211:     }
56211:     ~AutoReleaseNullablePtr() { if (ptr) cx->free(ptr); }
56211: };
56211: 
52503: class AutoLocalNameArray {
52503:   public:
52503:     explicit AutoLocalNameArray(JSContext *cx, JSFunction *fun
52503:                                 JS_GUARD_OBJECT_NOTIFIER_PARAM)
52503:       : context(cx),
52503:         mark(JS_ARENA_MARK(&cx->tempPool)),
52503:         names(fun->getLocalNameArray(cx, &cx->tempPool)),
52503:         count(fun->countLocalNames())
52503:     {
52503:         JS_GUARD_OBJECT_NOTIFIER_INIT;
52503:     }
52503: 
52503:     ~AutoLocalNameArray() {
52503:         JS_ARENA_RELEASE(&context->tempPool, mark);
52503:     }
52503: 
52503:     operator bool() const { return !!names; }
52503: 
52503:     uint32 length() const { return count; }
52503: 
52503:     const jsuword &operator [](unsigned i) const { return names[i]; }
52503: 
52503:   private:
52503:     JSContext   *context;
52503:     void        *mark;
52503:     jsuword     *names;
52503:     uint32      count;
52503: 
52503:     JS_DECL_USE_GUARD_OBJECT_NOTIFIER
52503: };
52503: 
40379: } /* namespace js */
40379: 
19712: class JSAutoResolveFlags
19712: {
19712:   public:
33538:     JSAutoResolveFlags(JSContext *cx, uintN flags
33538:                        JS_GUARD_OBJECT_NOTIFIER_PARAM)
40221:       : mContext(cx), mSaved(cx->resolveFlags)
40221:     {
33538:         JS_GUARD_OBJECT_NOTIFIER_INIT;
19712:         cx->resolveFlags = flags;
19712:     }
19712: 
19712:     ~JSAutoResolveFlags() { mContext->resolveFlags = mSaved; }
19712: 
19712:   private:
19712:     JSContext *mContext;
19712:     uintN mSaved;
33538:     JS_DECL_USE_GUARD_OBJECT_NOTIFIER
19712: };
24293: 
34365: extern JSThreadData *
34365: js_CurrentThreadData(JSRuntime *rt);
34365: 
    1: extern JSBool
26569: js_InitThreads(JSRuntime *rt);
    1: 
26569: extern void
26569: js_FinishThreads(JSRuntime *rt);
26569: 
26569: extern void
26569: js_PurgeThreads(JSContext *cx);
22627: 
42712: namespace js {
42712: 
42712: #ifdef JS_THREADSAFE
42712: 
42712: /* Iterator over JSThreadData from all JSThread instances. */
42712: class ThreadDataIter : public JSThread::Map::Range
42712: {
42712:   public:
42712:     ThreadDataIter(JSRuntime *rt) : JSThread::Map::Range(rt->threads.all()) {}
42712: 
42712:     JSThreadData *threadData() const {
42712:         return &front().value->data;
42712:     }
42712: };
42712: 
42712: #else /* !JS_THREADSAFE */
42712: 
42712: class ThreadDataIter
42712: {
42712:     JSRuntime *runtime;
42712:     bool done;
42712:   public:
42712:     ThreadDataIter(JSRuntime *rt) : runtime(rt), done(false) {}
42712: 
42712:     bool empty() const {
42712:         return done;
42712:     }
42712: 
42712:     void popFront() {
42712:         JS_ASSERT(!done);
42712:         done = true;
42712:     }
42712: 
42712:     JSThreadData *threadData() const {
42712:         JS_ASSERT(!done);
42712:         return &runtime->threadData;
42712:     }
42712: };
42712: 
42712: #endif  /* !JS_THREADSAFE */
42712: 
53631: } /* namespace js */
53631: 
22627: /*
    1:  * Create and destroy functions for JSContext, which is manually allocated
    1:  * and exclusively owned.
    1:  */
    1: extern JSContext *
    1: js_NewContext(JSRuntime *rt, size_t stackChunkSize);
    1: 
    1: extern void
    1: js_DestroyContext(JSContext *cx, JSDestroyContextMode mode);
    1: 
23092: static JS_INLINE JSContext *
23092: js_ContextFromLinkField(JSCList *link)
23092: {
23092:     JS_ASSERT(link);
23092:     return (JSContext *) ((uint8 *) link - offsetof(JSContext, link));
23092: }
23092: 
    1: /*
    1:  * If unlocked, acquire and release rt->gcLock around *iterp update; otherwise
    1:  * the caller must be holding rt->gcLock.
    1:  */
23442: extern JSContext *
    1: js_ContextIterator(JSRuntime *rt, JSBool unlocked, JSContext **iterp);
    1: 
    1: /*
25087:  * Iterate through contexts with active requests. The caller must be holding
25087:  * rt->gcLock in case of a thread-safe build, or otherwise guarantee that the
25087:  * context list is not alternated asynchroniously.
25087:  */
25087: extern JS_FRIEND_API(JSContext *)
25087: js_NextActiveContext(JSRuntime *, JSContext *);
25087: 
25087: /*
48470:  * Class.resolve and watchpoint recursion damping machinery.
    1:  */
    1: extern JSBool
    1: js_StartResolving(JSContext *cx, JSResolvingKey *key, uint32 flag,
    1:                   JSResolvingEntry **entryp);
    1: 
    1: extern void
    1: js_StopResolving(JSContext *cx, JSResolvingKey *key, uint32 flag,
    1:                  JSResolvingEntry *entry, uint32 generation);
    1: 
    1: /*
    1:  * Report an exception, which is currently realized as a printf-style format
    1:  * string and its arguments.
    1:  */
    1: typedef enum JSErrNum {
    1: #define MSG_DEF(name, number, count, exception, format) \
    1:     name = number,
    1: #include "js.msg"
    1: #undef MSG_DEF
    1:     JSErr_Limit
    1: } JSErrNum;
    1: 
18543: extern JS_FRIEND_API(const JSErrorFormatString *)
    1: js_GetErrorMessage(void *userRef, const char *locale, const uintN errorNumber);
    1: 
    1: #ifdef va_start
    1: extern JSBool
    1: js_ReportErrorVA(JSContext *cx, uintN flags, const char *format, va_list ap);
    1: 
    1: extern JSBool
    1: js_ReportErrorNumberVA(JSContext *cx, uintN flags, JSErrorCallback callback,
    1:                        void *userRef, const uintN errorNumber,
    1:                        JSBool charArgs, va_list ap);
    1: 
    1: extern JSBool
    1: js_ExpandErrorArguments(JSContext *cx, JSErrorCallback callback,
    1:                         void *userRef, const uintN errorNumber,
    1:                         char **message, JSErrorReport *reportp,
35302:                         bool charArgs, va_list ap);
    1: #endif
    1: 
48619: extern void
48619: js_ReportOutOfMemory(JSContext *cx);
48619: 
    1: /*
 8296:  * Report that cx->scriptStackQuota is exhausted.
 8296:  */
42714: void
 8296: js_ReportOutOfScriptQuota(JSContext *cx);
 8296: 
51514: extern JS_FRIEND_API(void)
 8296: js_ReportOverRecursed(JSContext *cx);
 8296: 
47574: extern JS_FRIEND_API(void)
12983: js_ReportAllocationOverflow(JSContext *cx);
12983: 
11139: #define JS_CHECK_RECURSION(cx, onerror)                                       \
11139:     JS_BEGIN_MACRO                                                            \
11139:         int stackDummy_;                                                      \
11139:                                                                               \
54707:         if (!JS_CHECK_STACK_SIZE(cx->stackLimit, &stackDummy_)) {             \
11139:             js_ReportOverRecursed(cx);                                        \
11139:             onerror;                                                          \
11139:         }                                                                     \
11139:     JS_END_MACRO
11139: 
 8296: /*
    1:  * Report an exception using a previously composed JSErrorReport.
    1:  * XXXbe remove from "friend" API
    1:  */
    1: extern JS_FRIEND_API(void)
    1: js_ReportErrorAgain(JSContext *cx, const char *message, JSErrorReport *report);
    1: 
    1: extern void
    1: js_ReportIsNotDefined(JSContext *cx, const char *name);
    1: 
    1: /*
 7897:  * Report an attempt to access the property of a null or undefined value (v).
 7897:  */
 7897: extern JSBool
48470: js_ReportIsNullOrUndefined(JSContext *cx, intN spindex, const js::Value &v,
 7897:                            JSString *fallback);
 7897: 
16519: extern void
48470: js_ReportMissingArg(JSContext *cx, const js::Value &v, uintN arg);
16519: 
 7897: /*
    1:  * Report error using js_DecompileValueGenerator(cx, spindex, v, fallback) as
    1:  * the first argument for the error message. If the error message has less
    1:  * then 3 arguments, use null for arg1 or arg2.
    1:  */
    1: extern JSBool
    1: js_ReportValueErrorFlags(JSContext *cx, uintN flags, const uintN errorNumber,
48470:                          intN spindex, const js::Value &v, JSString *fallback,
    1:                          const char *arg1, const char *arg2);
    1: 
    1: #define js_ReportValueError(cx,errorNumber,spindex,v,fallback)                \
    1:     ((void)js_ReportValueErrorFlags(cx, JSREPORT_ERROR, errorNumber,          \
    1:                                     spindex, v, fallback, NULL, NULL))
    1: 
    1: #define js_ReportValueError2(cx,errorNumber,spindex,v,fallback,arg1)          \
    1:     ((void)js_ReportValueErrorFlags(cx, JSREPORT_ERROR, errorNumber,          \
    1:                                     spindex, v, fallback, arg1, NULL))
    1: 
    1: #define js_ReportValueError3(cx,errorNumber,spindex,v,fallback,arg1,arg2)     \
    1:     ((void)js_ReportValueErrorFlags(cx, JSREPORT_ERROR, errorNumber,          \
    1:                                     spindex, v, fallback, arg1, arg2))
    1: 
    1: extern JSErrorFormatString js_ErrorFormatString[JSErr_Limit];
    1: 
48541: #ifdef JS_THREADSAFE
53548: # define JS_ASSERT_REQUEST_DEPTH(cx)  (JS_ASSERT((cx)->thread),               \
56559:                                        JS_ASSERT((cx)->thread->data.requestDepth >= 1))
48541: #else
48541: # define JS_ASSERT_REQUEST_DEPTH(cx)  ((void) 0)
48541: #endif
48541: 
 9780: /*
25087:  * If the operation callback flag was set, call the operation callback.
 9780:  * This macro can run the full GC. Return true if it is OK to continue and
 9780:  * false otherwise.
 9780:  */
25087: #define JS_CHECK_OPERATION_LIMIT(cx)                                          \
48541:     (JS_ASSERT_REQUEST_DEPTH(cx),                                             \
56559:      (!JS_THREAD_DATA(cx)->interruptFlags || js_InvokeOperationCallback(cx)))
56559: 
56559: JS_ALWAYS_INLINE void
56559: JSThreadData::triggerOperationCallback(JSRuntime *rt)
56559: {
56559:     /*
56559:      * Use JS_ATOMIC_SET and JS_ATOMIC_INCREMENT in the hope that it ensures
56559:      * the write will become immediately visible to other processors polling
56559:      * the flag.  Note that we only care about visibility here, not read/write
56559:      * ordering: this field can only be written with the GC lock held.
56559:      */
56559:     if (interruptFlags)
56559:         return;
56559:     JS_ATOMIC_SET(&interruptFlags, 1);
56559: 
56559: #ifdef JS_THREADSAFE
56559:     /* rt->interruptCounter does not reflect suspended threads. */
56559:     if (requestDepth != 0)
56559:         JS_ATOMIC_INCREMENT(&rt->interruptCounter);
56559: #endif
56559: }
 9780: 
 9780: /*
25087:  * Invoke the operation callback and return false if the current execution
25087:  * is to be terminated.
    1:  */
    1: extern JSBool
25087: js_InvokeOperationCallback(JSContext *cx);
23726: 
52753: extern JSBool
52753: js_HandleExecutionInterrupt(JSContext *cx);
52753: 
53592: namespace js {
53592: 
56559: /* These must be called with GC lock taken. */
56559: 
56560: JS_FRIEND_API(void)
56559: TriggerOperationCallback(JSContext *cx);
56559: 
48619: void
53592: TriggerAllOperationCallbacks(JSRuntime *rt);
53592: 
53592: } /* namespace js */
48619: 
25214: extern JSStackFrame *
25214: js_GetScriptedCaller(JSContext *cx, JSStackFrame *fp);
25214: 
26550: extern jsbytecode*
26550: js_GetCurrentBytecodePC(JSContext* cx);
26550: 
31911: extern bool
31911: js_CurrentPCIsInImacro(JSContext *cx);
31911: 
37741: namespace js {
37741: 
25214: #ifdef JS_TRACER
25214: /*
27882:  * Reconstruct the JS stack and clear cx->tracecx. We must be currently in a
27882:  * _FAIL builtin from trace on cx or another context on the same thread. The
27882:  * machine code for the trace remains on the C stack when js_DeepBail returns.
25214:  *
25214:  * Implemented in jstracer.cpp.
25214:  */
25214: JS_FORCES_STACK JS_FRIEND_API(void)
37741: DeepBail(JSContext *cx);
25214: #endif
25214: 
25214: static JS_FORCES_STACK JS_INLINE void
37741: LeaveTrace(JSContext *cx)
25214: {
25214: #ifdef JS_TRACER
25214:     if (JS_ON_TRACE(cx))
37741:         DeepBail(cx);
25214: #endif
25214: }
25214: 
27894: static JS_INLINE void
37741: LeaveTraceIfGlobalObject(JSContext *cx, JSObject *obj)
27894: {
48650:     if (!obj->parent)
37741:         LeaveTrace(cx);
27894: }
27894: 
25214: static JS_INLINE JSBool
37741: CanLeaveTrace(JSContext *cx)
25214: {
25214:     JS_ASSERT(JS_ON_TRACE(cx));
25214: #ifdef JS_TRACER
25214:     return cx->bailExit != NULL;
25214: #else
25214:     return JS_FALSE;
25214: #endif
25214: }
25214: 
48470: extern void
48470: SetPendingException(JSContext *cx, const Value &v);
48470: 
53858: class RegExpStatics;
53858: 
37741: } /* namespace js */
37741: 
22652: /*
51446:  * Get the current frame, first lazily instantiating stack frames if needed.
51446:  * (Do not access cx->fp() directly except in JS_REQUIRES_STACK code.)
22652:  *
22652:  * Defined in jstracer.cpp if JS_TRACER is defined.
22652:  */
25214: static JS_FORCES_STACK JS_INLINE JSStackFrame *
25214: js_GetTopStackFrame(JSContext *cx)
25214: {
37741:     js::LeaveTrace(cx);
51446:     return cx->maybefp();
25214: }
22652: 
33121: static JS_INLINE JSBool
33121: js_IsPropertyCacheDisabled(JSContext *cx)
33121: {
40362:     return cx->runtime->shapeGen >= js::SHAPE_OVERFLOW_BIT;
33121: }
33121: 
27546: static JS_INLINE uint32
27546: js_RegenerateShapeForGC(JSContext *cx)
27546: {
27546:     JS_ASSERT(cx->runtime->gcRunning);
30733:     JS_ASSERT(cx->runtime->gcRegenShapes);
27546: 
27546:     /*
27546:      * Under the GC, compared with js_GenerateShape, we don't need to use
27546:      * atomic increments but we still must make sure that after an overflow
27546:      * the shape stays such.
27546:      */
27546:     uint32 shape = cx->runtime->shapeGen;
40362:     shape = (shape + 1) | (shape & js::SHAPE_OVERFLOW_BIT);
27546:     cx->runtime->shapeGen = shape;
27546:     return shape;
27546: }
27546: 
34299: namespace js {
34299: 
38568: inline void *
38568: ContextAllocPolicy::malloc(size_t bytes)
34299: {
38568:     return cx->malloc(bytes);
38568: }
34299: 
38568: inline void
38568: ContextAllocPolicy::free(void *p)
38568: {
38568:     cx->free(p);
38568: }
34299: 
38568: inline void *
38568: ContextAllocPolicy::realloc(void *p, size_t bytes)
38568: {
38568:     return cx->realloc(p, bytes);
38568: }
38568: 
38568: inline void
38568: ContextAllocPolicy::reportAllocOverflow() const
38568: {
38568:     js_ReportAllocationOverflow(cx);
38568: }
34299: 
40418: class AutoValueVector : private AutoGCRooter
40418: {
40418:   public:
40418:     explicit AutoValueVector(JSContext *cx
40418:                              JS_GUARD_OBJECT_NOTIFIER_PARAM)
48470:         : AutoGCRooter(cx, VALVECTOR), vector(cx)
40418:     {
40418:         JS_GUARD_OBJECT_NOTIFIER_INIT;
40418:     }
40418: 
40418:     size_t length() const { return vector.length(); }
40418: 
48470:     bool append(const Value &v) { return vector.append(v); }
42641: 
42641:     void popBack() { vector.popBack(); }
40418: 
48470:     bool growBy(size_t inc) {
50457:         /* N.B. Value's default ctor leaves the Value undefined */
50451:         size_t oldLength = vector.length();
50451:         if (!vector.growByUninitialized(inc))
50451:             return false;
50451:         MakeValueRangeGCSafe(vector.begin() + oldLength, vector.end());
50451:         return true;
48470:     }
48470: 
40418:     bool resize(size_t newLength) {
50451:         size_t oldLength = vector.length();
50452:         if (newLength <= oldLength) {
50451:             vector.shrinkBy(oldLength - newLength);
50452:             return true;
50452:         }
50457:         /* N.B. Value's default ctor leaves the Value undefined */
50451:         if (!vector.growByUninitialized(newLength - oldLength))
50451:             return false;
50451:         MakeValueRangeGCSafe(vector.begin() + oldLength, vector.end());
50451:         return true;
40418:     }
40418: 
40418:     bool reserve(size_t newLength) {
40418:         return vector.reserve(newLength);
40418:     }
40418: 
48470:     Value &operator[](size_t i) { return vector[i]; }
48470:     const Value &operator[](size_t i) const { return vector[i]; }
48470: 
48470:     const Value *begin() const { return vector.begin(); }
48470:     Value *begin() { return vector.begin(); }
48470: 
48470:     const Value *end() const { return vector.end(); }
48470:     Value *end() { return vector.end(); }
48470: 
50465:     const jsval *jsval_begin() const { return Jsvalify(begin()); }
50465:     jsval *jsval_begin() { return Jsvalify(begin()); }
50465: 
50465:     const jsval *jsval_end() const { return Jsvalify(end()); }
50465:     jsval *jsval_end() { return Jsvalify(end()); }
50465: 
48470:     const Value &back() const { return vector.back(); }
40418: 
40418:     friend void AutoGCRooter::trace(JSTracer *trc);
40418: 
40418:   private:
48470:     Vector<Value, 8> vector;
40418:     JS_DECL_USE_GUARD_OBJECT_NOTIFIER
40418: };
40418: 
48470: class AutoIdVector : private AutoGCRooter
48470: {
48470:   public:
48470:     explicit AutoIdVector(JSContext *cx
48470:                           JS_GUARD_OBJECT_NOTIFIER_PARAM)
48470:         : AutoGCRooter(cx, IDVECTOR), vector(cx)
48470:     {
48470:         JS_GUARD_OBJECT_NOTIFIER_INIT;
48470:     }
48470: 
48470:     size_t length() const { return vector.length(); }
48470: 
48470:     bool append(jsid id) { return vector.append(id); }
48470: 
48470:     void popBack() { vector.popBack(); }
48470: 
48470:     bool growBy(size_t inc) {
50457:         /* N.B. jsid's default ctor leaves the jsid undefined */
50451:         size_t oldLength = vector.length();
50451:         if (!vector.growByUninitialized(inc))
50451:             return false;
50451:         MakeIdRangeGCSafe(vector.begin() + oldLength, vector.end());
50451:         return true;
48470:     }
48470: 
48470:     bool resize(size_t newLength) {
50451:         size_t oldLength = vector.length();
50452:         if (newLength <= oldLength) {
50451:             vector.shrinkBy(oldLength - newLength);
50452:             return true;
50452:         }
50457:         /* N.B. jsid's default ctor leaves the jsid undefined */
50451:         if (!vector.growByUninitialized(newLength - oldLength))
50451:             return false;
50451:         MakeIdRangeGCSafe(vector.begin() + oldLength, vector.end());
50451:         return true;
48470:     }
48470: 
48470:     bool reserve(size_t newLength) {
48470:         return vector.reserve(newLength);
48470:     }
48470: 
48470:     jsid &operator[](size_t i) { return vector[i]; }
48470:     const jsid &operator[](size_t i) const { return vector[i]; }
48470: 
48470:     const jsid *begin() const { return vector.begin(); }
48470:     jsid *begin() { return vector.begin(); }
48470: 
48470:     const jsid *end() const { return vector.end(); }
48470:     jsid *end() { return vector.end(); }
48470: 
48470:     const jsid &back() const { return vector.back(); }
48470: 
48470:     friend void AutoGCRooter::trace(JSTracer *trc);
48470: 
48470:   private:
48470:     Vector<jsid, 8> vector;
48470:     JS_DECL_USE_GUARD_OBJECT_NOTIFIER
48470: };
48470: 
42733: JSIdArray *
42733: NewIdArray(JSContext *cx, jsint length);
42733: 
48470: } /* namespace js */
48470: 
39928: #ifdef _MSC_VER
39928: #pragma warning(pop)
39928: #pragma warning(pop)
39928: #endif
39928: 
43110: #ifdef JS_UNDEFD_MOZALLOC_WRAPPERS
43110: #  include "mozilla/mozalloc_macro_wrappers.h"
43110: #endif
43110: 
    1: #endif /* jscntxt_h___ */
