29366: /* -*- Mode: C++; tab-width: 4; indent-tabs-mode: nil; c-basic-offset: 4 -*-
29900:  * vim: set ts=4 sw=4 et tw=99 ft=cpp:
17186:  *
17186:  * ***** BEGIN LICENSE BLOCK *****
17186:  * Version: MPL 1.1/GPL 2.0/LGPL 2.1
17186:  *
17186:  * The contents of this file are subject to the Mozilla Public License Version
17186:  * 1.1 (the "License"); you may not use this file except in compliance with
17186:  * the License. You may obtain a copy of the License at
17186:  * http://www.mozilla.org/MPL/
17186:  *
17186:  * Software distributed under the License is distributed on an "AS IS" basis,
17186:  * WITHOUT WARRANTY OF ANY KIND, either express or implied. See the License
17186:  * for the specific language governing rights and limitations under the
17186:  * License.
17186:  *
17186:  * The Original Code is Mozilla SpiderMonkey JavaScript 1.9 code, released
17186:  * May 28, 2008.
17186:  *
17186:  * The Initial Developer of the Original Code is
17339:  *   Brendan Eich <brendan@mozilla.org>
17186:  *
17186:  * Contributor(s):
17339:  *   Andreas Gal <gal@mozilla.com>
17671:  *   Mike Shaver <shaver@mozilla.org>
17671:  *   David Anderson <danderson@mozilla.com>
17186:  *
17186:  * Alternatively, the contents of this file may be used under the terms of
17186:  * either of the GNU General Public License Version 2 or later (the "GPL"),
17186:  * or the GNU Lesser General Public License Version 2.1 or later (the "LGPL"),
17186:  * in which case the provisions of the GPL or the LGPL are applicable instead
17186:  * of those above. If you wish to allow use of your version of this file only
17186:  * under the terms of either the GPL or the LGPL, and not to allow others to
17186:  * use your version of this file under the terms of the MPL, indicate your
17186:  * decision by deleting the provisions above and replace them with the notice
17186:  * and other provisions required by the GPL or the LGPL. If you do not delete
17186:  * the provisions above, a recipient may use your version of this file under
17186:  * the terms of any one of the MPL, the GPL or the LGPL.
17186:  *
17186:  * ***** END LICENSE BLOCK ***** */
17186: 
17196: #ifndef jstracer_h___
17196: #define jstracer_h___
17186: 
19171: #ifdef JS_TRACER
18091: 
21521: #include "jscntxt.h"
17811: #include "jstypes.h"
17186: #include "jslock.h"
17393: #include "jsnum.h"
17407: #include "jsinterp.h"
20408: #include "jsbuiltins.h"
17434: 
21459: #if defined(DEBUG) && !defined(JS_JIT_SPEW)
21459: #define JS_JIT_SPEW
21459: #endif
21459: 
17886: template <typename T>
21523: class Queue : public avmplus::GCObject {
17886:     T* _data;
17886:     unsigned _len;
17886:     unsigned _max;
17891: 
17891:     void ensure(unsigned size) {
29900:         if (!_max)
29900:             _max = 16;
17891:         while (_max < size)
17891:             _max <<= 1;
17891:         _data = (T*)realloc(_data, _max * sizeof(T));
24246: #if defined(DEBUG)
24246:         memset(&_data[_len], 0xcd, _max - _len);
24246: #endif
17891:     }
17886: public:
17886:     Queue(unsigned max = 16) {
17886:         this->_max = max;
17886:         this->_len = 0;
29900:         if (max)
17886:             this->_data = (T*)malloc(max * sizeof(T));
29900:         else
29900:             this->_data = NULL;
17886:     }
17886: 
17886:     ~Queue() {
17886:         free(_data);
17886:     }
17886: 
17973:     bool contains(T a) {
23709:         for (unsigned n = 0; n < _len; ++n) {
17973:             if (_data[n] == a)
17973:                 return true;
23709:         }
17973:         return false;
17973:     }
17973: 
17886:     void add(T a) {
18621:         ensure(_len + 1);
17886:         JS_ASSERT(_len <= _max);
17891:         _data[_len++] = a;
17886:     }
17891: 
18621:     void add(T* chunk, unsigned size) {
18621:         ensure(_len + size);
18621:         JS_ASSERT(_len <= _max);
18621:         memcpy(&_data[_len], chunk, size * sizeof(T));
18621:         _len += size;
18621:     }
18621: 
18051:     void addUnique(T a) {
18051:         if (!contains(a))
18051:             add(a);
18051:     }
18051: 
17891:     void setLength(unsigned len) {
17891:         ensure(len + 1);
17891:         _len = len;
17886:     }
17886: 
17886:     void clear() {
17886:         _len = 0;
17886:     }
17886: 
30279:     T & get(unsigned i) {
30279:         JS_ASSERT(i < length());
30279:         return _data[i];
30279:     }
30279: 
22609:     const T & get(unsigned i) const {
29900:         JS_ASSERT(i < length());
22609:         return _data[i];
22609:     }
22609: 
30279:     T & operator [](unsigned i) {
30279:         return get(i);
30279:     }
30279: 
29900:     const T & operator [](unsigned i) const {
29900:         return get(i);
29900:     }
29900: 
17886:     unsigned length() const {
17886:         return _len;
17886:     }
17886: 
17886:     T* data() const {
17886:         return _data;
17886:     }
17886: };
17886: 
17434: /*
17487:  * Tracker is used to keep track of values being manipulated by the interpreter
17487:  * during trace recording.
17293:  */
17487: class Tracker {
17293:     struct Page {
17293:         struct Page*    next;
17424:         jsuword         base;
17596:         nanojit::LIns*  map[1];
17293:     };
17293:     struct Page* pagelist;
17293: 
17424:     jsuword         getPageBase(const void* v) const;
17293:     struct Page*    findPage(const void* v) const;
17293:     struct Page*    addPage(const void* v);
17293: public:
17293:     Tracker();
17293:     ~Tracker();
17293: 
17773:     bool            has(const void* v) const;
17596:     nanojit::LIns*  get(const void* v) const;
17596:     void            set(const void* v, nanojit::LIns* ins);
17293:     void            clear();
17293: };
17293: 
23450: #ifdef JS_JIT_SPEW
29883: 
29883: enum LC_TMBits {
29883:     /* Output control bits for all non-Nanojit code.  Only use bits 16
29883:        and above, since Nanojit uses 0 .. 15 itself. */
29883:     LC_TMMinimal  = 1<<16,
29883:     LC_TMTracer   = 1<<17,
29883:     LC_TMRecorder = 1<<18,
29883:     LC_TMPatcher  = 1<<19,
29883:     LC_TMAbort    = 1<<20,
29883:     LC_TMStats    = 1<<21,
29883:     LC_TMRegexp   = 1<<22
29883: };
29883: 
29883: // Top level logging controller object.
29883: extern nanojit::LogControl js_LogController;
29883: 
29883: #define debug_only_stmt(stmt) \
29883:     stmt
29883: #define debug_only_printf(mask, fmt, ...) \
29883:     do { if ((js_LogController.lcbits & (mask)) > 0) {             \
29883:         js_LogController.printf(fmt, __VA_ARGS__); fflush(stdout); \
29883:     }} while (0)
29883: #define debug_only_print0(mask, str) \
29883:     do { if ((js_LogController.lcbits & (mask)) > 0) { \
29883:         js_LogController.printf(str); fflush(stdout);  \
29883:     }} while (0)
29883: 
23450: #else
29883: 
29883: #define debug_only_stmt(action)            /* */
29883: #define debug_only_printf(mask, fmt, ...)  /* */
29883: #define debug_only_print0(mask, str)       /* */
29883: 
23450: #endif
23450: 
17981: /*
24290:  * The oracle keeps track of hit counts for program counter locations, as
24290:  * well as slots that should not be demoted to int because we know them to
24290:  * overflow or they result in type-unstable traces. We are using simple
24290:  * hash tables.  Collisions lead to loss of optimization (demotable slots
24290:  * are not demoted, etc.) but have no correctness implications.
17981:  */
17981: #define ORACLE_SIZE 4096
17981: 
17981: class Oracle {
22613:     avmplus::BitSet _stackDontDemote;
22613:     avmplus::BitSet _globalDontDemote;
29354:     avmplus::BitSet _pcDontDemote;
17981: public:
24290:     Oracle();
24290: 
23456:     JS_REQUIRES_STACK void markGlobalSlotUndemotable(JSContext* cx, unsigned slot);
23456:     JS_REQUIRES_STACK bool isGlobalSlotUndemotable(JSContext* cx, unsigned slot) const;
23456:     JS_REQUIRES_STACK void markStackSlotUndemotable(JSContext* cx, unsigned slot);
23456:     JS_REQUIRES_STACK bool isStackSlotUndemotable(JSContext* cx, unsigned slot) const;
29354:     void markInstructionUndemotable(jsbytecode* pc);
29354:     bool isInstructionUndemotable(jsbytecode* pc) const;
29354: 
24290:     void clearDemotability();
24290:     void clear() {
24290:         clearDemotability();
24290:     }
17981: };
17981: 
29896: 
29896: #if defined(_MSC_VER) || defined(__GNUC__)
29896: #define USE_TRACE_TYPE_ENUM
29896: #endif
29896: 
29896: /*
29896:  * The types of values calculated during tracing, used to specialize operations
29896:  * to the types of those values.  These loosely correspond to the values of the
29896:  * JSVAL_* language types, but we add a few further divisions to enable further
29896:  * optimization at execution time.  Do not rely on this loose correspondence for
29896:  * correctness without adding static assertions!
29896:  *
29896:  * The ifdefs enforce that this enum occupies only one byte of memory, where
29896:  * possible.  If it doesn't, type maps will occupy more space but should
29896:  * otherwise work correctly.  A static assertion in jstracer.cpp verifies that
29896:  * this requirement is correctly enforced by these compilers.
29896:  */
29896: enum JSTraceType_
29896: #ifdef _MSC_VER
29896: : int8_t
29896: #endif
29896: {
29896:     TT_OBJECT         = 0, /* pointer to JSObject whose class is not js_FunctionClass */
29896:     TT_INT32          = 1, /* 32-bit signed integer */
29896:     TT_DOUBLE         = 2, /* pointer to jsdouble */
29896:     TT_JSVAL          = 3, /* arbitrary jsval */
29896:     TT_STRING         = 4, /* pointer to JSString */
29896:     TT_NULL           = 5, /* null */
29896:     TT_PSEUDOBOOLEAN  = 6, /* true, false, or undefined (0, 1, or 2) */
29896:     TT_FUNCTION       = 7  /* pointer to JSObject whose class is js_FunctionClass */
29896: }
29896: #ifdef __GNUC__
29896: __attribute__((packed))
29896: #endif
29896: ;
29896: 
29896: #ifdef USE_TRACE_TYPE_ENUM
29899: typedef JSTraceType_ JSTraceType;
29896: #else
29896: typedef int8_t JSTraceType;
29896: #endif
29896: 
29896: 
17992: typedef Queue<uint16> SlotList;
17992: 
29896: class TypeMap : public Queue<JSTraceType> {
17981: public:
29880:     JS_REQUIRES_STACK void captureTypes(JSContext* cx, JSObject* globalObj, SlotList& slots, unsigned callDepth);
29880:     JS_REQUIRES_STACK void captureMissingGlobalTypes(JSContext* cx, JSObject* globalObj, SlotList& slots,
24246:                                                      unsigned stackSlots);
18239:     bool matches(TypeMap& other) const;
17981: };
17981: 
29893: #define JS_TM_EXITCODES(_)    \
29893:     /*                                                                          \
29893:      * An exit at a possible branch-point in the trace at which to attach a     \
29893:      * future secondary trace. Therefore the recorder must generate different   \
29893:      * code to handle the other outcome of the branch condition from the        \
29893:      * primary trace's outcome.                                                 \
29893:      */                                                                         \
29893:     _(BRANCH)                                                                   \
29893:     /*                                                                          \
29893:      * Exit at a tableswitch via a numbered case.                               \
29893:      */                                                                         \
29893:     _(CASE)                                                                     \
29893:     /*                                                                          \
29893:      * Exit at a tableswitch via the default case.                              \
29893:      */                                                                         \
29893:     _(DEFAULT)                                                                  \
29893:     _(LOOP)                                                                     \
29893:     _(NESTED)                                                                   \
29893:     /*                                                                          \
29893:      * An exit from a trace because a condition relied upon at recording time   \
29893:      * no longer holds, where the alternate path of execution is so rare or     \
29893:      * difficult to address in native code that it is not traced at all, e.g.   \
29893:      * negative array index accesses, which differ from positive indexes in     \
29893:      * that they require a string-based property lookup rather than a simple    \
29893:      * memory access.                                                           \
29893:      */                                                                         \
29893:     _(MISMATCH)                                                                 \
29893:     /*                                                                          \
29893:      * A specialization of MISMATCH_EXIT to handle allocation failures.         \
29893:      */                                                                         \
29893:     _(OOM)                                                                      \
29893:     _(OVERFLOW)                                                                 \
29893:     _(UNSTABLE_LOOP)                                                            \
29893:     _(TIMEOUT)                                                                  \
29893:     _(DEEP_BAIL)                                                                \
29893:     _(STATUS)
29893:         
29893: 
21521: enum ExitType {
29893:     #define MAKE_EXIT_CODE(x) x##_EXIT,
29893:     JS_TM_EXITCODES(MAKE_EXIT_CODE)
29893:     #undef MAKE_EXIT_CODE
29895:     TOTAL_EXIT_TYPES
21521: };
21521: 
21521: struct VMSideExit : public nanojit::SideExit
21521: {
22925:     JSObject* block;
25111:     jsbytecode* pc;
25111:     jsbytecode* imacpc;
21521:     intptr_t sp_adj;
21521:     intptr_t rp_adj;
21521:     int32_t calldepth;
21521:     uint32 numGlobalSlots;
21521:     uint32 numStackSlots;
21521:     uint32 numStackSlotsBelowCurrentFrame;
21521:     ExitType exitType;
30034:     uintN lookupFlags;
28086: 
28086:     /*
28086:      * Ordinarily 0.  If a slow native function is atop the stack, the 1 bit is
28086:      * set if constructing and the other bits are a pointer to the funobj.
28086:      */
28446:     uintptr_t nativeCalleeWord;
28086: 
28086:     JSObject * nativeCallee() {
28086:         return (JSObject *) (nativeCalleeWord & ~1);
28086:     }
28086: 
28086:     bool constructing() {
28086:         return bool(nativeCalleeWord & 1);
28086:     }
28086: 
28086:     void setNativeCallee(JSObject *callee, bool constructing) {
28446:         nativeCalleeWord = uintptr_t(callee) | (constructing ? 1 : 0);
28086:     }
21521: };
21521: 
29896: static inline JSTraceType* getStackTypeMap(nanojit::SideExit* exit)
21521: {
29896:     return (JSTraceType*)(((VMSideExit*)exit) + 1);
21521: }
21521: 
29896: static inline JSTraceType* getGlobalTypeMap(nanojit::SideExit* exit)
24246: {
24246:     return getStackTypeMap(exit) + ((VMSideExit*)exit)->numStackSlots;
24246: }
24246: 
29896: static inline JSTraceType* getFullTypeMap(nanojit::SideExit* exit)
24246: {
24246:     return getStackTypeMap(exit);
24246: }
24246: 
24612: struct FrameInfo {
24612:     JSObject*       callee;     // callee function object
24612:     JSObject*       block;      // caller block chain head
25111:     jsbytecode*     pc;         // caller fp->regs->pc
25111:     jsbytecode*     imacpc;     // caller fp->imacpc
24612:     uint16          spdist;     // distance from fp->slots to fp->regs->sp at JSOP_CALL
28949: 
28949:     /*
28949:      * Bit  15 (0x8000) is a flag that is set if constructing (called through new).
28949:      * Bits 0-14 are the actual argument count. This may be less than fun->nargs.
28949:      */
28949:     uint16          argc;
28887: 
28840:     /*
28840:      * Stack pointer adjustment needed for navigation of native stack in
28840:      * js_GetUpvarOnTrace. spoffset is the number of slots in the native
28840:      * stack frame for the caller *before* the slots covered by spdist.
28840:      * This may be negative if the caller is the top level script.
28840:      * The key fact is that if we let 'cpos' be the start of the caller's
28840:      * native stack frame, then (cpos + spoffset) points to the first 
28840:      * non-argument slot in the callee's native stack frame.
28840:      */
28840:     int32          spoffset;
28949: 
28949:     // Safer accessors for argc.
28949:     enum { CONSTRUCTING_MASK = 0x8000 };
28949:     void   set_argc(uint16 argc, bool constructing) {
28949:         this->argc = argc | (constructing ? CONSTRUCTING_MASK : 0);
28949:     }
28949:     uint16 get_argc() const { return argc & ~CONSTRUCTING_MASK; }
28949:     bool   is_constructing() const { return (argc & CONSTRUCTING_MASK) != 0; }
28993: 
28993:     // The typemap just before the callee is called.
29896:     JSTraceType* get_typemap() { return (JSTraceType*) (this+1); }
21521: };
21521: 
21433: struct UnstableExit
21433: {
21433:     nanojit::Fragment* fragment;
21521:     VMSideExit* exit;
21433:     UnstableExit* next;
21433: };
21433: 
18056: class TreeInfo MMGC_SUBCLASS_DECL {
17701: public:
29021:     nanojit::Fragment* const      fragment;
18595:     JSScript*               script;
17815:     unsigned                maxNativeStackSlots;
17811:     ptrdiff_t               nativeStackBase;
17659:     unsigned                maxCallDepth;
24246:     TypeMap                 typeMap;
24491:     unsigned                nStackTypes;
24491:     SlotList*               globalSlots;
25491:     /* Dependent trees must be trashed if this tree dies, and updated on missing global types */
18650:     Queue<nanojit::Fragment*> dependentTrees;
25491:     /* Linked trees must be updated on missing global types, but are not dependent */
25491:     Queue<nanojit::Fragment*> linkedTrees;
18781:     unsigned                branchCount;
21521:     Queue<VMSideExit*>      sideExits;
21433:     UnstableExit*           unstableExits;
25627: #ifdef DEBUG
25627:     const char*             treeFileName;
25627:     uintN                   treeLineNumber;
25627:     uintN                   treePCOffset;
25627: #endif
17974: 
24491:     TreeInfo(nanojit::Fragment* _fragment,
24491:              SlotList* _globalSlots)
24491:       : fragment(_fragment),
24491:         script(NULL),
24491:         maxNativeStackSlots(0),
24491:         nativeStackBase(0),
24491:         maxCallDepth(0),
24491:         nStackTypes(0),
24491:         globalSlots(_globalSlots),
24491:         branchCount(0),
24491:         unstableExits(NULL)
24491:             {}
25102:     ~TreeInfo();
24246: 
24491:     inline unsigned nGlobalTypes() {
24491:         return typeMap.length() - nStackTypes;
24246:     }
29896:     inline JSTraceType* globalTypeMap() {
24491:         return typeMap.data() + nStackTypes;
24246:     }
29896:     inline JSTraceType* stackTypeMap() {
24246:         return typeMap.data();
24246:     }
17413: };
17413: 
24612: #if defined(JS_JIT_SPEW) && (defined(NANOJIT_IA32) || (defined(NANOJIT_AMD64) && defined(__GNUC__)))
24612: # define EXECUTE_TREE_TIMER
24612: #endif
24612: 
27166: typedef enum JSBuiltinStatus {
27166:     JSBUILTIN_BAILED = 1,
27166:     JSBUILTIN_ERROR = 2
27166: } JSBuiltinStatus;
27166: 
24612: struct InterpState
24612: {
24612:     double        *sp;                  // native stack pointer, stack[0] is spbase[0]
28268:     FrameInfo**   rp;                   // call stack pointer
24612:     JSContext     *cx;                  // current VM context handle
24612:     double        *eos;                 // first unusable word after the native stack
24612:     void          *eor;                 // first unusable word after the call stack
24612:     VMSideExit*    lastTreeExitGuard;   // guard we exited on during a tree call
24612:     VMSideExit*    lastTreeCallGuard;   // guard we want to grow from if the tree
24612:                                         // call exit guard mismatched
24612:     void*          rpAtLastTreeCall;    // value of rp at innermost tree call guard
24612:     TreeInfo*      outermostTree;       // the outermost tree we initially invoked
24612:     double*        stackBase;           // native stack base
24612:     FrameInfo**    callstackBase;       // call stack base
24612:     uintN*         inlineCallCountp;    // inline call count counter
24612:     VMSideExit**   innermostNestedGuardp;
24612:     void*          stackMark;
24612:     VMSideExit*    innermost;
24612: #ifdef EXECUTE_TREE_TIMER
24612:     uint64         startTime;
24612: #endif
28245:     InterpState*   prev;
27166: 
27166:     /*
27166:      * Used by _FAIL builtins; see jsbuiltins.h. The builtin sets the
27166:      * JSBUILTIN_BAILED bit if it bails off trace and the JSBUILTIN_ERROR bit
27166:      * if an error or exception occurred.
27166:      */
27166:     uint32         builtinStatus;
30287: 
30287:     // Used to communicate the location of the return value in case of a deep bail.
30287:     double*        deepBailSp;
20429: };
20429: 
27166: static JS_INLINE void
27166: js_SetBuiltinError(JSContext *cx)
27166: {
27166:     cx->interpState->builtinStatus |= JSBUILTIN_ERROR;
27166: }
27166: 
27933: #ifdef DEBUG_JSRS_NOT_BOOL
27933: struct JSRecordingStatus {
27933:     int code;
27933:     bool operator==(JSRecordingStatus &s) { return this->code == s.code; };
27933:     bool operator!=(JSRecordingStatus &s) { return this->code != s.code; };
23111: };
27933: enum JSRScodes {
27933:     JSRS_ERROR_code,
27933:     JSRS_STOP_code,
27933:     JSRS_CONTINUE_code,
27933:     JSRS_IMACRO_code
27933: };
27933: struct JSRecordingStatus JSRS_CONTINUE = { JSRS_CONTINUE_code };
27933: struct JSRecordingStatus JSRS_STOP     = { JSRS_STOP_code };
27933: struct JSRecordingStatus JSRS_IMACRO   = { JSRS_IMACRO_code };
27933: struct JSRecordingStatus JSRS_ERROR    = { JSRS_ERROR_code };
27933: #define STATUS_ABORTS_RECORDING(s) ((s) == JSRS_STOP || (s) == JSRS_ERROR)
27933: #else
27933: enum JSRecordingStatus {
27933:     JSRS_ERROR,        // Error; propagate to interpreter. 
27933:     JSRS_STOP,         // Abort recording.
27933:     JSRS_CONTINUE,     // Continue recording.
27933:     JSRS_IMACRO        // Entered imacro; continue recording.
27933:                        // Only JSOP_IS_IMACOP opcodes may return this.
27933: };
27933: #define STATUS_ABORTS_RECORDING(s) ((s) <= JSRS_STOP)
27933: #endif
27933: 
30279: class SlotMap;
27933: 
30279: /* Results of trying to compare two typemaps together */
30279: enum TypeConsensus
30279: {
30279:     TypeConsensus_Okay,         /* Two typemaps are compatible */
30279:     TypeConsensus_Undemotes,    /* Not compatible now, but would be with pending undemotes. */
30279:     TypeConsensus_Bad           /* Typemaps are not compatible */
30279: };
23111: 
21523: class TraceRecorder : public avmplus::GCObject {
17351:     JSContext*              cx;
18239:     JSTraceMonitor*         traceMonitor;
17657:     JSObject*               globalObj;
26238:     JSObject*               lexicalBlock;
17596:     Tracker                 tracker;
17815:     Tracker                 nativeFrameTracker;
17393:     char*                   entryTypeMap;
17789:     unsigned                callDepth;
17611:     JSAtom**                atoms;
21521:     VMSideExit*             anchor;
17334:     nanojit::Fragment*      fragment;
17785:     TreeInfo*               treeInfo;
17334:     nanojit::LirBuffer*     lirbuf;
17334:     nanojit::LirWriter*     lir;
17381:     nanojit::LirBufWriter*  lir_buf_writer;
17370:     nanojit::LirWriter*     verbose_filter;
17370:     nanojit::LirWriter*     cse_filter;
17370:     nanojit::LirWriter*     expr_filter;
17453:     nanojit::LirWriter*     func_filter;
18773:     nanojit::LirWriter*     float_filter;
17393:     nanojit::LIns*          cx_ins;
18118:     nanojit::LIns*          eos_ins;
18133:     nanojit::LIns*          eor_ins;
17818:     nanojit::LIns*          rval_ins;
18241:     nanojit::LIns*          inner_sp_ins;
28086:     nanojit::LIns*          native_rval_ins;
28086:     nanojit::LIns*          newobj_ins;
19068:     bool                    deepAborted;
22609:     bool                    trashSelf;
22609:     Queue<nanojit::Fragment*> whichTreesToTrash;
18694:     Queue<jsbytecode*>      cfgMerges;
19653:     jsval*                  global_dslots;
26552:     JSTraceableNative*      generatedTraceableNative;
20405:     JSTraceableNative*      pendingTraceableNative;
21723:     TraceRecorder*          nextRecorderToAbort;
21723:     bool                    wasRootFragment;
28244:     jsbytecode*             outer;     /* outer trace header PC */
28244:     uint32                  outerArgc; /* outer trace deepest frame argc */
26557:     bool                    loop;
17323: 
17815:     bool isGlobal(jsval* p) const;
18193:     ptrdiff_t nativeGlobalOffset(jsval* p) const;
22652:     JS_REQUIRES_STACK ptrdiff_t nativeStackOffset(jsval* p) const;
29896:     JS_REQUIRES_STACK void import(nanojit::LIns* base, ptrdiff_t offset, jsval* p, JSTraceType t,
18045:                                   const char *prefix, uintN index, JSStackFrame *fp);
24246:     JS_REQUIRES_STACK void import(TreeInfo* treeInfo, nanojit::LIns* sp, unsigned stackSlots,
29896:                                   unsigned callDepth, unsigned ngslots, JSTraceType* typeMap);
17815:     void trackNativeStackUse(unsigned slots);
17381: 
25938:     JS_REQUIRES_STACK bool isValidSlot(JSScope* scope, JSScopeProperty* sprop);
22652:     JS_REQUIRES_STACK bool lazilyImportGlobalSlot(unsigned slot);
17891: 
26972:     JS_REQUIRES_STACK void guard(bool expected, nanojit::LIns* cond, ExitType exitType);
27540:     JS_REQUIRES_STACK void guard(bool expected, nanojit::LIns* cond, VMSideExit* exit);
23111: 
17721:     nanojit::LIns* addName(nanojit::LIns* ins, const char* name);
17346: 
18197:     nanojit::LIns* writeBack(nanojit::LIns* i, nanojit::LIns* base, ptrdiff_t offset);
22652:     JS_REQUIRES_STACK void set(jsval* p, nanojit::LIns* l, bool initializing = false);
24381:     JS_REQUIRES_STACK nanojit::LIns* get(jsval* p);
24381:     JS_REQUIRES_STACK bool known(jsval* p);
24381:     JS_REQUIRES_STACK void checkForGlobalObjectReallocation();
17320: 
30279:     JS_REQUIRES_STACK TypeConsensus selfTypeStability(SlotMap& smap);
30279:     JS_REQUIRES_STACK TypeConsensus peerTypeStability(SlotMap& smap, VMFragment** peer);
17410: 
22652:     JS_REQUIRES_STACK jsval& argval(unsigned n) const;
22652:     JS_REQUIRES_STACK jsval& varval(unsigned n) const;
22652:     JS_REQUIRES_STACK jsval& stackval(int n) const;
17412: 
22652:     JS_REQUIRES_STACK nanojit::LIns* scopeChain() const;
30248:     JS_REQUIRES_STACK JSStackFrame* frameIfInRange(JSObject* obj, unsigned* depthp = NULL) const;
27933:     JS_REQUIRES_STACK JSRecordingStatus activeCallOrGlobalSlot(JSObject* obj, jsval*& vp);
18286: 
22652:     JS_REQUIRES_STACK nanojit::LIns* arg(unsigned n);
22652:     JS_REQUIRES_STACK void arg(unsigned n, nanojit::LIns* i);
22652:     JS_REQUIRES_STACK nanojit::LIns* var(unsigned n);
22652:     JS_REQUIRES_STACK void var(unsigned n, nanojit::LIns* i);
28923:     JS_REQUIRES_STACK nanojit::LIns* upvar(JSScript* script, JSUpvarArray* uva, uintN index, jsval& v);
30248:     nanojit::LIns* stackLoad(nanojit::LIns* addr, uint8 type);
22652:     JS_REQUIRES_STACK nanojit::LIns* stack(int n);
22652:     JS_REQUIRES_STACK void stack(int n, nanojit::LIns* i);
17412: 
23456:     JS_REQUIRES_STACK nanojit::LIns* alu(nanojit::LOpcode op, jsdouble v0, jsdouble v1,
21799:                                          nanojit::LIns* s0, nanojit::LIns* s1);
17469:     nanojit::LIns* f2i(nanojit::LIns* f);
22652:     JS_REQUIRES_STACK nanojit::LIns* makeNumberInt32(nanojit::LIns* f);
23456:     JS_REQUIRES_STACK nanojit::LIns* stringify(jsval& v);
21685: 
27933:     JS_REQUIRES_STACK JSRecordingStatus call_imacro(jsbytecode* imacro);
17469: 
27933:     JS_REQUIRES_STACK JSRecordingStatus ifop();
27933:     JS_REQUIRES_STACK JSRecordingStatus switchop();
25099: #ifdef NANOJIT_IA32
25099:     JS_REQUIRES_STACK nanojit::LIns* tableswitch();
25099: #endif
27933:     JS_REQUIRES_STACK JSRecordingStatus inc(jsval& v, jsint incr, bool pre = true);
27933:     JS_REQUIRES_STACK JSRecordingStatus inc(jsval& v, nanojit::LIns*& v_ins, jsint incr,
27933:                                                    bool pre = true);
27933:     JS_REQUIRES_STACK JSRecordingStatus incProp(jsint incr, bool pre = true);
27933:     JS_REQUIRES_STACK JSRecordingStatus incElem(jsint incr, bool pre = true);
27933:     JS_REQUIRES_STACK JSRecordingStatus incName(jsint incr, bool pre = true);
18687: 
23093:     JS_REQUIRES_STACK void strictEquality(bool equal, bool cmpCase);
27933:     JS_REQUIRES_STACK JSRecordingStatus equality(bool negate, bool tryBranchAfterCond);
27933:     JS_REQUIRES_STACK JSRecordingStatus equalityHelper(jsval l, jsval r,
23223:                                                        nanojit::LIns* l_ins, nanojit::LIns* r_ins,
23223:                                                        bool negate, bool tryBranchAfterCond,
23223:                                                        jsval& rval);
27933:     JS_REQUIRES_STACK JSRecordingStatus relational(nanojit::LOpcode op, bool tryBranchAfterCond);
17467: 
27933:     JS_REQUIRES_STACK JSRecordingStatus unary(nanojit::LOpcode op);
27933:     JS_REQUIRES_STACK JSRecordingStatus binary(nanojit::LOpcode op);
17467: 
17450:     bool ibinary(nanojit::LOpcode op);
17450:     bool iunary(nanojit::LOpcode op);
17436:     bool bbinary(nanojit::LOpcode op);
17453:     void demote(jsval& v, jsdouble result);
17417: 
30244:     inline nanojit::LIns* map(nanojit::LIns *obj_ins);
22652:     JS_REQUIRES_STACK bool map_is_native(JSObjectMap* map, nanojit::LIns* map_ins,
22652:                                          nanojit::LIns*& ops_ins, size_t op_offset = 0);
27933:     JS_REQUIRES_STACK JSRecordingStatus test_property_cache(JSObject* obj, nanojit::LIns* obj_ins,
22652:                                                             JSObject*& obj2, jsuword& pcval);
28554:     void stobj_set_fslot(nanojit::LIns *obj_ins, unsigned slot,
28554:                          nanojit::LIns* v_ins, const char *name);
28554:     void stobj_set_dslot(nanojit::LIns *obj_ins, unsigned slot, nanojit::LIns*& dslots_ins,
28554:                          nanojit::LIns* v_ins, const char *name);
22626:     void stobj_set_slot(nanojit::LIns* obj_ins, unsigned slot, nanojit::LIns*& dslots_ins,
22626:                         nanojit::LIns* v_ins);
22626: 
17899:     nanojit::LIns* stobj_get_fslot(nanojit::LIns* obj_ins, unsigned slot);
27012:     nanojit::LIns* stobj_get_dslot(nanojit::LIns* obj_ins, unsigned index,
27012:                                    nanojit::LIns*& dslots_ins);
17459:     nanojit::LIns* stobj_get_slot(nanojit::LIns* obj_ins, unsigned slot,
17459:                                   nanojit::LIns*& dslots_ins);
30248:     nanojit::LIns* stobj_get_private(nanojit::LIns* obj_ins, jsval mask=JSVAL_INT) {
30248:         return lir->ins2(nanojit::LIR_piand,
30248:                          stobj_get_fslot(obj_ins, JSSLOT_PRIVATE),
30248:                          lir->insImmPtr((void*) ~mask));
30248:     }
27933:     JSRecordingStatus native_set(nanojit::LIns* obj_ins, JSScopeProperty* sprop,
17429:                                  nanojit::LIns*& dslots_ins, nanojit::LIns* v_ins);
27933:     JSRecordingStatus native_get(nanojit::LIns* obj_ins, nanojit::LIns* pobj_ins,
27933:                                  JSScopeProperty* sprop, nanojit::LIns*& dslots_ins,
27933:                                  nanojit::LIns*& v_ins);
17429: 
27637:     nanojit::LIns* getStringLength(nanojit::LIns* str_ins);
27637: 
27933:     JS_REQUIRES_STACK JSRecordingStatus name(jsval*& vp);
27933:     JS_REQUIRES_STACK JSRecordingStatus prop(JSObject* obj, nanojit::LIns* obj_ins, uint32& slot,
22652:                                              nanojit::LIns*& v_ins);
28411:     JS_REQUIRES_STACK JSRecordingStatus denseArrayElement(jsval& oval, jsval& idx, jsval*& vp,
28411:                                                           nanojit::LIns*& v_ins,
28411:                                                           nanojit::LIns*& addr_ins);
27933:     JS_REQUIRES_STACK JSRecordingStatus getProp(JSObject* obj, nanojit::LIns* obj_ins);
27933:     JS_REQUIRES_STACK JSRecordingStatus getProp(jsval& v);
27933:     JS_REQUIRES_STACK JSRecordingStatus getThis(nanojit::LIns*& this_ins);
17758: 
23708:     JS_REQUIRES_STACK void box_jsval(jsval v, nanojit::LIns*& v_ins);
27540:     JS_REQUIRES_STACK void unbox_jsval(jsval v, nanojit::LIns*& v_ins, VMSideExit* exit);
22652:     JS_REQUIRES_STACK bool guardClass(JSObject* obj, nanojit::LIns* obj_ins, JSClass* clasp,
27540:                                       VMSideExit* exit);
22652:     JS_REQUIRES_STACK bool guardDenseArray(JSObject* obj, nanojit::LIns* obj_ins,
21685:                                            ExitType exitType = MISMATCH_EXIT);
29513:     JS_REQUIRES_STACK bool guardHasPrototype(JSObject* obj, nanojit::LIns* obj_ins,
29513:                                              JSObject** pobj, nanojit::LIns** pobj_ins,
29513:                                              VMSideExit* exit);
27933:     JS_REQUIRES_STACK JSRecordingStatus guardPrototypeHasNoIndexedProperties(JSObject* obj,
27933:                                                                              nanojit::LIns* obj_ins,
21521:                                                                              ExitType exitType);
27933:     JS_REQUIRES_STACK JSRecordingStatus guardNotGlobalObject(JSObject* obj,
27933:                                                              nanojit::LIns* obj_ins);
17818:     void clearFrameSlotsFromCache();
27933:     JS_REQUIRES_STACK JSRecordingStatus guardCallee(jsval& callee);
27933:     JS_REQUIRES_STACK JSRecordingStatus getClassPrototype(JSObject* ctor,
27933:                                                           nanojit::LIns*& proto_ins);
27933:     JS_REQUIRES_STACK JSRecordingStatus getClassPrototype(JSProtoKey key,
27933:                                                           nanojit::LIns*& proto_ins);
27933:     JS_REQUIRES_STACK JSRecordingStatus newArray(JSObject* ctor, uint32 argc, jsval* argv,
28086:                                                  jsval* rval);
28086:     JS_REQUIRES_STACK JSRecordingStatus newString(JSObject* ctor, uint32 argc, jsval* argv,
28086:                                                   jsval* rval);
27933:     JS_REQUIRES_STACK JSRecordingStatus interpretedFunctionCall(jsval& fval, JSFunction* fun,
27933:                                                                 uintN argc, bool constructing);
27933:     JS_REQUIRES_STACK JSRecordingStatus emitNativeCall(JSTraceableNative* known, uintN argc,
27933:                                                        nanojit::LIns* args[]);
27933:     JS_REQUIRES_STACK JSRecordingStatus callTraceableNative(JSFunction* fun, uintN argc,
22652:                                                             bool constructing);
28086:     JS_REQUIRES_STACK JSRecordingStatus callNative(uintN argc, JSOp mode);
28086:     JS_REQUIRES_STACK JSRecordingStatus functionCall(uintN argc, JSOp mode);
17921: 
22652:     JS_REQUIRES_STACK void trackCfgMerges(jsbytecode* pc);
26557:     JS_REQUIRES_STACK void emitIf(jsbytecode* pc, bool cond, nanojit::LIns* x);
22652:     JS_REQUIRES_STACK void fuseIf(jsbytecode* pc, bool cond, nanojit::LIns* x);
27933:     JS_REQUIRES_STACK JSRecordingStatus checkTraceEnd(jsbytecode* pc);
19068: 
21685:     bool hasMethod(JSObject* obj, jsid id);
24299:     JS_REQUIRES_STACK bool hasIteratorMethod(JSObject* obj);
21685: 
27014:     JS_REQUIRES_STACK jsatomid getFullIndex(ptrdiff_t pcoff = 0);
27012: 
17409: public:
22652:     JS_REQUIRES_STACK
21521:     TraceRecorder(JSContext* cx, VMSideExit*, nanojit::Fragment*, TreeInfo*,
29896:                   unsigned stackSlots, unsigned ngslots, JSTraceType* typeMap,
28244:                   VMSideExit* expectedInnerExit, jsbytecode* outerTree,
28244:                   uint32 outerArgc);
17409:     ~TraceRecorder();
17409: 
27933:     static JS_REQUIRES_STACK JSRecordingStatus monitorRecording(JSContext* cx, TraceRecorder* tr,
27933:                                                                 JSOp op);
23111: 
29896:     JS_REQUIRES_STACK JSTraceType determineSlotType(jsval* vp);
27540: 
27540:     /*
27540:      * Examines current interpreter state to record information suitable for
27540:      * returning to the interpreter through a side exit of the given type.
27540:      */
27540:     JS_REQUIRES_STACK VMSideExit* snapshot(ExitType exitType);
27540: 
27540:     /*
27540:      * Creates a separate but identical copy of the given side exit, allowing
27540:      * the guards associated with each to be entirely separate even after
27540:      * subsequent patching.
27540:      */
27540:     JS_REQUIRES_STACK VMSideExit* copy(VMSideExit* exit);
27540: 
27540:     /*
27540:      * Creates an instruction whose payload is a GuardRecord for the given exit.
27540:      * The instruction is suitable for use as the final argument of a single
27540:      * call to LirBuffer::insGuard; do not reuse the returned value.
27540:      */
27540:     JS_REQUIRES_STACK nanojit::LIns* createGuardRecord(VMSideExit* exit);
27540: 
17718:     nanojit::Fragment* getFragment() const { return fragment; }
25627:     TreeInfo* getTreeInfo() const { return treeInfo; }
24307:     JS_REQUIRES_STACK void compile(JSTraceMonitor* tm);
30279:     JS_REQUIRES_STACK bool closeLoop(TypeConsensus &consensus);
30279:     JS_REQUIRES_STACK bool closeLoop(SlotMap& slotMap, VMSideExit* exit, TypeConsensus &consensus);
30279:     JS_REQUIRES_STACK void endLoop();
30279:     JS_REQUIRES_STACK void endLoop(VMSideExit* exit);
22652:     JS_REQUIRES_STACK void joinEdgesToEntry(nanojit::Fragmento* fragmento,
26818:                                             VMFragment* peer_root);
17980:     void blacklist() { fragment->blacklist(); }
28239:     JS_REQUIRES_STACK void adjustCallerTypes(nanojit::Fragment* f);
28239:     JS_REQUIRES_STACK nanojit::Fragment* findNestedCompatiblePeer(nanojit::Fragment* f);
22652:     JS_REQUIRES_STACK void prepareTreeCall(nanojit::Fragment* inner);
22652:     JS_REQUIRES_STACK void emitTreeCall(nanojit::Fragment* inner, VMSideExit* exit);
17988:     unsigned getCallDepth() const;
21723:     void pushAbortStack();
21723:     void popAbortStack();
21723:     void removeFragmentoReferences();
26958:     void deepAbort();
17409: 
27933:     JS_REQUIRES_STACK JSRecordingStatus record_EnterFrame();
27933:     JS_REQUIRES_STACK JSRecordingStatus record_LeaveFrame();
27933:     JS_REQUIRES_STACK JSRecordingStatus record_SetPropHit(JSPropCacheEntry* entry,
27933:                                                           JSScopeProperty* sprop);
27933:     JS_REQUIRES_STACK JSRecordingStatus record_DefLocalFunSetSlot(uint32 slot, JSObject* obj);
28086:     JS_REQUIRES_STACK JSRecordingStatus record_NativeCallComplete();
17695: 
18706:     bool wasDeepAborted() { return deepAborted; }
21433:     TreeInfo* getTreeInfo() { return treeInfo; }
18706: 
17484: #define OPDEF(op,val,name,token,length,nuses,ndefs,prec,format)               \
27933:     JS_REQUIRES_STACK JSRecordingStatus record_##op();
17484: # include "jsopcode.tbl"
17484: #undef OPDEF
29880: 
29880:     friend class ImportBoxedStackSlotVisitor;
29880:     friend class ImportUnboxedStackSlotVisitor;
29880:     friend class ImportGlobalSlotVisitor;
29880:     friend class AdjustCallerGlobalTypesVisitor;
29880:     friend class AdjustCallerStackTypesVisitor;
29880:     friend class TypeCompatibilityVisitor;
30279:     friend class SlotMap;
30279:     friend class DefaultSlotMap;
17296: };
17331: #define TRACING_ENABLED(cx)       JS_HAS_OPTION(cx, JSOPTION_JIT)
19093: #define TRACE_RECORDER(cx)        (JS_TRACE_MONITOR(cx).recorder)
19093: #define SET_TRACE_RECORDER(cx,tr) (JS_TRACE_MONITOR(cx).recorder = (tr))
17186: 
27012: #define JSOP_IN_RANGE(op,lo,hi)   (uintN((op) - (lo)) <= uintN((hi) - (lo)))
27012: #define JSOP_IS_BINARY(op)        JSOP_IN_RANGE(op, JSOP_BITOR, JSOP_MOD)
27012: #define JSOP_IS_UNARY(op)         JSOP_IN_RANGE(op, JSOP_NEG, JSOP_POS)
27012: #define JSOP_IS_EQUALITY(op)      JSOP_IN_RANGE(op, JSOP_EQ, JSOP_NE)
21685: 
23111: #define TRACE_ARGS_(x,args)                                                   \
23110:     JS_BEGIN_MACRO                                                            \
23111:         TraceRecorder* tr_ = TRACE_RECORDER(cx);                              \
27933:         if (tr_ && !tr_->wasDeepAborted()) {                                  \
27933:             JSRecordingStatus status = tr_->record_##x args;                  \
27933:             if (STATUS_ABORTS_RECORDING(status)) {                            \
23111:                 js_AbortRecording(cx, #x);                                    \
27933:                 if (status == JSRS_ERROR)                                     \
27933:                     goto error;                                               \
27933:             }                                                                 \
27933:             JS_ASSERT(status != JSRS_IMACRO);                                 \
27933:         }                                                                     \
23110:     JS_END_MACRO
23110: 
23111: #define TRACE_ARGS(x,args)      TRACE_ARGS_(x, args)
19582: #define TRACE_0(x)              TRACE_ARGS(x, ())
19093: #define TRACE_1(x,a)            TRACE_ARGS(x, (a))
19093: #define TRACE_2(x,a,b)          TRACE_ARGS(x, (a, b))
19093: 
22652: extern JS_REQUIRES_STACK bool
20422: js_MonitorLoopEdge(JSContext* cx, uintN& inlineCallCount);
18683: 
23111: #ifdef DEBUG
23111: # define js_AbortRecording(cx, reason) js_AbortRecordingImpl(cx, reason)
23111: #else
23111: # define js_AbortRecording(cx, reason) js_AbortRecordingImpl(cx)
23111: #endif
17257: 
22652: extern JS_REQUIRES_STACK void
20422: js_AbortRecording(JSContext* cx, const char* reason);
17350: 
17442: extern void
18068: js_InitJIT(JSTraceMonitor *tm);
17442: 
17726: extern void
18075: js_FinishJIT(JSTraceMonitor *tm);
17726: 
17976: extern void
26569: js_PurgeScriptFragments(JSContext* cx, JSScript* script);
24879: 
26826: extern bool
27884: js_OverfullFragmento(JSTraceMonitor* tm, nanojit::Fragmento *frago);
26826: 
24879: extern void
26569: js_PurgeJITOracle();
18277: 
24384: extern JSObject *
24384: js_GetBuiltinFunction(JSContext *cx, uintN index);
24384: 
27884: extern void
27884: js_SetMaxCodeCacheBytes(JSContext* cx, uint32 bytes);
27884: 
29368: #ifdef MOZ_TRACEVIS
29368: 
29368: extern JS_FRIEND_API(bool)
29368: JS_StartTraceVis(const char* filename);
29368: 
29368: extern JS_FRIEND_API(JSBool)
29368: js_StartTraceVis(JSContext *cx, JSObject *obj, uintN argc, jsval *argv,
29368:                  jsval *rval);
29368: 
29368: extern JS_FRIEND_API(bool)
29368: JS_StopTraceVis();
29368: 
29368: extern JS_FRIEND_API(JSBool)
29368: js_StopTraceVis(JSContext *cx, JSObject *obj, uintN argc, jsval *argv,
29368:                 jsval *rval);
29368: 
29368: /* Must contain no more than 16 items. */
29368: enum TraceVisState {
29368:     S_EXITLAST,
29368:     S_INTERP,
29368:     S_MONITOR,
29368:     S_RECORD,
29368:     S_COMPILE,
29368:     S_EXECUTE,
29368:     S_NATIVE
29368: };
29368: 
29368: /* Reason for an exit to the interpreter. */
29368: enum TraceVisExitReason {
29368:     R_NONE,
29368:     R_ABORT,
29368:     /* Reasons in js_MonitorLoopEdge */
29368:     R_INNER_SIDE_EXIT,
29368:     R_DOUBLES,
29368:     R_CALLBACK_PENDING,
29368:     R_OOM_GETANCHOR,
29368:     R_BACKED_OFF,
29368:     R_COLD,
29368:     R_FAIL_RECORD_TREE,
29368:     R_MAX_PEERS,
29368:     R_FAIL_EXECUTE_TREE,
29368:     R_FAIL_STABILIZE,
29368:     R_FAIL_EXTEND_FLUSH,
29368:     R_FAIL_EXTEND_MAX_BRANCHES,
29368:     R_FAIL_EXTEND_START,
29368:     R_FAIL_EXTEND_COLD,
29368:     R_NO_EXTEND_OUTER,
29368:     R_MISMATCH_EXIT,
29368:     R_OOM_EXIT,
29368:     R_TIMEOUT_EXIT,
29368:     R_DEEP_BAIL_EXIT,
29368:     R_STATUS_EXIT,
29368:     R_OTHER_EXIT
29368: };
29368: 
29368: const unsigned long long MS64_MASK = 0xfllu << 60;
29368: const unsigned long long MR64_MASK = 0x1fllu << 55;
29368: const unsigned long long MT64_MASK = ~(MS64_MASK | MR64_MASK);
29368: 
29368: extern FILE* traceVisLogFile;
29368: 
29368: static inline void
29368: js_LogTraceVisState(TraceVisState s, TraceVisExitReason r)
29368: {
29368:     if (traceVisLogFile) {
29368:         unsigned long long sllu = s;
29368:         unsigned long long rllu = r;
29368:         unsigned long long d = (sllu << 60) | (rllu << 55) | (rdtsc() & MT64_MASK);
29368:         fwrite(&d, sizeof(d), 1, traceVisLogFile);
29368:     }
29368: }
29368: 
29368: static inline void 
29368: js_EnterTraceVisState(TraceVisState s, TraceVisExitReason r)
29368: {
29368:     js_LogTraceVisState(s, r);
29368: }
29368: 
29368: static inline void 
29368: js_ExitTraceVisState(TraceVisExitReason r)
29368: {
29368:     js_LogTraceVisState(S_EXITLAST, r);
29368: }
29368: 
29368: struct TraceVisStateObj {
29368:     TraceVisExitReason r;
29368: 
29368:     inline TraceVisStateObj(TraceVisState s) : r(R_NONE)
29368:     {
29368:         js_EnterTraceVisState(s, R_NONE);
29368:     }
29368:     inline ~TraceVisStateObj()
29368:     {
29368:         js_ExitTraceVisState(r);
29368:     }
29368: };
29368: 
29368: #endif /* MOZ_TRACEVIS */
29368: 
19171: #else  /* !JS_TRACER */
19171: 
19599: #define TRACE_0(x)              ((void)0)
19171: #define TRACE_1(x,a)            ((void)0)
19171: #define TRACE_2(x,a,b)          ((void)0)
19171: 
19171: #endif /* !JS_TRACER */
18091: 
17196: #endif /* jstracer_h___ */
