30266: /* -*- Mode: C++; c-basic-offset: 4; indent-tabs-mode: nil; tab-width: 4 -*- */
30266: /* vi: set ts=4 sw=4 expandtab: (add to ~/.vimrc: set modeline modelines=5) */
17274: /* ***** BEGIN LICENSE BLOCK *****
17274:  * Version: MPL 1.1/GPL 2.0/LGPL 2.1
17274:  *
17274:  * The contents of this file are subject to the Mozilla Public License Version
17274:  * 1.1 (the "License"); you may not use this file except in compliance with
17274:  * the License. You may obtain a copy of the License at
17274:  * http://www.mozilla.org/MPL/
17274:  *
17274:  * Software distributed under the License is distributed on an "AS IS" basis,
17274:  * WITHOUT WARRANTY OF ANY KIND, either express or implied. See the License
17274:  * for the specific language governing rights and limitations under the
17274:  * License.
17274:  *
17274:  * The Original Code is [Open Source Virtual Machine].
17274:  *
17274:  * The Initial Developer of the Original Code is
17274:  * Adobe System Incorporated.
17274:  * Portions created by the Initial Developer are Copyright (C) 2004-2007
17274:  * the Initial Developer. All Rights Reserved.
17274:  *
17274:  * Contributor(s):
17274:  *   Adobe AS3 Team
17274:  *
17274:  * Alternatively, the contents of this file may be used under the terms of
17274:  * either the GNU General Public License Version 2 or later (the "GPL"), or
17274:  * the GNU Lesser General Public License Version 2.1 or later (the "LGPL"),
17274:  * in which case the provisions of the GPL or the LGPL are applicable instead
17274:  * of those above. If you wish to allow use of your version of this file only
17274:  * under the terms of either the GPL or the LGPL, and not to allow others to
17274:  * use your version of this file under the terms of the MPL, indicate your
17274:  * decision by deleting the provisions above and replace them with the notice
17274:  * and other provisions required by the GPL or the LGPL. If you do not delete
17274:  * the provisions above, a recipient may use your version of this file under
17274:  * the terms of any one of the MPL, the GPL or the LGPL.
17274:  *
17274:  * ***** END LICENSE BLOCK ***** */
17274: 
17274: 
17274: #ifndef __nanojit_Assembler__
17274: #define __nanojit_Assembler__
17274: 
17274: 
17274: namespace nanojit
17274: {
17274:     /**
17274:      * Some notes on this Assembler (Emitter).
17274:      *
17274:      *   The class RegAlloc is essentially the register allocator from MIR
17274:      *
17274:      *   The Assembler class parses the LIR instructions starting at any point and converts
17274:      *   them to machine code.  It does the translation using expression trees which are simply
17274:      *   LIR instructions in the stream that have side-effects.  Any other instruction in the
17274:      *   stream is simply ignored.
17274:      *   This approach is interesting in that dead code elimination occurs for 'free', strength
17274:      *   reduction occurs fairly naturally, along with some other optimizations.
17274:      *
17274:      *   A negative is that we require state as we 'push' and 'pop' nodes along the tree.
17274:      *   Also, this is most easily performed using recursion which may not be desirable in
17274:      *   the mobile environment.
17274:      *
17274:      */
17274: 
17916:     #define STACK_GRANULARITY        sizeof(void *)
17916: 
35042:     // Basics:
35042:     // - 'entry' records the state of the native machine stack at particular
35042:     //   points during assembly.  Each entry represents four bytes.
35042:     //
35042:     // - Parts of the stack can be allocated by LIR_ialloc, in which case each
35042:     //   slot covered by the allocation contains a pointer to the LIR_ialloc
35042:     //   LIns.
35042:     //
35042:     // - The stack also holds spilled values, in which case each slot holding
35042:     //   a spilled value (one slot for 32-bit values, two slots for 64-bit
35042:     //   values) contains a pointer to the instruction defining the spilled
35042:     //   value.
35042:     //
35365:     // - Each LIns has a "reservation" which includes a stack index,
35365:     //   'arIndex'.  Combined with AR, it provides a two-way mapping between
35365:     //   stack slots and LIR instructions.
35042:     //
35042:     // - Invariant: the two-way mapping between active stack slots and their
35042:     //   defining/allocating instructions must hold in both directions and be
35042:     //   unambiguous.  More specifically:
35042:     //
35042:     //   * An LIns can appear in at most one contiguous sequence of slots in
35042:     //     AR, and the length of that sequence depends on the opcode (1 slot
35042:     //     for instructions producing 32-bit values, 2 slots for instructions
35042:     //     producing 64-bit values, N slots for LIR_ialloc).
35042:     //
35365:     //   * An LIns named by 'entry[i]' must have an in-use reservation with
35042:     //     arIndex==i (or an 'i' indexing the start of the same contiguous
35042:     //     sequence that 'entry[i]' belongs to).
35042:     //
35365:     //   * And vice versa:  an LIns with an in-use reservation with arIndex==i
35042:     //     must be named by 'entry[i]'.
35042:     //
35365:     //   * If an LIns's reservation names has arIndex==0 then LIns should not
35042:     //     be in 'entry[]'.
35042:     //
36664:     class AR
17274:     {
36664:     private:
36664:         uint32_t        _highWaterMark;                 /* index of highest entry used since last clear() */
36664:         LIns*           _entries[ NJ_MAX_STACK_ENTRY ]; /* maps to 4B contiguous locations relative to the frame pointer.
36664:                                                             NB: _entries[0] is always unused */
36676: 
36667:         #ifdef _DEBUG
36667:         static LIns* const BAD_ENTRY;
36667:         #endif
36664: 
36664:         bool isEmptyRange(uint32_t start, uint32_t nStackSlots) const;
36664:         static uint32_t nStackSlotsFor(LIns* ins);
36664: 
36664:     public:
36676:         AR();
36664: 
36664:         uint32_t stackSlotsNeeded() const;
36664: 
36664:         void clear();
36664:         void freeEntryAt(uint32_t i);
36664:         uint32_t reserveEntry(LIns* ins); /* return 0 if unable to reserve the entry */
36664: 
36664:         #ifdef _DEBUG
36677:         void validateQuick();
36677:         void validateFull();
36667:         void validate();
36664:         bool isValidEntry(uint32_t idx, LIns* ins) const; /* return true iff idx and ins are matched */
36677:         void checkForResourceConsistency(const RegAlloc& regs);
36664:         void checkForResourceLeaks() const;
36664:         #endif
36664: 
36664:         class Iter
36664:         {
36664:         private:
36664:             const AR& _ar;
36664:             uint32_t _i;
36664:         public:
36664:             inline Iter(const AR& ar) : _ar(ar), _i(1) { }
36664:             bool next(LIns*& ins, uint32_t& nStackSlots, int32_t& offset);             // get the next one (moves iterator forward)
17274:         };
36664:     };
36664: 
36676:     inline AR::AR()
36676:     {
36677:          _entries[0] = NULL;
36676:          clear();
36676:     }
36676: 
36664:     inline /*static*/ uint32_t AR::nStackSlotsFor(LIns* ins)
36664:     {
36664:         return ins->isop(LIR_alloc) ? (ins->size()>>2) : (ins->isQuad() ? 2 : 1);
36664:     }
36664: 
36664:     inline uint32_t AR::stackSlotsNeeded() const
36664:     {
36664:         // NB: _highWaterMark is an index, not a count
36664:         return _highWaterMark+1;
36664:     }
17274: 
33939:     #ifndef AVMPLUS_ALIGN16
17378:         #ifdef AVMPLUS_WIN32
17378:             #define AVMPLUS_ALIGN16(type) __declspec(align(16)) type
17378:         #else
17378:             #define AVMPLUS_ALIGN16(type) type __attribute__ ((aligned (16)))
17378:         #endif
33939:     #endif
17378: 
17274:     struct Stats
17274:     {
17274:         counter_define(steals;)
17274:         counter_define(remats;)
17274:         counter_define(spills;)
17274:         counter_define(native;)
17274:         counter_define(exitnative;)
17274: 
20893:         int32_t pages;
20893:         NIns* codeStart;
20893:         NIns* codeExitStart;
20893: 
17274:         DECLARE_PLATFORM_STATS()
17274: #ifdef __GNUC__
17274:         // inexplicably, gnuc gives padding/alignment warnings without this. pacify it.
17274:         bool pad[4];
17274: #endif
17274:     };
17274: 
17274:     // error codes
17274:     enum AssmError
17274:     {
17274:          None = 0
17274:         ,StackFull
20893:         ,UnknownBranch
17274:     };
17274: 
31514:     typedef SeqBuilder<NIns*> NInsList;
31512:     typedef HashMap<NIns*, LIns*> NInsMap;
37665: #if NJ_USES_QUAD_CONSTANTS
37665:     typedef HashMap<uint64_t, uint64_t*> QuadConstantMap;
37665: #endif
17308: 
33561: #ifdef VTUNE
33561:     class avmplus::CodegenLIR;
33561: #endif
33561: 
31509:     class LabelState
20893:     {
20893:     public:
20893:         RegAlloc regs;
20893:         NIns *addr;
20893:         LabelState(NIns *a, RegAlloc &r) : regs(r), addr(a)
20893:         {}
20893:     };
20893: 
20893:     class LabelStateMap
20893:     {
31509:         Allocator& alloc;
31509:         HashMap<LIns*, LabelState*> labels;
20893:     public:
31509:         LabelStateMap(Allocator& alloc) : alloc(alloc), labels(alloc)
20893:         {}
20893: 
31511:         void clear() { labels.clear(); }
20893:         void add(LIns *label, NIns *addr, RegAlloc &regs);
20893:         LabelState *get(LIns *);
20893:     };
31507: 
31509:     /** map tracking the register allocation state at each bailout point
31509:      *  (represented by SideExit*) in a trace fragment. */
31509:     typedef HashMap<SideExit*, RegAlloc*> RegAllocMap;
31509: 
17274:     /**
17274:      * Information about the activation record for the method is built up
17274:      * as we generate machine code.  As part of the prologue, we issue
17274:      * a stack adjustment instruction and then later patch the adjustment
17274:      * value.  Temporary values can be placed into the AR as method calls
31486:      * are issued.   Also LIR_alloc instructions will consume space.
17274:      */
31920:     class Assembler
17274:     {
17274:         friend class VerboseBlockReader;
17274:         public:
17274:             #ifdef NJ_VERBOSE
35364:             // Log controller object.  Contains what-stuff-should-we-print
35364:             // bits, and a sink function for debug printing.
35364:             LogControl* _logc;
35364:             // Buffer for holding text as we generate it in reverse order.
17274:             StringList* _outputCache;
29883: 
35364:             // Outputs the format string and 'outlineEOL', and resets
35364:             // 'outline' and 'outlineEOL'.
35364:             void outputf(const char* format, ...);
35364: 
35364:         private:
35364:             // Buffer used in most of the output function.  It must big enough
35364:             // to hold both the output line and the 'outlineEOL' buffer, which
35364:             // is concatenated onto 'outline' just before it is printed.
35364:             static char  outline[8192];
35364:             // Buffer used to hold extra text to be printed at the end of some
35364:             // lines.
35364:             static char  outlineEOL[512];
35364: 
35364:             // Outputs 'outline' and 'outlineEOL', and resets them both.
35364:             // Output goes to '_outputCache' if it's non-NULL, or is printed
35364:             // directly via '_logc'.
35364:             void output();
35364: 
35364:             // Sets 'outlineEOL'.
35364:             void setOutputForEOL(const char* format, ...);
35364: 
35364:             void printRegState();
35364:             void printActivationState();
33561:             #endif // NJ_VERBOSE
33561: 
35364:         public:
33561:             #ifdef VTUNE
33561:             avmplus::CodegenLIR *cgen;
17274:             #endif
17274: 
35087:             Assembler(CodeAlloc& codeAlloc, Allocator& dataAlloc, Allocator& alloc, AvmCore* core, LogControl* logc);
17274: 
32642:             void        endAssembly(Fragment* frag);
34341:             void        assemble(Fragment* frag, LirFilter* reader);
32642:             void        beginAssembly(Fragment *frag);
32642: 
17274:             void        releaseRegisters();
17274:             void        patch(GuardRecord *lr);
20931:             void        patch(SideExit *exit);
25099: #ifdef NANOJIT_IA32
25099:             void        patch(SideExit *exit, SwitchInfo* si);
25099: #endif
17274:             AssmError   error()    { return _err; }
17274:             void        setError(AssmError e) { _err = e; }
32642: 
31475:             void        reset();
17274: 
17274:             debug_only ( void       pageValidate(); )
17274: 
17274:             // support calling out from a fragment ; used to debug the jit
17274:             debug_only( void        resourceConsistencyCheck(); )
20893:             debug_only( void        registerConsistencyCheck(); )
17274: 
17274:             Stats       _stats;
31475:             CodeList*   codeList;                   // finished blocks of code.
17274: 
17274:         private:
17274: 
32642:             void        gen(LirFilter* toCompile);
20893:             NIns*       genPrologue();
20893:             NIns*       genEpilogue();
17274: 
36664:             uint32_t    arReserve(LIns* ins);
36664:             void        arFreeIfInUse(LIns* ins);
17274:             void        arReset();
17274: 
35316:             Register    registerAlloc(LIns* ins, RegisterMask allow);
35316:             Register    registerAllocTmp(RegisterMask allow);
17274:             void        registerResetAll();
32755:             void        evictAllActiveRegs();
32755:             void        evictSomeActiveRegs(RegisterMask regs);
20893:             void        evictScratchRegs();
20893:             void        intersectRegisterState(RegAlloc& saved);
20893:             void        unionRegisterState(RegAlloc& saved);
20893:             void        assignSaved(RegAlloc &saved, RegisterMask skip);
32662:             LInsp       findVictim(RegisterMask allow);
17274: 
36552:             Register    getBaseReg(LIns *i, int &d, RegisterMask allow);
37705:             void        getBaseReg2(RegisterMask allowValue, LIns* value, Register& rv,
37705:                                     RegisterMask allowBase, LIns* base, Register& rb, int &d);
37665: #if NJ_USES_QUAD_CONSTANTS
37665:             const uint64_t*
37665:                         findQuadConstant(uint64_t q);
37665: #endif
17274:             int         findMemFor(LIns* i);
17274:             Register    findRegFor(LIns* i, RegisterMask allow);
37705:             void        findRegFor2(RegisterMask allowa, LIns* ia, Register &ra,
37705:                                     RegisterMask allowb, LIns *ib, Register &rb);
34577:             Register    findSpecificRegFor(LIns* i, Register r);
34577:             Register    findSpecificRegForUnallocated(LIns* i, Register r);
17274:             Register    prepResultReg(LIns *i, RegisterMask allow);
36553:             Register    prepareResultReg(LIns *i, RegisterMask allow);
17274:             void        freeRsrcOf(LIns *i, bool pop);
36553:             void        freeResourcesOf(LIns *ins);
32621:             void        evictIfActive(Register r);
36553:             void        evict(LIns* vic);
17274:             RegisterMask hint(LIns*i, RegisterMask allow);
17274: 
32784:             void        codeAlloc(NIns *&start, NIns *&end, NIns *&eip
32784:                                   verbose_only(, size_t &nBytes));
20893:             bool        canRemat(LIns*);
17274: 
32727:             bool isKnownReg(Register r) {
32727:                 return r != UnknownReg;
32727:             }
32727: 
35087:             Allocator&          alloc;              // for items with same lifetime as this Assembler
35087:             CodeAlloc&          _codeAlloc;         // for code we generate
35087:             Allocator&          _dataAlloc;         // for data used by generated code
33093:             Fragment*           _thisfrag;
32642:             RegAllocMap         _branchStateMap;
32642:             NInsMap             _patches;
32642:             LabelStateMap       _labels;
37665:         #if NJ_USES_QUAD_CONSTANTS
37665:             QuadConstantMap     _quadConstants;
37665:         #endif
17274: 
35356:             // We generate code into two places:  normal code chunks, and exit
35356:             // code chunks (for exit stubs).  We use a hack to avoid having to
35356:             // parameterise the code that does the generating -- we let that
35356:             // code assume that it's always generating into a normal code
35356:             // chunk (most of the time it is), and when we instead need to
35356:             // generate into an exit code chunk, we set _inExit to true and
35356:             // temporarily swap all the code/exit variables below (using
35356:             // swapCodeChunks()).  Afterwards we swap them all back and set
35356:             // _inExit to false again.
35356:             bool        _inExit, vpad2[3];
35356:             NIns        *codeStart, *codeEnd;   // current normal code chunk
35356:             NIns        *exitStart, *exitEnd;   // current exit code chunk
35356:             NIns*       _nIns;                  // current instruction in current normal code chunk
35356:             NIns*       _nExitIns;              // current instruction in current exit code chunk
37698:                                                 // note: _nExitIns == NULL until the first side exit is seen.
35356:         #ifdef NJ_VERBOSE
35356:         public:
35356:             size_t      codeBytes;              // bytes allocated in normal code chunks
35356:             size_t      exitBytes;              // bytes allocated in exit code chunks
35356:         #endif
35356: 
35356:         private:
35356:             #define     SWAP(t, a, b)   do { t tmp = a; a = b; b = tmp; } while (0)
35356:             void        swapCodeChunks();
35356: 
17274:             NIns*       _epilogue;
17274:             AssmError   _err;           // 0 = means assemble() appears ok, otherwise it failed
33551:         #if PEDANTIC
33551:             NIns*       pedanticTop;
33551:         #endif
17274: 
17274:             AR          _activation;
17274:             RegAlloc    _allocator;
17274: 
32784:             verbose_only( void asm_inc_m32(uint32_t*); )
17274:             void        asm_mmq(Register rd, int dd, Register rs, int ds);
17308:             NIns*       asm_exit(LInsp guard);
17308:             NIns*       asm_leave_trace(LInsp guard);
17274:             void        asm_qjoin(LIns *ins);
36372:             void        asm_store32(LOpcode op, LIns *val, int d, LIns *base);
36372:             void        asm_store64(LOpcode op, LIns *val, int d, LIns *base);
35365:             void        asm_restore(LInsp, Register);
32727:             void        asm_spilli(LInsp i, bool pop);
20919:             void        asm_spill(Register rr, int d, bool pop, bool quad);
17274:             void        asm_load64(LInsp i);
32556:             void        asm_ret(LInsp p);
17378:             void        asm_quad(LInsp i);
20921:             void        asm_fcond(LInsp i);
20921:             void        asm_cond(LInsp i);
20921:             void        asm_arith(LInsp i);
20921:             void        asm_neg_not(LInsp i);
36372:             void        asm_load32(LInsp i);
20921:             void        asm_cmov(LInsp i);
20921:             void        asm_param(LInsp i);
20921:             void        asm_int(LInsp i);
20921:             void        asm_qlo(LInsp i);
20921:             void        asm_qhi(LInsp i);
17378:             void        asm_fneg(LInsp ins);
17378:             void        asm_fop(LInsp ins);
17378:             void        asm_i2f(LInsp ins);
17378:             void        asm_u2f(LInsp ins);
37700:             void        asm_f2i(LInsp ins);
32556:             void        asm_promote(LIns *ins);
17378:             void        asm_nongp_copy(Register r, Register s);
17687:             void        asm_call(LInsp);
18220:             Register    asm_binop_rhs_reg(LInsp ins);
30730:             NIns*       asm_branch(bool branchOnFalse, LInsp cond, NIns* targ);
25099:             void        asm_switch(LIns* ins, NIns* target);
35087:             void        asm_jtbl(LIns* ins, NIns** table);
25099:             void        emitJumpTable(SwitchInfo* si, NIns* target);
21477:             void        assignSavedRegs();
21477:             void        reserveSavedRegs();
21477:             void        assignParamRegs();
30253:             void        handleLoopCarriedExprs(InsList& pending_lives);
17274: 
17274:             // platform specific implementation (see NativeXXX.cpp file)
17274:             void        nInit(AvmCore *);
32634:             void        nBeginAssembly();
32584:             Register    nRegisterAllocFromSet(RegisterMask set);
17274:             void        nRegisterResetAll(RegAlloc& a);
32583:             static void nPatchBranch(NIns* branch, NIns* location);
17516:             void        nFragExit(LIns* guard);
17274: 
17274:             // platform specific methods
17274:         public:
20893:             const static Register savedRegs[NumSavedRegs];
17274:             DECLARE_PLATFORM_ASSEMBLER()
17274: 
17274:         private:
32793: #ifdef NANOJIT_IA32
17274:             debug_only( int32_t _fpuStkDepth; )
17274:             debug_only( int32_t _sv_fpuStkDepth; )
17274: 
17274:             // since we generate backwards the depth is negative
17274:             inline void fpu_push() {
35364:                 debug_only( ++_fpuStkDepth; NanoAssert(_fpuStkDepth<=0); )
17274:             }
17274:             inline void fpu_pop() {
35364:                 debug_only( --_fpuStkDepth; NanoAssert(_fpuStkDepth<=0); )
17274:             }
32793: #endif
22667:             avmplus::Config &config;
17274:     };
17274: 
32727:     inline int32_t disp(LIns* ins)
32727:     {
32727:         // even on 64bit cpu's, we allocate stack area in 4byte chunks
36667:         return -4 * int32_t(ins->getArIndex());
32727:     }
17274: }
17274: #endif // __nanojit_Assembler__
