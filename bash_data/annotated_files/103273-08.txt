 69223: /* -*- Mode: C; tab-width: 4; indent-tabs-mode: nil; c-basic-offset: 4 -*-
 69223:  * vim: set ts=4 sw=4 et tw=79 ft=cpp:
 69223:  *
 98983:  * This Source Code Form is subject to the terms of the Mozilla Public
 98983:  * License, v. 2.0. If a copy of the MPL was not distributed with this
 98983:  * file, You can obtain one at http://mozilla.org/MPL/2.0/. */
 69223: 
 90005: #include "jscntxt.h"
 97569: #include "gc/Marking.h"
 69223: #include "methodjit/MethodJIT.h"
 69223: #include "Stack.h"
 69223: 
 69223: #include "jsgcinlines.h"
 69223: #include "jsobjinlines.h"
 69223: 
 69223: #include "Stack-inl.h"
 69223: 
 69223: /* Includes to get to low-level memory-mapping functionality. */
 69223: #ifdef XP_WIN
 69223: # include "jswin.h"
 69223: #elif defined(XP_OS2)
 69223: # define INCL_DOSMEMMGR
 69223: # include <os2.h>
 69223: #else
 69223: # include <unistd.h>
 69223: # include <sys/mman.h>
 69223: # if !defined(MAP_ANONYMOUS)
 69223: #  if defined(MAP_ANON)
 69223: #   define MAP_ANONYMOUS MAP_ANON
 69223: #  else
 69223: #   define MAP_ANONYMOUS 0
 69223: #  endif
 69223: # endif
 69223: #endif
 69223: 
 69223: using namespace js;
 69223: 
 69223: /*****************************************************************************/
 69223: 
 71697: void
 71697: StackFrame::initExecuteFrame(JSScript *script, StackFrame *prev, FrameRegs *regs,
 71697:                              const Value &thisv, JSObject &scopeChain, ExecuteType type)
 71697: {
 71697:     /*
 71697:      * See encoding of ExecuteType. When GLOBAL isn't set, we are executing a
 71697:      * script in the context of another frame and the frame type is determined
 71697:      * by the context.
 71697:      */
 86077:     flags_ = type | HAS_SCOPECHAIN | HAS_BLOCKCHAIN | HAS_PREVPC;
 71697:     if (!(flags_ & GLOBAL))
 71697:         flags_ |= (prev->flags_ & (FUNCTION | GLOBAL));
 71697: 
 71697:     Value *dstvp = (Value *)this - 2;
 71697:     dstvp[1] = thisv;
 71697: 
 71697:     if (isFunctionFrame()) {
 71697:         dstvp[0] = prev->calleev();
 71697:         exec = prev->exec;
 87583:         u.evalScript = script;
 71697:     } else {
 71697:         JS_ASSERT(isGlobalFrame());
 71697:         dstvp[0] = NullValue();
 71697:         exec.script = script;
 71697: #ifdef DEBUG
 87583:         u.evalScript = (JSScript *)0xbad;
 71697: #endif
 71697:     }
 71697: 
 71697:     scopeChain_ = &scopeChain;
 71697:     prev_ = prev;
 71697:     prevpc_ = regs ? regs->pc : (jsbytecode *)0xbad;
 76193:     prevInline_ = regs ? regs->inlined() : NULL;
 86077:     blockChain_ = NULL;
 71697: 
 71697: #ifdef DEBUG
 71697:     ncode_ = (void *)0xbad;
 71697:     Debug_SetValueRangeToCrashOnTouch(&rval_, 1);
 71697:     hookData_ = (void *)0xbad;
 71697:     annotation_ = (void *)0xbad;
 71697: #endif
 71697: 
 71697:     if (prev && prev->annotation())
 71697:         setAnnotation(prev->annotation());
 71697: }
 71697: 
 71697: void
 71697: StackFrame::initDummyFrame(JSContext *cx, JSObject &chain)
 71697: {
 71697:     PodZero(this);
 71697:     flags_ = DUMMY | HAS_PREVPC | HAS_SCOPECHAIN;
 71697:     initPrev(cx);
 71697:     JS_ASSERT(chain.isGlobal());
101075:     scopeChain_ = &chain;
 71697: }
 71697: 
102714: template <StackFrame::TriggerPostBarriers doPostBarrier>
 71697: void
102714: StackFrame::copyFrameAndValues(JSContext *cx, Value *vp, StackFrame *otherfp,
102714:                                const Value *othervp, Value *othersp)
 71697: {
102714:     JS_ASSERT(vp == (Value *)this - ((Value *)otherfp - othervp));
102714:     JS_ASSERT(othervp == otherfp->generatorArgsSnapshotBegin());
 71697:     JS_ASSERT(othersp >= otherfp->slots());
101075:     JS_ASSERT(othersp <= otherfp->generatorSlotsSnapshotBegin() + otherfp->script()->nslots);
102714:     JS_ASSERT((Value *)this - vp == (Value *)otherfp - othervp);
 71697: 
 90005:     /* Copy args, StackFrame, and slots. */
102714:     const Value *srcend = otherfp->generatorArgsSnapshotEnd();
102714:     Value *dst = vp;
102714:     for (const Value *src = othervp; src < srcend; src++, dst++) {
 90005:         *dst = *src;
102714:         if (doPostBarrier)
102714:             HeapValue::writeBarrierPost(*dst, dst);
102714:     }
 71697: 
101616:     *this = *otherfp;
 90005:     if (doPostBarrier)
101616:         writeBarrierPost();
 90005: 
102714:     srcend = othersp;
102714:     dst = slots();
102714:     for (const Value *src = otherfp->slots(); src < srcend; src++, dst++) {
 90005:         *dst = *src;
102714:         if (doPostBarrier)
102714:             HeapValue::writeBarrierPost(*dst, dst);
102714:     }
 71697: 
 98921:     if (cx->compartment->debugMode())
101995:         cx->runtime->debugScopes->onGeneratorFrameChange(otherfp, this, cx);
 71697: }
 71697: 
 90005: /* Note: explicit instantiation for js_NewGenerator located in jsiter.cpp. */
101616: template
102714: void StackFrame::copyFrameAndValues<StackFrame::NoPostBarrier>(
102714:                                     JSContext *, Value *, StackFrame *, const Value *, Value *);
101616: template
102714: void StackFrame::copyFrameAndValues<StackFrame::DoPostBarrier>(
102714:                                     JSContext *, Value *, StackFrame *, const Value *, Value *);
 90005: 
 90005: void
 90005: StackFrame::writeBarrierPost()
 90005: {
101616:     /* This needs to follow the same rules as in StackFrame::mark. */
 90005:     if (scopeChain_)
 90005:         JSObject::writeBarrierPost(scopeChain_, (void *)&scopeChain_);
 90005:     if (isDummyFrame())
 90005:         return;
101075:     if (flags_ & HAS_ARGS_OBJ)
 90005:         JSObject::writeBarrierPost(argsObj_, (void *)&argsObj_);
 90005:     if (isFunctionFrame()) {
101616:         JSFunction::writeBarrierPost(exec.fun, (void *)&exec.fun);
 90005:         if (isEvalFrame())
 90005:             JSScript::writeBarrierPost(u.evalScript, (void *)&u.evalScript);
 90005:     } else {
 90005:         JSScript::writeBarrierPost(exec.script, (void *)&exec.script);
 90005:     }
 90005:     if (hasReturnValue())
 90005:         HeapValue::writeBarrierPost(rval_, &rval_);
 90005: }
 90005: 
101075: JSGenerator *
101075: StackFrame::maybeSuspendedGenerator(JSRuntime *rt)
101075: {
101075:     /*
101075:      * A suspended generator's frame is embedded inside the JSGenerator object
101075:      * instead of on the contiguous stack like all active frames.
101075:      */
101075:     if (!isGeneratorFrame() || rt->stackSpace.containsFast(this))
101075:         return NULL;
101075: 
101075:     /*
101075:      * Once we know we have a suspended generator frame, there is a static
101075:      * offset from the frame's snapshot to beginning of the JSGenerator.
101075:      */
101075:     char *vp = reinterpret_cast<char *>(generatorArgsSnapshotBegin());
101075:     char *p = vp - offsetof(JSGenerator, stackSnapshot);
101075:     JSGenerator *gen = reinterpret_cast<JSGenerator *>(p);
101075:     JS_ASSERT(gen->fp == this);
101075:     return gen;
101075: }
101075: 
 69223: jsbytecode *
101075: StackFrame::prevpcSlow(InlinedSite **pinlined)
 69223: {
 69223:     JS_ASSERT(!(flags_ & HAS_PREVPC));
 69223: #if defined(JS_METHODJIT) && defined(JS_MONOIC)
 69223:     StackFrame *p = prev();
 98147:     mjit::JITScript *jit = p->script()->getJIT(p->isConstructing(), p->compartment()->needsBarrier());
 76193:     prevpc_ = jit->nativeToPC(ncode_, &prevInline_);
 69223:     flags_ |= HAS_PREVPC;
 76193:     if (pinlined)
 76193:         *pinlined = prevInline_;
 69223:     return prevpc_;
 69223: #else
 69223:     JS_NOT_REACHED("Unknown PC for frame");
 69223:     return NULL;
 69223: #endif
 69223: }
 69223: 
 76193: jsbytecode *
102812: StackFrame::pcQuadratic(const ContextStack &stack, size_t maxDepth)
 76193: {
 76193:     StackSegment &seg = stack.space().containingSegment(this);
 76193:     FrameRegs &regs = seg.regs();
 76193: 
 76193:     /*
 76193:      * This isn't just an optimization; seg->computeNextFrame(fp) is only
102812:      * defined if fp != seg->regs->fp.
 76193:      */
102812:     if (regs.fp() == this)
 76193:         return regs.pc;
 76193: 
102812:     /*
102812:      * To compute fp's pc, we need the next frame (where next->prev == fp).
102812:      * This requires a linear search which we allow the caller to limit (in
102812:      * cases where we do not have a hard requirement to find the correct pc).
102812:      */
102812:     if (StackFrame *next = seg.computeNextFrame(this, maxDepth))
102812:         return next->prevpc();
102812: 
102812:     /* If we hit the limit, just return the beginning of the script. */
102812:     return regs.fp()->script()->code;
 76193: }
 76193: 
 98921: bool
101075: StackFrame::prologue(JSContext *cx, bool newType)
101075: {
101075:     JS_ASSERT(!isDummyFrame());
101075:     JS_ASSERT(!isGeneratorFrame());
101075:     JS_ASSERT(cx->regs().pc == script()->code);
101075: 
101075:     if (isEvalFrame()) {
101075:         if (script()->strictModeCode) {
101075:             CallObject *callobj = CallObject::createForStrictEval(cx, this);
101075:             if (!callobj)
101075:                 return false;
101075:             pushOnScopeChain(*callobj);
101075:             flags_ |= HAS_CALL_OBJ;
101075:         }
101075:         return true;
101075:     }
101075: 
101075:     if (isGlobalFrame())
101075:         return true;
101075: 
101075:     JS_ASSERT(isNonEvalFunctionFrame());
101075: 
101075:     if (fun()->isHeavyweight()) {
101075:         CallObject *callobj = CallObject::createForFunction(cx, this);
101075:         if (!callobj)
101075:             return false;
101075:         pushOnScopeChain(*callobj);
101075:         flags_ |= HAS_CALL_OBJ;
101075:     }
101075: 
101075:     if (script()->nesting()) {
101075:         types::NestingPrologue(cx, this);
101075:         flags_ |= HAS_NESTING;
101075:     }
101075: 
101075:     if (isConstructing()) {
101075:         RootedObject callee(cx, &this->callee());
101075:         JSObject *obj = js_CreateThisForFunction(cx, callee, newType);
101075:         if (!obj)
101075:             return false;
101075:         functionThis() = ObjectValue(*obj);
101075:     }
101075: 
101075:     Probes::enterJSFun(cx, fun(), script());
101075:     return true;
101075: }
101075: 
101075: void
101075: StackFrame::epilogue(JSContext *cx)
101075: {
101075:     JS_ASSERT(!isDummyFrame());
101075:     JS_ASSERT(!isYielding());
101075:     JS_ASSERT(!hasBlockChain());
101075: 
101075:     if (isEvalFrame()) {
101075:         if (isStrictEvalFrame()) {
101075:             JS_ASSERT_IF(hasCallObj(), scopeChain()->asCall().isForEval());
101075:             if (cx->compartment->debugMode())
101075:                 cx->runtime->debugScopes->onPopStrictEvalScope(this);
101075:         } else if (isDirectEvalFrame()) {
101075:             if (isDebuggerFrame())
101075:                 JS_ASSERT(!scopeChain()->isScope());
101075:             else
101075:                 JS_ASSERT(scopeChain() == prev()->scopeChain());
101075:         } else {
101075:             JS_ASSERT(scopeChain()->isGlobal());
101075:         }
101075:         return;
101075:     }
101075: 
101075:     if (isGlobalFrame()) {
101075:         JS_ASSERT(!scopeChain()->isScope());
101075:         return;
101075:     }
101075: 
101075:     JS_ASSERT(isNonEvalFunctionFrame());
101075:     if (fun()->isHeavyweight()) {
101075:         JS_ASSERT_IF(hasCallObj(),
101075:                      scopeChain()->asCall().getCalleeFunction()->script() == script());
101075:     } else {
101075:         JS_ASSERT(!scopeChain()->isCall() || scopeChain()->asCall().isForEval() ||
101075:                   scopeChain()->asCall().getCalleeFunction()->script() != script());
101075:     }
101075: 
101075:     if (cx->compartment->debugMode())
101995:         cx->runtime->debugScopes->onPopCall(this, cx);
101075: 
101075:     Probes::exitJSFun(cx, fun(), script());
101075: 
101075:     if (script()->nesting() && (flags_ & HAS_NESTING))
101075:         types::NestingEpilogue(this);
101075: 
101075:     if (isConstructing() && returnValue().isPrimitive())
101075:         setReturnValue(ObjectValue(constructorThis()));
101075: }
101075: 
101075: bool
101075: StackFrame::jitStrictEvalPrologue(JSContext *cx)
101075: {
101075:     JS_ASSERT(isStrictEvalFrame());
101075:     CallObject *callobj = CallObject::createForStrictEval(cx, this);
101075:     if (!callobj)
101075:         return false;
101075: 
101075:     pushOnScopeChain(*callobj);
101075:     flags_ |= HAS_CALL_OBJ;
101075:     return true;
101075: }
101075: 
101075: bool
 98921: StackFrame::pushBlock(JSContext *cx, StaticBlockObject &block)
 98921: {
 98921:     JS_ASSERT_IF(hasBlockChain(), blockChain_ == block.enclosingBlock());
 98921: 
 98921:     if (block.needsClone()) {
 99421:         Rooted<StaticBlockObject *> blockHandle(cx, &block);
 98921:         ClonedBlockObject *clone = ClonedBlockObject::create(cx, blockHandle, this);
 98921:         if (!clone)
 98921:             return false;
 98921: 
101075:         pushOnScopeChain(*clone);
 98921:     }
 98921: 
 98921:     flags_ |= HAS_BLOCKCHAIN;
 98921:     blockChain_ = &block;
 98921:     return true;
 98921: }
 98921: 
 98921: void
 98921: StackFrame::popBlock(JSContext *cx)
 98921: {
 98921:     JS_ASSERT(hasBlockChain());
 98921: 
 98921:     if (cx->compartment->debugMode())
 98921:         cx->runtime->debugScopes->onPopBlock(cx, this);
 98921: 
 98921:     if (blockChain_->needsClone()) {
101075:         JS_ASSERT(scopeChain_->asClonedBlock().staticBlock() == *blockChain_);
101075:         popOffScopeChain();
 98921:     }
 98921: 
 98921:     blockChain_ = blockChain_->enclosingBlock();
 98921: }
 98921: 
 98921: void
 98921: StackFrame::popWith(JSContext *cx)
 98921: {
101071:     if (cx->compartment->debugMode())
101071:         cx->runtime->debugScopes->onPopWith(this);
101071: 
101075:     JS_ASSERT(scopeChain()->isWith());
101075:     popOffScopeChain();
 98921: }
 98921: 
 89965: void
 89965: StackFrame::mark(JSTracer *trc)
 89965: {
 89965:     /*
 89965:      * Normally we would use MarkRoot here, except that generators also take
 89965:      * this path. However, generators use a special write barrier when the stack
 89965:      * frame is copied to the floating frame. Therefore, no barrier is needed.
 89965:      */
 91557:     if (flags_ & HAS_SCOPECHAIN)
 91557:         gc::MarkObjectUnbarriered(trc, &scopeChain_, "scope chain");
 89965:     if (isDummyFrame())
 89965:         return;
101075:     if (flags_ & HAS_ARGS_OBJ)
 91557:         gc::MarkObjectUnbarriered(trc, &argsObj_, "arguments");
 89965:     if (isFunctionFrame()) {
 91557:         gc::MarkObjectUnbarriered(trc, &exec.fun, "fun");
 89965:         if (isEvalFrame())
 91557:             gc::MarkScriptUnbarriered(trc, &u.evalScript, "eval script");
 89965:     } else {
 91557:         gc::MarkScriptUnbarriered(trc, &exec.script, "script");
 89965:     }
 89965:     if (IS_GC_MARKING_TRACER(trc))
 89965:         script()->compartment()->active = true;
 90302:     gc::MarkValueUnbarriered(trc, &returnValue(), "rval");
 89965: }
 89965: 
 71697: /*****************************************************************************/
 71697: 
 71697: bool
 71697: StackSegment::contains(const StackFrame *fp) const
 69223: {
 71697:     /* NB: this depends on the continuity of segments in memory. */
 71697:     return (Value *)fp >= slotsBegin() && (Value *)fp <= (Value *)maybefp();
 69223: }
 69223: 
 71697: bool
 71697: StackSegment::contains(const FrameRegs *regs) const
 71697: {
 71697:     return regs && contains(regs->fp());
 71697: }
 69223: 
 71697: bool
 71697: StackSegment::contains(const CallArgsList *call) const
 69223: {
 71697:     if (!call || !calls_)
 69223:         return false;
 69223: 
 71697:     /* NB: this depends on the continuity of segments in memory. */
 79387:     Value *vp = call->array();
 87583:     return vp > slotsBegin() && vp <= calls_->array();
 69223: }
 69223: 
 69223: StackFrame *
102812: StackSegment::computeNextFrame(const StackFrame *f, size_t maxDepth) const
 69223: {
 71697:     JS_ASSERT(contains(f) && f != fp());
 69223: 
 71697:     StackFrame *next = fp();
102812:     for (size_t i = 0; i <= maxDepth; ++i) {
102812:         if (next->prev() == f)
 69223:             return next;
102812:         next = next->prev();
102812:     }
102812: 
102812:     return NULL;
 69223: }
 69223: 
 71697: Value *
 71697: StackSegment::end() const
 71697: {
 71697:     /* NB: this depends on the continuity of segments in memory. */
 71697:     JS_ASSERT_IF(calls_ || regs_, contains(calls_) || contains(regs_));
 71697:     Value *p = calls_
 71697:                ? regs_
 71697:                  ? Max(regs_->sp, calls_->end())
 71697:                  : calls_->end()
 71697:                : regs_
 71697:                  ? regs_->sp
 71697:                  : slotsBegin();
 71697:     JS_ASSERT(p >= slotsBegin());
 71697:     return p;
 71697: }
 71697: 
 71697: FrameRegs *
 71697: StackSegment::pushRegs(FrameRegs &regs)
 71697: {
 71697:     JS_ASSERT_IF(contains(regs_), regs.fp()->prev() == regs_->fp());
 71697:     FrameRegs *prev = regs_;
 71697:     regs_ = &regs;
 71697:     return prev;
 71697: }
 71697: 
 71697: void
 71697: StackSegment::popRegs(FrameRegs *regs)
 71697: {
 71697:     JS_ASSERT_IF(regs && contains(regs->fp()), regs->fp() == regs_->fp()->prev());
 71697:     regs_ = regs;
 71697: }
 71697: 
 71697: void
 71697: StackSegment::pushCall(CallArgsList &callList)
 71697: {
 71697:     callList.prev_ = calls_;
 71697:     calls_ = &callList;
 71697: }
 71697: 
 71697: void
 71767: StackSegment::pointAtCall(CallArgsList &callList)
 71767: {
 71767:     calls_ = &callList;
 71767: }
 71767: 
 71767: void
 71697: StackSegment::popCall()
 71697: {
 71697:     calls_ = calls_->prev_;
 71697: }
 71697: 
 69223: /*****************************************************************************/
 69223: 
 69223: StackSpace::StackSpace()
 73495:   : seg_(NULL),
 73495:     base_(NULL),
 73495:     conservativeEnd_(NULL),
 73495: #ifdef XP_WIN
 69223:     commitEnd_(NULL),
 73495: #endif
 73495:     defaultEnd_(NULL),
 73495:     trustedEnd_(NULL)
 73495: {
 73495:     assertInvariants();
 73495: }
 69223: 
 69223: bool
 69223: StackSpace::init()
 69223: {
 69223:     void *p;
 69223: #ifdef XP_WIN
 69223:     p = VirtualAlloc(NULL, CAPACITY_BYTES, MEM_RESERVE, PAGE_READWRITE);
 69223:     if (!p)
 69223:         return false;
 69223:     void *check = VirtualAlloc(p, COMMIT_BYTES, MEM_COMMIT, PAGE_READWRITE);
 69223:     if (p != check)
 69223:         return false;
 69223:     base_ = reinterpret_cast<Value *>(p);
 73495:     conservativeEnd_ = commitEnd_ = base_ + COMMIT_VALS;
 73495:     trustedEnd_ = base_ + CAPACITY_VALS;
 73495:     defaultEnd_ = trustedEnd_ - BUFFER_VALS;
101796:     Debug_SetValueRangeToCrashOnTouch(base_, commitEnd_);
 69223: #elif defined(XP_OS2)
 69223:     if (DosAllocMem(&p, CAPACITY_BYTES, PAG_COMMIT | PAG_READ | PAG_WRITE | OBJ_ANY) &&
 69223:         DosAllocMem(&p, CAPACITY_BYTES, PAG_COMMIT | PAG_READ | PAG_WRITE))
 69223:         return false;
 69223:     base_ = reinterpret_cast<Value *>(p);
 73495:     trustedEnd_ = base_ + CAPACITY_VALS;
 73495:     conservativeEnd_ = defaultEnd_ = trustedEnd_ - BUFFER_VALS;
101796:     Debug_SetValueRangeToCrashOnTouch(base_, trustedEnd_);
 69223: #else
 69223:     JS_ASSERT(CAPACITY_BYTES % getpagesize() == 0);
 69223:     p = mmap(NULL, CAPACITY_BYTES, PROT_READ | PROT_WRITE, MAP_PRIVATE | MAP_ANONYMOUS, -1, 0);
 69223:     if (p == MAP_FAILED)
 69223:         return false;
 69223:     base_ = reinterpret_cast<Value *>(p);
 73495:     trustedEnd_ = base_ + CAPACITY_VALS;
 73495:     conservativeEnd_ = defaultEnd_ = trustedEnd_ - BUFFER_VALS;
101796:     Debug_SetValueRangeToCrashOnTouch(base_, trustedEnd_);
 69223: #endif
 73495:     assertInvariants();
 69223:     return true;
 69223: }
 69223: 
 69223: StackSpace::~StackSpace()
 69223: {
 73495:     assertInvariants();
 69223:     JS_ASSERT(!seg_);
 69223:     if (!base_)
 69223:         return;
 69223: #ifdef XP_WIN
 69223:     VirtualFree(base_, (commitEnd_ - base_) * sizeof(Value), MEM_DECOMMIT);
 69223:     VirtualFree(base_, 0, MEM_RELEASE);
 69223: #elif defined(XP_OS2)
 69223:     DosFreeMem(base_);
 69223: #else
 69223: #ifdef SOLARIS
 69223:     munmap((caddr_t)base_, CAPACITY_BYTES);
 69223: #else
 69223:     munmap(base_, CAPACITY_BYTES);
 69223: #endif
 69223: #endif
 69223: }
 69223: 
 71697: StackSegment &
 76193: StackSpace::containingSegment(const StackFrame *target) const
 69223: {
 71697:     for (StackSegment *s = seg_; s; s = s->prevInMemory()) {
 69223:         if (s->contains(target))
 69223:             return *s;
 69223:     }
 69223:     JS_NOT_REACHED("frame not in stack space");
 69223:     return *(StackSegment *)NULL;
 69223: }
 69223: 
 69223: void
101075: StackSpace::markFrameValues(JSTracer *trc, StackFrame *fp, Value *slotsEnd, jsbytecode *pc)
 89965: {
 89965:     Value *slotsBegin = fp->slots();
 89965: 
 89965:     if (!fp->isScriptFrame()) {
 89965:         JS_ASSERT(fp->isDummyFrame());
 90129:         gc::MarkValueRootRange(trc, slotsBegin, slotsEnd, "vm_stack");
 89965:         return;
 89965:     }
 89965: 
 89965:     /* If it's a scripted frame, we should have a pc. */
 89965:     JS_ASSERT(pc);
 89965: 
 89965:     JSScript *script = fp->script();
 89965:     if (!script->hasAnalysis() || !script->analysis()->ranLifetimes()) {
 90129:         gc::MarkValueRootRange(trc, slotsBegin, slotsEnd, "vm_stack");
 89965:         return;
 89965:     }
 89965: 
 89965:     /*
 89965:      * If the JIT ran a lifetime analysis, then it may have left garbage in the
 89965:      * slots considered not live. We need to avoid marking them. Additionally,
 89965:      * in case the analysis information is thrown out later, we overwrite these
 89965:      * dead slots with valid values so that future GCs won't crash. Analysis
 89965:      * results are thrown away during the sweeping phase, so we always have at
 89965:      * least one GC to do this.
 89965:      */
 89965:     analyze::AutoEnterAnalysis aea(script->compartment());
 89965:     analyze::ScriptAnalysis *analysis = script->analysis();
 89965:     uint32_t offset = pc - script->code;
 89965:     Value *fixedEnd = slotsBegin + script->nfixed;
 89965:     for (Value *vp = slotsBegin; vp < fixedEnd; vp++) {
 89965:         uint32_t slot = analyze::LocalSlot(script, vp - slotsBegin);
 89965: 
 97881:         /*
 97881:          * Will this slot be synced by the JIT? If not, replace with a dummy
 97881:          * value with the same type tag.
 97881:          */
102264:         if (!analysis->trackSlot(slot) || analysis->liveness(slot).live(offset)) {
 90302:             gc::MarkValueRoot(trc, vp, "vm_stack");
102264:         } else if (vp->isDouble()) {
102264:             *vp = DoubleValue(0.0);
102264:         } else {
102264:             /*
102264:              * It's possible that *vp may not be a valid Value. For example, it
102264:              * may be tagged as a NullValue but the low bits may be nonzero so
102264:              * that isNull() returns false. This can cause problems later on
102264:              * when marking the value. Extracting the type in this way and then
102264:              * overwriting the value circumvents the problem.
102264:              */
102264:             JSValueType type = vp->extractNonDoubleType();
102264:             if (type == JSVAL_TYPE_INT32)
102264:                 *vp = Int32Value(0);
102264:             else if (type == JSVAL_TYPE_UNDEFINED)
102264:                 *vp = UndefinedValue();
102264:             else if (type == JSVAL_TYPE_BOOLEAN)
102264:                 *vp = BooleanValue(false);
102264:             else if (type == JSVAL_TYPE_STRING)
102264:                 *vp = StringValue(trc->runtime->atomState.nullAtom);
102264:             else if (type == JSVAL_TYPE_NULL)
102264:                 *vp = NullValue();
102264:             else if (type == JSVAL_TYPE_OBJECT)
 97881:                 *vp = ObjectValue(fp->scopeChain()->global());
102264:         }
 89965:     }
 89965: 
 90129:     gc::MarkValueRootRange(trc, fixedEnd, slotsEnd, "vm_stack");
 89965: }
 89965: 
 89965: void
 69223: StackSpace::mark(JSTracer *trc)
 69223: {
 69223:     /*
 69223:      * JIT code can leave values in an incoherent (i.e., unsafe for precise
 69223:      * marking) state, hence MarkStackRangeConservatively.
 69223:      */
 69223: 
 71697:     /* NB: this depends on the continuity of segments in memory. */
 71697:     Value *nextSegEnd = firstUnused();
 71697:     for (StackSegment *seg = seg_; seg; seg = seg->prevInMemory()) {
 71697:         /*
 71697:          * A segment describes a linear region of memory that contains a stack
 71697:          * of native and interpreted calls. For marking purposes, though, we
 71697:          * only need to distinguish between frames and values and mark
 71697:          * accordingly. Since native calls only push values on the stack, we
 71697:          * can effectively lump them together and just iterate over interpreted
 71697:          * calls. Thus, marking can view the stack as the regex:
 71697:          *   (segment slots (frame slots)*)*
 71697:          * which gets marked in reverse order.
 71697:          */
 71697:         Value *slotsEnd = nextSegEnd;
 89965:         jsbytecode *pc = seg->maybepc();
 71697:         for (StackFrame *fp = seg->maybefp(); (Value *)fp > (Value *)seg; fp = fp->prev()) {
 89965:             /* Mark from fp->slots() to slotsEnd. */
101075:             markFrameValues(trc, fp, slotsEnd, pc);
 89965: 
 89965:             fp->mark(trc);
 71697:             slotsEnd = (Value *)fp;
 89965: 
101075:             InlinedSite *site;
 89965:             pc = fp->prevpc(&site);
 89965:             JS_ASSERT_IF(fp->prev(), !site);
 69223:         }
 90129:         gc::MarkValueRootRange(trc, seg->slotsBegin(), slotsEnd, "vm_stack");
 71697:         nextSegEnd = (Value *)seg;
 69223:     }
 69223: }
 69223: 
 90410: void
 90410: StackSpace::markActiveCompartments()
 90410: {
 90410:     for (StackSegment *seg = seg_; seg; seg = seg->prevInMemory()) {
 90410:         for (StackFrame *fp = seg->maybefp(); (Value *)fp > (Value *)seg; fp = fp->prev())
 90410:             MarkCompartmentActive(fp);
 90410:     }
 90410: }
 90410: 
 69223: JS_FRIEND_API(bool)
 76885: StackSpace::ensureSpaceSlow(JSContext *cx, MaybeReportError report, Value *from, ptrdiff_t nvals,
 76885:                             JSCompartment *dest) const
 69223: {
 73495:     assertInvariants();
 73495: 
 76885:     /* See CX_COMPARTMENT comment. */
 76885:     if (dest == (JSCompartment *)CX_COMPARTMENT)
 76885:         dest = cx->compartment;
 76885: 
 76885:     bool trusted = !dest || dest->principals == cx->runtime->trustedPrincipals();
 73495:     Value *end = trusted ? trustedEnd_ : defaultEnd_;
 73495: 
 73495:     /*
 73495:      * conservativeEnd_ must stay below defaultEnd_: if conservativeEnd_ were
 73495:      * to be bumped past defaultEnd_, untrusted JS would be able to consume the
 73495:      * buffer space at the end of the stack reserved for trusted JS.
 73495:      */
 73495: 
 73495:     if (end - from < nvals) {
 73495:         if (report)
 73495:             js_ReportOverRecursed(cx);
 69223:         return false;
 69223:     }
 69223: 
 73495: #ifdef XP_WIN
 73495:     if (commitEnd_ - from < nvals) {
 69223:         Value *newCommit = commitEnd_;
 69223:         Value *request = from + nvals;
 69223: 
 69223:         /* Use a dumb loop; will probably execute once. */
 73495:         JS_ASSERT((trustedEnd_ - newCommit) % COMMIT_VALS == 0);
 69223:         do {
 69223:             newCommit += COMMIT_VALS;
 73495:             JS_ASSERT((trustedEnd_ - newCommit) >= 0);
 69223:         } while (newCommit < request);
 69223: 
 69223:         /* The cast is safe because CAPACITY_BYTES is small. */
 84755:         int32_t size = static_cast<int32_t>(newCommit - commitEnd_) * sizeof(Value);
 69223: 
 69223:         if (!VirtualAlloc(commitEnd_, size, MEM_COMMIT, PAGE_READWRITE)) {
 73495:             if (report)
 73495:                 js_ReportOverRecursed(cx);
 69223:             return false;
 69223:         }
 69223: 
101796:         Debug_SetValueRangeToCrashOnTouch(commitEnd_, newCommit);
101796: 
 69223:         commitEnd_ = newCommit;
 73495:         conservativeEnd_ = Min(commitEnd_, defaultEnd_);
 73495:         assertInvariants();
 69223:     }
 69223: #endif
 69223: 
 73495:     return true;
 73495: }
 73495: 
 69223: bool
 91237: StackSpace::tryBumpLimit(JSContext *cx, Value *from, unsigned nvals, Value **limit)
 69223: {
 73495:     if (!ensureSpace(cx, REPORT_ERROR, from, nvals))
 71363:         return false;
 73495:     *limit = conservativeEnd_;
 69223:     return true;
 69223: }
 69223: 
 71366: size_t
 83122: StackSpace::sizeOfCommitted()
 71366: {
 73495: #ifdef XP_WIN
 71366:     return (commitEnd_ - base_) * sizeof(Value);
 73495: #else
 73495:     return (trustedEnd_ - base_) * sizeof(Value);
 73495: #endif
 71366: }
 71366: 
 98783: #ifdef DEBUG
 98783: bool
 98783: StackSpace::containsSlow(StackFrame *fp)
 98783: {
 98783:     for (AllFramesIter i(*this); !i.done(); ++i) {
 98783:         if (i.fp() == fp)
 98783:             return true;
 98783:     }
 98783:     return false;
 98783: }
 98783: #endif
 98783: 
 69223: /*****************************************************************************/
 69223: 
 69223: ContextStack::ContextStack(JSContext *cx)
 71697:   : seg_(NULL),
 88135:     space_(&cx->runtime->stackSpace),
 69223:     cx_(cx)
 88135: {}
 69223: 
 69223: ContextStack::~ContextStack()
 69223: {
 69223:     JS_ASSERT(!seg_);
 69223: }
 69223: 
 69223: bool
 71697: ContextStack::onTop() const
 69223: {
 71697:     return seg_ && seg_ == space().seg_;
 69223: }
 69223: 
 71697: bool
 71697: ContextStack::containsSlow(const StackFrame *target) const
 69223: {
 71697:     for (StackSegment *s = seg_; s; s = s->prevInContext()) {
 71697:         if (s->contains(target))
 71697:             return true;
 71697:     }
 71697:     return false;
 71697: }
 71697: 
 71697: /*
 71697:  * This helper function brings the ContextStack to the top of the thread stack
 71697:  * (so that it can be extended to push a frame and/or arguments) by potentially
 71697:  * pushing a StackSegment. The 'pushedSeg' outparam indicates whether such a
 71697:  * segment was pushed (and hence whether the caller needs to call popSegment).
 71697:  *
 71697:  * Additionally, to minimize calls to ensureSpace, ensureOnTop ensures that
 71697:  * there is space for nvars slots on top of the stack.
 71697:  */
 71697: Value *
 91237: ContextStack::ensureOnTop(JSContext *cx, MaybeReportError report, unsigned nvars,
 76885:                           MaybeExtend extend, bool *pushedSeg, JSCompartment *dest)
 71697: {
 71697:     Value *firstUnused = space().firstUnused();
 71697: 
 77377: #ifdef JS_METHODJIT
 77377:     /*
 77377:      * The only calls made by inlined methodjit frames can be to other JIT
 77398:      * frames associated with the same VMFrame. If we try to Invoke(),
 77398:      * Execute() or so forth, any topmost inline frame will need to be
 77398:      * expanded (along with other inline frames in the compartment).
 77398:      * To avoid pathological behavior here, make sure to mark any topmost
 77398:      * function as uninlineable, which will expand inline frames if there are
 77398:      * any and prevent the function from being inlined in the future.
 77377:      */
 77426:     if (FrameRegs *regs = cx->maybeRegs()) {
 77410:         JSFunction *fun = NULL;
101075:         if (InlinedSite *site = regs->inlined()) {
 87654:             mjit::JITChunk *chunk = regs->fp()->jit()->chunk(regs->pc);
 87654:             fun = chunk->inlineFrames()[site->inlineIndex].fun;
 77426:         } else {
 77426:             StackFrame *fp = regs->fp();
 77426:             if (fp->isFunctionFrame()) {
 77426:                 JSFunction *f = fp->fun();
 77426:                 if (f->isInterpreted())
 77426:                     fun = f;
 77426:             }
 77426:         }
 77426: 
 77410:         if (fun) {
 77410:             fun->script()->uninlineable = true;
 77410:             types::MarkTypeObjectFlags(cx, fun, types::OBJECT_FLAG_UNINLINEABLE);
 77398:         }
 77398:     }
 77410:     JS_ASSERT_IF(cx->hasfp(), !cx->regs().inlined());
 77377: #endif
 77377: 
 71697:     if (onTop() && extend) {
 76885:         if (!space().ensureSpace(cx, report, firstUnused, nvars, dest))
 71697:             return NULL;
 71697:         return firstUnused;
 71697:     }
 71697: 
 76885:     if (!space().ensureSpace(cx, report, firstUnused, VALUES_PER_STACK_SEGMENT + nvars, dest))
 71697:         return NULL;
 71697: 
 71697:     FrameRegs *regs;
 71697:     CallArgsList *calls;
 71697:     if (seg_ && extend) {
 71697:         regs = seg_->maybeRegs();
 71697:         calls = seg_->maybeCalls();
 71697:     } else {
 71697:         regs = NULL;
 71697:         calls = NULL;
 71697:     }
 71697: 
 71697:     seg_ = new(firstUnused) StackSegment(seg_, space().seg_, regs, calls);
 71697:     space().seg_ = seg_;
 71697:     *pushedSeg = true;
 71697:     return seg_->slotsBegin();
 69223: }
 69223: 
 69223: void
 71697: ContextStack::popSegment()
 69223: {
 71697:     space().seg_ = seg_->prevInMemory();
 71697:     seg_ = seg_->prevInContext();
 71697: 
 71697:     if (!seg_)
 71697:         cx_->maybeMigrateVersionOverride();
 69223: }
 69223: 
 71697: bool
 91237: ContextStack::pushInvokeArgs(JSContext *cx, unsigned argc, InvokeArgsGuard *iag)
 69223: {
 74602:     JS_ASSERT(argc <= StackSpace::ARGS_LENGTH_MAX);
 74602: 
 91237:     unsigned nvars = 2 + argc;
 73495:     Value *firstUnused = ensureOnTop(cx, REPORT_ERROR, nvars, CAN_EXTEND, &iag->pushedSeg_);
 71697:     if (!firstUnused)
 71697:         return false;
 69223: 
 91376:     MakeRangeGCSafe(firstUnused, nvars);
 90857: 
 71697:     ImplicitCast<CallArgs>(*iag) = CallArgsFromVp(argc, firstUnused);
 71697: 
 71697:     seg_->pushCall(*iag);
 71697:     JS_ASSERT(space().firstUnused() == iag->end());
 71697:     iag->setPushed(*this);
 71697:     return true;
 69223: }
 69223: 
 69223: void
 71697: ContextStack::popInvokeArgs(const InvokeArgsGuard &iag)
 69223: {
 71697:     JS_ASSERT(iag.pushed());
 71697:     JS_ASSERT(onTop());
 71697:     JS_ASSERT(space().firstUnused() == seg_->calls().end());
 69223: 
101796:     Value *oldend = seg_->end();
101796: 
 71697:     seg_->popCall();
 90750:     if (iag.pushedSeg_)
 71697:         popSegment();
101796: 
101796:     Debug_SetValueRangeToCrashOnTouch(space().firstUnused(), oldend);
 69223: }
 69223: 
 71697: bool
 71697: ContextStack::pushInvokeFrame(JSContext *cx, const CallArgs &args,
 77341:                               InitialFrameFlags initial, InvokeFrameGuard *ifg)
 69223: {
 71697:     JS_ASSERT(onTop());
 71697:     JS_ASSERT(space().firstUnused() == args.end());
 69223: 
 71697:     JSObject &callee = args.callee();
 83234:     JSFunction *fun = callee.toFunction();
 71697:     JSScript *script = fun->script();
 69223: 
 89722:     StackFrame::Flags flags = ToFrameFlags(initial);
 73495:     StackFrame *fp = getCallFrame(cx, REPORT_ERROR, args, fun, script, &flags);
 71697:     if (!fp)
 71697:         return false;
 69223: 
 89722:     fp->initCallFrame(cx, *fun, script, args.length(), flags);
 71697:     ifg->regs_.prepareToRun(*fp, script);
 69223: 
 71697:     ifg->prevRegs_ = seg_->pushRegs(ifg->regs_);
 71697:     JS_ASSERT(space().firstUnused() == ifg->regs_.sp);
 71697:     ifg->setPushed(*this);
 71697:     return true;
 69223: }
 69223: 
 69223: bool
 71695: ContextStack::pushExecuteFrame(JSContext *cx, JSScript *script, const Value &thisv,
 71695:                                JSObject &scopeChain, ExecuteType type,
 71695:                                StackFrame *evalInFrame, ExecuteFrameGuard *efg)
 69223: {
 71697:     /*
 71697:      * Even though global code and indirect eval do not execute in the context
 71697:      * of the current frame, prev-link these to the current frame so that the
 71697:      * callstack looks right to the debugger (via CAN_EXTEND). This is safe
 71697:      * since the scope chain is what determines name lookup and access, not
 71697:      * prev-links.
 71697:      *
 71697:      * Eval-in-frame is the exception since it prev-links to an arbitrary frame
 71697:      * (possibly in the middle of some previous segment). Thus pass CANT_EXTEND
 71697:      * (to start a new segment) and link the frame and call chain manually
 71697:      * below.
 71697:      */
 71697:     CallArgsList *evalInFrameCalls = NULL;  /* quell overwarning */
 71697:     MaybeExtend extend;
 71697:     if (evalInFrame) {
 71697:         /* Though the prev-frame is given, need to search for prev-call. */
 98784:         StackSegment &seg = cx->stack.space().containingSegment(evalInFrame);
 98784:         StackIter iter(cx->runtime, seg);
 71697:         while (!iter.isScript() || iter.fp() != evalInFrame)
 71697:             ++iter;
 71697:         evalInFrameCalls = iter.calls_;
 71697:         extend = CANT_EXTEND;
 71697:     } else {
 71697:         extend = CAN_EXTEND;
 71697:     }
 71695: 
 91237:     unsigned nvars = 2 /* callee, this */ + VALUES_PER_STACK_FRAME + script->nslots;
 73495:     Value *firstUnused = ensureOnTop(cx, REPORT_ERROR, nvars, extend, &efg->pushedSeg_);
 71697:     if (!firstUnused)
101773:         return false;
 71695: 
 98408:     StackFrame *prev = evalInFrame ? evalInFrame : maybefp();
 71697:     StackFrame *fp = reinterpret_cast<StackFrame *>(firstUnused + 2);
 71697:     fp->initExecuteFrame(script, prev, seg_->maybeRegs(), thisv, scopeChain, type);
101075:     fp->initVarsToUndefined();
 71697:     efg->regs_.prepareToRun(*fp, script);
 71695: 
 71697:     /* pushRegs() below links the prev-frame; manually link the prev-call. */
 71697:     if (evalInFrame && evalInFrameCalls)
 71767:         seg_->pointAtCall(*evalInFrameCalls);
 71697: 
 71697:     efg->prevRegs_ = seg_->pushRegs(efg->regs_);
 71697:     JS_ASSERT(space().firstUnused() == efg->regs_.sp);
 71697:     efg->setPushed(*this);
 71695:     return true;
 71695: }
 71695: 
 71695: bool
 76885: ContextStack::pushDummyFrame(JSContext *cx, JSCompartment *dest, JSObject &scopeChain, DummyFrameGuard *dfg)
 71697: {
 76885:     JS_ASSERT(dest == scopeChain.compartment());
 76885: 
 91237:     unsigned nvars = VALUES_PER_STACK_FRAME;
 76885:     Value *firstUnused = ensureOnTop(cx, REPORT_ERROR, nvars, CAN_EXTEND, &dfg->pushedSeg_, dest);
 71697:     if (!firstUnused)
 86462:         return false;
 71697: 
 71697:     StackFrame *fp = reinterpret_cast<StackFrame *>(firstUnused);
 71697:     fp->initDummyFrame(cx, scopeChain);
 71697:     dfg->regs_.initDummyFrame(*fp);
 71697: 
 77448:     cx->setCompartment(dest);
 71697:     dfg->prevRegs_ = seg_->pushRegs(dfg->regs_);
 71697:     JS_ASSERT(space().firstUnused() == dfg->regs_.sp);
 71697:     dfg->setPushed(*this);
 71697:     return true;
 71697: }
 71697: 
 71697: void
 71697: ContextStack::popFrame(const FrameGuard &fg)
 71697: {
 71697:     JS_ASSERT(fg.pushed());
 71697:     JS_ASSERT(onTop());
 71697:     JS_ASSERT(space().firstUnused() == fg.regs_.sp);
 71697:     JS_ASSERT(&fg.regs_ == &seg_->regs());
 71697: 
101796:     Value *oldend = seg_->end();
101796: 
 71697:     seg_->popRegs(fg.prevRegs_);
 90750:     if (fg.pushedSeg_)
 71697:         popSegment();
 71697: 
101796:     Debug_SetValueRangeToCrashOnTouch(space().firstUnused(), oldend);
101796: 
 71697:     /*
 71697:      * NB: this code can call out and observe the stack (e.g., through GC), so
 71697:      * it should only be called from a consistent stack state.
 71697:      */
 71697:     if (!hasfp())
 71697:         cx_->resetCompartment();
 71697: }
 71697: 
 71697: bool
 71695: ContextStack::pushGeneratorFrame(JSContext *cx, JSGenerator *gen, GeneratorFrameGuard *gfg)
 71695: {
101075:     HeapValue *genvp = gen->stackSnapshot;
101075:     JS_ASSERT(genvp == HeapValueify(gen->fp->generatorArgsSnapshotBegin()));
101075:     unsigned vplen = HeapValueify(gen->fp->generatorArgsSnapshotEnd()) - genvp;
 71695: 
101075:     unsigned nvars = vplen + VALUES_PER_STACK_FRAME + gen->fp->script()->nslots;
 73495:     Value *firstUnused = ensureOnTop(cx, REPORT_ERROR, nvars, CAN_EXTEND, &gfg->pushedSeg_);
 71697:     if (!firstUnused)
 71695:         return false;
 71695: 
 71697:     StackFrame *stackfp = reinterpret_cast<StackFrame *>(firstUnused + vplen);
 71695:     Value *stackvp = (Value *)stackfp - vplen;
 71695: 
 71697:     /* Save this for popGeneratorFrame. */
 71695:     gfg->gen_ = gen;
 71695:     gfg->stackvp_ = stackvp;
 71695: 
 87962:     /*
 87962:      * Trigger incremental barrier on the floating frame's generator object.
 87962:      * This is normally traced through only by associated arguments/call
 87962:      * objects, but only when the generator is not actually on the stack.
 87962:      * We don't need to worry about generational barriers as the generator
 87962:      * object has a trace hook and cannot be nursery allocated.
 87962:      */
101075:     JS_ASSERT(gen->obj->getClass()->trace);
101075:     JSObject::writeBarrierPre(gen->obj);
 87962: 
 71695:     /* Copy from the generator's floating frame to the stack. */
102714:     stackfp->copyFrameAndValues<StackFrame::NoPostBarrier>(cx, stackvp, gen->fp,
102714:                                                            Valueify(genvp), gen->regs.sp);
 71695:     stackfp->resetGeneratorPrev(cx);
 71697:     gfg->regs_.rebaseFromTo(gen->regs, *stackfp);
 71695: 
 71697:     gfg->prevRegs_ = seg_->pushRegs(gfg->regs_);
 71697:     JS_ASSERT(space().firstUnused() == gfg->regs_.sp);
 71697:     gfg->setPushed(*this);
 69223:     return true;
 69223: }
 69223: 
 69223: void
 71697: ContextStack::popGeneratorFrame(const GeneratorFrameGuard &gfg)
 69223: {
 71697:     JSGenerator *gen = gfg.gen_;
101075:     HeapValue *genvp = gen->stackSnapshot;
101075:     JS_ASSERT(genvp == HeapValueify(gen->fp->generatorArgsSnapshotBegin()));
 71695: 
 71697:     const FrameRegs &stackRegs = gfg.regs_;
 71695:     StackFrame *stackfp = stackRegs.fp();
 71697:     Value *stackvp = gfg.stackvp_;
 71695: 
 71695:     /* Copy from the stack to the generator's floating frame. */
101075:     if (stackfp->isYielding()) {
102714:         /*
102714:          * Assert that the frame is not markable so that we don't need an
102714:          * incremental write barrier when updating the generator's saved slots.
102714:          */
102714:         JS_ASSERT(!GeneratorHasMarkableFrame(gen));
102714: 
101075:         gen->regs.rebaseFromTo(stackRegs, *gen->fp);
102714:         gen->fp->copyFrameAndValues<StackFrame::DoPostBarrier>(cx_, (Value *)genvp, stackfp,
102714:                                                                stackvp, stackRegs.sp);
101075:     }
 71695: 
 71697:     /* ~FrameGuard/popFrame will finish the popping. */
 71697:     JS_ASSERT(ImplicitCast<const FrameGuard>(gfg).pushed());
 69223: }
 69223: 
 69223: bool
 71697: ContextStack::saveFrameChain()
 69223: {
 76885:     JSCompartment *dest = NULL;
 73495: 
 71697:     bool pushedSeg;
 76885:     if (!ensureOnTop(cx_, REPORT_ERROR, 0, CANT_EXTEND, &pushedSeg, dest))
 69223:         return false;
 73495: 
 71697:     JS_ASSERT(pushedSeg);
 71697:     JS_ASSERT(!hasfp());
 73495:     JS_ASSERT(onTop() && seg_->isEmpty());
 73495: 
 71697:     cx_->resetCompartment();
 69223:     return true;
 69223: }
 69223: 
 69223: void
 71697: ContextStack::restoreFrameChain()
 69223: {
 71697:     JS_ASSERT(onTop() && seg_->isEmpty());
 69223: 
 71697:     popSegment();
 69223:     cx_->resetCompartment();
 69223: }
 69223: 
 69223: /*****************************************************************************/
 69223: 
 71697: void
 71697: StackIter::poisonRegs()
 69223: {
 71697:     sp_ = (Value *)0xbad;
 71697:     pc_ = (jsbytecode *)0xbad;
 92133:     script_ = (JSScript *)0xbad;
 69223: }
 71697: 
 71697: void
 71697: StackIter::popFrame()
 71697: {
 71697:     StackFrame *oldfp = fp_;
 71697:     JS_ASSERT(seg_->contains(oldfp));
 71697:     fp_ = fp_->prev();
 71697:     if (seg_->contains(fp_)) {
101075:         InlinedSite *inline_;
 76193:         pc_ = oldfp->prevpc(&inline_);
 76193:         JS_ASSERT(!inline_);
 71697: 
 71697:         /*
 71697:          * If there is a CallArgsList element between oldfp and fp_, then sp_
 71697:          * is ignored, so we only consider the case where there is no
 71697:          * intervening CallArgsList. The stack representation is not optimized
 71697:          * for this operation so we need to do a full case analysis of how
 71697:          * frames are pushed by considering each ContextStack::push*Frame.
 71697:          */
 71697:         if (oldfp->isGeneratorFrame()) {
 71697:             /* Generator's args do not overlap with the caller's expr stack. */
101075:             sp_ = oldfp->generatorArgsSnapshotBegin();
 71697:         } else if (oldfp->isNonEvalFunctionFrame()) {
 71697:             /*
 71697:              * When Invoke is called from a native, there will be an enclosing
 71697:              * pushInvokeArgs which pushes a CallArgsList element so we can
 71697:              * ignore that case. The other two cases of function call frames are
 71697:              * Invoke called directly from script and pushInlineFrmae. In both
 71697:              * cases, the actual arguments of the callee should be included in
 71697:              * the caller's expr stack.
 71697:              */
101075:             sp_ = oldfp->actuals() + oldfp->numActualArgs();
 71697:         } else if (oldfp->isFramePushedByExecute()) {
 71697:             /* pushExecuteFrame pushes exactly (callee, this) before frame. */
 71697:             sp_ = (Value *)oldfp - 2;
 71697:         } else {
 71697:             /* pushDummyFrame pushes exactly 0 slots before frame. */
 71697:             JS_ASSERT(oldfp->isDummyFrame());
 71697:             sp_ = (Value *)oldfp;
 71363:         }
 92133: 
 92133:         script_ = fp_->maybeScript();
 71697:     } else {
 71697:         poisonRegs();
 71697:     }
 71697: }
 71697: 
 71697: void
 71697: StackIter::popCall()
 71697: {
 71697:     CallArgsList *oldCall = calls_;
 71697:     JS_ASSERT(seg_->contains(oldCall));
 71697:     calls_ = calls_->prev();
 71697:     if (seg_->contains(fp_)) {
 71697:         /* pc_ keeps its same value. */
 71697:         sp_ = oldCall->base();
 71697:     } else {
 71697:         poisonRegs();
 71697:     }
 71697: }
 71697: 
 71697: void
 71697: StackIter::settleOnNewSegment()
 71697: {
 71697:     if (FrameRegs *regs = seg_->maybeRegs()) {
 71697:         sp_ = regs->sp;
 71697:         pc_ = regs->pc;
 92133:         if (fp_)
 92133:             script_ = fp_->maybeScript();
 71697:     } else {
 71697:         poisonRegs();
 71697:     }
 71697: }
 71697: 
 71697: void
 71697: StackIter::startOnSegment(StackSegment *seg)
 71697: {
 71697:     seg_ = seg;
 71697:     fp_ = seg_->maybefp();
 71697:     calls_ = seg_->maybeCalls();
 71697:     settleOnNewSegment();
 71697: }
 71697: 
 99837: /*
 99837:  * Given that the iterator's current value of fp_ and calls_ (initialized on
 99837:  * construction or after operator++ popped the previous scripted/native call),
 99837:  * "settle" the iterator on a new StackIter::State value. The goal is to
 99837:  * present the client a simple linear sequence of native/scripted calls while
 99837:  * covering up unpleasant stack implementation details:
 99837:  *  - The frame change can be "saved" and "restored" (see JS_SaveFrameChain).
 99837:  *    This artificially cuts the call chain and the StackIter client may want
 99837:  *    to continue through this cut to the previous frame by passing
 99837:  *    GO_THROUGH_SAVED.
 99837:  *  - fp->prev can be in a different contiguous segment from fp. In this case,
 99837:  *    the current values of sp/pc after calling popFrame/popCall are incorrect
 99837:  *    and should be recovered from fp->prev's segment.
 99837:  *  - there is no explicit relationship to determine whether fp_ or calls_ is
 99837:  *    the innermost invocation so implicit memory ordering is used since both
 99837:  *    push values on the stack.
 99837:  *  - a native call's 'callee' argument is clobbered on return while the
 99837:  *    CallArgsList element is still visible.
 99837:  */
 71697: void
 71697: StackIter::settleOnNewState()
 71697: {
 71697:     /*
 71697:      * There are elements of the calls_ and fp_ chains that we want to skip
 71697:      * over so iterate until we settle on one or until there are no more.
 71697:      */
 71697:     while (true) {
 71697:         if (!fp_ && !calls_) {
 71697:             if (savedOption_ == GO_THROUGH_SAVED && seg_->prevInContext()) {
 71697:                 startOnSegment(seg_->prevInContext());
 71697:                 continue;
 71697:             }
 71697:             state_ = DONE;
 71363:             return;
 69223:         }
 69223: 
 71697:         /* Check if popFrame/popCall changed segment. */
 71697:         bool containsFrame = seg_->contains(fp_);
 71697:         bool containsCall = seg_->contains(calls_);
 71697:         while (!containsFrame && !containsCall) {
 99837:             /* Eval-in-frame can cross contexts, so use prevInMemory. */
 99837:             seg_ = seg_->prevInMemory();
 71697:             containsFrame = seg_->contains(fp_);
 71697:             containsCall = seg_->contains(calls_);
 71363: 
 71697:             /* Eval-in-frame allows jumping into the middle of a segment. */
 71697:             if (containsFrame && seg_->fp() != fp_) {
 71697:                 /* Avoid duplicating logic; seg_ contains fp_, so no iloop. */
 71697:                 StackIter tmp = *this;
 71697:                 tmp.startOnSegment(seg_);
 71697:                 while (!tmp.isScript() || tmp.fp() != fp_)
 71697:                     ++tmp;
 71697:                 JS_ASSERT(tmp.state_ == SCRIPTED && tmp.seg_ == seg_ && tmp.fp_ == fp_);
 71697:                 *this = tmp;
 71697:                 return;
 71697:             }
 99837: 
 71697:             /* There is no eval-in-frame equivalent for native calls. */
 71697:             JS_ASSERT_IF(containsCall, &seg_->calls() == calls_);
 99837: 
 71697:             settleOnNewSegment();
 71363:         }
 71363: 
 71697:         /*
 71697:          * In case of both a scripted frame and call record, use linear memory
 71697:          * ordering to decide which was the most recent.
 71697:          */
 79387:         if (containsFrame && (!containsCall || (Value *)fp_ >= calls_->array())) {
 71697:             /* Nobody wants to see dummy frames. */
 71697:             if (fp_->isDummyFrame()) {
 71697:                 popFrame();
 71697:                 continue;
 71697:             }
 69223: 
 71697:             state_ = SCRIPTED;
 95385:             script_ = fp_->script();
 97913: 
 97913:             /*
 97913:              * Check sp and pc. JM's getter ICs may push 2 extra values on the
 97913:              * stack; this is okay since the methodjit reserves some extra slots
 97913:              * for loop temporaries.
 97913:              */
103273:             if (*pc_ == JSOP_GETPROP || *pc_ == JSOP_CALLPROP)
 97913:                 JS_ASSERT(sp_ >= fp_->base() && sp_ <= fp_->slots() + script_->nslots + 2);
103273:             else if (*pc_ != JSOP_FUNAPPLY)
 97913:                 JS_ASSERT(sp_ >= fp_->base() && sp_ <= fp_->slots() + script_->nslots);
 95385:             JS_ASSERT(pc_ >= script_->code && pc_ < script_->code + script_->length);
 71697:             return;
 71697:         }
 71697: 
 71697:         /*
 71697:          * A CallArgsList element is pushed for any call to Invoke, regardless
 71697:          * of whether the callee is a scripted function or even a callable
 71697:          * object. Thus, it is necessary to filter calleev for natives.
 71697:          *
 71697:          * Second, stuff can happen after the args are pushed but before/after
 71697:          * the actual call, so only consider "active" calls. (Since Invoke
 71697:          * necessarily clobbers the callee, "active" is also necessary to
 71697:          * ensure that the callee slot is valid.)
 71697:          */
 71697:         if (calls_->active() && IsNativeFunction(calls_->calleev())) {
 71697:             state_ = NATIVE;
 71697:             args_ = *calls_;
 71697:             return;
 71697:         }
 71697: 
 71697:         /* Pop the call and keep looking. */
 71697:         popCall();
 71697:     }
 71697: }
 71697: 
 71697: StackIter::StackIter(JSContext *cx, SavedOption savedOption)
 98784:   : maybecx_(cx),
 71697:     savedOption_(savedOption)
 71697: {
 76193: #ifdef JS_METHODJIT
 95016:     CompartmentVector &v = cx->runtime->compartments;
 95016:     for (size_t i = 0; i < v.length(); i++)
 95016:         mjit::ExpandInlineFrames(v[i]);
 76193: #endif
 76193: 
 71697:     if (StackSegment *seg = cx->stack.seg_) {
 71697:         startOnSegment(seg);
 71697:         settleOnNewState();
 69223:     } else {
 71697:         state_ = DONE;
 69223:     }
 69223: }
 71697: 
 98784: StackIter::StackIter(JSRuntime *rt, StackSegment &seg)
 98784:   : maybecx_(NULL), savedOption_(STOP_AT_SAVED)
 98784: {
 98784: #ifdef JS_METHODJIT
 98784:     CompartmentVector &v = rt->compartments;
 98784:     for (size_t i = 0; i < v.length(); i++)
 98784:         mjit::ExpandInlineFrames(v[i]);
 98784: #endif
 98784:     startOnSegment(&seg);
 98784:     settleOnNewState();
 98784: }
 98784: 
 71697: StackIter &
 71697: StackIter::operator++()
 71697: {
 71697:     switch (state_) {
 71697:       case DONE:
 95385:         JS_NOT_REACHED("Unexpected state");
 71697:       case SCRIPTED:
 71697:         popFrame();
 71697:         settleOnNewState();
 71697:         break;
 71697:       case NATIVE:
 71697:         popCall();
 71697:         settleOnNewState();
 71697:         break;
 71697:     }
 71363:     return *this;
 71363: }
 71363: 
 71363: bool
 71697: StackIter::operator==(const StackIter &rhs) const
 71363: {
 71697:     return done() == rhs.done() &&
 71697:            (done() ||
 71697:             (isScript() == rhs.isScript() &&
 71697:              ((isScript() && fp() == rhs.fp()) ||
 71697:               (!isScript() && nativeArgs().base() == rhs.nativeArgs().base()))));
 69223: }
 69223: 
 95385: bool
 95385: StackIter::isFunctionFrame() const
 95385: {
 95385:     switch (state_) {
 95385:       case DONE:
 95392:         break;
 95385:       case SCRIPTED:
 95385:         return fp()->isFunctionFrame();
 95385:       case NATIVE:
 95394:         return false;
 95385:     }
 95392:     JS_NOT_REACHED("Unexpected state");
 95392:     return false;
 95385: }
 95385: 
 95385: bool
 95385: StackIter::isEvalFrame() const
 95385: {
 95385:     switch (state_) {
 95385:       case DONE:
 95392:         break;
 95385:       case SCRIPTED:
 95385:         return fp()->isEvalFrame();
 95385:       case NATIVE:
 95385:         return false;
 95385:     }
 95392:     JS_NOT_REACHED("Unexpected state");
 95392:     return false;
 95385: }
 95385: 
 95385: bool
 95385: StackIter::isNonEvalFunctionFrame() const
 95385: {
 95385:     JS_ASSERT(!done());
 95385:     switch (state_) {
 95385:       case DONE:
 95392:         break;
 95385:       case SCRIPTED:
 95385:         return fp()->isNonEvalFunctionFrame();
 95385:       case NATIVE:
 95385:         return !isEvalFrame() && isFunctionFrame();
 95385:     }
 95392:     JS_NOT_REACHED("Unexpected state");
 95392:     return false;
 95385: }
 95385: 
 97160: bool
 97160: StackIter::isConstructing() const
 97160: {
 97160:     switch (state_) {
 97160:       case DONE:
 97160:         JS_NOT_REACHED("Unexpected state");
 97160:         return false;
 97160:       case SCRIPTED:
 97160:       case NATIVE:
 97160:         return fp()->isConstructing();
 97160:     }
 97160:     return false;
 97160: }
 97160: 
 97160: JSFunction *
 95385: StackIter::callee() const
 95385: {
 95385:     switch (state_) {
 95385:       case DONE:
 95392:         break;
 95385:       case SCRIPTED:
 95394:         JS_ASSERT(isFunctionFrame());
 98921:         return &fp()->callee();
 95385:       case NATIVE:
 97160:         return nativeArgs().callee().toFunction();
 95385:     }
 95392:     JS_NOT_REACHED("Unexpected state");
 97160:     return NULL;
 95385: }
 95385: 
 95385: Value
 95385: StackIter::calleev() const
 95385: {
 95385:     switch (state_) {
 95385:       case DONE:
 95392:         break;
 95385:       case SCRIPTED:
 95394:         JS_ASSERT(isFunctionFrame());
 95385:         return fp()->calleev();
 95385:       case NATIVE:
 95385:         return nativeArgs().calleev();
 95385:     }
 95392:     JS_NOT_REACHED("Unexpected state");
 95392:     return Value();
 95385: }
 95385: 
 97160: Value
 97160: StackIter::thisv() const
 97160: {
 97160:     switch (state_) {
 97160:       case DONE:
 97182:         MOZ_NOT_REACHED("Unexpected state");
 97160:         return Value();
 97160:       case SCRIPTED:
 97160:       case NATIVE:
 97160:         return fp()->thisValue();
 97160:     }
 97182:     MOZ_NOT_REACHED("unexpected state");
 97182:     return Value();
 97160: }
 97160: 
 69223: /*****************************************************************************/
 69223: 
 71697: AllFramesIter::AllFramesIter(StackSpace &space)
 71697:   : seg_(space.seg_),
 71697:     fp_(seg_ ? seg_->maybefp() : NULL)
 87854: {
 87854:     settle();
 87854: }
 69223: 
 69223: AllFramesIter&
 69223: AllFramesIter::operator++()
 69223: {
 69223:     JS_ASSERT(!done());
 69223:     fp_ = fp_->prev();
 87854:     settle();
 69223:     return *this;
 69223: }
 87854: 
 87854: void
 87854: AllFramesIter::settle()
 87854: {
 87854:     while (seg_ && (!fp_ || !seg_->contains(fp_))) {
 87854:         seg_ = seg_->prevInMemory();
 87854:         fp_ = seg_ ? seg_->maybefp() : NULL;
 87854:     }
 87854: 
 87854:     JS_ASSERT(!!seg_ == !!fp_);
 87854:     JS_ASSERT_IF(fp_, seg_->contains(fp_));
 87854: }
