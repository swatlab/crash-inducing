 52558: /* -*- Mode: C++; tab-width: 4; indent-tabs-mode: nil; c-basic-offset: 4 -*-
 52558:  * vim: set ts=4 sw=4 et tw=99:
 52558:  *
 98983:  * This Source Code Form is subject to the terms of the Mozilla Public
 98983:  * License, v. 2.0. If a copy of the MPL was not distributed with this
 98983:  * file, You can obtain one at http://mozilla.org/MPL/2.0/. */
 53270: 
 52558: #include "MethodJIT.h"
 52651: #include "jsnum.h"
 52686: #include "jsbool.h"
 52737: #include "jsiter.h"
 52558: #include "Compiler.h"
 52611: #include "StubCalls.h"
 52826: #include "MonoIC.h"
 53270: #include "PolyIC.h"
 60597: #include "ICChecker.h"
 53168: #include "Retcon.h"
 52611: #include "assembler/jit/ExecutableAllocator.h"
 52826: #include "assembler/assembler/LinkBuffer.h"
 52618: #include "FrameState-inl.h"
 55746: #include "jsobjinlines.h"
 52668: #include "jsscriptinlines.h"
 68952: #include "InlineFrameAssembler.h"
 54707: #include "jscompartment.h"
 54855: #include "jsopcodeinlines.h"
 52560: 
 80271: #include "builtin/RegExp.h"
 80271: #include "vm/RegExpStatics.h"
 80271: #include "vm/RegExpObject.h"
 80271: 
 52560: #include "jsautooplen.h"
 77415: #include "jstypedarrayinlines.h"
 80271: #include "vm/RegExpObject-inl.h"
 80271: 
 52558: using namespace js;
 52558: using namespace js::mjit;
 56462: #if defined(JS_POLYIC) || defined(JS_MONOIC)
 53270: using namespace js::mjit::ic;
 53270: #endif
 76194: using namespace js::analyze;
 52558: 
 56037: #define RETURN_IF_OOM(retval)                                   \
 56037:     JS_BEGIN_MACRO                                              \
 61233:         if (oomInVector || masm.oom() || stubcc.masm.oom())     \
 56037:             return retval;                                      \
 56037:     JS_END_MACRO
 53168: 
 76194: /*
 76194:  * Number of times a script must be called or had a backedge before we try to
 76194:  * inline its calls.
 76194:  */
 76194: static const size_t USES_BEFORE_INLINING = 10000;
 76194: 
 87654: mjit::Compiler::Compiler(JSContext *cx, JSScript *outerScript,
 87654:                          unsigned chunkIndex, bool isConstructing)
 55463:   : BaseCompiler(cx),
 76194:     outerScript(outerScript),
 87654:     chunkIndex(chunkIndex),
 76194:     isConstructing(isConstructing),
 87654:     outerChunk(outerJIT()->chunkDescriptor(chunkIndex)),
 76194:     ssa(cx, outerScript),
 98960:     globalObj(cx, outerScript->hasGlobal() ? outerScript->global() : NULL),
 76194:     globalSlots(globalObj ? globalObj->getRawSlots() : NULL),
 76194:     frame(cx, *thisFromCtor(), masm, stubcc),
 76194:     a(NULL), outer(NULL), script(NULL), PC(NULL), loop(NULL),
 76194:     inlineFrames(CompilerAllocPolicy(cx, *thisFromCtor())),
 57679:     branchPatches(CompilerAllocPolicy(cx, *thisFromCtor())),
 53119: #if defined JS_MONOIC
 62386:     getGlobalNames(CompilerAllocPolicy(cx, *thisFromCtor())),
 62386:     setGlobalNames(CompilerAllocPolicy(cx, *thisFromCtor())),
 68952:     callICs(CompilerAllocPolicy(cx, *thisFromCtor())),
 57679:     equalityICs(CompilerAllocPolicy(cx, *thisFromCtor())),
 53119: #endif
 53119: #if defined JS_POLYIC
 57679:     pics(CompilerAllocPolicy(cx, *thisFromCtor())),
 57679:     getElemICs(CompilerAllocPolicy(cx, *thisFromCtor())),
 57679:     setElemICs(CompilerAllocPolicy(cx, *thisFromCtor())),
 53119: #endif
 68952:     callPatches(CompilerAllocPolicy(cx, *thisFromCtor())),
 57679:     callSites(CompilerAllocPolicy(cx, *thisFromCtor())),
 57679:     doubleList(CompilerAllocPolicy(cx, *thisFromCtor())),
 98147:     rootedTemplates(CompilerAllocPolicy(cx, *thisFromCtor())),
 98147:     rootedRegExps(CompilerAllocPolicy(cx, *thisFromCtor())),
 77457:     fixedIntToDoubleEntries(CompilerAllocPolicy(cx, *thisFromCtor())),
 77457:     fixedDoubleToAnyEntries(CompilerAllocPolicy(cx, *thisFromCtor())),
 59979:     jumpTables(CompilerAllocPolicy(cx, *thisFromCtor())),
 87654:     jumpTableEdges(CompilerAllocPolicy(cx, *thisFromCtor())),
 76194:     loopEntries(CompilerAllocPolicy(cx, *thisFromCtor())),
 87654:     chunkEdges(CompilerAllocPolicy(cx, *thisFromCtor())),
 76194:     stubcc(cx, *thisFromCtor(), frame),
 75489:     debugMode_(cx->compartment->debugMode()),
 76194:     inlining_(false),
 76194:     hasGlobalReallocation(false),
 57718:     oomInVector(false),
 78457:     overflowICSpace(false),
 77892:     gcNumber(cx->runtime->gcNumber),
 77407:     pcLengths(NULL)
 74457: {
 76194:     /* Once a script starts getting really hot we will inline calls in it. */
 76194:     if (!debugMode() && cx->typeInferenceEnabled() && globalObj &&
 77659:         (outerScript->getUseCount() >= USES_BEFORE_INLINING ||
 76194:          cx->hasRunOption(JSOPTION_METHODJIT_ALWAYS))) {
 76194:         inlining_ = true;
 76194:     }
 52558: }
 52558: 
 55503: CompileStatus
 55503: mjit::Compiler::compile()
 55503: {
 91569:     JS_ASSERT(!outerChunkRef().chunk);
 87654: 
 87654:     CompileStatus status = performCompilation();
 87654:     if (status != Compile_Okay && status != Compile_Retry) {
 99476:         if (!outerScript->ensureHasJITInfo(cx))
 99476:             return Compile_Error;
 98147:         JSScript::JITScriptHandle *jith = outerScript->jitHandle(isConstructing, cx->compartment->needsBarrier());
 94809:         JSScript::ReleaseCode(cx->runtime->defaultFreeOp(), jith);
 94809:         jith->setUnjittable();
 94809: 
 83256:         if (outerScript->function()) {
 77361:             outerScript->uninlineable = true;
 77391:             types::MarkTypeObjectFlags(cx, outerScript->function(),
 76194:                                        types::OBJECT_FLAG_UNINLINEABLE);
 76194:         }
 76194:     }
 76194: 
 76194:     return status;
 76194: }
 76194: 
 76194: CompileStatus
 76194: mjit::Compiler::checkAnalysis(JSScript *script)
 76194: {
 77630:     if (script->hasClearedGlobal()) {
 77630:         JaegerSpew(JSpew_Abort, "script has a cleared global\n");
 77630:         return Compile_Abort;
 77630:     }
 77630: 
 83256:     if (!script->ensureRanAnalysis(cx, NULL))
 77391:         return Compile_Error;
 90737: 
 97504:     if (!script->analysis()->jaegerCompileable()) {
 90737:         JaegerSpew(JSpew_Abort, "script has uncompileable opcodes\n");
 90737:         return Compile_Abort;
 90737:     }
 90737: 
 76194:     if (cx->typeInferenceEnabled() && !script->ensureRanInference(cx))
 76194:         return Compile_Error;
 77391: 
 77391:     ScriptAnalysis *analysis = script->analysis();
 84733:     analysis->assertMatchingDebugMode();
 76194:     if (analysis->failed()) {
 76194:         JaegerSpew(JSpew_Abort, "couldn't analyze bytecode; probably switchX or OOM\n");
 76194:         return Compile_Abort;
 76194:     }
 76194: 
 76194:     return Compile_Okay;
 76194: }
 76194: 
 76194: CompileStatus
 84755: mjit::Compiler::addInlineFrame(JSScript *script, uint32_t depth,
 84755:                                uint32_t parent, jsbytecode *parentpc)
 76194: {
 76194:     JS_ASSERT(inlining());
 76194: 
 76194:     CompileStatus status = checkAnalysis(script);
 76194:     if (status != Compile_Okay)
 76194:         return status;
 76194: 
 76194:     if (!ssa.addInlineFrame(script, depth, parent, parentpc))
 76194:         return Compile_Error;
 76194: 
 84755:     uint32_t index = ssa.iterFrame(ssa.numFrames() - 1).index;
 76194:     return scanInlineCalls(index, depth);
 76194: }
 76194: 
 76194: CompileStatus
 84755: mjit::Compiler::scanInlineCalls(uint32_t index, uint32_t depth)
 76194: {
 76194:     /* Maximum number of calls we will inline at the same site. */
 84755:     static const uint32_t INLINE_SITE_LIMIT = 5;
 76194: 
 76194:     JS_ASSERT(inlining() && globalObj);
 76194: 
 76194:     /* Not inlining yet from 'new' scripts. */
 76194:     if (isConstructing)
 76194:         return Compile_Okay;
 76194: 
 76194:     JSScript *script = ssa.getFrame(index).script;
 77391:     ScriptAnalysis *analysis = script->analysis();
 76194: 
 76194:     /* Don't inline from functions which could have a non-global scope object. */
 76194:     if (!script->hasGlobal() ||
 76194:         script->global() != globalObj ||
 83256:         (script->function() && script->function()->getParent() != globalObj) ||
 83256:         (script->function() && script->function()->isHeavyweight()) ||
 76194:         script->isActiveEval) {
 76194:         return Compile_Okay;
 76194:     }
 76194: 
 84755:     uint32_t nextOffset = 0;
 87654:     uint32_t lastOffset = script->length;
 87654: 
 87654:     if (index == CrossScriptSSA::OUTER_FRAME) {
 87654:         nextOffset = outerChunk.begin;
 87654:         lastOffset = outerChunk.end;
 87654:     }
 87654: 
 87654:     while (nextOffset < lastOffset) {
 84755:         uint32_t offset = nextOffset;
 76194:         jsbytecode *pc = script->code + offset;
 84195:         nextOffset = offset + GetBytecodeLength(pc);
 76194: 
 76194:         Bytecode *code = analysis->maybeCode(pc);
 76194:         if (!code)
 76194:             continue;
 76194: 
 76194:         /* :XXX: Not yet inlining 'new' calls. */
 76194:         if (JSOp(*pc) != JSOP_CALL)
 76194:             continue;
 76194: 
 76194:         /* Not inlining at monitored call sites or those with type barriers. */
 78194:         if (code->monitoredTypes || code->monitoredTypesReturn || analysis->typeBarriers(cx, pc) != NULL)
 76194:             continue;
 76194: 
 84755:         uint32_t argc = GET_ARGC(pc);
 76194:         types::TypeSet *calleeTypes = analysis->poppedTypes(pc, argc + 1);
 76194: 
 76194:         if (calleeTypes->getKnownTypeTag(cx) != JSVAL_TYPE_OBJECT)
 76194:             continue;
 76194: 
 76194:         if (calleeTypes->getObjectCount() >= INLINE_SITE_LIMIT)
 76194:             continue;
 76194: 
 76194:         /*
 76194:          * Compute the maximum height we can grow the stack for inlined frames.
 76194:          * We always reserve space for loop temporaries, for an extra stack
 76194:          * frame pushed when making a call from the deepest inlined frame, and
 76194:          * for the temporary slot used by type barriers.
 76194:          */
 84755:         uint32_t stackLimit = outerScript->nslots + StackSpace::STACK_JIT_EXTRA
 76194:             - VALUES_PER_STACK_FRAME - FrameState::TEMPORARY_LIMIT - 1;
 76194: 
 76194:         /* Compute the depth of any frames inlined at this site. */
 84755:         uint32_t nextDepth = depth + VALUES_PER_STACK_FRAME + script->nfixed + code->stackDepth;
 76194: 
 76194:         /*
 76194:          * Scan each of the possible callees for other conditions precluding
 76194:          * inlining. We only inline at a call site if all callees are inlineable.
 76194:          */
 76194:         unsigned count = calleeTypes->getObjectCount();
 76194:         bool okay = true;
 76194:         for (unsigned i = 0; i < count; i++) {
 77353:             if (calleeTypes->getTypeObject(i) != NULL) {
 76194:                 okay = false;
 76194:                 break;
 76194:             }
 76194: 
 77353:             JSObject *obj = calleeTypes->getSingleObject(i);
 77353:             if (!obj)
 77353:                 continue;
 77353: 
 77353:             if (!obj->isFunction()) {
 77353:                 okay = false;
 77353:                 break;
 77353:             }
 77353: 
 83234:             JSFunction *fun = obj->toFunction();
 76194:             if (!fun->isInterpreted()) {
 76194:                 okay = false;
 76194:                 break;
 76194:             }
 76194:             JSScript *script = fun->script();
 76194: 
 76194:             /*
 78729:              * Don't inline calls to scripts which haven't been analyzed.
 78729:              * We need to analyze the inlined scripts to compile them, and
 78729:              * doing so can change type information we have queried already
 78729:              * in making inlining decisions.
 78729:              */
 78729:             if (!script->hasAnalysis() || !script->analysis()->ranInference()) {
 78729:                 okay = false;
 78729:                 break;
 78729:             }
 78729: 
 78729:             /*
 76194:              * The outer and inner scripts must have the same scope. This only
 76194:              * allows us to inline calls between non-inner functions. Also
 76194:              * check for consistent strictness between the functions.
 76194:              */
 76194:             if (!globalObj ||
 76194:                 fun->getParent() != globalObj ||
 76194:                 outerScript->strictModeCode != script->strictModeCode) {
 76194:                 okay = false;
 76194:                 break;
 76194:             }
 76194: 
 76194:             /* We can't cope with inlining recursive functions yet. */
 84755:             uint32_t nindex = index;
 76194:             while (nindex != CrossScriptSSA::INVALID_FRAME) {
 76194:                 if (ssa.getFrame(nindex).script == script)
 76194:                     okay = false;
 76194:                 nindex = ssa.getFrame(nindex).parent;
 76194:             }
 76194:             if (!okay)
 76194:                 break;
 76194: 
 76194:             /* Watch for excessively deep nesting of inlined frames. */
 76194:             if (nextDepth + script->nslots >= stackLimit) {
 76194:                 okay = false;
 76194:                 break;
 76194:             }
 76194: 
 77884:             if (!script->types || !script->types->hasScope()) {
 77884:                 okay = false;
 77884:                 break;
 77884:             }
 77884: 
 76194:             CompileStatus status = checkAnalysis(script);
 76194:             if (status != Compile_Okay)
 76194:                 return status;
 76194: 
 77391:             if (!script->analysis()->inlineable(argc)) {
 76194:                 okay = false;
 76194:                 break;
 76194:             }
 76194: 
 77353:             if (types::TypeSet::HasObjectFlags(cx, fun->getType(cx),
 76194:                                                types::OBJECT_FLAG_UNINLINEABLE)) {
 76194:                 okay = false;
 76194:                 break;
 76194:             }
 76194: 
 76194:             /*
 76194:              * Don't inline scripts which use 'this' if it is possible they
 76194:              * could be called with a 'this' value requiring wrapping. During
 76194:              * inlining we do not want to modify frame entries belonging to the
 76194:              * caller.
 76194:              */
 77391:             if (script->analysis()->usesThisValue() &&
 77391:                 types::TypeScript::ThisTypes(script)->getKnownTypeTag(cx) != JSVAL_TYPE_OBJECT) {
 76194:                 okay = false;
 76194:                 break;
 76194:             }
 76194:         }
 76194:         if (!okay)
 76194:             continue;
 76194: 
 76194:         calleeTypes->addFreeze(cx);
 76194: 
 76194:         /*
 76194:          * Add the inline frames to the cross script SSA. We will pick these
 76194:          * back up when compiling the call site.
 76194:          */
 76194:         for (unsigned i = 0; i < count; i++) {
 77353:             JSObject *obj = calleeTypes->getSingleObject(i);
 77353:             if (!obj)
 76194:                 continue;
 76194: 
 83234:             JSFunction *fun = obj->toFunction();
 76194:             JSScript *script = fun->script();
 76194: 
 76194:             CompileStatus status = addInlineFrame(script, nextDepth, index, pc);
 76194:             if (status != Compile_Okay)
 76194:                 return status;
 76194:         }
 76194:     }
 76194: 
 76194:     return Compile_Okay;
 76194: }
 76194: 
 76194: CompileStatus
 84755: mjit::Compiler::pushActiveFrame(JSScript *script, uint32_t argc)
 76194: {
 95113:     if (cx->runtime->profilingScripts && !script->hasScriptCounts)
 94574:         script->initScriptCounts(cx);
 84803: 
 89972:     ActiveFrame *newa = OffTheBooks::new_<ActiveFrame>(cx);
 92002:     if (!newa) {
 92002:         js_ReportOutOfMemory(cx);
 76194:         return Compile_Error;
 92002:     }
 76194: 
 76194:     newa->parent = a;
 76194:     if (a)
 76194:         newa->parentPC = PC;
 76194:     newa->script = script;
 80222:     newa->mainCodeStart = masm.size();
 80222:     newa->stubCodeStart = stubcc.size();
 76194: 
 76194:     if (outer) {
 84755:         newa->inlineIndex = uint32_t(inlineFrames.length());
 76194:         inlineFrames.append(newa);
 55503:     } else {
 76194:         newa->inlineIndex = CrossScriptSSA::OUTER_FRAME;
 76194:         outer = newa;
 76194:     }
 76194:     JS_ASSERT(ssa.getFrame(newa->inlineIndex).script == script);
 76194: 
 80222:     newa->inlinePCOffset = ssa.frameLength(newa->inlineIndex);
 80222: 
 77391:     ScriptAnalysis *newAnalysis = script->analysis();
 76194: 
 76194: #ifdef JS_METHODJIT_SPEW
 76194:     if (cx->typeInferenceEnabled() && IsJaegerSpewChannelActive(JSpew_Regalloc)) {
 83256:         unsigned nargs = script->function() ? script->function()->nargs : 0;
 76194:         for (unsigned i = 0; i < nargs; i++) {
 84755:             uint32_t slot = ArgSlot(i);
 76194:             if (!newAnalysis->slotEscapes(slot)) {
 76194:                 JaegerSpew(JSpew_Regalloc, "Argument %u:", i);
 76194:                 newAnalysis->liveness(slot).print();
 76194:             }
 76194:         }
 76194:         for (unsigned i = 0; i < script->nfixed; i++) {
 84755:             uint32_t slot = LocalSlot(script, i);
 76194:             if (!newAnalysis->slotEscapes(slot)) {
 76194:                 JaegerSpew(JSpew_Regalloc, "Local %u:", i);
 76194:                 newAnalysis->liveness(slot).print();
 76194:             }
 76194:         }
 76194:     }
 76194: #endif
 76194: 
 76194:     if (!frame.pushActiveFrame(script, argc)) {
 76194:         js_ReportOutOfMemory(cx);
 76194:         return Compile_Error;
 76194:     }
 76194: 
 89972:     newa->jumpMap = (Label *)OffTheBooks::malloc_(sizeof(Label) * script->length);
 76194:     if (!newa->jumpMap) {
 76194:         js_ReportOutOfMemory(cx);
 76194:         return Compile_Error;
 76194:     }
 76194: #ifdef DEBUG
 84755:     for (uint32_t i = 0; i < script->length; i++)
 76194:         newa->jumpMap[i] = Label();
 76194: #endif
 76194: 
 76194:     if (cx->typeInferenceEnabled()) {
 76194:         CompileStatus status = prepareInferenceTypes(script, newa);
 76194:         if (status != Compile_Okay)
 55503:             return status;
 55503:     }
 55503: 
 76194:     this->script = script;
 76194:     this->analysis = newAnalysis;
 76194:     this->PC = script->code;
 76194:     this->a = newa;
 76194: 
 76194:     return Compile_Okay;
 76194: }
 76194: 
 76194: void
 76194: mjit::Compiler::popActiveFrame()
 76194: {
 76194:     JS_ASSERT(a->parent);
 86348:     a->mainCodeEnd = masm.size();
 86348:     a->stubCodeEnd = stubcc.size();
 76194:     this->PC = a->parentPC;
 86348:     this->a = (ActiveFrame *) a->parent;
 76194:     this->script = a->script;
 77391:     this->analysis = this->script->analysis();
 76194: 
 76194:     frame.popActiveFrame();
 76194: }
 76194: 
 52558: #define CHECK_STATUS(expr)                                           \
 52558:     JS_BEGIN_MACRO                                                   \
 52558:         CompileStatus status_ = (expr);                              \
 61233:         if (status_ != Compile_Okay) {                               \
 61233:             if (oomInVector || masm.oom() || stubcc.masm.oom())      \
 61233:                 js_ReportOutOfMemory(cx);                            \
 52558:             return status_;                                          \
 61233:         }                                                            \
 52558:     JS_END_MACRO
 52558: 
 52558: CompileStatus
 87654: mjit::Compiler::performCompilation()
 87654: {
 87654:     JaegerSpew(JSpew_Scripts,
 87654:                "compiling script (file \"%s\") (line \"%d\") (length \"%d\") (chunk \"%d\")\n",
 87654:                outerScript->filename, outerScript->lineno, outerScript->length, chunkIndex);
 76194: 
 76194:     if (inlining()) {
 87654:         JaegerSpew(JSpew_Inlining,
 87654:                    "inlining calls in script (file \"%s\") (line \"%d\")\n",
 76194:                    outerScript->filename, outerScript->lineno);
 76194:     }
 52558: 
 52654: #ifdef JS_METHODJIT_SPEW
 52558:     Profiler prof;
 52558:     prof.start();
 52654: #endif
 52558: 
 53590: #ifdef JS_METHODJIT
 76194:     outerScript->debugMode = debugMode();
 53590: #endif
 53590: 
 76194:     JS_ASSERT(cx->compartment->activeInference);
 76194: 
 76194:     {
 87654:         types::AutoEnterCompilation enter(cx, outerScript, isConstructing, chunkIndex);
 76194: 
 76194:         CHECK_STATUS(checkAnalysis(outerScript));
 76194:         if (inlining())
 76194:             CHECK_STATUS(scanInlineCalls(CrossScriptSSA::OUTER_FRAME, 0));
 76194:         CHECK_STATUS(pushActiveFrame(outerScript, 0));
 91193: 
 95113:         if (outerScript->hasScriptCounts || Probes::wantNativeAddressInfo(cx)) {
 91193:             size_t length = ssa.frameLength(ssa.numFrames() - 1);
 91193:             pcLengths = (PCLengthEntry *) OffTheBooks::calloc_(sizeof(pcLengths[0]) * length);
 91193:             if (!pcLengths)
 91193:                 return Compile_Error;
 91193:         }
 91193: 
 87654:         if (chunkIndex == 0)
 52558:             CHECK_STATUS(generatePrologue());
 52558:         CHECK_STATUS(generateMethod());
 87654:         if (outerJIT() && chunkIndex == outerJIT()->nchunks - 1)
 52558:             CHECK_STATUS(generateEpilogue());
 87654:         CHECK_STATUS(finishThisUp());
 76194:     }
 52558: 
 52558: #ifdef JS_METHODJIT_SPEW
 52558:     prof.stop();
 52558:     JaegerSpew(JSpew_Prof, "compilation took %d us\n", prof.time_us());
 52558: #endif
 52558: 
 77503:     JaegerSpew(JSpew_Scripts, "successfully compiled (code \"%p\") (size \"%u\")\n",
 91569:                outerChunkRef().chunk->code.m_code.executableAddress(),
 91569:                unsigned(outerChunkRef().chunk->code.m_size));
 87654: 
 52560:     return Compile_Okay;
 52558: }
 52558: 
 52558: #undef CHECK_STATUS
 52558: 
 86348: mjit::JSActiveFrame::JSActiveFrame()
 86348:     : parent(NULL), parentPC(NULL), script(NULL), inlineIndex(UINT32_MAX)
 86348: {
 86348: }
 86348: 
 76194: mjit::Compiler::ActiveFrame::ActiveFrame(JSContext *cx)
 86348:     : jumpMap(NULL),
 86348:       varTypes(NULL), needReturnValue(false),
 76194:       syncReturnValue(false), returnValueDouble(false), returnSet(false),
 76194:       returnEntry(NULL), returnJumps(NULL), exitState(NULL)
 76194: {}
 76194: 
 76194: mjit::Compiler::ActiveFrame::~ActiveFrame()
 76194: {
 76194:     js::Foreground::free_(jumpMap);
 76194:     if (varTypes)
 76194:         js::Foreground::free_(varTypes);
 76194: }
 76194: 
 52558: mjit::Compiler::~Compiler()
 52558: {
 76194:     if (outer)
 76194:         cx->delete_(outer);
 76194:     for (unsigned i = 0; i < inlineFrames.length(); i++)
 76194:         cx->delete_(inlineFrames[i]);
 76194:     while (loop) {
 76194:         LoopState *nloop = loop->outer;
 76194:         cx->delete_(loop);
 76194:         loop = nloop;
 76194:     }
 76194: }
 76194: 
 76194: CompileStatus
 76194: mjit::Compiler::prepareInferenceTypes(JSScript *script, ActiveFrame *a)
 76194: {
 76194:     /*
 76194:      * During our walk of the script, we need to preserve the invariant that at
 76194:      * join points the in memory type tag is always in sync with the known type
 76194:      * tag of the variable's SSA value at that join point. In particular, SSA
 76194:      * values inferred as (int|double) must in fact be doubles, stored either
 76194:      * in floating point registers or in memory. There is an exception for
 76194:      * locals whose value is currently dead, whose type might not be synced.
 76194:      *
 76194:      * To ensure this, we need to know the SSA values for each variable at each
 76194:      * join point, which the SSA analysis does not store explicitly. These can
 76194:      * be recovered, though. During the forward walk, the SSA value of a var
 76194:      * (and its associated type set) change only when we see an explicit assign
 76194:      * to the var or get to a join point with a phi node for that var. So we
 76194:      * can duplicate the effects of that walk here by watching for writes to
 76194:      * vars (updateVarTypes) and new phi nodes at join points.
 76194:      *
 76194:      * When we get to a branch and need to know a variable's value at the
 76194:      * branch target, we know it will either be a phi node at the target or
 76194:      * the variable's current value, as no phi node is created at the target
 76194:      * only if a variable has the same value on all incoming edges.
 76194:      */
 76194: 
 76194:     a->varTypes = (VarType *)
 89972:         OffTheBooks::calloc_(TotalSlots(script) * sizeof(VarType));
 92002:     if (!a->varTypes) {
 92002:         js_ReportOutOfMemory(cx);
 76194:         return Compile_Error;
 92002:     }
 76194: 
 84755:     for (uint32_t slot = ArgSlot(0); slot < TotalSlots(script); slot++) {
 76194:         VarType &vt = a->varTypes[slot];
 87654:         vt.setTypes(types::TypeScript::SlotTypes(script, slot));
 76194:     }
 76194: 
 76194:     return Compile_Okay;
 52558: }
 52558: 
 87654: /*
 87654:  * Number of times a script must be called or have back edges taken before we
 87654:  * run it in the methodjit. We wait longer if type inference is enabled, to
 87654:  * allow more gathering of type information and less recompilation.
 87654:  */
 87654: static const size_t USES_BEFORE_COMPILE       = 16;
 87654: static const size_t INFER_USES_BEFORE_COMPILE = 40;
 87654: 
 87654: /* Target maximum size, in bytecode length, for a compiled chunk of a script. */
 87654: static uint32_t CHUNK_LIMIT = 1500;
 87654: 
 87654: void
 87654: mjit::SetChunkLimit(uint32_t limit)
 87654: {
 87654:     if (limit)
 87654:         CHUNK_LIMIT = limit;
 87654: }
 87654: 
 87654: JITScript *
 94809: MakeJITScript(JSContext *cx, JSScript *script)
 87654: {
 87654:     if (!script->ensureRanAnalysis(cx, NULL))
 87654:         return NULL;
 87654: 
 87654:     ScriptAnalysis *analysis = script->analysis();
 87654: 
 87654:     Vector<ChunkDescriptor> chunks(cx);
 87654:     Vector<CrossChunkEdge> edges(cx);
 87654: 
 87654:     if (script->length < CHUNK_LIMIT || !cx->typeInferenceEnabled()) {
 87654:         ChunkDescriptor desc;
 87654:         desc.begin = 0;
 87654:         desc.end = script->length;
 87654:         if (!chunks.append(desc))
 87654:             return NULL;
 87654:     } else {
 87654:         if (!script->ensureRanInference(cx))
 87654:             return NULL;
 87654: 
 87654:         /* Outgoing edges within the current chunk. */
 87654:         Vector<CrossChunkEdge> currentEdges(cx);
 87654:         uint32_t chunkStart = 0;
 87654: 
 87654:         unsigned offset, nextOffset = 0;
 87654:         while (nextOffset < script->length) {
 87654:             offset = nextOffset;
 87654: 
 87654:             jsbytecode *pc = script->code + offset;
 87654:             JSOp op = JSOp(*pc);
 87654: 
 87654:             nextOffset = offset + GetBytecodeLength(pc);
 87654: 
 87654:             Bytecode *code = analysis->maybeCode(offset);
 87654:             if (!code)
 87654:                 continue;
 87654: 
 87654:             /* Whether this should be the last opcode in the chunk. */
 87654:             bool finishChunk = false;
 87654: 
 87654:             /* Keep going, override finishChunk. */
 87654:             bool preserveChunk = false;
 87654: 
 87654:             /*
 87654:              * Add an edge for opcodes which perform a branch. Skip LABEL ops,
 87654:              * which do not actually branch. XXX LABEL should not be JOF_JUMP.
 87654:              */
 87654:             uint32_t type = JOF_TYPE(js_CodeSpec[op].format);
 87654:             if (type == JOF_JUMP && op != JSOP_LABEL) {
 87654:                 CrossChunkEdge edge;
 87654:                 edge.source = offset;
 87654:                 edge.target = FollowBranch(cx, script, pc - script->code);
 87654:                 if (edge.target < offset) {
 87654:                     /* Always end chunks after loop back edges. */
 87654:                     finishChunk = true;
 87654:                     if (edge.target < chunkStart) {
 87654:                         analysis->getCode(edge.target).safePoint = true;
 87654:                         if (!edges.append(edge))
 87654:                             return NULL;
 87654:                     }
 87654:                 } else if (edge.target == nextOffset) {
 87654:                     /*
 87654:                      * Override finishChunk for bytecodes which directly
 87654:                      * jump to their fallthrough opcode ('if (x) {}'). This
 87654:                      * creates two CFG edges with the same source/target, which
 87654:                      * will confuse the compiler's edge patching code.
 87654:                      */
 87654:                     preserveChunk = true;
 87654:                 } else {
 87654:                     if (!currentEdges.append(edge))
 87654:                         return NULL;
 87654:                 }
 87654:             }
 87654: 
 87654:             if (op == JSOP_TABLESWITCH) {
 87654:                 jsbytecode *pc2 = pc;
 87654:                 unsigned defaultOffset = offset + GET_JUMP_OFFSET(pc);
 87654:                 pc2 += JUMP_OFFSET_LEN;
 91450:                 int32_t low = GET_JUMP_OFFSET(pc2);
 87654:                 pc2 += JUMP_OFFSET_LEN;
 91450:                 int32_t high = GET_JUMP_OFFSET(pc2);
 87654:                 pc2 += JUMP_OFFSET_LEN;
 87654: 
 87654:                 CrossChunkEdge edge;
 87654:                 edge.source = offset;
 87654:                 edge.target = defaultOffset;
 87654:                 if (!currentEdges.append(edge))
 87654:                     return NULL;
 87654: 
 91450:                 for (int32_t i = low; i <= high; i++) {
 87654:                     unsigned targetOffset = offset + GET_JUMP_OFFSET(pc2);
 87654:                     if (targetOffset != offset) {
 87654:                         /*
 87654:                          * This can end up inserting duplicate edges, all but
 87654:                          * the first of which will be ignored.
 87654:                          */
 87654:                         CrossChunkEdge edge;
 87654:                         edge.source = offset;
 87654:                         edge.target = targetOffset;
 87654:                         if (!currentEdges.append(edge))
 87654:                             return NULL;
 87654:                     }
 87654:                     pc2 += JUMP_OFFSET_LEN;
 87654:                 }
 87654:             }
 87654: 
 87983:             if (op == JSOP_LOOKUPSWITCH) {
 87983:                 unsigned defaultOffset = offset + GET_JUMP_OFFSET(pc);
 87983:                 jsbytecode *pc2 = pc + JUMP_OFFSET_LEN;
 87983:                 unsigned npairs = GET_UINT16(pc2);
 87983:                 pc2 += UINT16_LEN;
 87983: 
 87983:                 CrossChunkEdge edge;
 87983:                 edge.source = offset;
 87983:                 edge.target = defaultOffset;
 87983:                 if (!currentEdges.append(edge))
 87983:                     return NULL;
 87983: 
 87983:                 while (npairs) {
 90965:                     pc2 += UINT32_INDEX_LEN;
 87983:                     unsigned targetOffset = offset + GET_JUMP_OFFSET(pc2);
 87983:                     CrossChunkEdge edge;
 87983:                     edge.source = offset;
 87983:                     edge.target = targetOffset;
 87983:                     if (!currentEdges.append(edge))
 87983:                         return NULL;
 87983:                     pc2 += JUMP_OFFSET_LEN;
 87983:                     npairs--;
 87983:                 }
 87983:             }
 87983: 
 87654:             if (unsigned(offset - chunkStart) > CHUNK_LIMIT)
 87654:                 finishChunk = true;
 87654: 
 87654:             if (nextOffset >= script->length || !analysis->maybeCode(nextOffset)) {
 87654:                 /* Ensure that chunks do not start on unreachable opcodes. */
 87654:                 preserveChunk = true;
 87654:             } else {
 87654:                 /*
 87654:                  * Start new chunks at the opcode before each loop head.
 87654:                  * This ensures that the initial goto for loops is included in
 87654:                  * the same chunk as the loop itself.
 87654:                  */
 87654:                 jsbytecode *nextpc = script->code + nextOffset;
 87654: 
 87654:                 /*
 87654:                  * Don't insert a chunk boundary in the middle of two opcodes
 87654:                  * which may be fused together.
 87654:                  */
 87654:                 switch (JSOp(*nextpc)) {
 87654:                   case JSOP_POP:
 87654:                   case JSOP_IFNE:
 87654:                   case JSOP_IFEQ:
 87654:                     preserveChunk = true;
 87654:                     break;
 87654:                   default:
 87654:                     break;
 87654:                 }
 87654: 
 87654:                 uint32_t afterOffset = nextOffset + GetBytecodeLength(nextpc);
 87654:                 if (afterOffset < script->length) {
 87654:                     if (analysis->maybeCode(afterOffset) &&
 87654:                         JSOp(script->code[afterOffset]) == JSOP_LOOPHEAD &&
 87654:                         analysis->getLoop(afterOffset))
 87654:                     {
 87654:                         finishChunk = true;
 87654:                     }
 87654:                 }
 87654:             }
 87654: 
 87654:             if (finishChunk && !preserveChunk) {
 87654:                 ChunkDescriptor desc;
 87654:                 desc.begin = chunkStart;
 87654:                 desc.end = nextOffset;
 87654:                 if (!chunks.append(desc))
 87654:                     return NULL;
 87654: 
 87654:                 /* Add an edge for fallthrough from this chunk to the next one. */
 87654:                 if (!BytecodeNoFallThrough(op)) {
 87654:                     CrossChunkEdge edge;
 87654:                     edge.source = offset;
 87654:                     edge.target = nextOffset;
 87654:                     analysis->getCode(edge.target).safePoint = true;
 87654:                     if (!edges.append(edge))
 87654:                         return NULL;
 87654:                 }
 87654: 
 87654:                 chunkStart = nextOffset;
 87654:                 for (unsigned i = 0; i < currentEdges.length(); i++) {
 87654:                     const CrossChunkEdge &edge = currentEdges[i];
 87654:                     if (edge.target >= nextOffset) {
 87654:                         analysis->getCode(edge.target).safePoint = true;
 87654:                         if (!edges.append(edge))
 87654:                             return NULL;
 87654:                     }
 87654:                 }
 87654:                 currentEdges.clear();
 87654:             }
 87654:         }
 87654: 
 87654:         if (chunkStart != script->length) {
 87654:             ChunkDescriptor desc;
 87654:             desc.begin = chunkStart;
 87654:             desc.end = script->length;
 87654:             if (!chunks.append(desc))
 87654:                 return NULL;
 87654:         }
 87654:     }
 87654: 
 87654:     size_t dataSize = sizeof(JITScript)
 87654:         + (chunks.length() * sizeof(ChunkDescriptor))
 87654:         + (edges.length() * sizeof(CrossChunkEdge));
 89972:     uint8_t *cursor = (uint8_t *) OffTheBooks::calloc_(dataSize);
 87654:     if (!cursor)
 87654:         return NULL;
 87654: 
 87654:     JITScript *jit = (JITScript *) cursor;
 87654:     cursor += sizeof(JITScript);
 87654: 
 87654:     jit->script = script;
 87654:     JS_INIT_CLIST(&jit->callers);
 87654: 
 87654:     jit->nchunks = chunks.length();
 87654:     for (unsigned i = 0; i < chunks.length(); i++) {
 87654:         const ChunkDescriptor &a = chunks[i];
 87654:         ChunkDescriptor &b = jit->chunkDescriptor(i);
 87654:         b.begin = a.begin;
 87654:         b.end = a.end;
 87654: 
 87654:         if (chunks.length() == 1) {
 87654:             /* Seed the chunk's count so it is immediately compiled. */
 87654:             b.counter = INFER_USES_BEFORE_COMPILE;
 87654:         }
 87654:     }
 87654: 
 94809:     if (edges.empty())
 87654:         return jit;
 87654: 
 87654:     jit->nedges = edges.length();
 87654:     CrossChunkEdge *jitEdges = jit->edges();
 87654:     for (unsigned i = 0; i < edges.length(); i++) {
 87654:         const CrossChunkEdge &a = edges[i];
 87654:         CrossChunkEdge &b = jitEdges[i];
 87654:         b.source = a.source;
 87654:         b.target = a.target;
 87654:     }
 87654: 
 87654:     /* Generate a pool with all cross chunk shims, and set shimLabel for each edge. */
 87654:     Assembler masm;
 87654:     for (unsigned i = 0; i < jit->nedges; i++) {
 87654:         jsbytecode *pc = script->code + jitEdges[i].target;
 87654:         jitEdges[i].shimLabel = (void *) masm.distanceOf(masm.label());
 87654:         masm.move(JSC::MacroAssembler::ImmPtr(&jitEdges[i]), Registers::ArgReg1);
 87654:         masm.fallibleVMCall(true, JS_FUNC_TO_DATA_PTR(void *, stubs::CrossChunkShim),
 87654:                             pc, NULL, script->nfixed + analysis->getCode(pc).stackDepth);
 87654:     }
 87654:     LinkerHelper linker(masm, JSC::METHOD_CODE);
 87654:     JSC::ExecutablePool *ep = linker.init(cx);
 87654:     if (!ep)
 87654:         return NULL;
 87654:     jit->shimPool = ep;
 87654: 
 87654:     masm.finalize(linker);
 87654:     uint8_t *shimCode = (uint8_t *) linker.finalizeCodeAddendum().executableAddress();
 87654: 
 87654:     JS_ALWAYS_TRUE(linker.verifyRange(JSC::JITCode(shimCode, masm.size())));
 87654: 
 87654:     JaegerSpew(JSpew_PICs, "generated SHIM POOL stub %p (%lu bytes)\n",
 87654:                shimCode, (unsigned long)masm.size());
 87654: 
 87654:     for (unsigned i = 0; i < jit->nedges; i++) {
 87654:         CrossChunkEdge &edge = jitEdges[i];
 87654:         edge.shimLabel = shimCode + (size_t) edge.shimLabel;
 87654:     }
 87654: 
 87654:     return jit;
 87654: }
 87654: 
 87654: CompileStatus
 87654: mjit::CanMethodJIT(JSContext *cx, JSScript *script, jsbytecode *pc,
 87654:                    bool construct, CompileRequest request)
 87654: {
 87654:   restart:
 87654:     if (!cx->methodJitEnabled)
 87654:         return Compile_Abort;
 87654: 
 99476:     if (script->hasJITInfo()) {
 98147:         JSScript::JITScriptHandle *jith = script->jitHandle(construct, cx->compartment->needsBarrier());
 94809:         if (jith->isUnjittable())
 87654:             return Compile_Abort;
 99476:     }
 87654: 
 99701:     if (!cx->hasRunOption(JSOPTION_METHODJIT_ALWAYS) &&
 87654:         (cx->typeInferenceEnabled()
 87654:          ? script->incUseCount() <= INFER_USES_BEFORE_COMPILE
 87654:          : script->incUseCount() <= USES_BEFORE_COMPILE))
 87654:     {
 87654:         return Compile_Skipped;
 87654:     }
 87654: 
 97464:     if (!cx->runtime->getJaegerRuntime(cx))
 87654:         return Compile_Error;
 57705: 
 56201:     // Ensure that constructors have at least one slot.
 77461:     if (construct && !script->nslots)
 77461:         script->nslots++;
 76766: 
 98147:     uint64_t gcNumber = cx->runtime->gcNumber;
 98147: 
 99476:     if (!script->ensureHasJITInfo(cx))
 99476:         return Compile_Error;
 99476: 
 99476:     JSScript::JITScriptHandle *jith = script->jitHandle(construct, cx->compartment->needsBarrier());
 99476: 
 94809:     JITScript *jit;
 94809:     if (jith->isEmpty()) {
 94809:         jit = MakeJITScript(cx, script);
 87654:         if (!jit)
 87654:             return Compile_Error;
 94809:         jith->setValid(jit);
 94809:     } else {
 94809:         jit = jith->getValid();
 87654:     }
 98147: 
 98147:     // Script analysis can trigger GC, watch in case needsBarrier() changed.
 98147:     if (gcNumber != cx->runtime->gcNumber)
 98147:         goto restart;
 98147: 
 87654:     unsigned chunkIndex = jit->chunkIndex(pc);
 87654:     ChunkDescriptor &desc = jit->chunkDescriptor(chunkIndex);
 87654: 
 87654:     if (desc.chunk)
 87654:         return Compile_Okay;
 87654: 
 99701:     if (!cx->hasRunOption(JSOPTION_METHODJIT_ALWAYS) &&
 87654:         ++desc.counter <= INFER_USES_BEFORE_COMPILE)
 87654:     {
 87654:         return Compile_Skipped;
 87654:     }
 87654: 
 76194:     CompileStatus status;
 76194:     {
 76194:         types::AutoEnterTypeInference enter(cx, true);
 76194: 
 87654:         Compiler cc(cx, script, chunkIndex, construct);
 76194:         status = cc.compile();
 76194:     }
 76194: 
 76194:     if (status == Compile_Okay) {
 76194:         /*
 87654:          * Compiling a script can occasionally trigger its own recompilation,
 87654:          * so go back through the compilation logic.
 87654:          */
 87654:         goto restart;
 76194:     }
 76194: 
 76194:     /* Non-OOM errors should have an associated exception. */
 76194:     JS_ASSERT_IF(status == Compile_Error,
 76194:                  cx->isExceptionPending() || cx->runtime->hadOutOfMemory);
 76194: 
 76194:     return status;
 57766: }
 57766: 
 52611: CompileStatus
 52558: mjit::Compiler::generatePrologue()
 52558: {
 98891:     fastEntryLabel = masm.label();
 53471: 
 52873:     /*
 52873:      * If there is no function, then this can only be called via JaegerShot(),
 52873:      * which expects an existing frame to be initialized like the interpreter.
 52873:      */
 83256:     if (script->function()) {
 52873:         Jump j = masm.jump();
 53590: 
 53590:         /*
 53590:          * Entry point #2: The caller has partially constructed a frame, and
 53590:          * either argc >= nargs or the arity check has corrected the frame.
 53590:          */
 98891:         fastEntryLabel = masm.label();
 53590: 
 54832:         /* Store this early on so slow paths can access it. */
 83234:         masm.storePtr(ImmPtr(script->function()),
 83234:                       Address(JSFrameReg, StackFrame::offsetOfExec()));
 53590: 
 53590:         {
 53590:             /*
 53590:              * Entry point #3: The caller has partially constructed a frame,
 53590:              * but argc might be != nargs, so an arity check might be called.
 53590:              *
 53590:              * This loops back to entry point #2.
 53590:              */
 53590:             arityLabel = stubcc.masm.label();
 76194: 
 53840:             Jump argMatch = stubcc.masm.branch32(Assembler::Equal, JSParamReg_Argc,
 77391:                                                  Imm32(script->function()->nargs));
 53590: 
 53840:             if (JSParamReg_Argc != Registers::ArgReg1)
 53840:                 stubcc.masm.move(JSParamReg_Argc, Registers::ArgReg1);
 53840: 
 53590:             /* Slow path - call the arity check function. Returns new fp. */
 77391:             stubcc.masm.storePtr(ImmPtr(script->function()),
 76194:                                  Address(JSFrameReg, StackFrame::offsetOfExec()));
 76194:             OOL_STUBCALL(stubs::FixupArity, REJOIN_NONE);
 53590:             stubcc.masm.move(Registers::ReturnReg, JSFrameReg);
 76194:             argMatch.linkTo(stubcc.masm.label(), &stubcc.masm);
 76194: 
 76194:             argsCheckLabel = stubcc.masm.label();
 76194: 
 76194:             /* Type check the arguments as well. */
 76194:             if (cx->typeInferenceEnabled()) {
 76194: #ifdef JS_MONOIC
 76194:                 this->argsCheckJump = stubcc.masm.jump();
 76194:                 this->argsCheckStub = stubcc.masm.label();
 76194:                 this->argsCheckJump.linkTo(this->argsCheckStub, &stubcc.masm);
 76194: #endif
 83234:                 stubcc.masm.storePtr(ImmPtr(script->function()),
 83234:                                      Address(JSFrameReg, StackFrame::offsetOfExec()));
 76194:                 OOL_STUBCALL(stubs::CheckArgumentTypes, REJOIN_CHECK_ARGUMENTS);
 76194: #ifdef JS_MONOIC
 76194:                 this->argsCheckFallthrough = stubcc.masm.label();
 76194: #endif
 76194:             }
 76194: 
 98891:             stubcc.crossJump(stubcc.masm.jump(), fastEntryLabel);
 53590:         }
 53590: 
 53590:         /*
 76194:          * Guard that there is enough stack space. Note we reserve space for
 76194:          * any inline frames we end up generating, or a callee's stack frame
 76194:          * we write to before the callee checks the stack.
 53590:          */
 84755:         uint32_t nvals = VALUES_PER_STACK_FRAME + script->nslots + StackSpace::STACK_JIT_EXTRA;
 76194:         masm.addPtr(Imm32(nvals * sizeof(Value)), JSFrameReg, Registers::ReturnReg);
 53590:         Jump stackCheck = masm.branchPtr(Assembler::AboveOrEqual, Registers::ReturnReg,
 53590:                                          FrameAddress(offsetof(VMFrame, stackLimit)));
 53590: 
 74330:         /*
 74330:          * If the stack check fails then we need to either commit more of the
 74330:          * reserved stack space or throw an error. Specify that the number of
 74330:          * local slots is 0 (instead of the default script->nfixed) since the
 74330:          * range [fp->slots(), fp->base()) may not be commited. (The calling
 74330:          * contract requires only that the caller has reserved space for fp.)
 74330:          */
 53590:         {
 53590:             stubcc.linkExitDirect(stackCheck, stubcc.masm.label());
 76194:             OOL_STUBCALL(stubs::HitStackQuota, REJOIN_NONE);
 53590:             stubcc.crossJump(stubcc.masm.jump(), masm.label());
 53590:         }
 53590: 
 81077:         markUndefinedLocals();
 52872: 
100006:         types::TypeScriptNesting *nesting = script->nesting();
100006: 
100006:         /*
100006:          * Run the function prologue if necessary. This is always done in a
100006:          * stub for heavyweight functions (including nesting outer functions).
100006:          */
100006:         JS_ASSERT_IF(nesting && nesting->children, script->function()->isHeavyweight());
100006:         if (script->function()->isHeavyweight()) {
100006:             prepareStubCall(Uses(0));
100006:             INLINE_STUBCALL(stubs::FunctionFramePrologue, REJOIN_FUNCTION_PROLOGUE);
100006:         } else {
 77884:             /*
 77884:              * Load the scope chain into the frame if it will be needed by NAME
100006:              * opcodes or by the nesting prologue below. The scope chain is
100006:              * always set for global and eval frames, and will have been set by
100006:              * CreateFunCallObject for heavyweight function frames.
100006:              */
100006:             if (analysis->usesScopeChain() || nesting) {
 55483:                 RegisterID t0 = Registers::ReturnReg;
 55483:                 Jump hasScope = masm.branchTest32(Assembler::NonZero,
 76194:                                                   FrameFlagsAddress(), Imm32(StackFrame::HAS_SCOPECHAIN));
 77391:                 masm.loadPayload(Address(JSFrameReg, StackFrame::offsetOfCallee(script->function())), t0);
 83283:                 masm.loadPtr(Address(t0, JSFunction::offsetOfEnvironment()), t0);
 69223:                 masm.storePtr(t0, Address(JSFrameReg, StackFrame::offsetOfScopeChain()));
 55483:                 hasScope.linkTo(masm.label(), &masm);
 55483:             }
 76194: 
100006:             if (nesting) {
100006:                 /*
100006:                  * Inline the common case for the nesting prologue: the
100006:                  * function is a non-heavyweight inner function with no
100006:                  * children of its own. We ensure during inference that the
100006:                  * outer function does not add scope objects for 'let' or
100006:                  * 'with', so that the frame's scope chain will be
100006:                  * the parent's call object, and if it differs from the
100006:                  * parent's current activation then the parent is reentrant.
100006:                  */
100006:                 JSScript *parent = nesting->parent;
100006:                 JS_ASSERT(parent);
100006:                 JS_ASSERT_IF(parent->hasAnalysis() && parent->analysis()->ranBytecode(),
100006:                              !parent->analysis()->addsScopeObjects());
100006: 
100006:                 RegisterID t0 = Registers::ReturnReg;
100006:                 masm.move(ImmPtr(&parent->nesting()->activeCall), t0);
100006:                 masm.loadPtr(Address(t0), t0);
100006: 
100006:                 Address scopeChain(JSFrameReg, StackFrame::offsetOfScopeChain());
100006:                 Jump mismatch = masm.branchPtr(Assembler::NotEqual, t0, scopeChain);
100006:                 masm.add32(Imm32(1), AbsoluteAddress(&nesting->activeFrames));
100006: 
100006:                 stubcc.linkExitDirect(mismatch, stubcc.masm.label());
100006:                 OOL_STUBCALL(stubs::FunctionFramePrologue, REJOIN_FUNCTION_PROLOGUE);
100006:                 stubcc.crossJump(stubcc.masm.jump(), masm.label());
100006:             }
100006:         }
100006: 
 99994:         /*
 99994:          * When 'arguments' is used in the script, it may be optimized away
 99994:          * which involves reading from the stack frame directly, including
 99994:          * fp->u.nactual. fp->u.nactual is only set when numActual != numFormal,
 99994:          * so store 'fp->u.nactual = numFormal' when there is no over/underflow.
 99994:          */
 99994:         if (script->argumentsHasLocalBinding()) {
 99994:             Jump hasArgs = masm.branchTest32(Assembler::NonZero, FrameFlagsAddress(),
 99994:                                              Imm32(StackFrame::UNDERFLOW_ARGS |
 99994:                                                    StackFrame::OVERFLOW_ARGS));
 99994:             masm.storePtr(ImmPtr((void *)(size_t) script->function()->nargs),
 99994:                           Address(JSFrameReg, StackFrame::offsetOfNumActual()));
 99994:             hasArgs.linkTo(masm.label(), &masm);
 99994:         }
 99994: 
 99994:         j.linkTo(masm.label(), &masm);
 99994:     }
 99994: 
 99994:     if (cx->typeInferenceEnabled()) {
 99994: #ifdef DEBUG
 99994:         if (script->function()) {
 99994:             prepareStubCall(Uses(0));
 99994:             INLINE_STUBCALL(stubs::AssertArgumentTypes, REJOIN_NONE);
 99994:         }
 99994: #endif
 99994:         ensureDoubleArguments();
 99994:     }
 99994: 
 77414:     if (isConstructing) {
 77414:         if (!constructThis())
 77414:             return Compile_Error;
 77414:     }
 74457: 
 77413:     if (debugMode()) {
 77413:         prepareStubCall(Uses(0));
 76194:         INLINE_STUBCALL(stubs::ScriptDebugPrologue, REJOIN_RESUME);
 77413:     } else if (Probes::callTrackingActive(cx)) {
 77413:         prepareStubCall(Uses(0));
 76194:         INLINE_STUBCALL(stubs::ScriptProbeOnlyPrologue, REJOIN_RESUME);
 77413:     }
 76194: 
 76194:     recompileCheckHelper();
 74457: 
 52558:     return Compile_Okay;
 52558: }
 52558: 
 76194: void
 76194: mjit::Compiler::ensureDoubleArguments()
 76194: {
 76194:     /* Convert integer arguments which were inferred as (int|double) to doubles. */
 84755:     for (uint32_t i = 0; script->function() && i < script->function()->nargs; i++) {
 84755:         uint32_t slot = ArgSlot(i);
 87654:         if (a->varTypes[slot].getTypeTag(cx) == JSVAL_TYPE_DOUBLE && analysis->trackSlot(slot))
 76194:             frame.ensureDouble(frame.getArg(i));
 76194:     }
 76194: }
 76194: 
 81077: void
 91759: mjit::Compiler::markUndefinedLocal(uint32_t offset, uint32_t i)
 81077: {
 84755:     uint32_t depth = ssa.getFrame(a->inlineIndex).depth;
 84755:     uint32_t slot = LocalSlot(script, i);
 81077:     Address local(JSFrameReg, sizeof(StackFrame) + (depth + i) * sizeof(Value));
 81077:     if (!cx->typeInferenceEnabled() || !analysis->trackSlot(slot)) {
 81077:         masm.storeValue(UndefinedValue(), local);
 81077:     } else {
 91759:         Lifetime *lifetime = analysis->liveness(slot).live(offset);
 81077:         if (lifetime)
 81077:             masm.storeValue(UndefinedValue(), local);
 81077:     }
 81077: }
 91759: 
 91759: void
 91759: mjit::Compiler::markUndefinedLocals()
 91759: {
 91759:     /*
100006:      * Set locals to undefined, as in initCallFrameLatePrologue.
100006:      * Skip locals which aren't closed and are known to be defined before used,
 91759:      */
 91759:     for (uint32_t i = 0; i < script->nfixed; i++)
 91759:         markUndefinedLocal(0, i);
 81077: }
 81077: 
 52611: CompileStatus
 52611: mjit::Compiler::generateEpilogue()
 52611: {
 52611:     return Compile_Okay;
 52611: }
 52611: 
 52611: CompileStatus
 87654: mjit::Compiler::finishThisUp()
 52611: {
 90435: #ifdef JS_CPU_X64
 90435:     /* Generate trampolines to ensure that cross chunk edges are patchable. */
 90435:     for (unsigned i = 0; i < chunkEdges.length(); i++) {
 90435:         chunkEdges[i].sourceTrampoline = stubcc.masm.label();
 90435:         stubcc.masm.move(ImmPtr(NULL), Registers::ScratchReg);
 90435:         stubcc.masm.jump(Registers::ScratchReg);
 90435:     }
 90435: #endif
 90435: 
 56037:     RETURN_IF_OOM(Compile_Error);
 56037: 
 76194:     /*
 76194:      * Watch for reallocation of the global slots while we were in the middle
 76194:      * of compiling due to, e.g. standard class initialization.
 76194:      */
 76194:     if (globalSlots && globalObj->getRawSlots() != globalSlots)
 76194:         return Compile_Retry;
 76194: 
 77892:     /*
 77892:      * Watch for GCs which occurred during compilation. These may have
 77892:      * renumbered shapes baked into the jitcode.
 77892:      */
 77892:     if (cx->runtime->gcNumber != gcNumber)
 77892:         return Compile_Retry;
 77892: 
 87654:     /* The JIT will not have been cleared if no GC has occurred. */
 87654:     JITScript *jit = outerJIT();
 87654:     JS_ASSERT(jit != NULL);
 87654: 
 78457:     if (overflowICSpace) {
 78457:         JaegerSpew(JSpew_Scripts, "dumped a constant pool while generating an IC\n");
 78457:         return Compile_Abort;
 78457:     }
 78457: 
 86348:     a->mainCodeEnd = masm.size();
 86348:     a->stubCodeEnd = stubcc.size();
 86348: 
 52611:     for (size_t i = 0; i < branchPatches.length(); i++) {
 76194:         Label label = labelOf(branchPatches[i].pc, branchPatches[i].inlineIndex);
 52611:         branchPatches[i].jump.linkTo(label, &masm);
 52611:     }
 52611: 
 53147: #ifdef JS_CPU_ARM
 53147:     masm.forceFlushConstantPool();
 53147:     stubcc.masm.forceFlushConstantPool();
 53147: #endif
 75290:     JaegerSpew(JSpew_Insns, "## Fast code (masm) size = %lu, Slow code (stubcc) size = %lu.\n",
 75290:                (unsigned long) masm.size(), (unsigned long) stubcc.size());
 53147: 
 87250:     /* To make inlineDoubles and oolDoubles aligned to sizeof(double) bytes,
 87250:        MIPS adds extra sizeof(double) bytes to codeSize.  */
 69289:     size_t codeSize = masm.size() +
 87250: #if defined(JS_CPU_MIPS)
 87250:                       stubcc.size() + sizeof(double) +
 87250: #else
 53183:                       stubcc.size() +
 87250: #endif
 76194:                       (masm.numDoubles() * sizeof(double)) +
 76194:                       (stubcc.masm.numDoubles() * sizeof(double)) +
 87654:                       jumpTableEdges.length() * sizeof(void *);
 87654: 
 87654:     Vector<ChunkJumpTableEdge> chunkJumps(cx);
 87654:     if (!chunkJumps.reserve(jumpTableEdges.length()))
 87654:         return Compile_Error;
 53183: 
 97464:     JSC::ExecutableAllocator &execAlloc = cx->runtime->execAlloc();
 64243:     JSC::ExecutablePool *execPool;
 97464:     uint8_t *result = (uint8_t *)execAlloc.alloc(codeSize, &execPool, JSC::METHOD_CODE);
 64243:     if (!result) {
 61233:         js_ReportOutOfMemory(cx);
 61233:         return Compile_Error;
 61233:     }
 64243:     JS_ASSERT(execPool);
 69289:     JSC::ExecutableAllocator::makeWritable(result, codeSize);
 53147:     masm.executableCopy(result);
 53147:     stubcc.masm.executableCopy(result + masm.size());
 52611: 
 77559:     JSC::LinkBuffer fullCode(result, codeSize, JSC::METHOD_CODE);
 77559:     JSC::LinkBuffer stubCode(result + masm.size(), stubcc.size(), JSC::METHOD_CODE);
 53498: 
 87654:     JS_ASSERT(!loop);
 87654: 
 76194:     size_t nNmapLive = loopEntries.length();
 87654:     for (size_t i = outerChunk.begin; i < outerChunk.end; i++) {
 76194:         Bytecode *opinfo = analysis->maybeCode(i);
 84195:         if (opinfo && opinfo->safePoint)
 58993:             nNmapLive++;
 58993:     }
 58993: 
 88145:     /* Please keep in sync with JITChunk::sizeOfIncludingThis! */
 87654:     size_t dataSize = sizeof(JITChunk) +
 58993:                       sizeof(NativeMapEntry) * nNmapLive +
 76194:                       sizeof(InlineFrame) * inlineFrames.length() +
 76194:                       sizeof(CallSite) * callSites.length() +
 98147:                       sizeof(JSObject*) * rootedTemplates.length() +
 98147:                       sizeof(RegExpShared*) * rootedRegExps.length() +
 53498: #if defined JS_MONOIC
 62386:                       sizeof(ic::GetGlobalNameIC) * getGlobalNames.length() +
 62386:                       sizeof(ic::SetGlobalNameIC) * setGlobalNames.length() +
 68952:                       sizeof(ic::CallICInfo) * callICs.length() +
 56192:                       sizeof(ic::EqualityICInfo) * equalityICs.length() +
 53498: #endif
 53498: #if defined JS_POLYIC
 53498:                       sizeof(ic::PICInfo) * pics.length() +
 56738:                       sizeof(ic::GetElementIC) * getElemICs.length() +
 57671:                       sizeof(ic::SetElementIC) * setElemICs.length() +
 53498: #endif
 76194:                       0;
 53498: 
 89972:     uint8_t *cursor = (uint8_t *)OffTheBooks::calloc_(dataSize);
 53498:     if (!cursor) {
 52661:         execPool->release();
 61233:         js_ReportOutOfMemory(cx);
 52661:         return Compile_Error;
 52661:     }
 52661: 
 87654:     JITChunk *chunk = new(cursor) JITChunk;
 87654:     cursor += sizeof(JITChunk);
 53498: 
 76194:     JS_ASSERT(outerScript == script);
 76194: 
 87654:     chunk->code = JSC::MacroAssemblerCodeRef(result, execPool, masm.size() + stubcc.size());
 87654:     chunk->pcLengths = pcLengths;
 87654: 
 87654:     if (chunkIndex == 0) {
 55503:         jit->invokeEntry = result;
 83256:         if (script->function()) {
 94626:             jit->arityCheckEntry = stubCode.locationOf(arityLabel).executableAddress();
 76194:             jit->argsCheckEntry = stubCode.locationOf(argsCheckLabel).executableAddress();
 98891:             jit->fastEntry = fullCode.locationOf(fastEntryLabel).executableAddress();
 87654:         }
 87654:     }
 62075: 
 62075:     /*
 62075:      * WARNING: mics(), callICs() et al depend on the ordering of these
 87654:      * variable-length sections.  See JITChunk's declaration for details.
 62075:      */
 53520: 
 76194:     /* ICs can only refer to bytecodes in the outermost script, not inlined calls. */
 76194:     Label *jumpMap = a->jumpMap;
 76194: 
 53498:     /* Build the pc -> ncode mapping. */
 62075:     NativeMapEntry *jitNmap = (NativeMapEntry *)cursor;
 87654:     chunk->nNmapPairs = nNmapLive;
 87654:     cursor += sizeof(NativeMapEntry) * chunk->nNmapPairs;
 58993:     size_t ix = 0;
 87654:     if (chunk->nNmapPairs > 0) {
 87654:         for (size_t i = outerChunk.begin; i < outerChunk.end; i++) {
 76194:             Bytecode *opinfo = analysis->maybeCode(i);
 56602:             if (opinfo && opinfo->safePoint) {
 58993:                 Label L = jumpMap[i];
 71317:                 JS_ASSERT(L.isSet());
 62075:                 jitNmap[ix].bcOff = i;
 84755:                 jitNmap[ix].ncode = (uint8_t *)(result + masm.distanceOf(L));
 58993:                 ix++;
 58993:             }
 58993:         }
 76194:         for (size_t i = 0; i < loopEntries.length(); i++) {
 76194:             /* Insert the entry at the right position. */
 76194:             const LoopEntry &entry = loopEntries[i];
 76194:             size_t j;
 76194:             for (j = 0; j < ix; j++) {
 76194:                 if (jitNmap[j].bcOff > entry.pcOffset) {
 76194:                     memmove(jitNmap + j + 1, jitNmap + j, (ix - j) * sizeof(NativeMapEntry));
 76194:                     break;
 76194:                 }
 76194:             }
 76194:             jitNmap[j].bcOff = entry.pcOffset;
 84755:             jitNmap[j].ncode = (uint8_t *) stubCode.locationOf(entry.label).executableAddress();
 76194:             ix++;
 76194:         }
 58993:     }
 87654:     JS_ASSERT(ix == chunk->nNmapPairs);
 53590: 
 76194:     /* Build the table of inlined frames. */
 76194:     InlineFrame *jitInlineFrames = (InlineFrame *)cursor;
 87654:     chunk->nInlineFrames = inlineFrames.length();
 87654:     cursor += sizeof(InlineFrame) * chunk->nInlineFrames;
 87654:     for (size_t i = 0; i < chunk->nInlineFrames; i++) {
 76194:         InlineFrame &to = jitInlineFrames[i];
 76194:         ActiveFrame *from = inlineFrames[i];
 76194:         if (from->parent != outer)
 76194:             to.parent = &jitInlineFrames[from->parent->inlineIndex];
 76194:         else
 76194:             to.parent = NULL;
 76194:         to.parentpc = from->parentPC;
 77391:         to.fun = from->script->function();
 76194:         to.depth = ssa.getFrame(from->inlineIndex).depth;
 76194:     }
 76194: 
 76194:     /* Build the table of call sites. */
 76194:     CallSite *jitCallSites = (CallSite *)cursor;
 87654:     chunk->nCallSites = callSites.length();
 87654:     cursor += sizeof(CallSite) * chunk->nCallSites;
 87654:     for (size_t i = 0; i < chunk->nCallSites; i++) {
 76194:         CallSite &to = jitCallSites[i];
 76194:         InternalCallSite &from = callSites[i];
 76194: 
 76194:         /* Patch stores of f.regs.inlined for stubs called from within inline frames. */
 76194:         if (cx->typeInferenceEnabled() &&
 76194:             from.rejoin != REJOIN_TRAP &&
 76194:             from.rejoin != REJOIN_SCRIPTED &&
 84755:             from.inlineIndex != UINT32_MAX) {
 76194:             if (from.ool)
 76194:                 stubCode.patch(from.inlinePatch, &to);
 76194:             else
 76194:                 fullCode.patch(from.inlinePatch, &to);
 76194:         }
 76194: 
 76194:         JSScript *script =
 84755:             (from.inlineIndex == UINT32_MAX) ? outerScript : inlineFrames[from.inlineIndex]->script;
 84755:         uint32_t codeOffset = from.ool
 76194:                             ? masm.size() + from.returnOffset
 76194:                             : from.returnOffset;
 76194:         to.initialize(codeOffset, from.inlineIndex, from.inlinepc - script->code, from.rejoin);
 76194: 
 76194:         /*
 76194:          * Patch stores of the base call's return address for InvariantFailure
 76194:          * calls. InvariantFailure will patch its own return address to this
 76194:          * pointer before triggering recompilation.
 76194:          */
 76194:         if (from.loopPatch.hasPatch)
 76194:             stubCode.patch(from.loopPatch.codePatch, result + codeOffset);
 76194:     }
 76194: 
 98147:     JSObject **jitRootedTemplates = (JSObject **)cursor;
 98147:     chunk->nRootedTemplates = rootedTemplates.length();
 98147:     cursor += sizeof(JSObject*) * chunk->nRootedTemplates;
 98147:     for (size_t i = 0; i < chunk->nRootedTemplates; i++)
 98147:         jitRootedTemplates[i] = rootedTemplates[i];
 98147: 
 98147:     RegExpShared **jitRootedRegExps = (RegExpShared **)cursor;
 98147:     chunk->nRootedRegExps = rootedRegExps.length();
 98147:     cursor += sizeof(RegExpShared*) * chunk->nRootedRegExps;
 98147:     for (size_t i = 0; i < chunk->nRootedRegExps; i++) {
 98147:         jitRootedRegExps[i] = rootedRegExps[i];
 98147:         jitRootedRegExps[i]->incRef();
 98147:     }
 98147: 
 53119: #if defined JS_MONOIC
 87654:     if (chunkIndex == 0 && script->function()) {
 87654:         JS_ASSERT(jit->argsCheckPool == NULL);
 87654:         if (cx->typeInferenceEnabled()) {
 76194:             jit->argsCheckStub = stubCode.locationOf(argsCheckStub);
 76194:             jit->argsCheckFallthrough = stubCode.locationOf(argsCheckFallthrough);
 76194:             jit->argsCheckJump = stubCode.locationOf(argsCheckJump);
 87654:         }
 76194:     }
 76194: 
 62386:     ic::GetGlobalNameIC *getGlobalNames_ = (ic::GetGlobalNameIC *)cursor;
 87654:     chunk->nGetGlobalNames = getGlobalNames.length();
 87654:     cursor += sizeof(ic::GetGlobalNameIC) * chunk->nGetGlobalNames;
 87654:     for (size_t i = 0; i < chunk->nGetGlobalNames; i++) {
 62386:         ic::GetGlobalNameIC &to = getGlobalNames_[i];
 62386:         GetGlobalNameICInfo &from = getGlobalNames[i];
 62386:         from.copyTo(to, fullCode, stubCode);
 62386: 
 62386:         int offset = fullCode.locationOf(from.load) - to.fastPathStart;
 62386:         to.loadStoreOffset = offset;
 62386:         JS_ASSERT(to.loadStoreOffset == offset);
 62386: 
 62386:         stubCode.patch(from.addrLabel, &to);
 62386:     }
 62386: 
 62386:     ic::SetGlobalNameIC *setGlobalNames_ = (ic::SetGlobalNameIC *)cursor;
 87654:     chunk->nSetGlobalNames = setGlobalNames.length();
 87654:     cursor += sizeof(ic::SetGlobalNameIC) * chunk->nSetGlobalNames;
 87654:     for (size_t i = 0; i < chunk->nSetGlobalNames; i++) {
 62386:         ic::SetGlobalNameIC &to = setGlobalNames_[i];
 62386:         SetGlobalNameICInfo &from = setGlobalNames[i];
 62386:         from.copyTo(to, fullCode, stubCode);
 62386:         to.slowPathStart = stubCode.locationOf(from.slowPathStart);
 62386: 
 62386:         int offset = fullCode.locationOf(from.store).labelAtOffset(0) -
 62386:                      to.fastPathStart;
 62386:         to.loadStoreOffset = offset;
 62386:         JS_ASSERT(to.loadStoreOffset == offset);
 62386: 
 62386:         to.objConst = from.objConst;
 62386:         to.shapeReg = from.shapeReg;
 62386:         to.objReg = from.objReg;
 62386:         to.vr = from.vr;
 62386: 
 62386:         offset = fullCode.locationOf(from.shapeGuardJump) -
 62386:                  to.fastPathStart;
 62386:         to.inlineShapeJump = offset;
 62386:         JS_ASSERT(to.inlineShapeJump == offset);
 62386: 
 62386:         offset = fullCode.locationOf(from.fastPathRejoin) -
 62386:                  to.fastPathStart;
 62386:         to.fastRejoinOffset = offset;
 62386:         JS_ASSERT(to.fastRejoinOffset == offset);
 62386: 
 62386:         stubCode.patch(from.addrLabel, &to);
 62075:     }
 62075: 
 68952:     ic::CallICInfo *jitCallICs = (ic::CallICInfo *)cursor;
 87654:     chunk->nCallICs = callICs.length();
 87654:     cursor += sizeof(ic::CallICInfo) * chunk->nCallICs;
 87654:     for (size_t i = 0; i < chunk->nCallICs; i++) {
 68952:         jitCallICs[i].funGuard = fullCode.locationOf(callICs[i].funGuard);
 68952:         jitCallICs[i].funJump = fullCode.locationOf(callICs[i].funJump);
 68952:         jitCallICs[i].slowPathStart = stubCode.locationOf(callICs[i].slowPathStart);
 76194:         jitCallICs[i].typeMonitored = callICs[i].typeMonitored;
 68952: 
 68952:         /* Compute the hot call offset. */
 84755:         uint32_t offset = fullCode.locationOf(callICs[i].hotJump) -
 68952:                         fullCode.locationOf(callICs[i].funGuard);
 68952:         jitCallICs[i].hotJumpOffset = offset;
 68952:         JS_ASSERT(jitCallICs[i].hotJumpOffset == offset);
 68952: 
 68952:         /* Compute the join point offset. */
 68952:         offset = fullCode.locationOf(callICs[i].joinPoint) -
 68952:                  fullCode.locationOf(callICs[i].funGuard);
 68952:         jitCallICs[i].joinPointOffset = offset;
 68952:         JS_ASSERT(jitCallICs[i].joinPointOffset == offset);
 68952: 
 68952:         /* Compute the OOL call offset. */
 68952:         offset = stubCode.locationOf(callICs[i].oolCall) -
 68952:                  stubCode.locationOf(callICs[i].slowPathStart);
 68952:         jitCallICs[i].oolCallOffset = offset;
 68952:         JS_ASSERT(jitCallICs[i].oolCallOffset == offset);
 68952: 
 68952:         /* Compute the OOL jump offset. */
 68952:         offset = stubCode.locationOf(callICs[i].oolJump) -
 68952:                  stubCode.locationOf(callICs[i].slowPathStart);
 68952:         jitCallICs[i].oolJumpOffset = offset;
 68952:         JS_ASSERT(jitCallICs[i].oolJumpOffset == offset);
 68952: 
 68952:         /* Compute the start of the OOL IC call. */
 68952:         offset = stubCode.locationOf(callICs[i].icCall) -
 68952:                  stubCode.locationOf(callICs[i].slowPathStart);
 68952:         jitCallICs[i].icCallOffset = offset;
 68952:         JS_ASSERT(jitCallICs[i].icCallOffset == offset);
 68952: 
 68952:         /* Compute the slow join point offset. */
 68952:         offset = stubCode.locationOf(callICs[i].slowJoinPoint) -
 68952:                  stubCode.locationOf(callICs[i].slowPathStart);
 68952:         jitCallICs[i].slowJoinOffset = offset;
 68952:         JS_ASSERT(jitCallICs[i].slowJoinOffset == offset);
 68952: 
 68952:         /* Compute the join point offset for continuing on the hot path. */
 68952:         offset = stubCode.locationOf(callICs[i].hotPathLabel) -
 68952:                  stubCode.locationOf(callICs[i].funGuard);
 68952:         jitCallICs[i].hotPathOffset = offset;
 68952:         JS_ASSERT(jitCallICs[i].hotPathOffset == offset);
 68952: 
 76194:         jitCallICs[i].call = &jitCallSites[callICs[i].callIndex];
 68952:         jitCallICs[i].frameSize = callICs[i].frameSize;
 68952:         jitCallICs[i].funObjReg = callICs[i].funObjReg;
 68952:         stubCode.patch(callICs[i].addrLabel1, &jitCallICs[i]);
 68952:         stubCode.patch(callICs[i].addrLabel2, &jitCallICs[i]);
 68952:     }
 68952: 
 62075:     ic::EqualityICInfo *jitEqualityICs = (ic::EqualityICInfo *)cursor;
 87654:     chunk->nEqualityICs = equalityICs.length();
 87654:     cursor += sizeof(ic::EqualityICInfo) * chunk->nEqualityICs;
 87654:     for (size_t i = 0; i < chunk->nEqualityICs; i++) {
 76194:         if (equalityICs[i].trampoline) {
 76194:             jitEqualityICs[i].target = stubCode.locationOf(equalityICs[i].trampolineStart);
 76194:         } else {
 84755:             uint32_t offs = uint32_t(equalityICs[i].jumpTarget - script->code);
 71317:             JS_ASSERT(jumpMap[offs].isSet());
 62075:             jitEqualityICs[i].target = fullCode.locationOf(jumpMap[offs]);
 76194:         }
 62075:         jitEqualityICs[i].stubEntry = stubCode.locationOf(equalityICs[i].stubEntry);
 62075:         jitEqualityICs[i].stubCall = stubCode.locationOf(equalityICs[i].stubCall);
 62075:         jitEqualityICs[i].stub = equalityICs[i].stub;
 62075:         jitEqualityICs[i].lvr = equalityICs[i].lvr;
 62075:         jitEqualityICs[i].rvr = equalityICs[i].rvr;
 62075:         jitEqualityICs[i].tempReg = equalityICs[i].tempReg;
 62075:         jitEqualityICs[i].cond = equalityICs[i].cond;
 56192:         if (equalityICs[i].jumpToStub.isSet())
 62075:             jitEqualityICs[i].jumpToStub = fullCode.locationOf(equalityICs[i].jumpToStub.get());
 62075:         jitEqualityICs[i].fallThrough = fullCode.locationOf(equalityICs[i].fallThrough);
 62075: 
 62075:         stubCode.patch(equalityICs[i].addrLabel, &jitEqualityICs[i]);
 62075:     }
 53119: #endif /* JS_MONOIC */
 53119: 
 68952:     for (size_t i = 0; i < callPatches.length(); i++) {
 68952:         CallPatchInfo &patch = callPatches[i];
 68952: 
 76194:         CodeLocationLabel joinPoint = patch.joinSlow
 76194:             ? stubCode.locationOf(patch.joinPoint)
 76194:             : fullCode.locationOf(patch.joinPoint);
 76194: 
 68952:         if (patch.hasFastNcode)
 76194:             fullCode.patch(patch.fastNcodePatch, joinPoint);
 68952:         if (patch.hasSlowNcode)
 76194:             stubCode.patch(patch.slowNcodePatch, joinPoint);
 68952:     }
 68952: 
 60598: #ifdef JS_POLYIC
 62075:     ic::GetElementIC *jitGetElems = (ic::GetElementIC *)cursor;
 87654:     chunk->nGetElems = getElemICs.length();
 87654:     cursor += sizeof(ic::GetElementIC) * chunk->nGetElems;
 87654:     for (size_t i = 0; i < chunk->nGetElems; i++) {
 62075:         ic::GetElementIC &to = jitGetElems[i];
 56738:         GetElementICInfo &from = getElemICs[i];
 57671: 
 57671:         new (&to) ic::GetElementIC();
 56738:         from.copyTo(to, fullCode, stubCode);
 56738: 
 56738:         to.typeReg = from.typeReg;
 56738:         to.objReg = from.objReg;
 56738:         to.idRemat = from.id;
 56738: 
 56738:         if (from.typeGuard.isSet()) {
 56738:             int inlineTypeGuard = fullCode.locationOf(from.typeGuard.get()) -
 56738:                                   fullCode.locationOf(from.fastPathStart);
 56738:             to.inlineTypeGuard = inlineTypeGuard;
 56738:             JS_ASSERT(to.inlineTypeGuard == inlineTypeGuard);
 56738:         }
 83222:         int inlineShapeGuard = fullCode.locationOf(from.shapeGuard) -
 56738:                                fullCode.locationOf(from.fastPathStart);
 83222:         to.inlineShapeGuard = inlineShapeGuard;
 83222:         JS_ASSERT(to.inlineShapeGuard == inlineShapeGuard);
 56738: 
 56738:         stubCode.patch(from.paramAddr, &to);
 56738:     }
 60598: 
 62075:     ic::SetElementIC *jitSetElems = (ic::SetElementIC *)cursor;
 87654:     chunk->nSetElems = setElemICs.length();
 87654:     cursor += sizeof(ic::SetElementIC) * chunk->nSetElems;
 87654:     for (size_t i = 0; i < chunk->nSetElems; i++) {
 62075:         ic::SetElementIC &to = jitSetElems[i];
 57671:         SetElementICInfo &from = setElemICs[i];
 57671: 
 57671:         new (&to) ic::SetElementIC();
 57671:         from.copyTo(to, fullCode, stubCode);
 57671: 
 57671:         to.strictMode = script->strictModeCode;
 57671:         to.vr = from.vr;
 57671:         to.objReg = from.objReg;
 57671:         to.objRemat = from.objRemat.toInt32();
 57671:         JS_ASSERT(to.objRemat == from.objRemat.toInt32());
 57671: 
 57671:         to.hasConstantKey = from.key.isConstant();
 57671:         if (from.key.isConstant())
 57671:             to.keyValue = from.key.index();
 57671:         else
 57671:             to.keyReg = from.key.reg();
 57671: 
 83222:         int inlineShapeGuard = fullCode.locationOf(from.shapeGuard) -
 57671:                                fullCode.locationOf(from.fastPathStart);
 83222:         to.inlineShapeGuard = inlineShapeGuard;
 83222:         JS_ASSERT(to.inlineShapeGuard == inlineShapeGuard);
 57671: 
 57671:         int inlineHoleGuard = fullCode.locationOf(from.holeGuard) -
 57671:                                fullCode.locationOf(from.fastPathStart);
 57671:         to.inlineHoleGuard = inlineHoleGuard;
 57671:         JS_ASSERT(to.inlineHoleGuard == inlineHoleGuard);
 57671: 
 60597:         CheckIsStubCall(to.slowPathCall.labelAtOffset(0));
 60597: 
 60164:         to.volatileMask = from.volatileMask;
 60164:         JS_ASSERT(to.volatileMask == from.volatileMask);
 60164: 
 57671:         stubCode.patch(from.paramAddr, &to);
 57671:     }
 60598: 
 62075:     ic::PICInfo *jitPics = (ic::PICInfo *)cursor;
 87654:     chunk->nPICs = pics.length();
 87654:     cursor += sizeof(ic::PICInfo) * chunk->nPICs;
 87654:     for (size_t i = 0; i < chunk->nPICs; i++) {
 62075:         new (&jitPics[i]) ic::PICInfo();
 62075:         pics[i].copyTo(jitPics[i], fullCode, stubCode);
 62075:         pics[i].copySimpleMembersTo(jitPics[i]);
 62075: 
 62075:         jitPics[i].shapeGuard = masm.distanceOf(pics[i].shapeGuard) -
 53270:                                 masm.distanceOf(pics[i].fastPathStart);
 62075:         JS_ASSERT(jitPics[i].shapeGuard == masm.distanceOf(pics[i].shapeGuard) -
 53426:                                            masm.distanceOf(pics[i].fastPathStart));
 62075:         jitPics[i].shapeRegHasBaseShape = true;
 62075:         jitPics[i].pc = pics[i].pc;
 52887: 
 94227:         if (pics[i].kind == ic::PICInfo::SET) {
 62075:             jitPics[i].u.vr = pics[i].vr;
 86855:         } else if (pics[i].kind != ic::PICInfo::NAME) {
 52884:             if (pics[i].hasTypeCheck) {
 84755:                 int32_t distance = stubcc.masm.distanceOf(pics[i].typeCheck) -
 52884:                                  stubcc.masm.distanceOf(pics[i].slowPathStart);
 53264:                 JS_ASSERT(distance <= 0);
 62075:                 jitPics[i].u.get.typeCheckOffset = distance;
 62075:             }
 62075:         }
 62075:         stubCode.patch(pics[i].paramAddr, &jitPics[i]);
 52880:     }
 60597: #endif
 52880: 
 87654:     JS_ASSERT(size_t(cursor - (uint8_t*)chunk) == dataSize);
 88145:     /* Use the computed size here -- we don't want slop bytes to be counted. */
 88145:     JS_ASSERT(chunk->computedSizeOfIncludingThis() == dataSize);
 76194: 
 52613:     /* Link fast and slow paths together. */
 52613:     stubcc.fixCrossJumps(result, masm.size(), masm.size() + stubcc.size());
 52613: 
 87250: #if defined(JS_CPU_MIPS)
 87250:     /* Make sure doubleOffset is aligned to sizeof(double) bytes.  */
 87250:     size_t doubleOffset = (((size_t)result + masm.size() + stubcc.size() +
 87250:                             sizeof(double) - 1) & (~(sizeof(double) - 1))) -
 87250:                           (size_t)result;
 87250:     JS_ASSERT((((size_t)result + doubleOffset) & 7) == 0);
 87250: #else
 53183:     size_t doubleOffset = masm.size() + stubcc.size();
 87250: #endif
 87250: 
 76194:     double *inlineDoubles = (double *) (result + doubleOffset);
 76194:     double *oolDoubles = (double*) (result + doubleOffset +
 76194:                                     masm.numDoubles() * sizeof(double));
 53183: 
 59979:     /* Generate jump tables. */
 76194:     void **jumpVec = (void **)(oolDoubles + stubcc.masm.numDoubles());
 59979: 
 87654:     for (size_t i = 0; i < jumpTableEdges.length(); i++) {
 87654:         JumpTableEdge edge = jumpTableEdges[i];
 87654:         if (bytecodeInChunk(script->code + edge.target)) {
 87654:             JS_ASSERT(jumpMap[edge.target].isSet());
 87654:             jumpVec[i] = (void *)(result + masm.distanceOf(jumpMap[edge.target]));
 87654:         } else {
 87654:             ChunkJumpTableEdge nedge;
 87654:             nedge.edge = edge;
 87654:             nedge.jumpTableEntry = &jumpVec[i];
 87654:             chunkJumps.infallibleAppend(nedge);
 87654:             jumpVec[i] = NULL;
 87654:         }
 59979:     }
 59979: 
 59979:     /* Patch jump table references. */
 59979:     for (size_t i = 0; i < jumpTables.length(); i++) {
 59979:         JumpTable &jumpTable = jumpTables[i];
 59979:         fullCode.patch(jumpTable.label, &jumpVec[jumpTable.offsetIndex]);
 59979:     }
 59979: 
 52613:     /* Patch all outgoing calls. */
 76194:     masm.finalize(fullCode, inlineDoubles);
 76194:     stubcc.masm.finalize(stubCode, oolDoubles);
 52611: 
 52611:     JSC::ExecutableAllocator::makeExecutable(result, masm.size() + stubcc.size());
 52611:     JSC::ExecutableAllocator::cacheFlush(result, masm.size() + stubcc.size());
 52611: 
 96957:     Probes::registerMJITCode(cx, chunk,
 86348:                              a,
 86348:                              (JSActiveFrame**) inlineFrames.begin(),
 80222:                              result, masm.size(),
 80222:                              result + masm.size(), stubcc.size());
 80222: 
 91569:     outerChunkRef().chunk = chunk;
 87654: 
 87654:     /* Patch all incoming and outgoing cross-chunk jumps. */
 87654:     CrossChunkEdge *crossEdges = jit->edges();
 87654:     for (unsigned i = 0; i < jit->nedges; i++) {
 87654:         CrossChunkEdge &edge = crossEdges[i];
 87654:         if (bytecodeInChunk(outerScript->code + edge.source)) {
 87654:             JS_ASSERT(!edge.sourceJump1 && !edge.sourceJump2);
 87654:             void *label = edge.targetLabel ? edge.targetLabel : edge.shimLabel;
 87654:             CodeLocationLabel targetLabel(label);
 87654:             JSOp op = JSOp(script->code[edge.source]);
 87654:             if (op == JSOP_TABLESWITCH) {
 87654:                 if (edge.jumpTableEntries)
 87654:                     cx->free_(edge.jumpTableEntries);
 87654:                 CrossChunkEdge::JumpTableEntryVector *jumpTableEntries = NULL;
 87654:                 bool failed = false;
 87654:                 for (unsigned j = 0; j < chunkJumps.length(); j++) {
 87654:                     ChunkJumpTableEdge nedge = chunkJumps[j];
 87654:                     if (nedge.edge.source == edge.source && nedge.edge.target == edge.target) {
 87654:                         if (!jumpTableEntries) {
 89972:                             jumpTableEntries = OffTheBooks::new_<CrossChunkEdge::JumpTableEntryVector>();
 87654:                             if (!jumpTableEntries)
 87654:                                 failed = true;
 87654:                         }
 87654:                         if (!jumpTableEntries->append(nedge.jumpTableEntry))
 87654:                             failed = true;
 87654:                         *nedge.jumpTableEntry = label;
 87654:                     }
 87654:                 }
 87654:                 if (failed) {
 87654:                     execPool->release();
 87654:                     cx->free_(chunk);
 87654:                     js_ReportOutOfMemory(cx);
 87654:                     return Compile_Error;
 87654:                 }
 87654:                 edge.jumpTableEntries = jumpTableEntries;
 87654:             }
 87654:             for (unsigned j = 0; j < chunkEdges.length(); j++) {
 87654:                 const OutgoingChunkEdge &oedge = chunkEdges[j];
 87654:                 if (oedge.source == edge.source && oedge.target == edge.target) {
 87654:                     /*
 87654:                      * Only a single edge needs to be patched; we ensured while
 87654:                      * generating chunks that no two cross chunk edges can have
 87654:                      * the same source and target. Note that there may not be
 87654:                      * an edge to patch, if constant folding determined the
 87654:                      * jump is never taken.
 87654:                      */
 87654:                     edge.sourceJump1 = fullCode.locationOf(oedge.fastJump).executableAddress();
 87654:                     if (oedge.slowJump.isSet()) {
 87654:                         edge.sourceJump2 =
 87654:                             stubCode.locationOf(oedge.slowJump.get()).executableAddress();
 90435:                     }
 90435: #ifdef JS_CPU_X64
 90435:                     edge.sourceTrampoline =
 90435:                         stubCode.locationOf(oedge.sourceTrampoline).executableAddress();
 90435: #endif
 90435:                     jit->patchEdge(edge, label);
 87654:                     break;
 87654:                 }
 87654:             }
 87654:         } else if (bytecodeInChunk(outerScript->code + edge.target)) {
 87654:             JS_ASSERT(!edge.targetLabel);
 87654:             JS_ASSERT(jumpMap[edge.target].isSet());
 87654:             edge.targetLabel = fullCode.locationOf(jumpMap[edge.target]).executableAddress();
 87654:             jit->patchEdge(edge, edge.targetLabel);
 87654:         }
 87654:     }
 53168: 
 52611:     return Compile_Okay;
 52611: }
 52611: 
 52776: #ifdef DEBUG
 52776: #define SPEW_OPCODE()                                                         \
 52776:     JS_BEGIN_MACRO                                                            \
 52776:         if (IsJaegerSpewChannelActive(JSpew_JSOps)) {                         \
 87952:             Sprinter sprinter(cx);                                            \
 87952:             sprinter.init();                                                  \
 52776:             js_Disassemble1(cx, script, PC, PC - script->code,                \
 64374:                             JS_TRUE, &sprinter);                              \
 80567:             JaegerSpew(JSpew_JSOps, "    %2d %s",                             \
 87952:                        frame.stackDepth(), sprinter.string());                \
 52776:         }                                                                     \
 52776:     JS_END_MACRO;
 52776: #else
 52776: #define SPEW_OPCODE()
 52776: #endif /* DEBUG */
 52776: 
 52560: #define BEGIN_CASE(name)        case name:
 52560: #define END_CASE(name)                      \
 52560:     JS_BEGIN_MACRO                          \
 52560:         PC += name##_LENGTH;                \
 52560:     JS_END_MACRO;                           \
 52560:     break;
 52560: 
 76194: static inline void
 76194: FixDouble(Value &val)
 76194: {
 76194:     if (val.isInt32())
 76194:         val.setDouble((double)val.toInt32());
 76194: }
 76194: 
 87654: inline bool
 87654: mjit::Compiler::shouldStartLoop(jsbytecode *head)
 87654: {
 87654:     /*
 87654:      * Don't do loop based optimizations or register allocation for loops which
 87654:      * span multiple chunks.
 87654:      */
 87654:     if (*head == JSOP_LOOPHEAD && analysis->getLoop(head)) {
 87654:         uint32_t backedge = analysis->getLoop(head)->backedge;
 87654:         if (!bytecodeInChunk(script->code + backedge))
 87654:             return false;
 87654:         return true;
 87654:     }
 87654:     return false;
 87654: }
 87654: 
 52558: CompileStatus
 52558: mjit::Compiler::generateMethod()
 52558: {
 80222:     SrcNoteLineScanner scanner(script->notes(), script->lineno);
 52558: 
 76194:     /* For join points, whether there was fallthrough from the previous opcode. */
 76194:     bool fallthrough = true;
 76194: 
 77407:     /* Last bytecode processed. */
 77407:     jsbytecode *lastPC = NULL;
 77407: 
 87654:     if (!outerJIT())
 87654:         return Compile_Retry;
 87654: 
 87654:     uint32_t chunkBegin = 0, chunkEnd = script->length;
 87654:     if (!a->parent) {
 87654:         const ChunkDescriptor &desc =
 87654:             outerJIT()->chunkDescriptor(chunkIndex);
 87654:         chunkBegin = desc.begin;
 87654:         chunkEnd = desc.end;
 87654: 
 87654:         while (PC != script->code + chunkBegin) {
 87654:             Bytecode *opinfo = analysis->maybeCode(PC);
 87654:             if (opinfo) {
 87654:                 if (opinfo->jumpTarget) {
 87654:                     /* Update variable types for all new values at this bytecode. */
 87654:                     const SlotValue *newv = analysis->newValues(PC);
 87654:                     if (newv) {
 87654:                         while (newv->slot) {
 87654:                             if (newv->slot < TotalSlots(script)) {
 87654:                                 VarType &vt = a->varTypes[newv->slot];
 87654:                                 vt.setTypes(analysis->getValueTypes(newv->value));
 87654:                             }
 87654:                             newv++;
 87654:                         }
 87654:                     }
 87654:                 }
 87654:                 if (analyze::BytecodeUpdatesSlot(JSOp(*PC))) {
 87654:                     uint32_t slot = GetBytecodeSlot(script, PC);
 87654:                     if (analysis->trackSlot(slot)) {
 87654:                         VarType &vt = a->varTypes[slot];
 87654:                         vt.setTypes(analysis->pushedTypes(PC, 0));
 87654:                     }
 87654:                 }
 87654:             }
 87654: 
 87654:             PC += GetBytecodeLength(PC);
 87654:         }
 87654: 
 87654:         if (chunkIndex != 0) {
 87654:             uint32_t depth = analysis->getCode(PC).stackDepth;
 87654:             for (uint32_t i = 0; i < depth; i++)
 87654:                 frame.pushSynced(JSVAL_TYPE_UNKNOWN);
 87654:         }
 87654:     }
 87654: 
 52558:     for (;;) {
 52558:         JSOp op = JSOp(*PC);
 59882:         int trap = stubs::JSTRAP_NONE;
 84195: 
 84195:         if (script->hasBreakpointsAt(PC))
 59882:             trap |= stubs::JSTRAP_TRAP;
 53168: 
 76194:         Bytecode *opinfo = analysis->maybeCode(PC);
 56602: 
 56602:         if (!opinfo) {
 52558:             if (op == JSOP_STOP)
 52558:                 break;
 52558:             if (js_CodeSpec[op].length != -1)
 52558:                 PC += js_CodeSpec[op].length;
 52558:             else
 52558:                 PC += js_GetVariableBytecodeLength(PC);
 52558:             continue;
 52558:         }
 52558: 
 87654:         if (PC >= script->code + script->length)
 87654:             break;
 87654: 
 80222:         scanner.advanceTo(PC - script->code);
 80222:         if (script->stepModeEnabled() &&
 80222:             (scanner.isLineHeader() || opinfo->jumpTarget))
 80222:         {
 80222:             trap |= stubs::JSTRAP_SINGLESTEP;
 80222:         }
 80222: 
 76194:         frame.setPC(PC);
 56602:         frame.setInTryBlock(opinfo->inTryBlock);
 76194: 
 76194:         if (fallthrough) {
 76194:             /*
 76194:              * If there is fallthrough from the previous opcode and we changed
 76194:              * any entries into doubles for a branch at that previous op,
 77457:              * revert those entries into integers. Similarly, if we forgot that
 77457:              * an entry is a double then make it a double again, as the frame
 77457:              * may have assigned it a normal register.
 76194:              */
 77457:             for (unsigned i = 0; i < fixedIntToDoubleEntries.length(); i++) {
 77457:                 FrameEntry *fe = frame.getSlotEntry(fixedIntToDoubleEntries[i]);
 76194:                 frame.ensureInteger(fe);
 76194:             }
 77457:             for (unsigned i = 0; i < fixedDoubleToAnyEntries.length(); i++) {
 77457:                 FrameEntry *fe = frame.getSlotEntry(fixedDoubleToAnyEntries[i]);
 77457:                 frame.syncAndForgetFe(fe);
 77457:             }
 77457:         }
 77457:         fixedIntToDoubleEntries.clear();
 77457:         fixedDoubleToAnyEntries.clear();
 76194: 
 87654:         if (PC >= script->code + chunkEnd) {
 87654:             if (fallthrough) {
 87980:                 if (opinfo->jumpTarget)
 87980:                     fixDoubleTypes(PC);
 87654:                 frame.syncAndForgetEverything();
 87654:                 jsbytecode *curPC = PC;
 87654:                 do {
 87654:                     PC--;
 87654:                 } while (!analysis->maybeCode(PC));
 87654:                 if (!jumpAndRun(masm.jump(), curPC, NULL, NULL, /* fallthrough = */ true))
 87654:                     return Compile_Error;
 87654:                 PC = curPC;
 87654:             }
 87654:             break;
 87654:         }
 87654: 
 56602:         if (opinfo->jumpTarget || trap) {
 76194:             if (fallthrough) {
 76194:                 fixDoubleTypes(PC);
 77457:                 fixedIntToDoubleEntries.clear();
 77457:                 fixedDoubleToAnyEntries.clear();
 76194: 
 76194:                 /*
 76194:                  * Watch for fallthrough to the head of a 'do while' loop.
 76194:                  * We don't know what register state we will be using at the head
 76194:                  * of the loop so sync, branch, and fix it up after the loop
 76194:                  * has been processed.
 76194:                  */
 87654:                 if (cx->typeInferenceEnabled() && shouldStartLoop(PC)) {
 76194:                     frame.syncAndForgetEverything();
 76194:                     Jump j = masm.jump();
 76194:                     if (!startLoop(PC, j, PC))
 76194:                         return Compile_Error;
 76194:                 } else {
 77407:                     Label start = masm.label();
 76194:                     if (!frame.syncForBranch(PC, Uses(0)))
 76194:                         return Compile_Error;
 82134:                     if (pcLengths && lastPC) {
 77407:                         /* Track this sync code for the previous op. */
 77407:                         size_t length = masm.size() - masm.distanceOf(start);
 84755:                         uint32_t offset = ssa.frameLength(a->inlineIndex) + lastPC - script->code;
 77407:                         pcLengths[offset].codeLength += length;
 77407:                     }
 76194:                     JS_ASSERT(frame.consistentRegisters(PC));
 76194:                 }
 76194:             }
 76194: 
 76194:             if (!frame.discardForJoin(analysis->getAllocation(PC), opinfo->stackDepth))
 76194:                 return Compile_Error;
 76194:             updateJoinVarTypes();
 76194:             fallthrough = true;
 76194: 
 76194:             if (!cx->typeInferenceEnabled()) {
 76194:                 /* All join points have synced state if we aren't doing cross-branch regalloc. */
 56602:                 opinfo->safePoint = true;
 56602:             }
 87654:         } else if (opinfo->safePoint) {
 79910:             frame.syncAndForgetEverything();
 76194:         }
 76194:         frame.assertValidRegisterState();
 84755:         a->jumpMap[uint32_t(PC - script->code)] = masm.label();
 76766: 
 97796:         if (cx->typeInferenceEnabled() && opinfo->safePoint) {
 97796:             /*
 97796:              * We may have come in from a table switch, which does not watch
 97796:              * for the new types introduced for variables at each dispatch
 97796:              * target. Make sure that new SSA values at this safe point with
 97796:              * double type have the correct in memory representation.
 97796:              */
 97796:             const SlotValue *newv = analysis->newValues(PC);
 97796:             if (newv) {
 97796:                 while (newv->slot) {
 97796:                     if (newv->value.kind() == SSAValue::PHI &&
 97796:                         newv->value.phiOffset() == uint32_t(PC - script->code) &&
 97796:                         analysis->trackSlot(newv->slot) &&
 97796:                         a->varTypes[newv->slot].getTypeTag(cx) == JSVAL_TYPE_DOUBLE) {
 97796:                         FrameEntry *fe = frame.getSlotEntry(newv->slot);
 97796:                         masm.ensureInMemoryDouble(frame.addressOf(fe));
 97796:                     }
 97796:                     newv++;
 97796:                 }
 97796:             }
 97796:         }
 97796: 
 77452:         // Now that we have the PC's register allocation, make sure it gets
 77452:         // explicitly updated if this is the loop entry and new loop registers
 77452:         // are allocated later on.
 77452:         if (loop && !a->parent)
 77452:             loop->setOuterPC(PC);
 56602: 
 52776:         SPEW_OPCODE();
 56602:         JS_ASSERT(frame.stackDepth() == opinfo->stackDepth);
 56602: 
 87654:         if (op == JSOP_LOOPHEAD && analysis->getLoop(PC)) {
 87654:             jsbytecode *backedge = script->code + analysis->getLoop(PC)->backedge;
 87654:             if (!bytecodeInChunk(backedge)){
 87654:                 for (uint32_t slot = ArgSlot(0); slot < TotalSlots(script); slot++) {
 87654:                     if (a->varTypes[slot].getTypeTag(cx) == JSVAL_TYPE_DOUBLE) {
 87654:                         FrameEntry *fe = frame.getSlotEntry(slot);
 87654:                         masm.ensureInMemoryDouble(frame.addressOf(fe));
 87654:                     }
 87654:                 }
 87654:             }
 87654:         }
 87654: 
 77167:         // If this is an exception entry point, then jsl_InternalThrow has set
 77167:         // VMFrame::fp to the correct fp for the entry point. We need to copy
 77167:         // that value here to FpReg so that FpReg also has the correct sp.
 77167:         // Otherwise, we would simply be using a stale FpReg value.
 77360:         if (op == JSOP_ENTERBLOCK && analysis->getCode(PC).exceptionEntry)
 76194:             masm.loadPtr(FrameAddress(VMFrame::offsetOfFp), JSFrameReg);
 77167: 
 56602:         if (trap) {
 53168:             prepareStubCall(Uses(0));
 59882:             masm.move(Imm32(trap), Registers::ArgReg1);
 76194:             Call cl = emitStubCall(JS_FUNC_TO_DATA_PTR(void *, stubs::Trap), NULL);
 76194:             InternalCallSite site(masm.callReturnOffset(cl), a->inlineIndex, PC,
 76194:                                   REJOIN_TRAP, false);
 57766:             addCallSite(site);
 73894:         }
 73894: 
 77357:         /* Don't compile fat opcodes, run the decomposed version instead. */
 77357:         if (js_CodeSpec[op].format & JOF_DECOMPOSE) {
 77357:             PC += js_CodeSpec[op].length;
 77357:             continue;
 74457:         }
 74457: 
 77407:         Label codeStart = masm.label();
 94574:         bool countsUpdated = false;
 82134:         bool arithUpdated = false;
 82134: 
 82134:         JSValueType arithFirstUseType = JSVAL_TYPE_UNKNOWN;
 82134:         JSValueType arithSecondUseType = JSVAL_TYPE_UNKNOWN;
 95113:         if (script->hasScriptCounts && !!(js_CodeSpec[op].format & JOF_ARITH)) {
 82134:             if (GetUseCount(script, PC - script->code) == 1) {
 82134:                 FrameEntry *use = frame.peek(-1);
 82134:                 /*
 82134:                  * Pretend it's a binary operation and the second operand has
 82134:                  * the same type as the first one.
 82134:                  */
 82134:                 if (use->isTypeKnown())
 82134:                     arithFirstUseType = arithSecondUseType = use->getKnownType();
 82134:             } else {
 82134:                 FrameEntry *use = frame.peek(-1);
 82134:                 if (use->isTypeKnown())
 82134:                     arithFirstUseType = use->getKnownType();
 82134:                 use = frame.peek(-2);
 82134:                 if (use->isTypeKnown())
 82134:                     arithSecondUseType = use->getKnownType();
 82134:             }
 82134:         }
 77407: 
 77407:         /*
 94574:          * Update PC counts for jump opcodes at their start, so that we don't
 77407:          * miss them when taking the jump. This is delayed for other opcodes,
 77407:          * as we want to skip updating for ops we didn't generate any code for.
 77407:          */
 95113:         if (script->hasScriptCounts && JOF_OPTYPE(op) == JOF_JUMP)
 94574:             updatePCCounts(PC, &codeStart, &countsUpdated);
 53168: 
 52560:     /**********************
 52560:      * BEGIN COMPILER OPS *
 52560:      **********************/
 52560: 
 77407:         lastPC = PC;
 76194: 
 52558:         switch (op) {
 52647:           BEGIN_CASE(JSOP_NOP)
 52647:           END_CASE(JSOP_NOP)
 52647: 
 84493:           BEGIN_CASE(JSOP_UNDEFINED)
 53081:             frame.push(UndefinedValue());
 84493:           END_CASE(JSOP_UNDEFINED)
 52769: 
 52662:           BEGIN_CASE(JSOP_POPV)
 52806:           BEGIN_CASE(JSOP_SETRVAL)
 52662:           {
 54832:             RegisterID reg = frame.allocReg();
 54832:             masm.load32(FrameFlagsAddress(), reg);
 69223:             masm.or32(Imm32(StackFrame::HAS_RVAL), reg);
 54832:             masm.store32(reg, FrameFlagsAddress());
 54832:             frame.freeReg(reg);
 54832: 
 76194:             /* Scripts which write to the frame's return slot aren't inlined. */
 76194:             JS_ASSERT(a == outer);
 76194: 
 52662:             FrameEntry *fe = frame.peek(-1);
 69223:             frame.storeTo(fe, Address(JSFrameReg, StackFrame::offsetOfReturnValue()), true);
 52662:             frame.pop();
 52662:           }
 52662:           END_CASE(JSOP_POPV)
 52662: 
 52650:           BEGIN_CASE(JSOP_RETURN)
 95113:             if (script->hasScriptCounts)
 94574:                 updatePCCounts(PC, &codeStart, &countsUpdated);
 54832:             emitReturn(frame.peek(-1));
 76194:             fallthrough = false;
 52650:           END_CASE(JSOP_RETURN)
 52650: 
 52599:           BEGIN_CASE(JSOP_GOTO)
 64230:           BEGIN_CASE(JSOP_DEFAULT)
 52599:           {
 76194:             unsigned targetOffset = FollowBranch(cx, script, PC - script->code);
 76194:             jsbytecode *target = script->code + targetOffset;
 76194: 
 76194:             fixDoubleTypes(target);
 76194: 
 76194:             /*
 76194:              * Watch for gotos which are entering a 'for' or 'while' loop.
 76194:              * These jump to the loop condition test and are immediately
 76194:              * followed by the head of the loop.
 76194:              */
 77438:             jsbytecode *next = PC + js_CodeSpec[op].length;
 87654:             if (cx->typeInferenceEnabled() &&
 87654:                 analysis->maybeCode(next) &&
 87654:                 shouldStartLoop(next))
 87654:             {
 54719:                 frame.syncAndForgetEverything();
 52599:                 Jump j = masm.jump();
 76194:                 if (!startLoop(next, j, target))
 56766:                     return Compile_Error;
 76194:             } else {
 76194:                 if (!frame.syncForBranch(target, Uses(0)))
 76194:                     return Compile_Error;
 76194:                 Jump j = masm.jump();
 82738:                 if (!jumpAndRun(j, target))
 76194:                     return Compile_Error;
 76194:             }
 76194:             fallthrough = false;
 77438:             PC += js_CodeSpec[op].length;
 77438:             break;
 52599:           }
 52599:           END_CASE(JSOP_GOTO)
 52599: 
 52686:           BEGIN_CASE(JSOP_IFEQ)
 52686:           BEGIN_CASE(JSOP_IFNE)
 86877:           {
 86877:             jsbytecode *target = PC + GET_JUMP_OFFSET(PC);
 76194:             fixDoubleTypes(target);
 76194:             if (!jsop_ifneq(op, target))
 56766:                 return Compile_Error;
 77438:             PC += js_CodeSpec[op].length;
 77438:             break;
 76194:           }
 52737:           END_CASE(JSOP_IFNE)
 52737: 
 52778:           BEGIN_CASE(JSOP_ARGUMENTS)
 95100:             if (script->needsArgsObj()) {
 95100:                 prepareStubCall(Uses(0));
 95100:                 INLINE_STUBCALL(stubs::Arguments, REJOIN_FALLTHROUGH);
 76194:                 pushSyncedEntry(0);
 93251:             } else {
 93251:                 frame.push(MagicValue(JS_OPTIMIZED_ARGUMENTS));
 93251:             }
 52778:           END_CASE(JSOP_ARGUMENTS)
 52778: 
 74052:           BEGIN_CASE(JSOP_ITERNEXT)
 77824:             iterNext(GET_INT8(PC));
 74052:           END_CASE(JSOP_ITERNEXT)
 52686: 
 52714:           BEGIN_CASE(JSOP_DUP)
 52714:             frame.dup();
 52714:           END_CASE(JSOP_DUP)
 52714: 
 52715:           BEGIN_CASE(JSOP_DUP2)
 52715:             frame.dup2();
 52715:           END_CASE(JSOP_DUP2)
 52715: 
 77357:           BEGIN_CASE(JSOP_SWAP)
 77357:             frame.dup2();
 77357:             frame.shift(-3);
 77357:             frame.shift(-1);
 77357:           END_CASE(JSOP_SWAP)
 77357: 
 77357:           BEGIN_CASE(JSOP_PICK)
 77357:           {
 87974:             uint32_t amt = GET_UINT8(PC);
 77357: 
 77357:             // Push -(amt + 1), say amt == 2
 77357:             // Stack before: X3 X2 X1
 77357:             // Stack after:  X3 X2 X1 X3
 87974:             frame.dupAt(-int32_t(amt + 1));
 77357: 
 77357:             // For each item X[i...1] push it then move it down.
 77357:             // The above would transition like so:
 77357:             //   X3 X2 X1 X3 X2 (dupAt)
 77357:             //   X2 X2 X1 X3    (shift)
 77357:             //   X2 X2 X1 X3 X1 (dupAt)
 77357:             //   X2 X1 X1 X3    (shift)
 87974:             for (int32_t i = -int32_t(amt); i < 0; i++) {
 77357:                 frame.dupAt(i - 1);
 77357:                 frame.shift(i - 2);
 77357:             }
 77357: 
 77357:             // The stack looks like:
 77357:             // Xn ... X1 X1 X{n+1}
 77357:             // So shimmy the last value down.
 77357:             frame.shimmy(1);
 77357:           }
 77357:           END_CASE(JSOP_PICK)
 77357: 
 52721:           BEGIN_CASE(JSOP_BITOR)
 52718:           BEGIN_CASE(JSOP_BITXOR)
 52685:           BEGIN_CASE(JSOP_BITAND)
 52685:             jsop_bitop(op);
 52685:           END_CASE(JSOP_BITAND)
 52685: 
 52651:           BEGIN_CASE(JSOP_LT)
 52651:           BEGIN_CASE(JSOP_LE)
 52651:           BEGIN_CASE(JSOP_GT)
 52651:           BEGIN_CASE(JSOP_GE)
 52679:           BEGIN_CASE(JSOP_EQ)
 52679:           BEGIN_CASE(JSOP_NE)
 52651:           {
 95113:            if (script->hasScriptCounts) {
 94574:                updateArithCounts(PC, NULL, arithFirstUseType, arithSecondUseType);
 82134:                arithUpdated = true;
 82134:            }
 82134: 
 52652:             /* Detect fusions. */
 52652:             jsbytecode *next = &PC[JSOP_GE_LENGTH];
 52652:             JSOp fused = JSOp(*next);
 56602:             if ((fused != JSOP_IFEQ && fused != JSOP_IFNE) || analysis->jumpTarget(next))
 52651:                 fused = JSOP_NOP;
 52652: 
 52652:             /* Get jump target, if any. */
 52652:             jsbytecode *target = NULL;
 76194:             if (fused != JSOP_NOP) {
 95113:                 if (script->hasScriptCounts)
 94574:                     updatePCCounts(PC, &codeStart, &countsUpdated);
 52652:                 target = next + GET_JUMP_OFFSET(next);
 76194:                 fixDoubleTypes(target);
 76194:             }
 52651: 
 52652:             BoolStub stub = NULL;
 52652:             switch (op) {
 52652:               case JSOP_LT:
 52652:                 stub = stubs::LessThan;
 52652:                 break;
 52652:               case JSOP_LE:
 52652:                 stub = stubs::LessEqual;
 52652:                 break;
 52652:               case JSOP_GT:
 52652:                 stub = stubs::GreaterThan;
 52652:                 break;
 52652:               case JSOP_GE:
 52652:                 stub = stubs::GreaterEqual;
 52652:                 break;
 52679:               case JSOP_EQ:
 52679:                 stub = stubs::Equal;
 52679:                 break;
 52679:               case JSOP_NE:
 52679:                 stub = stubs::NotEqual;
 52679:                 break;
 52652:               default:
 52652:                 JS_NOT_REACHED("WAT");
 52652:                 break;
 52652:             }
 52653: 
 76194:             /*
 76194:              * We need to ensure in the target case that we always rejoin
 76194:              * before the rval test. In the non-target case we will rejoin
 76194:              * correctly after the op finishes.
 76194:              */
 76194: 
 52653:             FrameEntry *rhs = frame.peek(-1);
 52653:             FrameEntry *lhs = frame.peek(-2);
 52653: 
 52653:             /* Check for easy cases that the parser does not constant fold. */
 52653:             if (lhs->isConstant() && rhs->isConstant()) {
 52653:                 /* Primitives can be trivially constant folded. */
 52653:                 const Value &lv = lhs->getValue();
 52653:                 const Value &rv = rhs->getValue();
 52653: 
 52653:                 if (lv.isPrimitive() && rv.isPrimitive()) {
 52653:                     bool result = compareTwoValues(cx, op, lv, rv);
 52653: 
 52652:                     frame.pop();
 52652:                     frame.pop();
 52652: 
 52652:                     if (!target) {
 53081:                         frame.push(Value(BooleanValue(result)));
 52652:                     } else {
 52653:                         if (fused == JSOP_IFEQ)
 52653:                             result = !result;
 76194:                         if (!constantFoldBranch(target, result))
 56766:                             return Compile_Error;
 52652:                     }
 52652:                 } else {
 56766:                     if (!emitStubCmpOp(stub, target, fused))
 56766:                         return Compile_Error;
 52653:                 }
 52653:             } else {
 52651:                 /* Anything else should go through the fast path generator. */
 56766:                 if (!jsop_relational(op, stub, target, fused))
 56766:                     return Compile_Error;
 52651:             }
 52651: 
 52651:             /* Advance PC manually. */
 52679:             JS_STATIC_ASSERT(JSOP_LT_LENGTH == JSOP_GE_LENGTH);
 52679:             JS_STATIC_ASSERT(JSOP_LE_LENGTH == JSOP_GE_LENGTH);
 52679:             JS_STATIC_ASSERT(JSOP_GT_LENGTH == JSOP_GE_LENGTH);
 52679:             JS_STATIC_ASSERT(JSOP_EQ_LENGTH == JSOP_GE_LENGTH);
 52679:             JS_STATIC_ASSERT(JSOP_NE_LENGTH == JSOP_GE_LENGTH);
 52679: 
 52651:             PC += JSOP_GE_LENGTH;
 52776:             if (fused != JSOP_NOP) {
 52776:                 SPEW_OPCODE();
 52651:                 PC += JSOP_IFNE_LENGTH;
 52776:             }
 52651:             break;
 52651:           }
 52651:           END_CASE(JSOP_GE)
 52651: 
 52685:           BEGIN_CASE(JSOP_LSH)
 53230:             jsop_bitop(op);
 53230:           END_CASE(JSOP_LSH)
 53230: 
 52685:           BEGIN_CASE(JSOP_RSH)
 76194:             jsop_bitop(op);
 52685:           END_CASE(JSOP_RSH)
 52560: 
 52725:           BEGIN_CASE(JSOP_URSH)
 53581:             jsop_bitop(op);
 52725:           END_CASE(JSOP_URSH)
 52725: 
 52692:           BEGIN_CASE(JSOP_ADD)
 76194:             if (!jsop_binary(op, stubs::Add, knownPushedType(0), pushedTypeSet(0)))
 76194:                 return Compile_Retry;
 52692:           END_CASE(JSOP_ADD)
 52692: 
 52692:           BEGIN_CASE(JSOP_SUB)
 76194:             if (!jsop_binary(op, stubs::Sub, knownPushedType(0), pushedTypeSet(0)))
 76194:                 return Compile_Retry;
 52692:           END_CASE(JSOP_SUB)
 52692: 
 52692:           BEGIN_CASE(JSOP_MUL)
 76194:             if (!jsop_binary(op, stubs::Mul, knownPushedType(0), pushedTypeSet(0)))
 76194:                 return Compile_Retry;
 52692:           END_CASE(JSOP_MUL)
 52692: 
 52692:           BEGIN_CASE(JSOP_DIV)
 76194:             if (!jsop_binary(op, stubs::Div, knownPushedType(0), pushedTypeSet(0)))
 76194:                 return Compile_Retry;
 52692:           END_CASE(JSOP_DIV)
 52692: 
 52692:           BEGIN_CASE(JSOP_MOD)
 76194:             if (!jsop_mod())
 76194:                 return Compile_Retry;
 52692:           END_CASE(JSOP_MOD)
 52692: 
 52734:           BEGIN_CASE(JSOP_NOT)
 52734:             jsop_not();
 52734:           END_CASE(JSOP_NOT)
 52734: 
 52724:           BEGIN_CASE(JSOP_BITNOT)
 52724:           {
 52724:             FrameEntry *top = frame.peek(-1);
 52724:             if (top->isConstant() && top->getValue().isPrimitive()) {
 52724:                 int32_t i;
 84161:                 JS_ALWAYS_TRUE(ToInt32(cx, top->getValue(), &i));
 52724:                 i = ~i;
 52724:                 frame.pop();
 53081:                 frame.push(Int32Value(i));
 52724:             } else {
 52724:                 jsop_bitnot();
 52724:             }
 52724:           }
 52724:           END_CASE(JSOP_BITNOT)
 52724: 
 52713:           BEGIN_CASE(JSOP_NEG)
 52713:           {
 52713:             FrameEntry *top = frame.peek(-1);
 52713:             if (top->isConstant() && top->getValue().isPrimitive()) {
 52713:                 double d;
 73894:                 JS_ALWAYS_TRUE(ToNumber(cx, top->getValue(), &d));
 52713:                 d = -d;
 76194:                 Value v = NumberValue(d);
 76194: 
 76194:                 /* Watch for overflow in constant propagation. */
 76194:                 types::TypeSet *pushed = pushedTypeSet(0);
 77353:                 if (!v.isInt32() && pushed && !pushed->hasType(types::Type::DoubleType())) {
 77391:                     types::TypeScript::MonitorOverflow(cx, script, PC);
 76194:                     return Compile_Retry;
 76194:                 }
 76194: 
 52713:                 frame.pop();
 76194:                 frame.push(v);
 52713:             } else {
 52713:                 jsop_neg();
 52713:             }
 52713:           }
 52713:           END_CASE(JSOP_NEG)
 52713: 
 53039:           BEGIN_CASE(JSOP_POS)
 53039:             jsop_pos();
 53039:           END_CASE(JSOP_POS)
 53039: 
 54409:           BEGIN_CASE(JSOP_DELNAME)
 54409:           {
 90965:             uint32_t index = GET_UINT32_INDEX(PC);
 86542:             PropertyName *name = script->getName(index);
 54409: 
 54409:             prepareStubCall(Uses(0));
 86542:             masm.move(ImmPtr(name), Registers::ArgReg1);
 76194:             INLINE_STUBCALL(stubs::DelName, REJOIN_FALLTHROUGH);
 76194:             pushSyncedEntry(0);
 54409:           }
 54409:           END_CASE(JSOP_DELNAME)
 54409: 
 54406:           BEGIN_CASE(JSOP_DELPROP)
 54406:           {
 90965:             uint32_t index = GET_UINT32_INDEX(PC);
 86542:             PropertyName *name = script->getName(index);
 54406: 
 54406:             prepareStubCall(Uses(1));
 86542:             masm.move(ImmPtr(name), Registers::ArgReg1);
 76194:             INLINE_STUBCALL(STRICT_VARIANT(stubs::DelProp), REJOIN_FALLTHROUGH);
 54406:             frame.pop();
 76194:             pushSyncedEntry(0);
 54406:           }
 54406:           END_CASE(JSOP_DELPROP)
 54406: 
 54406:           BEGIN_CASE(JSOP_DELELEM)
 76194:           {
 54406:             prepareStubCall(Uses(2));
 76194:             INLINE_STUBCALL(STRICT_VARIANT(stubs::DelElem), REJOIN_FALLTHROUGH);
 54406:             frame.popn(2);
 76194:             pushSyncedEntry(0);
 76194:           }
 54406:           END_CASE(JSOP_DELELEM)
 54406: 
 52738:           BEGIN_CASE(JSOP_TYPEOF)
 52784:           BEGIN_CASE(JSOP_TYPEOFEXPR)
 52738:             jsop_typeof();
 52738:           END_CASE(JSOP_TYPEOF)
 52738: 
 52676:           BEGIN_CASE(JSOP_VOID)
 52676:             frame.pop();
 53081:             frame.push(UndefinedValue());
 52676:           END_CASE(JSOP_VOID)
 52676: 
 52741:           BEGIN_CASE(JSOP_GETPROP)
 86855:           BEGIN_CASE(JSOP_CALLPROP)
 76194:           BEGIN_CASE(JSOP_LENGTH)
 90965:             if (!jsop_getprop(script->getName(GET_UINT32_INDEX(PC)), knownPushedType(0)))
 56037:                 return Compile_Error;
 52741:           END_CASE(JSOP_GETPROP)
 52741: 
 52693:           BEGIN_CASE(JSOP_GETELEM)
 86855:           BEGIN_CASE(JSOP_CALLELEM)
 95113:             if (script->hasScriptCounts)
 94574:                 updateElemCounts(PC, frame.peek(-2), frame.peek(-1));
 86855:             if (!jsop_getelem())
 56037:                 return Compile_Error;
 52693:           END_CASE(JSOP_GETELEM)
 52693: 
 77357:           BEGIN_CASE(JSOP_TOID)
 77357:             jsop_toid();
 77357:           END_CASE(JSOP_TOID)
 77357: 
 52693:           BEGIN_CASE(JSOP_SETELEM)
 78413:           {
 95113:             if (script->hasScriptCounts)
 94574:                 updateElemCounts(PC, frame.peek(-3), frame.peek(-2));
 60164:             jsbytecode *next = &PC[JSOP_SETELEM_LENGTH];
 60164:             bool pop = (JSOp(*next) == JSOP_POP && !analysis->jumpTarget(next));
 60164:             if (!jsop_setelem(pop))
 57671:                 return Compile_Error;
 60164:           }
 52693:           END_CASE(JSOP_SETELEM);
 52693: 
 56556:           BEGIN_CASE(JSOP_EVAL)
 56775:           {
 56775:             JaegerSpew(JSpew_Insns, " --- EVAL --- \n");
 56775:             emitEval(GET_ARGC(PC));
 56775:             JaegerSpew(JSpew_Insns, " --- END EVAL --- \n");
 56775:           }
 56556:           END_CASE(JSOP_EVAL)
 56556: 
 52645:           BEGIN_CASE(JSOP_CALL)
 76194:           BEGIN_CASE(JSOP_NEW)
 57712:           BEGIN_CASE(JSOP_FUNAPPLY)
 57712:           BEGIN_CASE(JSOP_FUNCALL)
 52645:           {
 76194:             bool callingNew = (op == JSOP_NEW);
 76194: 
 76194:             bool done = false;
 77413:             if ((op == JSOP_CALL || op == JSOP_NEW) && !monitored(PC)) {
 76194:                 CompileStatus status = inlineNativeFunction(GET_ARGC(PC), callingNew);
 76194:                 if (status == Compile_Okay)
 76194:                     done = true;
 76194:                 else if (status != Compile_InlineAbort)
 76194:                     return status;
 76194:             }
 76194:             if (!done && inlining()) {
 76194:                 CompileStatus status = inlineScriptedFunction(GET_ARGC(PC), callingNew);
 76194:                 if (status == Compile_Okay)
 76194:                     done = true;
 76194:                 else if (status != Compile_InlineAbort)
 76194:                     return status;
 95113:                 if (script->hasScriptCounts) {
 77413:                     /* Code generated while inlining has been accounted for. */
 94574:                     updatePCCounts(PC, &codeStart, &countsUpdated);
 77413:                 }
 76194:             }
 76194: 
 76194:             FrameSize frameSize;
 76194:             frameSize.initStatic(frame.totalDepth(), GET_ARGC(PC));
 76194: 
 76194:             if (!done) {
 52648:                 JaegerSpew(JSpew_Insns, " --- SCRIPTED CALL --- \n");
 81078:                 if (!inlineCallHelper(GET_ARGC(PC), callingNew, frameSize))
 81078:                     return Compile_Error;
 52648:                 JaegerSpew(JSpew_Insns, " --- END SCRIPTED CALL --- \n");
 52645:             }
 76194:           }
 52645:           END_CASE(JSOP_CALL)
 52645: 
 52615:           BEGIN_CASE(JSOP_NAME)
 86855:           BEGIN_CASE(JSOP_CALLNAME)
 86752:           {
 90965:             PropertyName *name = script->getName(GET_UINT32_INDEX(PC));
 86855:             jsop_name(name, knownPushedType(0));
 86752:             frame.extra(frame.peek(-1)).name = name;
 86752:           }
 86752:           END_CASE(JSOP_NAME)
 86752: 
 86855:           BEGIN_CASE(JSOP_IMPLICITTHIS)
 86855:           {
 86855:             prepareStubCall(Uses(0));
 90965:             masm.move(ImmPtr(script->getName(GET_UINT32_INDEX(PC))), Registers::ArgReg1);
 86855:             INLINE_STUBCALL(stubs::ImplicitThis, REJOIN_FALLTHROUGH);
 86855:             frame.pushSynced(JSVAL_TYPE_UNKNOWN);
 86855:           }
 86855:           END_CASE(JSOP_IMPLICITTHIS)
 71340: 
 52605:           BEGIN_CASE(JSOP_DOUBLE)
 52605:           {
 90965:             double d = script->getConst(GET_UINT32_INDEX(PC)).toDouble();
 53081:             frame.push(Value(DoubleValue(d)));
 52605:           }
 52605:           END_CASE(JSOP_DOUBLE)
 52605: 
 52653:           BEGIN_CASE(JSOP_STRING)
 90965:             frame.push(StringValue(script->getAtom(GET_UINT32_INDEX(PC))));
 52653:           END_CASE(JSOP_STRING)
 52653: 
 52560:           BEGIN_CASE(JSOP_ZERO)
 78614:             frame.push(JSVAL_ZERO);
 52560:           END_CASE(JSOP_ZERO)
 52560: 
 52560:           BEGIN_CASE(JSOP_ONE)
 78614:             frame.push(JSVAL_ONE);
 52560:           END_CASE(JSOP_ONE)
 52560: 
 52675:           BEGIN_CASE(JSOP_NULL)
 53081:             frame.push(NullValue());
 52675:           END_CASE(JSOP_NULL)
 52675: 
 52704:           BEGIN_CASE(JSOP_THIS)
 52741:             jsop_this();
 52704:           END_CASE(JSOP_THIS)
 52704: 
 52666:           BEGIN_CASE(JSOP_FALSE)
 53081:             frame.push(Value(BooleanValue(false)));
 52666:           END_CASE(JSOP_FALSE)
 52666: 
 52665:           BEGIN_CASE(JSOP_TRUE)
 53081:             frame.push(Value(BooleanValue(true)));
 52665:           END_CASE(JSOP_TRUE)
 52665: 
 52733:           BEGIN_CASE(JSOP_OR)
 52733:           BEGIN_CASE(JSOP_AND)
 76194:           {
 76194:             jsbytecode *target = PC + GET_JUMP_OFFSET(PC);
 76194:             fixDoubleTypes(target);
 76194:             if (!jsop_andor(op, target))
 56766:                 return Compile_Error;
 76194:           }
 52733:           END_CASE(JSOP_AND)
 52733: 
 52794:           BEGIN_CASE(JSOP_TABLESWITCH)
 76194:             /*
 76194:              * Note: there is no need to syncForBranch for the various targets of
 76194:              * switch statement. The liveness analysis has already marked these as
 76194:              * allocated with no registers in use. There is also no need to fix
 76194:              * double types, as we don't track types of slots in scripts with
 76194:              * switch statements (could be fixed).
 76194:              */
 95113:             if (script->hasScriptCounts)
 94574:                 updatePCCounts(PC, &codeStart, &countsUpdated);
 59979: #if defined JS_CPU_ARM /* Need to implement jump(BaseIndex) for ARM */
 76194:             frame.syncAndKillEverything();
 52794:             masm.move(ImmPtr(PC), Registers::ArgReg1);
 53338: 
 54719:             /* prepareStubCall() is not needed due to syncAndForgetEverything() */
 87983:             INLINE_STUBCALL(stubs::TableSwitch, REJOIN_NONE);
 53338:             frame.pop();
 53338: 
 52794:             masm.jump(Registers::ReturnReg);
 59979: #else
 61233:             if (!jsop_tableswitch(PC))
 61233:                 return Compile_Error;
 59979: #endif
 52794:             PC += js_GetVariableBytecodeLength(PC);
 52794:             break;
 52794:           END_CASE(JSOP_TABLESWITCH)
 52794: 
 52793:           BEGIN_CASE(JSOP_LOOKUPSWITCH)
 95113:             if (script->hasScriptCounts)
 94574:                 updatePCCounts(PC, &codeStart, &countsUpdated);
 54719:             frame.syncAndForgetEverything();
 52793:             masm.move(ImmPtr(PC), Registers::ArgReg1);
 53338: 
 54719:             /* prepareStubCall() is not needed due to syncAndForgetEverything() */
 87983:             INLINE_STUBCALL(stubs::LookupSwitch, REJOIN_NONE);
 53338:             frame.pop();
 53338: 
 52793:             masm.jump(Registers::ReturnReg);
 52793:             PC += js_GetVariableBytecodeLength(PC);
 52793:             break;
 52793:           END_CASE(JSOP_LOOKUPSWITCH)
 52793: 
 64230:           BEGIN_CASE(JSOP_CASE)
 64230:             // X Y
 64230: 
 64230:             frame.dupAt(-2);
 64230:             // X Y X
 64230: 
 64230:             jsop_stricteq(JSOP_STRICTEQ);
 64230:             // X cond
 64230: 
 64230:             if (!jsop_ifneq(JSOP_IFNE, PC + GET_JUMP_OFFSET(PC)))
 64230:                 return Compile_Error;
 64230:           END_CASE(JSOP_CASE)
 64230: 
 52739:           BEGIN_CASE(JSOP_STRICTEQ)
 82134:           BEGIN_CASE(JSOP_STRICTNE)
 95113:             if (script->hasScriptCounts) {
 94574:                 updateArithCounts(PC, NULL, arithFirstUseType, arithSecondUseType);
 82134:                 arithUpdated = true;
 82134:             }
 52855:             jsop_stricteq(op);
 52739:           END_CASE(JSOP_STRICTEQ)
 52739: 
 52736:           BEGIN_CASE(JSOP_ITER)
 87974:             if (!iter(GET_UINT8(PC)))
 61055:                 return Compile_Error;
 52736:           END_CASE(JSOP_ITER)
 52736: 
 52737:           BEGIN_CASE(JSOP_MOREITER)
 76194:           {
 61055:             /* At the byte level, this is always fused with IFNE or IFNEX. */
 95113:             if (script->hasScriptCounts)
 94574:                 updatePCCounts(PC, &codeStart, &countsUpdated);
 76194:             jsbytecode *target = &PC[JSOP_MOREITER_LENGTH];
 76194:             JSOp next = JSOp(*target);
 86877:             JS_ASSERT(next == JSOP_IFNE);
 86877: 
 86877:             target += GET_JUMP_OFFSET(target);
 76194: 
 76194:             fixDoubleTypes(target);
 76194:             if (!iterMore(target))
 61055:                 return Compile_Error;
 76194:             PC += JSOP_MOREITER_LENGTH;
 76194:             PC += js_CodeSpec[next].length;
 60785:             break;
 76194:           }
 52737:           END_CASE(JSOP_MOREITER)
 52737: 
 52737:           BEGIN_CASE(JSOP_ENDITER)
 53404:             iterEnd();
 52737:           END_CASE(JSOP_ENDITER)
 52737: 
 52575:           BEGIN_CASE(JSOP_POP)
 52575:             frame.pop();
 52575:           END_CASE(JSOP_POP)
 52575: 
 52656:           BEGIN_CASE(JSOP_GETARG)
 52678:           BEGIN_CASE(JSOP_CALLARG)
 52656:           {
 76194:             restoreVarType();
 84755:             uint32_t arg = GET_SLOTNO(PC);
 76194:             if (JSObject *singleton = pushedSingleton(0))
 76194:                 frame.push(ObjectValue(*singleton));
 76194:             else
 76194:                 frame.pushArg(arg);
 52656:           }
 52656:           END_CASE(JSOP_GETARG)
 52656: 
 52825:           BEGIN_CASE(JSOP_BINDGNAME)
 52826:             jsop_bindgname();
 52825:           END_CASE(JSOP_BINDGNAME)
 52825: 
 52728:           BEGIN_CASE(JSOP_SETARG)
 57787:           {
 76194:             jsbytecode *next = &PC[JSOP_SETARG_LENGTH];
 57787:             bool pop = JSOp(*next) == JSOP_POP && !analysis->jumpTarget(next);
100006:             frame.storeArg(GET_SLOTNO(PC), pop);
 76194:             updateVarType();
 76194: 
 57787:             if (pop) {
 57787:                 frame.pop();
 57787:                 PC += JSOP_SETARG_LENGTH + JSOP_POP_LENGTH;
 57787:                 break;
 57787:             }
 57787:           }
 52728:           END_CASE(JSOP_SETARG)
 52728: 
100006:           BEGIN_CASE(JSOP_GETALIASEDVAR)
100006:           BEGIN_CASE(JSOP_CALLALIASEDVAR)
100006:           {
100006:             /* This is all temporary until bug 659577. */
100006:             if (JSObject *singleton = pushedSingleton(0)) {
100006:                 frame.push(ObjectValue(*singleton));
100006:             } else {
100006:                 ScopeCoordinate sc = ScopeCoordinate(PC);
100006:                 if (script->bindings.bindingIsArg(sc.binding))
100006:                     frame.pushArg(script->bindings.bindingToArg(sc.binding));
100006:                 else
100006:                     frame.pushLocal(script->bindings.bindingToLocal(sc.binding));
100006:             }
100006:           }
100006:           END_CASE(JSOP_GETALIASEDVAR)
100006: 
 99994:           BEGIN_CASE(JSOP_GETLOCAL)
 99994:           BEGIN_CASE(JSOP_CALLLOCAL)
100006:           {
100006: 
 76194:             /*
 76194:              * Update the var type unless we are about to pop the variable.
 76194:              * Sync is not guaranteed for types of dead locals, and GETLOCAL
 76194:              * followed by POP is not regarded as a use of the variable.
 76194:              */
 76194:             jsbytecode *next = &PC[JSOP_GETLOCAL_LENGTH];
 76194:             if (JSOp(*next) != JSOP_POP || analysis->jumpTarget(next))
 76194:                 restoreVarType();
100006:             uint32_t slot = GET_SLOTNO(PC);
 86855:             if (JSObject *singleton = pushedSingleton(0))
 86855:                 frame.push(ObjectValue(*singleton));
 86855:             else
100006:                 frame.pushLocal(slot);
100006:           }
100006:           END_CASE(JSOP_GETLOCAL)
100006: 
100006:           BEGIN_CASE(JSOP_SETALIASEDVAR)
100006:           {
100006:             /* This is all temporary until bug 659577. */
100006:             jsbytecode *next = &PC[JSOP_SETALIASEDVAR_LENGTH];
100006:             bool pop = JSOp(*next) == JSOP_POP && !analysis->jumpTarget(next);
100006:             ScopeCoordinate sc = ScopeCoordinate(PC);
100006:             if (script->bindings.bindingIsArg(sc.binding))
100006:                 frame.storeArg(script->bindings.bindingToArg(sc.binding), pop);
100006:             else
100006:                 frame.storeLocal(script->bindings.bindingToLocal(sc.binding), pop);
100006:             updateVarType();
100006: 
100006:             if (pop) {
100006:                 frame.pop();
100006:                 PC += JSOP_SETALIASEDVAR_LENGTH + JSOP_POP_LENGTH;
 99994:                 break;
 52670:             }
100006:           }
100006:           END_CASE(JSOP_SETALIASEDVAR)
 52670: 
 99994:           BEGIN_CASE(JSOP_SETLOCAL)
100006:           {
100006:             jsbytecode *next = &PC[JSOP_SETLOCAL_LENGTH];
 95101:             bool pop = JSOp(*next) == JSOP_POP && !analysis->jumpTarget(next);
 99994:             frame.storeLocal(GET_SLOTNO(PC), pop);
 95101:             updateVarType();
 95101: 
 95101:             if (pop) {
 95101:                 frame.pop();
100006:                 PC += JSOP_SETLOCAL_LENGTH + JSOP_POP_LENGTH;
 95101:                 break;
 95101:             }
 54719:           }
 54719:           END_CASE(JSOP_SETLOCAL)
 54719: 
 52575:           BEGIN_CASE(JSOP_UINT16)
 53081:             frame.push(Value(Int32Value((int32_t) GET_UINT16(PC))));
 52575:           END_CASE(JSOP_UINT16)
 52575: 
 52719:           BEGIN_CASE(JSOP_NEWINIT)
 76194:             if (!jsop_newinit())
 76194:                 return Compile_Error;
 52719:           END_CASE(JSOP_NEWINIT)
 52719: 
 58056:           BEGIN_CASE(JSOP_NEWARRAY)
 76194:             if (!jsop_newinit())
 76194:                 return Compile_Error;
 58056:           END_CASE(JSOP_NEWARRAY)
 58056: 
 58056:           BEGIN_CASE(JSOP_NEWOBJECT)
 76194:             if (!jsop_newinit())
 76194:                 return Compile_Error;
 58056:           END_CASE(JSOP_NEWOBJECT)
 58056: 
 52719:           BEGIN_CASE(JSOP_ENDINIT)
 52719:           END_CASE(JSOP_ENDINIT)
 52719: 
 52735:           BEGIN_CASE(JSOP_INITPROP)
 58056:             jsop_initprop();
 52735:             frame.pop();
 52735:           END_CASE(JSOP_INITPROP)
 52735: 
 52723:           BEGIN_CASE(JSOP_INITELEM)
 58056:             jsop_initelem();
 52723:             frame.popn(2);
 52723:           END_CASE(JSOP_INITELEM)
 52723: 
 52804:           BEGIN_CASE(JSOP_INCARG)
 52804:           BEGIN_CASE(JSOP_DECARG)
 52804:           BEGIN_CASE(JSOP_ARGINC)
 52804:           BEGIN_CASE(JSOP_ARGDEC)
 95113:             if (script->hasScriptCounts) {
 82134:                 restoreVarType();
 82134:                 FrameEntry *fe = frame.getArg(GET_SLOTNO(PC));
 82134:                 if (fe->isTypeKnown())
 82134:                     arithFirstUseType = fe->getKnownType();
 82134:             }
 82134: 
 76194:             if (!jsop_arginc(op, GET_SLOTNO(PC)))
 76194:                 return Compile_Retry;
 82134: 
 95113:             if (script->hasScriptCounts) {
 82134:                 FrameEntry *fe = frame.getArg(GET_SLOTNO(PC));
 94574:                 updateArithCounts(PC, fe, arithFirstUseType, JSVAL_TYPE_INT32);
 82134:                 arithUpdated = true;
 82134:             }
 52804:           END_CASE(JSOP_ARGDEC)
 52804: 
 52808:           BEGIN_CASE(JSOP_INCLOCAL)
 52808:           BEGIN_CASE(JSOP_DECLOCAL)
 52808:           BEGIN_CASE(JSOP_LOCALINC)
 52808:           BEGIN_CASE(JSOP_LOCALDEC)
 95113:             if (script->hasScriptCounts) {
 82134:                 restoreVarType();
 82134:                 FrameEntry *fe = frame.getLocal(GET_SLOTNO(PC));
 82134:                 if (fe->isTypeKnown())
 82134:                     arithFirstUseType = fe->getKnownType();
 82134:             }
 82134: 
 76194:             if (!jsop_localinc(op, GET_SLOTNO(PC)))
 76194:                 return Compile_Retry;
 82134: 
 95113:             if (script->hasScriptCounts) {
 82134:                 FrameEntry *fe = frame.getLocal(GET_SLOTNO(PC));
 94574:                 updateArithCounts(PC, fe, arithFirstUseType, JSVAL_TYPE_INT32);
 82134:                 arithUpdated = true;
 82134:             }
 52808:           END_CASE(JSOP_LOCALDEC)
 52808: 
 52560:           BEGIN_CASE(JSOP_BINDNAME)
 90965:             jsop_bindname(script->getName(GET_UINT32_INDEX(PC)));
 52560:           END_CASE(JSOP_BINDNAME)
 52560: 
 52886:           BEGIN_CASE(JSOP_SETPROP)
 78413:           {
 78413:             jsbytecode *next = &PC[JSOP_SETPROP_LENGTH];
 78413:             bool pop = JSOp(*next) == JSOP_POP && !analysis->jumpTarget(next);
 90965:             if (!jsop_setprop(script->getName(GET_UINT32_INDEX(PC)), pop))
 78413:                 return Compile_Error;
 78413:           }
 78413:           END_CASE(JSOP_SETPROP)
 78413: 
 52611:           BEGIN_CASE(JSOP_SETNAME)
 76194:           {
 78413:             jsbytecode *next = &PC[JSOP_SETNAME_LENGTH];
 76194:             bool pop = JSOp(*next) == JSOP_POP && !analysis->jumpTarget(next);
 90965:             if (!jsop_setprop(script->getName(GET_UINT32_INDEX(PC)), pop))
 56037:                 return Compile_Error;
 76194:           }
 52611:           END_CASE(JSOP_SETNAME)
 52611: 
 52772:           BEGIN_CASE(JSOP_THROW)
 53087:             prepareStubCall(Uses(1));
 76194:             INLINE_STUBCALL(stubs::Throw, REJOIN_NONE);
 52772:             frame.pop();
 82112:             fallthrough = false;
 52772:           END_CASE(JSOP_THROW)
 52772: 
 54413:           BEGIN_CASE(JSOP_IN)
 76194:           {
 88181:             jsop_in();
 76194:           }
 54413:           END_CASE(JSOP_IN)
 54413: 
 52780:           BEGIN_CASE(JSOP_INSTANCEOF)
 56037:             if (!jsop_instanceof())
 56037:                 return Compile_Error;
 52780:           END_CASE(JSOP_INSTANCEOF)
 52780: 
 52786:           BEGIN_CASE(JSOP_EXCEPTION)
 76194:           {
 60211:             prepareStubCall(Uses(0));
 76194:             INLINE_STUBCALL(stubs::Exception, REJOIN_FALLTHROUGH);
 76194:             frame.pushSynced(JSVAL_TYPE_UNKNOWN);
 76194:           }
 52786:           END_CASE(JSOP_EXCEPTION)
 52786: 
 52768:           BEGIN_CASE(JSOP_LINENO)
 52768:           END_CASE(JSOP_LINENO)
 52768: 
 56586:           BEGIN_CASE(JSOP_ENUMELEM)
 56586:             // Normally, SETELEM transforms the stack
 56586:             //  from: OBJ ID VALUE
 56586:             //  to:   VALUE
 56586:             //
 56586:             // Here, the stack transition is
 56586:             //  from: VALUE OBJ ID
 56586:             //  to:
 56586:             // So we make the stack look like a SETELEM, and re-use it.
 56586: 
 56586:             // Before: VALUE OBJ ID
 56586:             // After:  VALUE OBJ ID VALUE
 56586:             frame.dupAt(-3);
 56586: 
 56586:             // Before: VALUE OBJ ID VALUE
 56586:             // After:  VALUE VALUE
 60164:             if (!jsop_setelem(true))
 57671:                 return Compile_Error;
 56586: 
 56586:             // Before: VALUE VALUE
 56586:             // After:
 56586:             frame.popn(2);
 56586:           END_CASE(JSOP_ENUMELEM)
 56586: 
 54415:           BEGIN_CASE(JSOP_CONDSWITCH)
 54415:             /* No-op for the decompiler. */
 54415:           END_CASE(JSOP_CONDSWITCH)
 54415: 
 82079:           BEGIN_CASE(JSOP_LABEL)
 82079:           END_CASE(JSOP_LABEL)
 82079: 
 52647:           BEGIN_CASE(JSOP_DEFFUN)
 53591:           {
 89253:             JSFunction *innerFun = script->getFunction(GET_UINT32_INDEX(PC));
 59968: 
 53087:             prepareStubCall(Uses(0));
 59968:             masm.move(ImmPtr(innerFun), Registers::ArgReg1);
 76194:             INLINE_STUBCALL(STRICT_VARIANT(stubs::DefFun), REJOIN_FALLTHROUGH);
 53591:           }
 52647:           END_CASE(JSOP_DEFFUN)
 52647: 
 54408:           BEGIN_CASE(JSOP_DEFVAR)
 57795:           BEGIN_CASE(JSOP_DEFCONST)
 54408:           {
 90965:             PropertyName *name = script->getName(GET_UINT32_INDEX(PC));
 54408: 
 54408:             prepareStubCall(Uses(0));
 86542:             masm.move(ImmPtr(name), Registers::ArgReg1);
 76194:             INLINE_STUBCALL(stubs::DefVarOrConst, REJOIN_FALLTHROUGH);
 54408:           }
 54408:           END_CASE(JSOP_DEFVAR)
 54408: 
 57795:           BEGIN_CASE(JSOP_SETCONST)
 57795:           {
 90965:             PropertyName *name = script->getName(GET_UINT32_INDEX(PC));
 57795: 
 57795:             prepareStubCall(Uses(1));
 86542:             masm.move(ImmPtr(name), Registers::ArgReg1);
 76194:             INLINE_STUBCALL(stubs::SetConst, REJOIN_FALLTHROUGH);
 57795:           }
 57795:           END_CASE(JSOP_SETCONST)
 57795: 
 52730:           BEGIN_CASE(JSOP_LAMBDA)
 52730:           {
 89253:             JSFunction *fun = script->getFunction(GET_UINT32_INDEX(PC));
 53249: 
 53249:             JSObjStubFun stub = stubs::Lambda;
 84755:             uint32_t uses = 0;
 53249: 
 53249:             prepareStubCall(Uses(uses));
 52730:             masm.move(ImmPtr(fun), Registers::ArgReg1);
 53128: 
 76194:             INLINE_STUBCALL(stub, REJOIN_PUSH_OBJECT);
 53249: 
 52730:             frame.takeReg(Registers::ReturnReg);
 53025:             frame.pushTypedPayload(JSVAL_TYPE_OBJECT, Registers::ReturnReg);
 52730:           }
 52730:           END_CASE(JSOP_LAMBDA)
 52730: 
 52774:           BEGIN_CASE(JSOP_TRY)
 54719:             frame.syncAndForgetEverything();
 52774:           END_CASE(JSOP_TRY)
 52774: 
 52806:           BEGIN_CASE(JSOP_RETRVAL)
 54832:             emitReturn(NULL);
 82112:             fallthrough = false;
 52806:           END_CASE(JSOP_RETRVAL)
 52806: 
 52825:           BEGIN_CASE(JSOP_GETGNAME)
 52825:           BEGIN_CASE(JSOP_CALLGNAME)
 76194:           {
 90965:             uint32_t index = GET_UINT32_INDEX(PC);
 99781:             if (!jsop_getgname(index))
 99781:                 return Compile_Error;
 86542:             frame.extra(frame.peek(-1)).name = script->getName(index);
 76194:           }
 52825:           END_CASE(JSOP_GETGNAME)
 52825: 
 52825:           BEGIN_CASE(JSOP_SETGNAME)
 76194:           {
 76194:             jsbytecode *next = &PC[JSOP_SETGNAME_LENGTH];
 76194:             bool pop = JSOp(*next) == JSOP_POP && !analysis->jumpTarget(next);
 99781:             if (!jsop_setgname(script->getName(GET_UINT32_INDEX(PC)), pop))
 99781:                 return Compile_Error;
 76194:           }
 52825:           END_CASE(JSOP_SETGNAME)
 52825: 
 52729:           BEGIN_CASE(JSOP_REGEXP)
 80431:             if (!jsop_regexp())
 80431:                 return Compile_Error;
 52729:           END_CASE(JSOP_REGEXP)
 52729: 
 59962:           BEGIN_CASE(JSOP_OBJECT)
 59962:           {
 89253:             JSObject *object = script->getObject(GET_UINT32_INDEX(PC));
 59962:             RegisterID reg = frame.allocReg();
 59962:             masm.move(ImmPtr(object), reg);
 59962:             frame.pushTypedPayload(JSVAL_TYPE_OBJECT, reg);
 59962:           }
 59962:           END_CASE(JSOP_OBJECT)
 59962: 
 52575:           BEGIN_CASE(JSOP_UINT24)
 53081:             frame.push(Value(Int32Value((int32_t) GET_UINT24(PC))));
 52575:           END_CASE(JSOP_UINT24)
 52575: 
 52560:           BEGIN_CASE(JSOP_STOP)
 95113:             if (script->hasScriptCounts)
 94574:                 updatePCCounts(PC, &codeStart, &countsUpdated);
 54832:             emitReturn(NULL);
 52560:             goto done;
 52560:           END_CASE(JSOP_STOP)
 52560: 
 54847:           BEGIN_CASE(JSOP_GETXPROP)
 90965:             if (!jsop_xname(script->getName(GET_UINT32_INDEX(PC))))
 56037:                 return Compile_Error;
 54847:           END_CASE(JSOP_GETXPROP)
 54847: 
 52785:           BEGIN_CASE(JSOP_ENTERBLOCK)
 86078:           BEGIN_CASE(JSOP_ENTERLET0)
 86078:           BEGIN_CASE(JSOP_ENTERLET1)
 89253:             enterBlock(&script->getObject(GET_UINT32_INDEX(PC))->asStaticBlock());
 54840:           END_CASE(JSOP_ENTERBLOCK);
 52785: 
 52785:           BEGIN_CASE(JSOP_LEAVEBLOCK)
 54840:             leaveBlock();
 52785:           END_CASE(JSOP_LEAVEBLOCK)
 52785: 
 52575:           BEGIN_CASE(JSOP_INT8)
 53081:             frame.push(Value(Int32Value(GET_INT8(PC))));
 52575:           END_CASE(JSOP_INT8)
 52575: 
 52575:           BEGIN_CASE(JSOP_INT32)
 53081:             frame.push(Value(Int32Value(GET_INT32(PC))));
 52575:           END_CASE(JSOP_INT32)
 52575: 
 54415:           BEGIN_CASE(JSOP_HOLE)
 54415:             frame.push(MagicValue(JS_ARRAY_HOLE));
 54415:           END_CASE(JSOP_HOLE)
 54415: 
 83115:           BEGIN_CASE(JSOP_LOOPHEAD)
 52753:           {
 76194:             if (analysis->jumpTarget(PC)) {
 53223:                 interruptCheckHelper();
 76194:                 recompileCheckHelper();
 76194:             }
 52753:           }
 83115:           END_CASE(JSOP_LOOPHEAD)
 52617: 
 87961:           BEGIN_CASE(JSOP_LOOPENTRY)
 87961:           END_CASE(JSOP_LOOPENTRY)
 87961: 
 53395:           BEGIN_CASE(JSOP_DEBUGGER)
 76194:           {
 53395:             prepareStubCall(Uses(0));
 53396:             masm.move(ImmPtr(PC), Registers::ArgReg1);
 77434:             INLINE_STUBCALL(stubs::DebuggerStatement, REJOIN_FALLTHROUGH);
 76194:           }
 53395:           END_CASE(JSOP_DEBUGGER)
 53395: 
 52558:           default:
 90737:             JS_NOT_REACHED("Opcode not implemented");
 52558:         }
 52560: 
 52560:     /**********************
 52560:      *  END COMPILER OPS  *
 52560:      **********************/
 52578: 
 84195:         if (cx->typeInferenceEnabled() && PC == lastPC + GetBytecodeLength(lastPC)) {
 76194:             /*
 76194:              * Inform the frame of the type sets for values just pushed. Skip
 76194:              * this if we did any opcode fusions, we don't keep track of the
 76194:              * associated type sets in such cases.
 76194:              */
 77407:             unsigned nuses = GetUseCount(script, lastPC - script->code);
 77407:             unsigned ndefs = GetDefCount(script, lastPC - script->code);
 76194:             for (unsigned i = 0; i < ndefs; i++) {
 76194:                 FrameEntry *fe = frame.getStack(opinfo->stackDepth - nuses + i);
 76194:                 if (fe) {
 76194:                     /* fe may be NULL for conditionally pushed entries, e.g. JSOP_AND */
 77407:                     frame.extra(fe).types = analysis->pushedTypes(lastPC - script->code, i);
 77407:                 }
 77407:             }
 77407:         }
 77407: 
 95113:         if (script->hasScriptCounts) {
 77407:             size_t length = masm.size() - masm.distanceOf(codeStart);
 82134:             bool typesUpdated = false;
 82134: 
 82134:             /* Update information about the type of value pushed by arithmetic ops. */
 82134:             if ((js_CodeSpec[op].format & JOF_ARITH) && !arithUpdated) {
 82134:                 FrameEntry *pushed = NULL;
 84195:                 if (PC == lastPC + GetBytecodeLength(lastPC))
 82134:                     pushed = frame.peek(-1);
 94574:                 updateArithCounts(lastPC, pushed, arithFirstUseType, arithSecondUseType);
 82134:                 typesUpdated = true;
 82134:             }
 82134: 
 82134:             /* Update information about the result type of access operations. */
 94574:             if (PCCounts::accessOp(op) &&
 94227:                 op != JSOP_SETPROP && op != JSOP_SETELEM) {
 82134:                 FrameEntry *fe = (GetDefCount(script, lastPC - script->code) == 1)
 82134:                     ? frame.peek(-1)
 82134:                     : frame.peek(-2);
 82134:                 updatePCTypes(lastPC, fe);
 82134:                 typesUpdated = true;
 82134:             }
 82134: 
 94574:             if (countsUpdated || typesUpdated || length != 0) {
 94574:                 if (!countsUpdated)
 94574:                     updatePCCounts(lastPC, &codeStart, &countsUpdated);
 77407: 
 80222:                 if (pcLengths) {
 77407:                     /* Fill in the amount of inline code generated for the op. */
 84755:                     uint32_t offset = ssa.frameLength(a->inlineIndex) + lastPC - script->code;
 77407:                     pcLengths[offset].codeLength += length;
 76194:                 }
 76194:             }
 82134:         } else if (pcLengths) {
 82134:             /* Fill in the amount of inline code generated for the op. */
 82134:             size_t length = masm.size() - masm.distanceOf(codeStart);
 84755:             uint32_t offset = ssa.frameLength(a->inlineIndex) + lastPC - script->code;
 82134:             pcLengths[offset].codeLength += length;
 80222:         }
 76194: 
 52578:         frame.assertValidRegisterState();
 52558:     }
 52558: 
 52560:   done:
 52558:     return Compile_Okay;
 52558: }
 52558: 
 52560: #undef END_CASE
 52560: #undef BEGIN_CASE
 52560: 
 77407: void
 94574: mjit::Compiler::updatePCCounts(jsbytecode *pc, Label *start, bool *updated)
 94574: {
 95113:     JS_ASSERT(script->hasScriptCounts);
 82134: 
 77407:     /*
 77407:      * Bump the METHODJIT count for the opcode, read the METHODJIT_CODE_LENGTH
 77407:      * and METHODJIT_PICS_LENGTH counts, indicating the amounts of inline path
 77407:      * code and generated code, respectively, and add them to the accumulated
 77407:      * total for the op.
 77407:      */
 84755:     uint32_t offset = ssa.frameLength(a->inlineIndex) + pc - script->code;
 77407: 
 77407:     /*
 77407:      * Base register for addresses, we can't use AbsoluteAddress in all places.
 77407:      * This may hold a live value, so write it out to the top of the stack
 77407:      * first. This cannot overflow the stack, as space is always reserved for
 77407:      * an extra callee frame.
 77407:      */
 77407:     RegisterID reg = Registers::ReturnReg;
 77407:     masm.storePtr(reg, frame.addressOfTop());
 77407: 
 94574:     PCCounts counts = script->getPCCounts(pc);
 94574: 
 94574:     double *code = &counts.get(PCCounts::BASE_METHODJIT_CODE);
 77407:     double *codeLength = &pcLengths[offset].codeLength;
 94574:     masm.addCount(codeLength, code, reg);
 94574: 
 94574:     double *pics = &counts.get(PCCounts::BASE_METHODJIT_PICS);
 77407:     double *picsLength = &pcLengths[offset].picsLength;
 94574:     masm.addCount(picsLength, pics, reg);
 94574: 
 94574:     double *count = &counts.get(PCCounts::BASE_METHODJIT);
 94574:     masm.bumpCount(count, reg);
 77407: 
 77407:     /* Reload the base register's original value. */
 77407:     masm.loadPtr(frame.addressOfTop(), reg);
 77407: 
 77407:     /* The start label should reflect the code for the op, not instrumentation. */
 77407:     *start = masm.label();
 77407:     *updated = true;
 77407: }
 77407: 
 82134: static inline bool
 82134: HasPayloadType(types::TypeSet *types)
 82134: {
 82134:     if (types->unknown())
 82134:         return false;
 82134: 
 82134:     types::TypeFlags flags = types->baseFlags();
 82134:     bool objects = !!(flags & types::TYPE_FLAG_ANYOBJECT) || !!types->getObjectCount();
 82134: 
 82134:     if (objects && !!(flags & types::TYPE_FLAG_STRING))
 82134:         return false;
 82134: 
 82134:     flags = flags & ~(types::TYPE_FLAG_ANYOBJECT | types::TYPE_FLAG_STRING);
 82134: 
 82134:     return (flags == types::TYPE_FLAG_UNDEFINED)
 82134:         || (flags == types::TYPE_FLAG_NULL)
 82134:         || (flags == types::TYPE_FLAG_BOOLEAN);
 82134: }
 82134: 
 82134: void
 82134: mjit::Compiler::updatePCTypes(jsbytecode *pc, FrameEntry *fe)
 82134: {
 95113:     JS_ASSERT(script->hasScriptCounts);
 94574: 
 94574:     /*
 94574:      * Get a temporary register, as for updatePCCounts. Don't overlap with
 82134:      * the backing store for the entry's type tag, if there is one.
 82134:      */
 82134:     RegisterID reg = Registers::ReturnReg;
 82134:     if (frame.peekTypeInRegister(fe) && reg == frame.tempRegForType(fe)) {
 82134:         JS_STATIC_ASSERT(Registers::ReturnReg != Registers::ArgReg1);
 82134:         reg = Registers::ArgReg1;
 82134:     }
 82134:     masm.push(reg);
 82134: 
 94574:     PCCounts counts = script->getPCCounts(pc);
 94574: 
 94574:     /* Update the counts for pushed type tags and possible access types. */
 82134:     if (fe->isTypeKnown()) {
 94574:         masm.bumpCount(&counts.get(PCCounts::ACCESS_MONOMORPHIC), reg);
 94574:         PCCounts::AccessCounts count = PCCounts::ACCESS_OBJECT;
 82134:         switch (fe->getKnownType()) {
 94574:           case JSVAL_TYPE_UNDEFINED:  count = PCCounts::ACCESS_UNDEFINED;  break;
 94574:           case JSVAL_TYPE_NULL:       count = PCCounts::ACCESS_NULL;       break;
 94574:           case JSVAL_TYPE_BOOLEAN:    count = PCCounts::ACCESS_BOOLEAN;    break;
 94574:           case JSVAL_TYPE_INT32:      count = PCCounts::ACCESS_INT32;      break;
 94574:           case JSVAL_TYPE_DOUBLE:     count = PCCounts::ACCESS_DOUBLE;     break;
 94574:           case JSVAL_TYPE_STRING:     count = PCCounts::ACCESS_STRING;     break;
 94574:           case JSVAL_TYPE_OBJECT:     count = PCCounts::ACCESS_OBJECT;     break;
 82134:           default:;
 82134:         }
 94574:         if (count)
 94574:             masm.bumpCount(&counts.get(count), reg);
 82134:     } else {
 82134:         types::TypeSet *types = frame.extra(fe).types;
 82134:         if (types && HasPayloadType(types))
 94574:             masm.bumpCount(&counts.get(PCCounts::ACCESS_DIMORPHIC), reg);
 82134:         else
 94574:             masm.bumpCount(&counts.get(PCCounts::ACCESS_POLYMORPHIC), reg);
 82134: 
 82134:         frame.loadTypeIntoReg(fe, reg);
 82134: 
 82134:         Jump j = masm.testUndefined(Assembler::NotEqual, reg);
 94574:         masm.bumpCount(&counts.get(PCCounts::ACCESS_UNDEFINED), reg);
 82134:         frame.loadTypeIntoReg(fe, reg);
 82134:         j.linkTo(masm.label(), &masm);
 82134: 
 82134:         j = masm.testNull(Assembler::NotEqual, reg);
 94574:         masm.bumpCount(&counts.get(PCCounts::ACCESS_NULL), reg);
 82134:         frame.loadTypeIntoReg(fe, reg);
 82134:         j.linkTo(masm.label(), &masm);
 82134: 
 82134:         j = masm.testBoolean(Assembler::NotEqual, reg);
 94574:         masm.bumpCount(&counts.get(PCCounts::ACCESS_BOOLEAN), reg);
 82134:         frame.loadTypeIntoReg(fe, reg);
 82134:         j.linkTo(masm.label(), &masm);
 82134: 
 82134:         j = masm.testInt32(Assembler::NotEqual, reg);
 94574:         masm.bumpCount(&counts.get(PCCounts::ACCESS_INT32), reg);
 82134:         frame.loadTypeIntoReg(fe, reg);
 82134:         j.linkTo(masm.label(), &masm);
 82134: 
 82134:         j = masm.testDouble(Assembler::NotEqual, reg);
 94574:         masm.bumpCount(&counts.get(PCCounts::ACCESS_DOUBLE), reg);
 82134:         frame.loadTypeIntoReg(fe, reg);
 82134:         j.linkTo(masm.label(), &masm);
 82134: 
 82134:         j = masm.testString(Assembler::NotEqual, reg);
 94574:         masm.bumpCount(&counts.get(PCCounts::ACCESS_STRING), reg);
 82134:         frame.loadTypeIntoReg(fe, reg);
 82134:         j.linkTo(masm.label(), &masm);
 82134: 
 82134:         j = masm.testObject(Assembler::NotEqual, reg);
 94574:         masm.bumpCount(&counts.get(PCCounts::ACCESS_OBJECT), reg);
 82134:         frame.loadTypeIntoReg(fe, reg);
 82134:         j.linkTo(masm.label(), &masm);
 82134:     }
 82134: 
 94574:     /* Update the count for accesses with type barriers. */
 82134:     if (js_CodeSpec[*pc].format & JOF_TYPESET) {
 94574:         double *count = &counts.get(hasTypeBarriers(pc)
 94574:                                       ? PCCounts::ACCESS_BARRIER
 94574:                                       : PCCounts::ACCESS_NOBARRIER);
 94574:         masm.bumpCount(count, reg);
 82134:     }
 82134: 
 82134:     /* Reload the base register's original value. */
 82134:     masm.pop(reg);
 82134: }
 82134: 
 82134: void
 94574: mjit::Compiler::updateArithCounts(jsbytecode *pc, FrameEntry *fe,
 82134:                                   JSValueType firstUseType, JSValueType secondUseType)
 82134: {
 95113:     JS_ASSERT(script->hasScriptCounts);
 82134: 
 82134:     RegisterID reg = Registers::ReturnReg;
 82134:     masm.push(reg);
 82134: 
 82134:     /*
 94574:      * What count we bump for arithmetic expressions depend on the
 82134:      * known types of its operands.
 82134:      *
 82134:      * ARITH_INT: operands are known ints, result is int
 82134:      * ARITH_OVERFLOW: operands are known ints, result is double
 82134:      * ARITH_DOUBLE: either operand is a known double, result is double
 82134:      * ARITH_OTHER: operands are monomorphic but not int or double
 82134:      * ARITH_UNKNOWN: operands are polymorphic
 82134:      */
 82134: 
 94574:     PCCounts::ArithCounts count;
 82134:     if (firstUseType == JSVAL_TYPE_INT32 && secondUseType == JSVAL_TYPE_INT32 &&
 82134:         (!fe || fe->isNotType(JSVAL_TYPE_DOUBLE))) {
 94574:         count = PCCounts::ARITH_INT;
 82134:     } else if (firstUseType == JSVAL_TYPE_INT32 || firstUseType == JSVAL_TYPE_DOUBLE ||
 82134:                secondUseType == JSVAL_TYPE_INT32 || secondUseType == JSVAL_TYPE_DOUBLE) {
 94574:         count = PCCounts::ARITH_DOUBLE;
 82134:     } else if (firstUseType != JSVAL_TYPE_UNKNOWN && secondUseType != JSVAL_TYPE_UNKNOWN &&
 82134:                (!fe || fe->isTypeKnown())) {
 94574:         count = PCCounts::ARITH_OTHER;
 82134:     } else {
 94574:         count = PCCounts::ARITH_UNKNOWN;
 94574:     }
 94574: 
 94574:     masm.bumpCount(&script->getPCCounts(pc).get(count), reg);
 82134:     masm.pop(reg);
 82134: }
 82134: 
 82134: void
 94574: mjit::Compiler::updateElemCounts(jsbytecode *pc, FrameEntry *obj, FrameEntry *id)
 94574: {
 95113:     JS_ASSERT(script->hasScriptCounts);
 82134: 
 82134:     RegisterID reg = Registers::ReturnReg;
 82134:     masm.push(reg);
 82134: 
 94574:     PCCounts counts = script->getPCCounts(pc);
 94574: 
 94574:     PCCounts::ElementCounts count;
 82134:     if (id->isTypeKnown()) {
 82134:         switch (id->getKnownType()) {
 94574:           case JSVAL_TYPE_INT32:   count = PCCounts::ELEM_ID_INT;     break;
 94574:           case JSVAL_TYPE_DOUBLE:  count = PCCounts::ELEM_ID_DOUBLE;  break;
 94574:           default:                 count = PCCounts::ELEM_ID_OTHER;   break;
 82134:         }
 82134:     } else {
 94574:         count = PCCounts::ELEM_ID_UNKNOWN;
 94574:     }
 94574:     masm.bumpCount(&counts.get(count), reg);
 82134: 
 82134:     if (obj->mightBeType(JSVAL_TYPE_OBJECT)) {
 82134:         types::TypeSet *types = frame.extra(obj).types;
 82134:         if (types && !types->hasObjectFlags(cx, types::OBJECT_FLAG_NON_TYPED_ARRAY) &&
 82134:             types->getTypedArrayType(cx) != TypedArray::TYPE_MAX) {
 94574:             count = PCCounts::ELEM_OBJECT_TYPED;
 82134:         } else if (types && !types->hasObjectFlags(cx, types::OBJECT_FLAG_NON_DENSE_ARRAY)) {
 82134:             if (!types->hasObjectFlags(cx, types::OBJECT_FLAG_NON_PACKED_ARRAY))
 94574:                 count = PCCounts::ELEM_OBJECT_PACKED;
 82134:             else
 94574:                 count = PCCounts::ELEM_OBJECT_DENSE;
 82134:         } else {
 94574:             count = PCCounts::ELEM_OBJECT_OTHER;
 94574:         }
 94574:         masm.bumpCount(&counts.get(count), reg);
 82134:     } else {
 94574:         masm.bumpCount(&counts.get(PCCounts::ELEM_OBJECT_OTHER), reg);
 82134:     }
 82134: 
 82134:     masm.pop(reg);
 82134: }
 82134: 
 82134: void
 94574: mjit::Compiler::bumpPropCount(jsbytecode *pc, int count)
 82134: {
 82134:     /* Don't accumulate counts for property ops fused with other ops. */
 82134:     if (!(js_CodeSpec[*pc].format & JOF_PROP))
 82134:         return;
 82134:     RegisterID reg = Registers::ReturnReg;
 82134:     masm.push(reg);
 94574:     masm.bumpCount(&script->getPCCounts(pc).get(count), reg);
 82134:     masm.pop(reg);
 82134: }
 82134: 
 52653: JSC::MacroAssembler::Label
 84755: mjit::Compiler::labelOf(jsbytecode *pc, uint32_t inlineIndex)
 84755: {
 84755:     ActiveFrame *a = (inlineIndex == UINT32_MAX) ? outer : inlineFrames[inlineIndex];
 84755:     JS_ASSERT(uint32_t(pc - a->script->code) < a->script->length);
 84755: 
 84755:     uint32_t offs = uint32_t(pc - a->script->code);
 76194:     JS_ASSERT(a->jumpMap[offs].isSet());
 76194:     return a->jumpMap[offs];
 52599: }
 52599: 
 52653: bool
 52653: mjit::Compiler::knownJump(jsbytecode *pc)
 52653: {
 52653:     return pc < PC;
 52653: }
 52653: 
 56766: bool
 52599: mjit::Compiler::jumpInScript(Jump j, jsbytecode *pc)
 52599: {
 84755:     JS_ASSERT(pc >= script->code && uint32_t(pc - script->code) < script->length);
 52599: 
 56766:     if (pc < PC) {
 84755:         j.linkTo(a->jumpMap[uint32_t(pc - script->code)], &masm);
 56766:         return true;
 56766:     }
 76194:     return branchPatches.append(BranchPatch(j, pc, a->inlineIndex));
 52599: }
 52599: 
 52560: void
 54832: mjit::Compiler::emitFinalReturn(Assembler &masm)
 52560: {
 69223:     masm.loadPtr(Address(JSFrameReg, StackFrame::offsetOfNcode()), Registers::ReturnReg);
 54832:     masm.jump(Registers::ReturnReg);
 54832: }
 54832: 
 55503: // Emits code to load a return value of the frame into the scripted-ABI
 55503: // type & data register pair. If the return value is in fp->rval, then |fe|
 55503: // is NULL. Otherwise, |fe| contains the return value.
 55503: //
 55503: // If reading from fp->rval, |undefined| is loaded optimistically, before
 55503: // checking if fp->rval is set in the frame flags and loading that instead.
 55503: //
 55503: // Otherwise, if |masm| is the inline path, it is loaded as efficiently as
 55503: // the FrameState can manage. If |masm| is the OOL path, the value is simply
 55503: // loaded from its slot in the frame, since the caller has guaranteed it's
 55503: // been synced.
 55503: //
 54832: void
 55503: mjit::Compiler::loadReturnValue(Assembler *masm, FrameEntry *fe)
 54427: {
 55503:     RegisterID typeReg = JSReturnReg_Type;
 55503:     RegisterID dataReg = JSReturnReg_Data;
 55503: 
 55503:     if (fe) {
 55503:         // If using the OOL assembler, the caller signifies that the |fe| is
 55503:         // synced, but not to rely on its register state.
 55503:         if (masm != &this->masm) {
 55503:             if (fe->isConstant()) {
 55503:                 stubcc.masm.loadValueAsComponents(fe->getValue(), typeReg, dataReg);
 55503:             } else {
 55503:                 Address rval(frame.addressOf(fe));
 76194:                 if (fe->isTypeKnown() && !fe->isType(JSVAL_TYPE_DOUBLE)) {
 55503:                     stubcc.masm.loadPayload(rval, dataReg);
 55503:                     stubcc.masm.move(ImmType(fe->getKnownType()), typeReg);
 55503:                 } else {
 55503:                     stubcc.masm.loadValueAsComponents(rval, typeReg, dataReg);
 55503:                 }
 55503:             }
 55503:         } else {
 56572:             frame.loadForReturn(fe, typeReg, dataReg, Registers::ReturnReg);
 55503:         }
 55503:     } else {
 55503:          // Load a return value from POPV or SETRVAL into the return registers,
 55503:          // otherwise return undefined.
 55503:         masm->loadValueAsComponents(UndefinedValue(), typeReg, dataReg);
 56602:         if (analysis->usesReturnValue()) {
 55503:             Jump rvalClear = masm->branchTest32(Assembler::Zero,
 55503:                                                FrameFlagsAddress(),
 69223:                                                Imm32(StackFrame::HAS_RVAL));
 69223:             Address rvalAddress(JSFrameReg, StackFrame::offsetOfReturnValue());
 55503:             masm->loadValueAsComponents(rvalAddress, typeReg, dataReg);
 55503:             rvalClear.linkTo(masm->label(), masm);
 55487:         }
 55487:     }
 55503: }
 55503: 
 55503: // This ensures that constructor return values are an object. If a non-object
 55503: // is returned, either explicitly or implicitly, the newly created object is
 55503: // loaded out of the frame. Otherwise, the explicitly returned object is kept.
 55503: //
 55503: void
 55503: mjit::Compiler::fixPrimitiveReturn(Assembler *masm, FrameEntry *fe)
 55503: {
 55503:     JS_ASSERT(isConstructing);
 55503: 
 57787:     bool ool = (masm != &this->masm);
 77391:     Address thisv(JSFrameReg, StackFrame::offsetOfThis(script->function()));
 55503: 
 58700:     // We can just load |thisv| if either of the following is true:
 58700:     //  (1) There is no explicit return value, AND fp->rval is not used.
 58700:     //  (2) There is an explicit return value, and it's known to be primitive.
 58700:     if ((!fe && !analysis->usesReturnValue()) ||
 58700:         (fe && fe->isTypeKnown() && fe->getKnownType() != JSVAL_TYPE_OBJECT))
 58700:     {
 57787:         if (ool)
 55503:             masm->loadValueAsComponents(thisv, JSReturnReg_Type, JSReturnReg_Data);
 57787:         else
 57787:             frame.loadThisForReturn(JSReturnReg_Type, JSReturnReg_Data, Registers::ReturnReg);
 55503:         return;
 55503:     }
 55503: 
 55503:     // If the type is known to be an object, just load the return value as normal.
 58700:     if (fe && fe->isTypeKnown() && fe->getKnownType() == JSVAL_TYPE_OBJECT) {
 55503:         loadReturnValue(masm, fe);
 55503:         return;
 55503:     }
 55503: 
 55503:     // There's a return value, and its type is unknown. Test the type and load
 77431:     // |thisv| if necessary. Sync the 'this' entry before doing so, as it may
 77431:     // be stored in registers if we constructed it inline.
 77431:     frame.syncThis();
 55503:     loadReturnValue(masm, fe);
 55503:     Jump j = masm->testObject(Assembler::Equal, JSReturnReg_Type);
 55503:     masm->loadValueAsComponents(thisv, JSReturnReg_Type, JSReturnReg_Data);
 55503:     j.linkTo(masm->label(), masm);
 55503: }
 55503: 
 55503: // Loads the return value into the scripted ABI register pair, such that JS
 55503: // semantics in constructors are preserved.
 55503: //
 55503: void
 55503: mjit::Compiler::emitReturnValue(Assembler *masm, FrameEntry *fe)
 55503: {
 55503:     if (isConstructing)
 55503:         fixPrimitiveReturn(masm, fe);
 55503:     else
 55503:         loadReturnValue(masm, fe);
 55503: }
 54832: 
 54832: void
 76194: mjit::Compiler::emitInlineReturnValue(FrameEntry *fe)
 76194: {
 76194:     JS_ASSERT(!isConstructing && a->needReturnValue);
 76194: 
 76194:     if (a->syncReturnValue) {
 76194:         /* Needed return value with unknown type, the caller's entry is synced. */
 76194:         Address address = frame.addressForInlineReturn();
 76194:         if (fe)
 76194:             frame.storeTo(fe, address);
 76194:         else
 76194:             masm.storeValue(UndefinedValue(), address);
 76194:         return;
 76194:     }
 76194: 
 76194:     /*
 76194:      * For inlined functions that simply return an entry present in the outer
 76194:      * script (e.g. a loop invariant term), mark the copy and propagate it
 76194:      * after popping the frame.
 76194:      */
 76194:     if (!a->exitState && fe && fe->isCopy() && frame.isOuterSlot(fe->backing())) {
 76194:         a->returnEntry = fe->backing();
 76194:         return;
 76194:     }
 76194: 
 76194:     if (a->returnValueDouble) {
 76194:         JS_ASSERT(fe);
 76194:         frame.ensureDouble(fe);
 76194:         Registers mask(a->returnSet
 76194:                        ? Registers::maskReg(a->returnRegister)
 76194:                        : Registers::AvailFPRegs);
 76194:         FPRegisterID fpreg;
 76194:         if (!fe->isConstant()) {
 76194:             fpreg = frame.tempRegInMaskForData(fe, mask.freeMask).fpreg();
 76194:             frame.syncAndForgetFe(fe, true);
 76194:             frame.takeReg(fpreg);
 76194:         } else {
 76194:             fpreg = frame.allocReg(mask.freeMask).fpreg();
 76194:             masm.slowLoadConstantDouble(fe->getValue().toDouble(), fpreg);
 76194:         }
 76194:         JS_ASSERT_IF(a->returnSet, fpreg == a->returnRegister.fpreg());
 76194:         a->returnRegister = fpreg;
 76194:     } else {
 76194:         Registers mask(a->returnSet
 76194:                        ? Registers::maskReg(a->returnRegister)
 76194:                        : Registers::AvailRegs);
 76194:         RegisterID reg;
 76194:         if (fe && !fe->isConstant()) {
 76194:             reg = frame.tempRegInMaskForData(fe, mask.freeMask).reg();
 76194:             frame.syncAndForgetFe(fe, true);
 76194:             frame.takeReg(reg);
 76194:         } else {
 76194:             reg = frame.allocReg(mask.freeMask).reg();
 76194:             Value val = fe ? fe->getValue() : UndefinedValue();
 76194:             masm.loadValuePayload(val, reg);
 76194:         }
 76194:         JS_ASSERT_IF(a->returnSet, reg == a->returnRegister.reg());
 76194:         a->returnRegister = reg;
 76194:     }
 76194: 
 76194:     a->returnSet = true;
 76194:     if (a->exitState)
 76194:         a->exitState->setUnassigned(a->returnRegister);
 76194: }
 76194: 
 76194: void
 54832: mjit::Compiler::emitReturn(FrameEntry *fe)
 54832: {
 83256:     JS_ASSERT_IF(!script->function(), JSOp(*PC) == JSOP_STOP);
 52847: 
 54832:     /* Only the top of the stack can be returned. */
 54832:     JS_ASSERT_IF(fe, fe == frame.peek(-1));
 54832: 
 57766:     if (debugMode() || Probes::callTrackingActive(cx)) {
 91435:         /* If the return value isn't in the frame's rval slot, move it there. */
 91435:         if (fe) {
 91435:             frame.storeTo(fe, Address(JSFrameReg, StackFrame::offsetOfReturnValue()), true);
 91435: 
 91435:             /* Set the frame flag indicating it's there. */
 91435:             RegisterID reg = frame.allocReg();
 91435:             masm.load32(FrameFlagsAddress(), reg);
 91435:             masm.or32(Imm32(StackFrame::HAS_RVAL), reg);
 91435:             masm.store32(reg, FrameFlagsAddress());
 91435:             frame.freeReg(reg);
 91435: 
 91435:             /* Use the frame's return value when generating further code. */
 91435:             fe = NULL;
 91435:         }
 91435: 
 56201:         prepareStubCall(Uses(0));
 76194:         INLINE_STUBCALL(stubs::ScriptDebugEpilogue, REJOIN_RESUME);
 76194:     }
 76194: 
 76194:     if (a != outer) {
 76194:         /*
 76194:          * Returning from an inlined script. The checks we do for inlineability
 76194:          * and recompilation triggered by args object construction ensure that
 76194:          * there can't be an arguments or call object.
 76194:          */
 76194: 
 76194:         if (a->needReturnValue)
 76194:             emitInlineReturnValue(fe);
 76194: 
 76194:         if (a->exitState) {
 76194:             /*
 76194:              * Restore the register state to reflect that at the original call,
 76194:              * modulo entries which will be popped once the call finishes and any
 76194:              * entry which will be clobbered by the return value register.
 76194:              */
 76194:             frame.syncForAllocation(a->exitState, true, Uses(0));
 76194:         }
 76194: 
 76194:         /*
 76194:          * Simple tests to see if we are at the end of the script and will
 76194:          * fallthrough after the script body finishes, thus won't need to jump.
 76194:          */
 76194:         bool endOfScript =
 76194:             (JSOp(*PC) == JSOP_STOP) ||
 76194:             (JSOp(*PC) == JSOP_RETURN &&
 84195:              (JSOp(PC[JSOP_RETURN_LENGTH]) == JSOP_STOP &&
 76194:               !analysis->maybeCode(PC + JSOP_RETURN_LENGTH)));
 76194:         if (!endOfScript)
 76194:             a->returnJumps->append(masm.jump());
 76194: 
 76194:         if (a->returnSet)
 76194:             frame.freeReg(a->returnRegister);
 76194:         return;
 56201:     }
 56201: 
100006:     /*
100006:      * Outside the mjit, activation objects (call objects and arguments objects) are put
100006:      * by ContextStack::pop* members. For JSOP_RETURN, the interpreter only calls
100006:      * popInlineFrame if fp != entryFrame since the VM protocol is that Invoke/Execute are
100006:      * responsible for pushing/popping the initial frame. However, an mjit function
100006:      * epilogue doesn't treat the initial StackFrame of its VMFrame specially: it always
100006:      * puts activation objects. And furthermore, if the last mjit frame throws, the mjit
100006:      * does *not* put the activation objects. So we can't assume any particular state of
100006:      * puttedness upon exit from the mjit.
100006:      *
100006:      * To avoid double-putting, EnterMethodJIT calls updateEpilogueFlags to clear the
100006:      * entry frame's hasArgsObj() and hasCallObj() flags if the given objects have already
100006:      * been put.
100006:      */
100006:     if (script->function()) {
100006:         types::TypeScriptNesting *nesting = script->nesting();
100006:         if (script->function()->isHeavyweight() || script->needsArgsObj() ||
100006:             (nesting && nesting->children) || debugMode())
100006:         {
100006:             prepareStubCall(Uses(fe ? 1 : 0));
100006:             INLINE_STUBCALL(stubs::FunctionFrameEpilogue, REJOIN_NONE);
100006:         } else {
100006:             /* if hasCallObj() */
100006:             Jump putObjs = masm.branchTest32(Assembler::NonZero,
100006:                                              Address(JSFrameReg, StackFrame::offsetOfFlags()),
100006:                                              Imm32(StackFrame::HAS_CALL_OBJ));
100006:             stubcc.linkExit(putObjs, Uses(frame.frameSlots()));
100006: 
100006:             stubcc.leave();
100006:             OOL_STUBCALL(stubs::FunctionFrameEpilogue, REJOIN_NONE);
100006: 
100006:             emitReturnValue(&stubcc.masm, fe);
100006:             emitFinalReturn(stubcc.masm);
100006: 
100006:             /*
100006:              * Do frame count balancing inline for inner functions in a nesting
100006:              * with no children of their own.
100006:              */
100006:             if (nesting)
100006:                 masm.sub32(Imm32(1), AbsoluteAddress(&nesting->activeFrames));
100006:         }
 54427:     }
 54832: 
 55503:     emitReturnValue(&masm, fe);
 54832:     emitFinalReturn(masm);
 64365: 
 64365:     /*
 64365:      * After we've placed the call object, all tracked state can be
 64365:      * thrown away. This will happen anyway because the next live opcode (if
 64365:      * any) must have an incoming edge. It's an optimization to throw it away
 64365:      * early - the tracker won't be spilled on further exits or join points.
 64365:      */
 54832:     frame.discardFrame();
 52560: }
 52560: 
 52611: void
 53087: mjit::Compiler::prepareStubCall(Uses uses)
 52611: {
 52613:     JaegerSpew(JSpew_Insns, " ---- STUB CALL, SYNCING FRAME ---- \n");
 76194:     frame.syncAndKill(Registers(Registers::TempAnyRegs), uses);
 52611:     JaegerSpew(JSpew_Insns, " ---- FRAME SYNCING DONE ---- \n");
 52611: }
 52611: 
 52611: JSC::MacroAssembler::Call
 76194: mjit::Compiler::emitStubCall(void *ptr, DataLabelPtr *pinline)
 52611: {
 52611:     JaegerSpew(JSpew_Insns, " ---- CALLING STUB ---- \n");
 77407: 
 94574:     masm.bumpStubCount(script, PC, Registers::tempCallReg());
 77407: 
 76194:     Call cl = masm.fallibleVMCall(cx->typeInferenceEnabled(),
 78413:                                   ptr, outerPC(), pinline, frame.totalDepth());
 52613:     JaegerSpew(JSpew_Insns, " ---- END STUB CALL ---- \n");
 52611:     return cl;
 52611: }
 52611: 
 52645: void
 53223: mjit::Compiler::interruptCheckHelper()
 53223: {
 82130:     Jump jump;
 90410:     if (cx->runtime->gcZeal() == js::gc::ZealVerifierValue) {
 82130:         /* For barrier verification, always take the interrupt so we can verify. */
 82130:         jump = masm.jump();
 82130:     } else {
 88135:         void *interrupt = (void*) &cx->runtime->interrupt;
 87250: #if defined(JS_CPU_X86) || defined(JS_CPU_ARM) || defined(JS_CPU_MIPS)
 82130:         jump = masm.branch32(Assembler::NotEqual, AbsoluteAddress(interrupt), Imm32(0));
 56559: #else
 56559:         /* Handle processors that can't load from absolute addresses. */
 76194:         RegisterID reg = frame.allocReg();
 56559:         masm.move(ImmPtr(interrupt), reg);
 82130:         jump = masm.branchTest32(Assembler::NonZero, Address(reg, 0));
 76194:         frame.freeReg(reg);
 56559: #endif
 82130:     }
 56559: 
 56559:     stubcc.linkExitDirect(jump, stubcc.masm.label());
 56559: 
 56559:     frame.sync(stubcc.masm, Uses(0));
 53223:     stubcc.masm.move(ImmPtr(PC), Registers::ArgReg1);
 76194:     OOL_STUBCALL(stubs::Interrupt, REJOIN_RESUME);
 53223:     stubcc.rejoin(Changes(0));
 76194: }
 76194: 
 76194: void
 76194: mjit::Compiler::recompileCheckHelper()
 76194: {
 76194:     if (inlining() || debugMode() || !globalObj ||
 76194:         !analysis->hasFunctionCalls() || !cx->typeInferenceEnabled()) {
 76194:         return;
 76194:     }
 76194: 
 97829:     uint32_t *addr = script->addressOfUseCount();
 76194:     masm.add32(Imm32(1), AbsoluteAddress(addr));
 76194: #if defined(JS_CPU_X86) || defined(JS_CPU_ARM)
 76194:     Jump jump = masm.branch32(Assembler::GreaterThanOrEqual, AbsoluteAddress(addr),
 76194:                               Imm32(USES_BEFORE_INLINING));
 76194: #else
 76194:     /* Handle processors that can't load from absolute addresses. */
 76194:     RegisterID reg = frame.allocReg();
 76194:     masm.move(ImmPtr(addr), reg);
 76194:     Jump jump = masm.branch32(Assembler::GreaterThanOrEqual, Address(reg, 0),
 76194:                               Imm32(USES_BEFORE_INLINING));
 76194:     frame.freeReg(reg);
 56559: #endif
 76194:     stubcc.linkExit(jump, Uses(0));
 76194:     stubcc.leave();
 76194: 
 76194:     OOL_STUBCALL(stubs::RecompileForInline, REJOIN_RESUME);
 76194:     stubcc.rejoin(Changes(0));
 53223: }
 53223: 
 53223: void
 76194: mjit::Compiler::addReturnSite()
 76194: {
 76194:     InternalCallSite site(masm.distanceOf(masm.label()), a->inlineIndex, PC,
 76194:                           REJOIN_SCRIPTED, false);
 57766:     addCallSite(site);
 76194:     masm.loadPtr(Address(JSFrameReg, StackFrame::offsetOfPrev()), JSFrameReg);
 57766: }
 57766: 
 68952: void
 84755: mjit::Compiler::emitUncachedCall(uint32_t argc, bool callingNew)
 68952: {
 68952:     CallPatchInfo callPatch;
 68952: 
 68952:     RegisterID r0 = Registers::ReturnReg;
 68952:     VoidPtrStubUInt32 stub = callingNew ? stubs::UncachedNew : stubs::UncachedCall;
 68952: 
 76194:     frame.syncAndKill(Uses(argc + 2));
 68952:     prepareStubCall(Uses(argc + 2));
 68952:     masm.move(Imm32(argc), Registers::ArgReg1);
 76194:     INLINE_STUBCALL(stub, REJOIN_CALL_PROLOGUE);
 68952: 
 68952:     Jump notCompiled = masm.branchTestPtr(Assembler::Zero, r0, r0);
 68952: 
 82150:     masm.loadPtr(FrameAddress(VMFrame::offsetOfRegsSp()), JSFrameReg);
 68952:     callPatch.hasFastNcode = true;
 68952:     callPatch.fastNcodePatch =
 68952:         masm.storePtrWithPatch(ImmPtr(NULL),
 69223:                                Address(JSFrameReg, StackFrame::offsetOfNcode()));
 68952: 
 68952:     masm.jump(r0);
 68952:     callPatch.joinPoint = masm.label();
 76194:     addReturnSite();
 68952: 
 68952:     frame.popn(argc + 2);
 76194: 
 68952:     frame.takeReg(JSReturnReg_Type);
 68952:     frame.takeReg(JSReturnReg_Data);
 76194:     frame.pushRegs(JSReturnReg_Type, JSReturnReg_Data, knownPushedType(0));
 76194: 
 76194:     BarrierState barrier = testBarrier(JSReturnReg_Type, JSReturnReg_Data,
 76194:                                        /* testUndefined = */ false,
 76194:                                        /* testReturn = */ true);
 68952: 
 68952:     stubcc.linkExitDirect(notCompiled, stubcc.masm.label());
 76194:     stubcc.rejoin(Changes(1));
 68952:     callPatches.append(callPatch);
 76194: 
 76194:     finishBarrier(barrier, REJOIN_FALLTHROUGH, 0);
 68952: }
 68952: 
 68952: void
 95100: mjit::Compiler::checkCallApplySpeculation(uint32_t argc, FrameEntry *origCallee, FrameEntry *origThis,
 68952:                                           MaybeRegisterID origCalleeType, RegisterID origCalleeData,
 68952:                                           MaybeRegisterID origThisType, RegisterID origThisData,
 68952:                                           Jump *uncachedCallSlowRejoin, CallPatchInfo *uncachedCallPatch)
 68952: {
 68952:     JS_ASSERT(IsLowerableFunCallOrApply(PC));
 68952: 
 83222:     RegisterID temp;
 83222:     Registers tempRegs(Registers::AvailRegs);
 83222:     if (origCalleeType.isSet())
 83222:         tempRegs.takeReg(origCalleeType.reg());
 83222:     tempRegs.takeReg(origCalleeData);
 83222:     if (origThisType.isSet())
 83222:         tempRegs.takeReg(origThisType.reg());
 83222:     tempRegs.takeReg(origThisData);
 83222:     temp = tempRegs.takeAnyReg().reg();
 83222: 
 68952:     /*
 68952:      * if (origCallee.isObject() &&
 68952:      *     origCallee.toObject().isFunction &&
 83234:      *     origCallee.toObject().toFunction() == js_fun_{call,apply})
 68952:      */
 68952:     MaybeJump isObj;
 68952:     if (origCalleeType.isSet())
 68952:         isObj = masm.testObject(Assembler::NotEqual, origCalleeType.reg());
 83222:     Jump isFun = masm.testFunction(Assembler::NotEqual, origCalleeData, temp);
 68952:     Native native = *PC == JSOP_FUNCALL ? js_fun_call : js_fun_apply;
 68952:     Jump isNative = masm.branchPtr(Assembler::NotEqual,
 68952:                                    Address(origCalleeData, JSFunction::offsetOfNativeOrScript()),
 68952:                                    ImmPtr(JS_FUNC_TO_DATA_PTR(void *, native)));
 68952: 
 68952:     /*
 68952:      * If speculation fails, we can't use the ic, since it is compiled on the
 68952:      * assumption that speculation succeeds. Instead, just do an uncached call.
 68952:      */
 68952:     {
 68952:         if (isObj.isSet())
 68952:             stubcc.linkExitDirect(isObj.getJump(), stubcc.masm.label());
 68952:         stubcc.linkExitDirect(isFun, stubcc.masm.label());
 68952:         stubcc.linkExitDirect(isNative, stubcc.masm.label());
 68952: 
 95100:         stubcc.masm.move(Imm32(argc), Registers::ArgReg1);
 68952:         JaegerSpew(JSpew_Insns, " ---- BEGIN SLOW CALL CODE ---- \n");
 76194:         OOL_STUBCALL_LOCAL_SLOTS(JS_FUNC_TO_DATA_PTR(void *, stubs::SlowCall),
 95100:                                  REJOIN_FALLTHROUGH, frame.totalDepth());
 68952:         JaegerSpew(JSpew_Insns, " ---- END SLOW CALL CODE ---- \n");
 68952: 
 68952:         /*
 68952:          * inlineCallHelper will link uncachedCallSlowRejoin to the join point
 68952:          * at the end of the ic. At that join point, the return value of the
 68952:          * call is assumed to be in registers, so load them before jumping.
 68952:          */
 68952:         JaegerSpew(JSpew_Insns, " ---- BEGIN SLOW RESTORE CODE ---- \n");
 68952:         Address rval = frame.addressOf(origCallee);  /* vp[0] == rval */
 76194:         if (knownPushedType(0) == JSVAL_TYPE_DOUBLE)
 76194:             stubcc.masm.ensureInMemoryDouble(rval);
 68952:         stubcc.masm.loadValueAsComponents(rval, JSReturnReg_Type, JSReturnReg_Data);
 68952:         *uncachedCallSlowRejoin = stubcc.masm.jump();
 68952:         JaegerSpew(JSpew_Insns, " ---- END SLOW RESTORE CODE ---- \n");
 68952:     }
 57713: }
 57713: 
 68952: /* See MonoIC.cpp, CallCompiler for more information on call ICs. */
 76194: bool
 95100: mjit::Compiler::inlineCallHelper(uint32_t argc, bool callingNew, FrameSize &callFrameSize)
 95100: {
 77355:     /*
 77355:      * Check for interrupts on function call. We don't do this for lazy
 77355:      * arguments objects as the interrupt may kick this frame into the
 77355:      * interpreter, which doesn't know about the apply tricks. Instead, we
 77355:      * do the interrupt check at the start of the JSOP_ARGUMENTS.
 77355:      */
 77355:     interruptCheckHelper();
 77355: 
 95100:     FrameEntry *origCallee = frame.peek(-(int(argc) + 2));
 95100:     FrameEntry *origThis = frame.peek(-(int(argc) + 1));
 68952: 
 76194:     /*
 76194:      * 'this' does not need to be synced for constructing. :FIXME: is it
 76194:      * possible that one of the arguments is directly copying the 'this'
 76194:      * entry (something like 'new x.f(x)')?
 76194:      */
 77361:     if (callingNew) {
 57713:         frame.discardFe(origThis);
 57713: 
 68952:         /*
 94176:          * We store NULL here to ensure that the slot doesn't contain
 94176:          * garbage. Additionally, we need to store a non-object value here for
 94176:          * TI. If a GC gets triggered before the callee can fill in the slot
 94176:          * (i.e. the GC happens on constructing the 'new' object or the call
 94176:          * object for a heavyweight callee), it needs to be able to read the
 94176:          * 'this' value to tell whether newScript constraints will need to be
 94176:          * regenerated afterwards.
 94176:          */
 77361:         masm.storeValue(NullValue(), frame.addressOf(origThis));
 77361:     }
 77361: 
 73894:     /*
 68952:      * From the presence of JSOP_FUN{CALL,APPLY}, we speculate that we are
 68952:      * going to call js_fun_{call,apply}. Normally, this call would go through
 68952:      * js::Invoke to ultimately call 'this'. We can do much better by having
 68952:      * the callIC cache and call 'this' directly. However, if it turns out that
 68952:      * we are not actually calling js_fun_call, the callIC must act as normal.
 76194:      *
 76194:      * Note: do *NOT* use type information or inline state in any way when
 76194:      * deciding whether to lower a CALL or APPLY. The stub calls here store
 76194:      * their return values in a different slot, so when recompiling we need
 76194:      * to go down the exact same path.
 68952:      */
 68952:     bool lowerFunCallOrApply = IsLowerableFunCallOrApply(PC);
 68952: 
 76194:     bool newType = callingNew && cx->typeInferenceEnabled() && types::UseNewType(cx, script, PC);
 76194: 
 68952: #ifdef JS_MONOIC
 76194:     if (debugMode() || newType) {
 68952: #endif
 95100:         emitUncachedCall(argc, callingNew);
 76194:         return true;
 68952: #ifdef JS_MONOIC
 68952:     }
 68952: 
 76194:     frame.forgetMismatchedObject(origCallee);
 76194:     if (lowerFunCallOrApply)
 76194:         frame.forgetMismatchedObject(origThis);
 76194: 
 68952:     /* Initialized by both branches below. */
 76194:     CallGenInfo     callIC;
 68952:     CallPatchInfo   callPatch;
 68952:     MaybeRegisterID icCalleeType; /* type to test for function-ness */
 68952:     RegisterID      icCalleeData; /* data to call */
 68952:     Address         icRvalAddr;   /* return slot on slow-path rejoin */
 68952: 
 68952:     /*
 68952:      * IC space must be reserved (using RESERVE_IC_SPACE or RESERVE_OOL_SPACE) between the
 68952:      * following labels (as used in finishThisUp):
 68952:      *  - funGuard -> hotJump
 68952:      *  - funGuard -> joinPoint
 68952:      *  - funGuard -> hotPathLabel
 68952:      *  - slowPathStart -> oolCall
 68952:      *  - slowPathStart -> oolJump
 68952:      *  - slowPathStart -> icCall
 68952:      *  - slowPathStart -> slowJoinPoint
 68952:      * Because the call ICs are fairly long (compared to PICs), we don't reserve the space in each
 68952:      * path until the first usage of funGuard (for the in-line path) or slowPathStart (for the
 68952:      * out-of-line path).
 68952:      */
 68952: 
 68952:     /* Initialized only on lowerFunCallOrApply branch. */
 68952:     Jump            uncachedCallSlowRejoin;
 68952:     CallPatchInfo   uncachedCallPatch;
 68952: 
 57713:     {
 68952:         MaybeRegisterID origCalleeType, maybeOrigCalleeData;
 68952:         RegisterID origCalleeData;
 68952: 
 68952:         /* Get the callee in registers. */
 68952:         frame.ensureFullRegs(origCallee, &origCalleeType, &maybeOrigCalleeData);
 68952:         origCalleeData = maybeOrigCalleeData.reg();
 57713:         PinRegAcrossSyncAndKill p1(frame, origCalleeData), p2(frame, origCalleeType);
 57713: 
 68952:         if (lowerFunCallOrApply) {
 68952:             MaybeRegisterID origThisType, maybeOrigThisData;
 68952:             RegisterID origThisData;
 57713:             {
 68952:                 /* Get thisv in registers. */
 68952:                 frame.ensureFullRegs(origThis, &origThisType, &maybeOrigThisData);
 68952:                 origThisData = maybeOrigThisData.reg();
 57713:                 PinRegAcrossSyncAndKill p3(frame, origThisData), p4(frame, origThisType);
 57713: 
 68952:                 /* Leaves pinned regs untouched. */
 95100:                 frame.syncAndKill(Uses(argc + 2));
 95100:             }
 95100: 
 95100:             checkCallApplySpeculation(argc, origCallee, origThis,
 68952:                                       origCalleeType, origCalleeData,
 68952:                                       origThisType, origThisData,
 68952:                                       &uncachedCallSlowRejoin, &uncachedCallPatch);
 68952: 
 68952:             icCalleeType = origThisType;
 68952:             icCalleeData = origThisData;
 68952:             icRvalAddr = frame.addressOf(origThis);
 68952: 
 68952:             /*
 68952:              * For f.call(), since we compile the ic under the (checked)
 68952:              * assumption that call == js_fun_call, we still have a static
 68952:              * frame size. For f.apply(), the frame size depends on the dynamic
 68952:              * length of the array passed to apply.
 68952:              */
 68952:             if (*PC == JSOP_FUNCALL)
 95100:                 callIC.frameSize.initStatic(frame.totalDepth(), argc - 1);
 68952:             else
 68952:                 callIC.frameSize.initDynamic();
 68952:         } else {
 68952:             /* Leaves pinned regs untouched. */
 95100:             frame.syncAndKill(Uses(argc + 2));
 68952: 
 68952:             icCalleeType = origCalleeType;
 68952:             icCalleeData = origCalleeData;
 68952:             icRvalAddr = frame.addressOf(origCallee);
 95100:             callIC.frameSize.initStatic(frame.totalDepth(), argc);
 76194:         }
 76194:     }
 76194: 
 76194:     callFrameSize = callIC.frameSize;
 76194: 
 76194:     callIC.typeMonitored = monitored(PC) || hasTypeBarriers(PC);
 68952: 
 68952:     /* Test the type if necessary. Failing this always takes a really slow path. */
 68952:     MaybeJump notObjectJump;
 68952:     if (icCalleeType.isSet())
 68952:         notObjectJump = masm.testObject(Assembler::NotEqual, icCalleeType.reg());
 68952: 
 68952:     /*
 83234:      * For an optimized apply, keep icCalleeData in a callee-saved register for
 83234:      * the subsequent ic::SplatApplyArgs call.
 68952:      */
 76194:     Registers tempRegs(Registers::AvailRegs);
 68952:     if (callIC.frameSize.isDynamic() && !Registers::isSaved(icCalleeData)) {
 76194:         RegisterID x = tempRegs.takeAnyReg(Registers::SavedRegs).reg();
 68952:         masm.move(icCalleeData, x);
 68952:         icCalleeData = x;
 68952:     } else {
 68952:         tempRegs.takeReg(icCalleeData);
 68952:     }
 68952: 
 68952:     /* Reserve space just before initialization of funGuard. */
 68952:     RESERVE_IC_SPACE(masm);
 68952: 
 68952:     /*
 68952:      * Guard on the callee identity. This misses on the first run. If the
 68952:      * callee is scripted, compiled/compilable, and argc == nargs, then this
 68952:      * guard is patched, and the compiled code address is baked in.
 68952:      */
 68952:     Jump j = masm.branchPtrWithPatch(Assembler::NotEqual, icCalleeData, callIC.funGuard);
 68952:     callIC.funJump = j;
 68952: 
 68952:     /* Reserve space just before initialization of slowPathStart. */
 68952:     RESERVE_OOL_SPACE(stubcc.masm);
 68952: 
 68952:     Jump rejoin1, rejoin2;
 68945:     {
 68945:         RESERVE_OOL_SPACE(stubcc.masm);
 68952:         stubcc.linkExitDirect(j, stubcc.masm.label());
 68952:         callIC.slowPathStart = stubcc.masm.label();
 68952: 
 83222:         RegisterID tmp = tempRegs.takeAnyReg().reg();
 83222: 
 68952:         /*
 68952:          * Test if the callee is even a function. If this doesn't match, we
 68952:          * take a _really_ slow path later.
 68952:          */
 83222:         Jump notFunction = stubcc.masm.testFunction(Assembler::NotEqual, icCalleeData, tmp);
 68952: 
 68952:         /* Test if the function is scripted. */
 83234:         stubcc.masm.load16(Address(icCalleeData, offsetof(JSFunction, flags)), tmp);
 68952:         stubcc.masm.and32(Imm32(JSFUN_KINDMASK), tmp);
 68952:         Jump isNative = stubcc.masm.branch32(Assembler::Below, tmp, Imm32(JSFUN_INTERPRETED));
 68952:         tempRegs.putReg(tmp);
 68952: 
 68952:         /*
 68952:          * N.B. After this call, the frame will have a dynamic frame size.
 68952:          * Check after the function is known not to be a native so that the
 68952:          * catch-all/native path has a static depth.
 68952:          */
 68952:         if (callIC.frameSize.isDynamic())
 76194:             OOL_STUBCALL(ic::SplatApplyArgs, REJOIN_CALL_SPLAT);
 68952: 
 68952:         /*
 68952:          * No-op jump that gets patched by ic::New/Call to the stub generated
 68952:          * by generateFullCallStub.
 68952:          */
 68952:         Jump toPatch = stubcc.masm.jump();
 68952:         toPatch.linkTo(stubcc.masm.label(), &stubcc.masm);
 68952:         callIC.oolJump = toPatch;
 68952:         callIC.icCall = stubcc.masm.label();
 68952: 
 76194:         RejoinState rejoinState = callIC.frameSize.rejoinState(PC, false);
 76194: 
 68952:         /*
 68952:          * At this point the function is definitely scripted, so we try to
 68952:          * compile it and patch either funGuard/funJump or oolJump. This code
 68952:          * is only executed once.
 68952:          */
 68952:         callIC.addrLabel1 = stubcc.masm.moveWithPatch(ImmPtr(NULL), Registers::ArgReg1);
 68952:         void *icFunPtr = JS_FUNC_TO_DATA_PTR(void *, callingNew ? ic::New : ic::Call);
 76194:         if (callIC.frameSize.isStatic()) {
 76194:             callIC.oolCall = OOL_STUBCALL_LOCAL_SLOTS(icFunPtr, rejoinState, frame.totalDepth());
 76194:         } else {
 76194:             callIC.oolCall = OOL_STUBCALL_LOCAL_SLOTS(icFunPtr, rejoinState, -1);
 76194:         }
 68952: 
 68952:         callIC.funObjReg = icCalleeData;
 68952: 
 68952:         /*
 68952:          * The IC call either returns NULL, meaning call completed, or a
 76194:          * function pointer to jump to.
 68952:          */
 68952:         rejoin1 = stubcc.masm.branchTestPtr(Assembler::Zero, Registers::ReturnReg,
 68952:                                             Registers::ReturnReg);
 68952:         if (callIC.frameSize.isStatic())
 68952:             stubcc.masm.move(Imm32(callIC.frameSize.staticArgc()), JSParamReg_Argc);
 68952:         else
 82150:             stubcc.masm.load32(FrameAddress(VMFrame::offsetOfDynamicArgc()), JSParamReg_Argc);
 82150:         stubcc.masm.loadPtr(FrameAddress(VMFrame::offsetOfRegsSp()), JSFrameReg);
 68952:         callPatch.hasSlowNcode = true;
 68952:         callPatch.slowNcodePatch =
 68952:             stubcc.masm.storePtrWithPatch(ImmPtr(NULL),
 69223:                                           Address(JSFrameReg, StackFrame::offsetOfNcode()));
 68952:         stubcc.masm.jump(Registers::ReturnReg);
 68952: 
 76194: 
 76194: 
 68952:         /*
 68952:          * This ool path is the catch-all for everything but scripted function
 68952:          * callees. For native functions, ic::NativeNew/NativeCall will repatch
 68952:          * funGaurd/funJump with a fast call stub. All other cases
 68952:          * (non-function callable objects and invalid callees) take the slow
 68952:          * path through js::Invoke.
 68952:          */
 68952:         if (notObjectJump.isSet())
 68952:             stubcc.linkExitDirect(notObjectJump.get(), stubcc.masm.label());
 68952:         notFunction.linkTo(stubcc.masm.label(), &stubcc.masm);
 68952:         isNative.linkTo(stubcc.masm.label(), &stubcc.masm);
 68952: 
 68952:         callIC.addrLabel2 = stubcc.masm.moveWithPatch(ImmPtr(NULL), Registers::ArgReg1);
 76194:         OOL_STUBCALL(callingNew ? ic::NativeNew : ic::NativeCall, rejoinState);
 68952: 
 68952:         rejoin2 = stubcc.masm.jump();
 68952:     }
 68952: 
 68952:     /*
 68952:      * If the call site goes to a closure over the same function, it will
 68952:      * generate an out-of-line stub that joins back here.
 68952:      */
 68952:     callIC.hotPathLabel = masm.label();
 68952: 
 84755:     uint32_t flags = 0;
 68952:     if (callingNew)
 69223:         flags |= StackFrame::CONSTRUCTING;
 68952: 
 68952:     InlineFrameAssembler inlFrame(masm, callIC, flags);
 68952:     callPatch.hasFastNcode = true;
 77341:     callPatch.fastNcodePatch = inlFrame.assemble(NULL, PC);
 68952: 
 68952:     callIC.hotJump = masm.jump();
 68952:     callIC.joinPoint = callPatch.joinPoint = masm.label();
 76194:     callIC.callIndex = callSites.length();
 76194:     addReturnSite();
 68952:     if (lowerFunCallOrApply)
 68952:         uncachedCallPatch.joinPoint = callIC.joinPoint;
 53590: 
 68952:     /*
 68952:      * We've placed hotJump, joinPoint and hotPathLabel, and no other labels are located by offset
 68952:      * in the in-line path so we can check the IC space now.
 68952:      */
 68952:     CHECK_IC_SPACE();
 68952: 
 76194:     JSValueType type = knownPushedType(0);
 76194: 
 95100:     frame.popn(argc + 2);
 53590:     frame.takeReg(JSReturnReg_Type);
 53590:     frame.takeReg(JSReturnReg_Data);
 76194:     frame.pushRegs(JSReturnReg_Type, JSReturnReg_Data, type);
 76194: 
 76194:     BarrierState barrier = testBarrier(JSReturnReg_Type, JSReturnReg_Data,
 76194:                                        /* testUndefined = */ false,
 76194:                                        /* testReturn = */ true);
 53590: 
 68952:     /*
 68952:      * Now that the frame state is set, generate the rejoin path. Note that, if
 68952:      * lowerFunCallOrApply, we cannot just call 'stubcc.rejoin' since the return
 68952:      * value has been placed at vp[1] which is not the stack address associated
 68952:      * with frame.peek(-1).
 68952:      */
 68952:     callIC.slowJoinPoint = stubcc.masm.label();
 68952:     rejoin1.linkTo(callIC.slowJoinPoint, &stubcc.masm);
 68952:     rejoin2.linkTo(callIC.slowJoinPoint, &stubcc.masm);
 68952:     JaegerSpew(JSpew_Insns, " ---- BEGIN SLOW RESTORE CODE ---- \n");
 76194:     frame.reloadEntry(stubcc.masm, icRvalAddr, frame.peek(-1));
 68952:     stubcc.crossJump(stubcc.masm.jump(), masm.label());
 68952:     JaegerSpew(JSpew_Insns, " ---- END SLOW RESTORE CODE ---- \n");
 68952: 
 62361:     CHECK_OOL_SPACE();
 68952: 
 68952:     if (lowerFunCallOrApply)
 68952:         stubcc.crossJump(uncachedCallSlowRejoin, masm.label());
 68952: 
 68952:     callICs.append(callIC);
 68952:     callPatches.append(callPatch);
 68952:     if (lowerFunCallOrApply)
 68952:         callPatches.append(uncachedCallPatch);
 57718: 
 76194:     finishBarrier(barrier, REJOIN_FALLTHROUGH, 0);
 76194:     return true;
 68952: #endif
 52645: }
 52645: 
 76194: /* Maximum number of calls we will inline at the same site. */
 84755: static const uint32_t INLINE_SITE_LIMIT = 5;
 76194: 
 76194: CompileStatus
 84755: mjit::Compiler::inlineScriptedFunction(uint32_t argc, bool callingNew)
 76194: {
 76194:     JS_ASSERT(inlining());
 76194: 
 76194:     /* We already know which frames we are inlining at each PC, so scan the list of inline frames. */
 76194:     bool calleeMultipleReturns = false;
 76194:     Vector<JSScript *> inlineCallees(CompilerAllocPolicy(cx, *this));
 76194:     for (unsigned i = 0; i < ssa.numFrames(); i++) {
 76194:         if (ssa.iterFrame(i).parent == a->inlineIndex && ssa.iterFrame(i).parentpc == PC) {
 76194:             JSScript *script = ssa.iterFrame(i).script;
 76194:             inlineCallees.append(script);
 77391:             if (script->analysis()->numReturnSites() > 1)
 76194:                 calleeMultipleReturns = true;
 76194:         }
 76194:     }
 76194: 
 76194:     if (inlineCallees.empty())
 76194:         return Compile_InlineAbort;
 76194: 
 76194:     JS_ASSERT(!monitored(PC));
 76194: 
 76194:     /*
 76194:      * Remove all dead entries from the frame's tracker. We will not recognize
 76194:      * them as dead after pushing the new frame.
 76194:      */
 76194:     frame.pruneDeadEntries();
 76194: 
 76194:     RegisterAllocation *exitState = NULL;
 76194:     if (inlineCallees.length() > 1 || calleeMultipleReturns) {
 76194:         /*
 76194:          * Multiple paths through the callees, get a register allocation for
 76194:          * the various incoming edges.
 76194:          */
 76194:         exitState = frame.computeAllocation(PC + JSOP_CALL_LENGTH);
 76194:     }
 76194: 
 76194:     /*
 76194:      * If this is a polymorphic callsite, get a register for the callee too.
 76194:      * After this, do not touch the register state in the current frame until
 76194:      * stubs for all callees have been generated.
 76194:      */
 76194:     FrameEntry *origCallee = frame.peek(-((int)argc + 2));
 76194:     FrameEntry *entrySnapshot = NULL;
 76194:     MaybeRegisterID calleeReg;
 76194:     if (inlineCallees.length() > 1) {
 76194:         frame.forgetMismatchedObject(origCallee);
 76194:         calleeReg = frame.tempRegForData(origCallee);
 76194: 
 76194:         entrySnapshot = frame.snapshotState();
 76194:         if (!entrySnapshot)
 76194:             return Compile_Error;
 76194:     }
 76194:     MaybeJump calleePrevious;
 76194: 
 76194:     JSValueType returnType = knownPushedType(0);
 76194: 
 76194:     bool needReturnValue = JSOP_POP != (JSOp)*(PC + JSOP_CALL_LENGTH);
 76194:     bool syncReturnValue = needReturnValue && returnType == JSVAL_TYPE_UNKNOWN;
 76194: 
 76194:     /* Track register state after the call. */
 76194:     bool returnSet = false;
 76194:     AnyRegisterID returnRegister;
 76194:     const FrameEntry *returnEntry = NULL;
 76194: 
 76194:     Vector<Jump, 4, CompilerAllocPolicy> returnJumps(CompilerAllocPolicy(cx, *this));
 76194: 
 76194:     for (unsigned i = 0; i < inlineCallees.length(); i++) {
 76194:         if (entrySnapshot)
 76194:             frame.restoreFromSnapshot(entrySnapshot);
 76194: 
 76194:         JSScript *script = inlineCallees[i];
 76194:         CompileStatus status;
 76194: 
 76194:         status = pushActiveFrame(script, argc);
 76194:         if (status != Compile_Okay)
 76194:             return status;
 76194: 
 76194:         a->exitState = exitState;
 76194: 
 76194:         JaegerSpew(JSpew_Inlining, "inlining call to script (file \"%s\") (line \"%d\")\n",
 76194:                    script->filename, script->lineno);
 76194: 
 76194:         if (calleePrevious.isSet()) {
 76194:             calleePrevious.get().linkTo(masm.label(), &masm);
 76194:             calleePrevious = MaybeJump();
 76194:         }
 76194: 
 76194:         if (i + 1 != inlineCallees.length()) {
 76194:             /* Guard on the callee, except when this object must be the callee. */
 76194:             JS_ASSERT(calleeReg.isSet());
 77391:             calleePrevious = masm.branchPtr(Assembler::NotEqual, calleeReg.reg(), ImmPtr(script->function()));
 76194:         }
 76194: 
 76194:         a->returnJumps = &returnJumps;
 76194:         a->needReturnValue = needReturnValue;
 76194:         a->syncReturnValue = syncReturnValue;
 76194:         a->returnValueDouble = returnType == JSVAL_TYPE_DOUBLE;
 76194:         if (returnSet) {
 76194:             a->returnSet = true;
 76194:             a->returnRegister = returnRegister;
 76194:         }
 76194: 
 76194:         /*
 76194:          * Update the argument frame entries in place if the callee has had an
 76194:          * argument inferred as double but we are passing an int.
 76194:          */
 76194:         ensureDoubleArguments();
 76194: 
 81077:         markUndefinedLocals();
 81077: 
 76194:         status = generateMethod();
 76194:         if (status != Compile_Okay) {
 76194:             popActiveFrame();
 76194:             if (status == Compile_Abort) {
 76194:                 /* The callee is uncompileable, mark it as uninlineable and retry. */
 77361:                 script->uninlineable = true;
 77391:                 types::MarkTypeObjectFlags(cx, script->function(),
 76194:                                            types::OBJECT_FLAG_UNINLINEABLE);
 76194:                 return Compile_Retry;
 76194:             }
 76194:             return status;
 76194:         }
 76194: 
 76194:         if (needReturnValue && !returnSet) {
 76194:             if (a->returnSet) {
 76194:                 returnSet = true;
 76194:                 returnRegister = a->returnRegister;
 76194:             } else {
 76194:                 returnEntry = a->returnEntry;
 76194:             }
 76194:         }
 76194: 
 76194:         popActiveFrame();
 76194: 
 76194:         if (i + 1 != inlineCallees.length())
 76194:             returnJumps.append(masm.jump());
 76194:     }
 76194: 
 76194:     for (unsigned i = 0; i < returnJumps.length(); i++)
 76194:         returnJumps[i].linkTo(masm.label(), &masm);
 76194: 
 76194:     frame.popn(argc + 2);
 76194: 
 76194:     if (entrySnapshot)
 76194:         cx->array_delete(entrySnapshot);
 76194: 
 76194:     if (exitState)
 76194:         frame.discardForJoin(exitState, analysis->getCode(PC).stackDepth - (argc + 2));
 76194: 
 76194:     if (returnSet) {
 76194:         frame.takeReg(returnRegister);
 76194:         if (returnRegister.isReg())
 76194:             frame.pushTypedPayload(returnType, returnRegister.reg());
 76194:         else
 76194:             frame.pushDouble(returnRegister.fpreg());
 76194:     } else if (returnEntry) {
 76194:         frame.pushCopyOf((FrameEntry *) returnEntry);
 76194:     } else {
 76194:         frame.pushSynced(JSVAL_TYPE_UNKNOWN);
 76194:     }
 76194: 
 76194:     JaegerSpew(JSpew_Inlining, "finished inlining call to script (file \"%s\") (line \"%d\")\n",
 76194:                script->filename, script->lineno);
 76194: 
 76194:     return Compile_Okay;
 76194: }
 76194: 
 53168: /*
 53168:  * This function must be called immediately after any instruction which could
 69223:  * cause a new StackFrame to be pushed and could lead to a new debug trap
 53168:  * being set. This includes any API callbacks and any scripted or native call.
 53168:  */
 53168: void
 57766: mjit::Compiler::addCallSite(const InternalCallSite &site)
 53168: {
 53168:     callSites.append(site);
 53168: }
 53168: 
 52645: void
 78454: mjit::Compiler::inlineStubCall(void *stub, RejoinState rejoin, Uses uses)
 76194: {
 76194:     DataLabelPtr inlinePatch;
 76194:     Call cl = emitStubCall(stub, &inlinePatch);
 76194:     InternalCallSite site(masm.callReturnOffset(cl), a->inlineIndex, PC,
 76194:                           rejoin, false);
 76194:     site.inlinePatch = inlinePatch;
 76194:     if (loop && loop->generatingInvariants()) {
 76194:         Jump j = masm.jump();
 76194:         Label l = masm.label();
 78454:         loop->addInvariantCall(j, l, false, false, callSites.length(), uses);
 76194:     }
 76194:     addCallSite(site);
 52645: }
 52645: 
 52651: bool
 52651: mjit::Compiler::compareTwoValues(JSContext *cx, JSOp op, const Value &lhs, const Value &rhs)
 52651: {
 52651:     JS_ASSERT(lhs.isPrimitive());
 52651:     JS_ASSERT(rhs.isPrimitive());
 52651: 
 52651:     if (lhs.isString() && rhs.isString()) {
 84755:         int32_t cmp;
 59890:         CompareStrings(cx, lhs.toString(), rhs.toString(), &cmp);
 52651:         switch (op) {
 52651:           case JSOP_LT:
 52651:             return cmp < 0;
 52651:           case JSOP_LE:
 52651:             return cmp <= 0;
 52651:           case JSOP_GT:
 52651:             return cmp > 0;
 52651:           case JSOP_GE:
 52651:             return cmp >= 0;
 52679:           case JSOP_EQ:
 52679:             return cmp == 0;
 52679:           case JSOP_NE:
 52679:             return cmp != 0;
 52651:           default:
 52651:             JS_NOT_REACHED("NYI");
 52651:         }
 52651:     } else {
 52651:         double ld, rd;
 52651: 
 52651:         /* These should be infallible w/ primitives. */
 73894:         JS_ALWAYS_TRUE(ToNumber(cx, lhs, &ld));
 73894:         JS_ALWAYS_TRUE(ToNumber(cx, rhs, &rd));
 52651:         switch(op) {
 52651:           case JSOP_LT:
 52651:             return ld < rd;
 52651:           case JSOP_LE:
 52651:             return ld <= rd;
 52651:           case JSOP_GT:
 52651:             return ld > rd;
 52651:           case JSOP_GE:
 52651:             return ld >= rd;
 52679:           case JSOP_EQ: /* fall through */
 52679:           case JSOP_NE:
 52679:             /* Special case null/undefined/void comparisons. */
 52679:             if (lhs.isNullOrUndefined()) {
 52679:                 if (rhs.isNullOrUndefined())
 52679:                     return op == JSOP_EQ;
 52679:                 return op == JSOP_NE;
 52679:             }
 52679:             if (rhs.isNullOrUndefined())
 52679:                 return op == JSOP_NE;
 52679: 
 52679:             /* Normal return. */
 52679:             return (op == JSOP_EQ) ? (ld == rd) : (ld != rd);
 52651:           default:
 52651:             JS_NOT_REACHED("NYI");
 52651:         }
 52651:     }
 52651: 
 52651:     JS_NOT_REACHED("NYI");
 52651:     return false;
 52651: }
 52651: 
 56766: bool
 76194: mjit::Compiler::constantFoldBranch(jsbytecode *target, bool taken)
 76194: {
 76194:     if (taken) {
 76194:         if (!frame.syncForBranch(target, Uses(0)))
 76194:             return false;
 76194:         Jump j = masm.jump();
 82738:         if (!jumpAndRun(j, target))
 76194:             return false;
 76194:     } else {
 76194:         /*
 76194:          * Branch is never taken, but clean up any loop
 76194:          * if this is a backedge.
 76194:          */
 76194:         if (target < PC && !finishLoop(target))
 76194:             return false;
 76194:     }
 76194:     return true;
 76194: }
 76194: 
 76194: bool
 52653: mjit::Compiler::emitStubCmpOp(BoolStub stub, jsbytecode *target, JSOp fused)
 52653: {
 76194:     if (target)
 76194:         frame.syncAndKillEverything();
 76194:     else
 76194:         frame.syncAndKill(Uses(2));
 76194: 
 53087:     prepareStubCall(Uses(2));
 76194:     INLINE_STUBCALL(stub, target ? REJOIN_BRANCH : REJOIN_PUSH_BOOLEAN);
 71314:     frame.popn(2);
 76194: 
 76194:     if (!target) {
 71314:         frame.takeReg(Registers::ReturnReg);
 53025:         frame.pushTypedPayload(JSVAL_TYPE_BOOLEAN, Registers::ReturnReg);
 56766:         return true;
 56766:     }
 56766: 
 52679:     JS_ASSERT(fused == JSOP_IFEQ || fused == JSOP_IFNE);
 76194:     Jump j = masm.branchTest32(GetStubCompareCondition(fused), Registers::ReturnReg,
 52653:                                Registers::ReturnReg);
 82738:     return jumpAndRun(j, target);
 52653: }
 52653: 
 52692: void
 86855: mjit::Compiler::jsop_setprop_slow(PropertyName *name)
 52886: {
 53087:     prepareStubCall(Uses(2));
 86542:     masm.move(ImmPtr(name), Registers::ArgReg1);
 76194:     INLINE_STUBCALL(STRICT_VARIANT(stubs::SetName), REJOIN_FALLTHROUGH);
 52886:     JS_STATIC_ASSERT(JSOP_SETNAME_LENGTH == JSOP_SETPROP_LENGTH);
 52886:     frame.shimmy(1);
 95113:     if (script->hasScriptCounts)
 94574:         bumpPropCount(PC, PCCounts::PROP_OTHER);
 52886: }
 52886: 
 52886: void
 86855: mjit::Compiler::jsop_getprop_slow(PropertyName *name, bool forPrototype)
 52743: {
 76194:     /* See ::jsop_getprop */
 86855:     RejoinState rejoin = forPrototype ? REJOIN_THIS_PROTOTYPE : REJOIN_GETTER;
 86752: 
 86752:     prepareStubCall(Uses(1));
 86855:     masm.move(ImmPtr(name), Registers::ArgReg1);
 86855:     INLINE_STUBCALL(forPrototype ? stubs::GetPropNoCache : stubs::GetProp, rejoin);
 86855: 
 86855:     if (!forPrototype)
 86752:         testPushedType(rejoin, -1, /* ool = */ false);
 86752: 
 86752:     frame.pop();
 86752:     frame.pushSynced(JSVAL_TYPE_UNKNOWN);
 86752: 
 95113:     if (script->hasScriptCounts)
 94574:         bumpPropCount(PC, PCCounts::PROP_OTHER);
 86752: }
 86752: 
 76194: #ifdef JS_MONOIC
 76194: void
 76194: mjit::Compiler::passMICAddress(GlobalNameICInfo &ic)
 76194: {
 76194:     ic.addrLabel = stubcc.masm.moveWithPatch(ImmPtr(NULL), Registers::ArgReg1);
 76194: }
 76194: #endif
 76194: 
 76194: #if defined JS_POLYIC
 76194: void
 76194: mjit::Compiler::passICAddress(BaseICInfo *ic)
 76194: {
 76194:     ic->paramAddr = stubcc.masm.moveWithPatch(ImmPtr(NULL), Registers::ArgReg1);
 76194: }
 76194: 
 56037: bool
 86542: mjit::Compiler::jsop_getprop(PropertyName *name, JSValueType knownType,
 86855:                              bool doTypeCheck, bool forPrototype)
 52884: {
 52884:     FrameEntry *top = frame.peek(-1);
 52884: 
 76194:     /*
 76194:      * Use a different rejoin for GETPROP computing the 'this' object, as we
 76194:      * can't use the current bytecode within InternalInterpret to tell this is
 76194:      * fetching the 'this' value.
 76194:      */
 76194:     RejoinState rejoin = REJOIN_GETTER;
 86855:     if (forPrototype) {
 76194:         JS_ASSERT(top->isType(JSVAL_TYPE_OBJECT) &&
 86542:                   name == cx->runtime->atomState.classPrototypeAtom);
 76194:         rejoin = REJOIN_THIS_PROTOTYPE;
 76194:     }
 76194: 
 76194:     /* Handle length accesses on known strings without using a PIC. */
 86542:     if (name == cx->runtime->atomState.lengthAtom &&
 76194:         top->isType(JSVAL_TYPE_STRING) &&
 77355:         (!cx->typeInferenceEnabled() || knownPushedType(0) == JSVAL_TYPE_INT32)) {
 52884:         if (top->isConstant()) {
 53081:             JSString *str = top->getValue().toString();
 52884:             Value v;
 84755:             v.setNumber(uint32_t(str->length()));
 52884:             frame.pop();
 52884:             frame.push(v);
 52884:         } else {
 52884:             RegisterID str = frame.ownRegForData(top);
 59888:             masm.loadPtr(Address(str, JSString::offsetOfLengthAndFlags()), str);
 59977:             masm.urshift32(Imm32(JSString::LENGTH_SHIFT), str);
 52884:             frame.pop();
 53025:             frame.pushTypedPayload(JSVAL_TYPE_INT32, str);
 52884:         }
 56037:         return true;
 52884:     }
 52884: 
 86855:     if (top->mightBeType(JSVAL_TYPE_OBJECT) &&
 86855:         JSOp(*PC) == JSOP_LENGTH && cx->typeInferenceEnabled() &&
 77353:         !hasTypeBarriers(PC) && knownPushedType(0) == JSVAL_TYPE_INT32) {
 76194:         /* Check if this is an array we can make a loop invariant entry for. */
 76194:         if (loop && loop->generatingInvariants()) {
 76194:             CrossSSAValue topv(a->inlineIndex, analysis->poppedValue(PC, 0));
 76194:             FrameEntry *fe = loop->invariantLength(topv);
 76194:             if (fe) {
 76194:                 frame.learnType(fe, JSVAL_TYPE_INT32, false);
 74052:                 frame.pop();
 76194:                 frame.pushCopyOf(fe);
 95113:                 if (script->hasScriptCounts)
 94574:                     bumpPropCount(PC, PCCounts::PROP_STATIC);
 74052:                 return true;
 76194:             }
 76194:         }
 76194: 
 76194:         types::TypeSet *types = analysis->poppedTypes(PC, 0);
 76194: 
 76194:         /*
 76194:          * Check if we are accessing the 'length' property of a known dense array.
 76194:          * Note that if the types are known to indicate dense arrays, their lengths
 76194:          * must fit in an int32.
 76194:          */
 76194:         if (!types->hasObjectFlags(cx, types::OBJECT_FLAG_NON_DENSE_ARRAY)) {
 76194:             bool isObject = top->isTypeKnown();
 76194:             if (!isObject) {
 76194:                 Jump notObject = frame.testObject(Assembler::NotEqual, top);
 76194:                 stubcc.linkExit(notObject, Uses(1));
 76194:                 stubcc.leave();
 86855:                 stubcc.masm.move(ImmPtr(name), Registers::ArgReg1);
 76194:                 OOL_STUBCALL(stubs::GetProp, rejoin);
 78456:                 if (rejoin == REJOIN_GETTER)
 78456:                     testPushedType(rejoin, -1);
 76194:             }
 83231:             RegisterID result = frame.allocReg();
 76194:             RegisterID reg = frame.tempRegForData(top);
 76194:             frame.pop();
 83231:             masm.loadPtr(Address(reg, JSObject::offsetOfElements()), result);
 83231:             masm.load32(Address(result, ObjectElements::offsetOfLength()), result);
 83231:             frame.pushTypedPayload(JSVAL_TYPE_INT32, result);
 95113:             if (script->hasScriptCounts)
 94574:                 bumpPropCount(PC, PCCounts::PROP_DEFINITE);
 76194:             if (!isObject)
 76194:                 stubcc.rejoin(Changes(1));
 76194:             return true;
 76194:         }
 76194: 
 76194:         /*
 77344:          * Check if we're accessing the 'length' property of a typed array.
 77344:          * The typed array length always fits in an int32.
 77344:          */
 77344:         if (!types->hasObjectFlags(cx, types::OBJECT_FLAG_NON_TYPED_ARRAY)) {
 77344:             bool isObject = top->isTypeKnown();
 77344:             if (!isObject) {
 77344:                 Jump notObject = frame.testObject(Assembler::NotEqual, top);
 77344:                 stubcc.linkExit(notObject, Uses(1));
 77344:                 stubcc.leave();
 86855:                 stubcc.masm.move(ImmPtr(name), Registers::ArgReg1);
 77344:                 OOL_STUBCALL(stubs::GetProp, rejoin);
 78456:                 if (rejoin == REJOIN_GETTER)
 78456:                     testPushedType(rejoin, -1);
 77344:             }
 77344:             RegisterID reg = frame.copyDataIntoReg(top);
 77344:             frame.pop();
 80240:             masm.loadPayload(Address(reg, TypedArray::lengthOffset()), reg);
 80240:             frame.pushTypedPayload(JSVAL_TYPE_INT32, reg);
 95113:             if (script->hasScriptCounts)
 94574:                 bumpPropCount(PC, PCCounts::PROP_DEFINITE);
 77344:             if (!isObject)
 77344:                 stubcc.rejoin(Changes(1));
 77344:             return true;
 77344:         }
 77344: 
 77344:         /*
 76194:          * Check if we are accessing the 'length' of the lazy arguments for the
 87583:          * current frame.
 76194:          */
 95100:         if (types->isMagicArguments(cx)) {
 76194:             frame.pop();
 87583:             frame.pushWord(Address(JSFrameReg, StackFrame::offsetOfNumActual()), JSVAL_TYPE_INT32);
 95113:             if (script->hasScriptCounts)
 94574:                 bumpPropCount(PC, PCCounts::PROP_DEFINITE);
 76194:             return true;
 76194:         }
 76194:     }
 74052: 
 86855:     /* If the access will definitely be fetching a particular value, nop it. */
 86855:     bool testObject;
 86855:     JSObject *singleton =
 86855:         (*PC == JSOP_GETPROP || *PC == JSOP_CALLPROP) ? pushedSingleton(0) : NULL;
 86855:     if (singleton && singleton->isFunction() && !hasTypeBarriers(PC) &&
 99421:         testSingletonPropertyTypes(top, RootedId(cx, NameToId(name)), &testObject)) {
 86855:         if (testObject) {
 86855:             Jump notObject = frame.testObject(Assembler::NotEqual, top);
 86855:             stubcc.linkExit(notObject, Uses(1));
 86855:             stubcc.leave();
 86855:             stubcc.masm.move(ImmPtr(name), Registers::ArgReg1);
 86855:             OOL_STUBCALL(stubs::GetProp, REJOIN_FALLTHROUGH);
 86855:             testPushedType(REJOIN_FALLTHROUGH, -1);
 86855:         }
 86855: 
 86855:         frame.pop();
 86855:         frame.push(ObjectValue(*singleton));
 86855: 
 95113:         if (script->hasScriptCounts && cx->typeInferenceEnabled())
 94574:             bumpPropCount(PC, PCCounts::PROP_STATIC);
 86855: 
 86855:         if (testObject)
 86855:             stubcc.rejoin(Changes(1));
 86855: 
 86855:         return true;
 86855:     }
 86855: 
 76194:     /* Check if this is a property access we can make a loop invariant entry for. */
 76194:     if (loop && loop->generatingInvariants() && !hasTypeBarriers(PC)) {
 76194:         CrossSSAValue topv(a->inlineIndex, analysis->poppedValue(PC, 0));
 97828:         if (FrameEntry *fe = loop->invariantProperty(topv, NameToId(name))) {
 76194:             if (knownType != JSVAL_TYPE_UNKNOWN && knownType != JSVAL_TYPE_DOUBLE)
 76194:                 frame.learnType(fe, knownType, false);
 76194:             frame.pop();
 76194:             frame.pushCopyOf(fe);
 95113:             if (script->hasScriptCounts)
 94574:                 bumpPropCount(PC, PCCounts::PROP_STATIC);
 76194:             return true;
 76194:         }
 76194:     }
 76194: 
 86855:     /* If the incoming type will never PIC, take slow path. */
 86855:     if (top->isNotType(JSVAL_TYPE_OBJECT)) {
 86855:         jsop_getprop_slow(name, forPrototype);
 86855:         return true;
 86855:     }
 86855: 
 86855:     frame.forgetMismatchedObject(top);
 86855: 
 76194:     /*
 76194:      * Check if we are accessing a known type which always has the property
 76194:      * in a particular inline slot. Get the property directly in this case,
 76194:      * without using an IC.
 76194:      */
 97828:     jsid id = NameToId(name);
 76194:     types::TypeSet *types = frame.extra(top).types;
 77357:     if (types && !types->unknownObject() &&
 77353:         types->getObjectCount() == 1 &&
 77353:         types->getTypeObject(0) != NULL &&
 77353:         !types->getTypeObject(0)->unknownProperties() &&
 77353:         id == types::MakeTypeId(cx, id)) {
 86855:         JS_ASSERT(!forPrototype);
 77353:         types::TypeObject *object = types->getTypeObject(0);
 76194:         types::TypeSet *propertyTypes = object->getProperty(cx, id, false);
 76194:         if (!propertyTypes)
 76194:             return false;
 77361:         if (propertyTypes->isDefiniteProperty() &&
 77361:             !propertyTypes->isOwnProperty(cx, object, true)) {
 76194:             types->addFreeze(cx);
 84755:             uint32_t slot = propertyTypes->definiteSlot();
 76194:             bool isObject = top->isTypeKnown();
 76194:             if (!isObject) {
 76194:                 Jump notObject = frame.testObject(Assembler::NotEqual, top);
 76194:                 stubcc.linkExit(notObject, Uses(1));
 76194:                 stubcc.leave();
 86855:                 stubcc.masm.move(ImmPtr(name), Registers::ArgReg1);
 76194:                 OOL_STUBCALL(stubs::GetProp, rejoin);
 78456:                 if (rejoin == REJOIN_GETTER)
 78456:                     testPushedType(rejoin, -1);
 76194:             }
 76194:             RegisterID reg = frame.tempRegForData(top);
 76194:             frame.pop();
 76194: 
 95113:             if (script->hasScriptCounts)
 94574:                 bumpPropCount(PC, PCCounts::PROP_DEFINITE);
 82134: 
 76194:             Address address(reg, JSObject::getFixedSlotOffset(slot));
 76194:             BarrierState barrier = pushAddressMaybeBarrier(address, knownType, false);
 76194:             if (!isObject)
 76194:                 stubcc.rejoin(Changes(1));
 76194:             finishBarrier(barrier, rejoin, 0);
 76194: 
 76194:             return true;
 76194:         }
 76194:     }
 76194: 
 86855:     /* Check for a dynamic dispatch. */
 86855:     if (cx->typeInferenceEnabled()) {
 86855:         if (*PC == JSOP_CALLPROP && jsop_getprop_dispatch(name))
 86855:             return true;
 86855:     }
 86855: 
 95113:     if (script->hasScriptCounts)
 94574:         bumpPropCount(PC, PCCounts::PROP_OTHER);
 82134: 
 52884:     /*
 52884:      * These two must be loaded first. The objReg because the string path
 52884:      * wants to read it, and the shapeReg because it could cause a spill that
 52884:      * the string path wouldn't sink back.
 52884:      */
 86855:     RegisterID objReg = frame.copyDataIntoReg(top);
 86855:     RegisterID shapeReg = frame.allocReg();
 52884: 
 60592:     RESERVE_IC_SPACE(masm);
 60592: 
 86855:     PICGenInfo pic(ic::PICInfo::GET, JSOp(*PC));
 52880: 
 78454:     /*
 78454:      * If this access has been on a shape with a getter hook, make preparations
 78454:      * so that we can generate a stub to call the hook directly (rather than be
 78454:      * forced to make a stub call). Sync the stack up front and kill all
 78454:      * registers so that PIC stubs can contain calls, and always generate a
 78454:      * type barrier if inference is enabled (known property types do not
 78454:      * reflect properties with getter hooks).
 78454:      */
 78456:     pic.canCallHook = pic.forcedTypeBarrier =
 86855:         !forPrototype &&
 78822:         JSOp(*PC) == JSOP_GETPROP &&
 78822:         analysis->getCode(PC).accessGetter;
 87143: 
 87143:     /* Guard that the type is an object. */
 87143:     Label typeCheck;
 87143:     if (doTypeCheck && !top->isTypeKnown()) {
 87143:         RegisterID reg = frame.tempRegForType(top);
 87143:         pic.typeReg = reg;
 87143: 
 87143:         if (pic.canCallHook) {
 87143:             PinRegAcrossSyncAndKill p1(frame, reg);
 87143:             frame.syncAndKillEverything();
 87143:         }
 87143: 
 87143:         /* Start the hot path where it's easy to patch it. */
 87143:         pic.fastPathStart = masm.label();
 87143:         Jump j = masm.testObject(Assembler::NotEqual, reg);
 87143:         typeCheck = masm.label();
 87143:         RETURN_IF_OOM(false);
 87143: 
 87143:         pic.typeCheck = stubcc.linkExit(j, Uses(1));
 87143:         pic.hasTypeCheck = true;
 87143:     } else {
 78454:         if (pic.canCallHook)
 78454:             frame.syncAndKillEverything();
 78454: 
 87143:         pic.fastPathStart = masm.label();
 87143:         pic.hasTypeCheck = false;
 87143:         pic.typeReg = Registers::ReturnReg;
 87143:     }
 87143: 
 52880:     pic.shapeReg = shapeReg;
 86542:     pic.name = name;
 52880: 
 52880:     /* Guard on shape. */
 53445:     masm.loadShape(objReg, shapeReg);
 52880:     pic.shapeGuard = masm.label();
 53270: 
 83221:     DataLabelPtr inlineShapeLabel;
 83221:     Jump j = masm.branchPtrWithPatch(Assembler::NotEqual, shapeReg,
 83221:                                      inlineShapeLabel, ImmPtr(NULL));
 60592:     Label inlineShapeJump = masm.label();
 60592: 
 60592:     RESERVE_OOL_SPACE(stubcc.masm);
 53479:     pic.slowPathStart = stubcc.linkExit(j, Uses(1));
 98147:     pic.cached = !forPrototype;
 52880: 
 52880:     stubcc.leave();
 56738:     passICAddress(&pic);
 98147:     pic.slowPathCall = OOL_STUBCALL(ic::GetProp, rejoin);
 60592:     CHECK_OOL_SPACE();
 78456:     if (rejoin == REJOIN_GETTER)
 78456:         testPushedType(rejoin, -1);
 60592: 
 60592:     /* Load the base slot address. */
 83231:     Label dslotsLoadLabel = masm.loadPtrWithPatchToLEA(Address(objReg, JSObject::offsetOfSlots()),
 60592:                                                                objReg);
 52880: 
 52880:     /* Copy the slot value to the expression stack. */
 52880:     Address slot(objReg, 1 << 24);
 52880:     frame.pop();
 53270: 
 60592:     Label fastValueLoad = masm.loadValueWithAddressOffsetPatch(slot, shapeReg, objReg);
 60592:     pic.fastPathRejoin = masm.label();
 60592: 
 60592:     RETURN_IF_OOM(false);
 60592: 
 60592:     /* Initialize op labels. */
 60592:     GetPropLabels &labels = pic.getPropLabels();
 60592:     labels.setDslotsLoad(masm, pic.fastPathRejoin, dslotsLoadLabel);
 60592:     labels.setInlineShapeData(masm, pic.shapeGuard, inlineShapeLabel);
 60592: 
 60592:     labels.setValueLoad(masm, pic.fastPathRejoin, fastValueLoad);
 60592:     if (pic.hasTypeCheck)
 60592:         labels.setInlineTypeJump(masm, pic.fastPathStart, typeCheck);
 60592:     labels.setInlineShapeJump(masm, pic.shapeGuard, inlineShapeJump);
 53270: 
 78455:     CHECK_IC_SPACE();
 78455: 
 52880:     pic.objReg = objReg;
 76194:     frame.pushRegs(shapeReg, objReg, knownType);
 78454:     BarrierState barrier = testBarrier(pic.shapeReg, pic.objReg, false, false,
 78454:                                        /* force = */ pic.canCallHook);
 52880: 
 53088:     stubcc.rejoin(Changes(1));
 52880:     pics.append(pic);
 76194: 
 76194:     finishBarrier(barrier, rejoin, 0);
 56037:     return true;
 52880: }
 60598: 
 52903: bool
 98960: mjit::Compiler::testSingletonProperty(HandleObject obj, HandleId id)
 76194: {
 76194:     /*
 76194:      * We would like to completely no-op property/global accesses which can
 76194:      * produce only a particular JSObject or undefined, provided we can
 76194:      * determine the pushed value must not be undefined (or, if it could be
 76194:      * undefined, a recompilation will be triggered).
 76194:      *
 76194:      * If the access definitely goes through obj, either directly or on the
 76194:      * prototype chain, then if obj has a defined property now, and the
 76194:      * property has a default or method shape, the only way it can produce
 76194:      * undefined in the future is if it is deleted. Deletion causes type
 76194:      * properties to be explicitly marked with undefined.
 76194:      */
 76194: 
 77384:     JSObject *nobj = obj;
 77384:     while (nobj) {
 77384:         if (!nobj->isNative())
 76194:             return false;
 80442:         if (nobj->getClass()->ops.lookupGeneric)
 76194:             return false;
 77384:         nobj = nobj->getProto();
 77384:     }
 76194: 
 76194:     JSObject *holder;
 76194:     JSProperty *prop = NULL;
 80442:     if (!obj->lookupGeneric(cx, id, &holder, &prop))
 76194:         return false;
 76194:     if (!prop)
 76194:         return false;
 76194: 
 76194:     Shape *shape = (Shape *) prop;
 76194:     if (shape->hasDefaultGetter()) {
 76194:         if (!shape->hasSlot())
 76194:             return false;
 83221:         if (holder->getSlot(shape->slot()).isUndefined())
 76194:             return false;
 94227:     } else {
 76194:         return false;
 76194:     }
 76194: 
 76194:     return true;
 76194: }
 76194: 
 76194: bool
 98960: mjit::Compiler::testSingletonPropertyTypes(FrameEntry *top, HandleId id, bool *testObject)
 76194: {
 76194:     *testObject = false;
 76194: 
 76194:     types::TypeSet *types = frame.extra(top).types;
 77353:     if (!types || types->unknownObject())
 76194:         return false;
 76194: 
 99421:     RootedObject singleton(cx, types->getSingleton(cx));
 76194:     if (singleton)
 76194:         return testSingletonProperty(singleton, id);
 76194: 
 76194:     if (!globalObj)
 76194:         return false;
 76194: 
 76194:     JSProtoKey key;
 76194:     JSValueType type = types->getKnownTypeTag(cx);
 76194:     switch (type) {
 76194:       case JSVAL_TYPE_STRING:
 76194:         key = JSProto_String;
 76194:         break;
 76194: 
 76194:       case JSVAL_TYPE_INT32:
 76194:       case JSVAL_TYPE_DOUBLE:
 76194:         key = JSProto_Number;
 76194:         break;
 76194: 
 76194:       case JSVAL_TYPE_BOOLEAN:
 76194:         key = JSProto_Boolean;
 76194:         break;
 76194: 
 76194:       case JSVAL_TYPE_OBJECT:
 76194:       case JSVAL_TYPE_UNKNOWN:
 76194:         if (types->getObjectCount() == 1 && !top->isNotType(JSVAL_TYPE_OBJECT)) {
 76194:             JS_ASSERT_IF(top->isTypeKnown(), top->isType(JSVAL_TYPE_OBJECT));
 77353:             types::TypeObject *object = types->getTypeObject(0);
 77353:             if (object && object->proto) {
 99421:                 if (!testSingletonProperty(RootedObject(cx, object->proto), id))
 76194:                     return false;
 76194:                 types->addFreeze(cx);
 76194: 
 76194:                 /* If we don't know this is an object, we will need a test. */
 76194:                 *testObject = (type != JSVAL_TYPE_OBJECT) && !top->isTypeKnown();
 76194:                 return true;
 76194:             }
 76194:         }
 76194:         return false;
 76194: 
 76194:       default:
 76194:         return false;
 76194:     }
 76194: 
 99421:     RootedObject proto(cx);
 98960:     if (!js_GetClassPrototype(cx, globalObj, key, proto.address(), NULL))
 76194:         return NULL;
 76194: 
 76194:     return testSingletonProperty(proto, id);
 76194: }
 76194: 
 76194: bool
 86855: mjit::Compiler::jsop_getprop_dispatch(PropertyName *name)
 76194: {
 76194:     /*
 76194:      * Check for a CALLPROP which is a dynamic dispatch: every value it can
 76194:      * push is a singleton, and the pushed value is determined by the type of
 76194:      * the object being accessed. Return true if the CALLPROP has been fully
 76194:      * processed, false if no code was generated.
 76194:      */
 76194:     FrameEntry *top = frame.peek(-1);
 76194:     if (top->isNotType(JSVAL_TYPE_OBJECT))
 76194:         return false;
 76194: 
 99421:     RootedId id(cx, NameToId(name));
 98960:     if (id.reference() != types::MakeTypeId(cx, id))
 76194:         return false;
 76194: 
 76194:     types::TypeSet *pushedTypes = pushedTypeSet(0);
 77353:     if (pushedTypes->unknownObject() || pushedTypes->baseFlags() != 0)
 76194:         return false;
 76194: 
 76194:     /* Check every pushed value is a singleton. */
 76194:     for (unsigned i = 0; i < pushedTypes->getObjectCount(); i++) {
 77353:         if (pushedTypes->getTypeObject(i) != NULL)
 76194:             return false;
 76194:     }
 76194: 
 76194:     types::TypeSet *objTypes = analysis->poppedTypes(PC, 0);
 77353:     if (objTypes->unknownObject() || objTypes->getObjectCount() == 0)
 76194:         return false;
 76194: 
 76194:     pushedTypes->addFreeze(cx);
 76194: 
 76194:     /* Map each type in the object to the resulting pushed value. */
 76194:     Vector<JSObject *> results(CompilerAllocPolicy(cx, *this));
 76194: 
 76194:     /*
 76194:      * For each type of the base object, check it has no 'own' property for the
 76194:      * accessed id and that its prototype does have such a property.
 76194:      */
 84755:     uint32_t last = 0;
 76194:     for (unsigned i = 0; i < objTypes->getObjectCount(); i++) {
 77353:         if (objTypes->getSingleObject(i) != NULL)
 77353:             return false;
 77353:         types::TypeObject *object = objTypes->getTypeObject(i);
 76194:         if (!object) {
 77403:             results.append((JSObject *) NULL);
 76194:             continue;
 76194:         }
 76194:         if (object->unknownProperties() || !object->proto)
 76194:             return false;
 76194:         types::TypeSet *ownTypes = object->getProperty(cx, id, false);
 77361:         if (ownTypes->isOwnProperty(cx, object, false))
 76194:             return false;
 76194: 
 99421:         if (!testSingletonProperty(RootedObject(cx, object->proto), id))
 76194:             return false;
 76194: 
 77363:         if (object->proto->getType(cx)->unknownProperties())
 77363:             return false;
 77363:         types::TypeSet *protoTypes = object->proto->type()->getProperty(cx, id, false);
 77353:         if (!protoTypes)
 77353:             return false;
 76194:         JSObject *singleton = protoTypes->getSingleton(cx);
 76194:         if (!singleton)
 76194:             return false;
 76194: 
 76194:         results.append(singleton);
 76194:         last = i;
 76194:     }
 76194: 
 76194:     if (oomInVector)
 76194:         return false;
 76194: 
 76194:     objTypes->addFreeze(cx);
 76194: 
 76194:     /* Done filtering, now generate code which dispatches on the type. */
 76194: 
 76194:     frame.forgetMismatchedObject(top);
 76194: 
 76194:     if (!top->isType(JSVAL_TYPE_OBJECT)) {
 76194:         Jump notObject = frame.testObject(Assembler::NotEqual, top);
 76194:         stubcc.linkExit(notObject, Uses(1));
 76194:     }
 76194: 
 76194:     RegisterID reg = frame.tempRegForData(top);
 76194:     frame.pinReg(reg);
 76194:     RegisterID pushreg = frame.allocReg();
 76194:     frame.unpinReg(reg);
 76194: 
 77353:     Address typeAddress(reg, JSObject::offsetOfType());
 76194: 
 76194:     Vector<Jump> rejoins(CompilerAllocPolicy(cx, *this));
 76194:     MaybeJump lastMiss;
 76194: 
 76194:     for (unsigned i = 0; i < objTypes->getObjectCount(); i++) {
 77353:         types::TypeObject *object = objTypes->getTypeObject(i);
 76194:         if (!object) {
 76194:             JS_ASSERT(results[i] == NULL);
 76194:             continue;
 76194:         }
 76194:         if (lastMiss.isSet())
 76194:             lastMiss.get().linkTo(masm.label(), &masm);
 76194: 
 76194:         /*
 76194:          * Check that the pushed result is actually in the known pushed types
 76194:          * for the bytecode; this bytecode may have type barriers. Redirect to
 76194:          * the stub to update said pushed types.
 76194:          */
 77353:         if (!pushedTypes->hasType(types::Type::ObjectType(results[i]))) {
 76194:             JS_ASSERT(hasTypeBarriers(PC));
 76194:             if (i == last) {
 76194:                 stubcc.linkExit(masm.jump(), Uses(1));
 76194:                 break;
 76194:             } else {
 76194:                 lastMiss.setJump(masm.branchPtr(Assembler::NotEqual, typeAddress, ImmPtr(object)));
 76194:                 stubcc.linkExit(masm.jump(), Uses(1));
 76194:                 continue;
 76194:             }
 76194:         }
 76194: 
 76194:         if (i == last) {
 76194:             masm.move(ImmPtr(results[i]), pushreg);
 76194:             break;
 76194:         } else {
 76194:             lastMiss.setJump(masm.branchPtr(Assembler::NotEqual, typeAddress, ImmPtr(object)));
 76194:             masm.move(ImmPtr(results[i]), pushreg);
 76194:             rejoins.append(masm.jump());
 76194:         }
 76194:     }
 76194: 
 76194:     for (unsigned i = 0; i < rejoins.length(); i++)
 76194:         rejoins[i].linkTo(masm.label(), &masm);
 76194: 
 76194:     stubcc.leave();
 86542:     stubcc.masm.move(ImmPtr(name), Registers::ArgReg1);
 86855:     OOL_STUBCALL(stubs::GetProp, REJOIN_FALLTHROUGH);
 78456:     testPushedType(REJOIN_FALLTHROUGH, -1);
 76194: 
 86855:     frame.pop();
 76194:     frame.pushTypedPayload(JSVAL_TYPE_OBJECT, pushreg);
 76194: 
 95113:     if (script->hasScriptCounts)
 94574:         bumpPropCount(PC, PCCounts::PROP_DEFINITE);
 82134: 
 76194:     stubcc.rejoin(Changes(2));
 52903:     return true;
 52896: }
 52896: 
 52903: bool
 86855: mjit::Compiler::jsop_setprop(PropertyName *name, bool popGuaranteed)
 52886: {
 52887:     FrameEntry *lhs = frame.peek(-2);
 52887:     FrameEntry *rhs = frame.peek(-1);
 52887: 
 52887:     /* If the incoming type will never PIC, take slow path. */
 53025:     if (lhs->isTypeKnown() && lhs->getKnownType() != JSVAL_TYPE_OBJECT) {
 86855:         jsop_setprop_slow(name);
 56037:         return true;
 52887:     }
 52887: 
 76194:     /*
 77884:      * If this is a SETNAME to a variable of a non-reentrant outer function,
 77884:      * set the variable's slot directly for the active call object.
 77884:      */
 77884:     if (cx->typeInferenceEnabled() && js_CodeSpec[*PC].format & JOF_NAME) {
 77884:         ScriptAnalysis::NameAccess access =
 97828:             analysis->resolveNameAccess(cx, NameToId(name), true);
 77884:         if (access.nesting) {
 87606:             /* Use a SavedReg so it isn't clobbered by the stub call. */
 82129:             RegisterID nameReg = frame.allocReg(Registers::SavedRegs).reg();
 82129:             Address address = frame.loadNameAddress(access, nameReg);
 82129: 
 82129: #ifdef JSGC_INCREMENTAL_MJ
 82129:             /* Write barrier. */
 82129:             if (cx->compartment->needsBarrier()) {
 82129:                 stubcc.linkExit(masm.jump(), Uses(0));
 82129:                 stubcc.leave();
 88446: 
 88446:                 /* sync() may have overwritten nameReg, so we reload its data. */
 88446:                 JS_ASSERT(address.base == nameReg);
 88446:                 stubcc.masm.move(ImmPtr(access.basePointer()), nameReg);
 88446:                 stubcc.masm.loadPtr(Address(nameReg), nameReg);
 88446:                 stubcc.masm.addPtr(Imm32(address.offset), nameReg, Registers::ArgReg1);
 88446: 
 82129:                 OOL_STUBCALL(stubs::WriteBarrier, REJOIN_NONE);
 82129:                 stubcc.rejoin(Changes(0));
 82129:             }
 82129: #endif
 82129: 
 77884:             frame.storeTo(rhs, address, popGuaranteed);
 77884:             frame.shimmy(1);
 77884:             frame.freeReg(address.base);
 77884:             return true;
 77884:         }
 77884:     }
 77884: 
 77884:     /*
 76194:      * Set the property directly if we are accessing a known object which
 76194:      * always has the property in a particular inline slot.
 76194:      */
 97828:     jsid id = NameToId(name);
 76194:     types::TypeSet *types = frame.extra(lhs).types;
 76194:     if (JSOp(*PC) == JSOP_SETPROP && id == types::MakeTypeId(cx, id) &&
 77353:         types && !types->unknownObject() &&
 77353:         types->getObjectCount() == 1 &&
 77353:         types->getTypeObject(0) != NULL &&
 77353:         !types->getTypeObject(0)->unknownProperties()) {
 77353:         types::TypeObject *object = types->getTypeObject(0);
 76194:         types::TypeSet *propertyTypes = object->getProperty(cx, id, false);
 76194:         if (!propertyTypes)
 76194:             return false;
 77361:         if (propertyTypes->isDefiniteProperty() &&
 77361:             !propertyTypes->isOwnProperty(cx, object, true)) {
 76194:             types->addFreeze(cx);
 84755:             uint32_t slot = propertyTypes->definiteSlot();
 82129:             RegisterID reg = frame.tempRegForData(lhs);
 96824:             frame.pinReg(reg);
 76194:             bool isObject = lhs->isTypeKnown();
 84172:             MaybeJump notObject;
 84172:             if (!isObject)
 84172:                 notObject = frame.testObject(Assembler::NotEqual, lhs);
 82129: #ifdef JSGC_INCREMENTAL_MJ
 82129:             if (cx->compartment->needsBarrier() && propertyTypes->needsBarrier(cx)) {
 82129:                 /* Write barrier. */
 84172:                 Jump j = masm.testGCThing(Address(reg, JSObject::getFixedSlotOffset(slot)));
 82129:                 stubcc.linkExit(j, Uses(0));
 82129:                 stubcc.leave();
 82129:                 stubcc.masm.addPtr(Imm32(JSObject::getFixedSlotOffset(slot)),
 82129:                                    reg, Registers::ArgReg1);
 82129:                 OOL_STUBCALL(stubs::GCThingWriteBarrier, REJOIN_NONE);
 82129:                 stubcc.rejoin(Changes(0));
 87606:             }
 82129: #endif
 76194:             if (!isObject) {
 84172:                 stubcc.linkExit(notObject.get(), Uses(2));
 76194:                 stubcc.leave();
 86542:                 stubcc.masm.move(ImmPtr(name), Registers::ArgReg1);
 76194:                 OOL_STUBCALL(STRICT_VARIANT(stubs::SetName), REJOIN_FALLTHROUGH);
 76194:             }
 76194:             frame.storeTo(rhs, Address(reg, JSObject::getFixedSlotOffset(slot)), popGuaranteed);
 96824:             frame.unpinReg(reg);
 76194:             frame.shimmy(1);
 76194:             if (!isObject)
 76194:                 stubcc.rejoin(Changes(1));
 95113:             if (script->hasScriptCounts)
 94574:                 bumpPropCount(PC, PCCounts::PROP_DEFINITE);
 76194:             return true;
 76194:         }
 76194:     }
 76194: 
 95113:     if (script->hasScriptCounts)
 94574:         bumpPropCount(PC, PCCounts::PROP_OTHER);
 82134: 
 89969:     JSOp op = JSOp(*PC);
 89969: 
 82129: #ifdef JSGC_INCREMENTAL_MJ
 89970:     /* Write barrier. We don't have type information for JSOP_SETNAME. */
 89969:     if (cx->compartment->needsBarrier() &&
 89970:         (!types || op == JSOP_SETNAME || types->propertyNeedsBarrier(cx, id)))
 89969:     {
 86855:         jsop_setprop_slow(name);
 82129:         return true;
 82129:     }
 82129: #endif
 82129: 
 94227:     PICGenInfo pic(ic::PICInfo::SET, op);
 86542:     pic.name = name;
 52887: 
 76194:     if (monitored(PC)) {
 77353:         pic.typeMonitored = true;
 76194:         types::TypeSet *types = frame.extra(rhs).types;
 77353:         if (!types) {
 77353:             /* Handle FORNAME and other compound opcodes. Yuck. */
 77353:             types = types::TypeSet::make(cx, "unknownRHS");
 77353:             if (!types)
 76194:                 return false;
 77353:             types->addType(cx, types::Type::UnknownType());
 77353:         }
 77353:         pic.rhsTypes = types;
 76194:     } else {
 76194:         pic.typeMonitored = false;
 76194:         pic.rhsTypes = NULL;
 76194:     }
 76194: 
 60595:     RESERVE_IC_SPACE(masm);
 60595:     RESERVE_OOL_SPACE(stubcc.masm);
 60595: 
 52887:     /* Guard that the type is an object. */
 52887:     Jump typeCheck;
 52887:     if (!lhs->isTypeKnown()) {
 52887:         RegisterID reg = frame.tempRegForType(lhs);
 52887:         pic.typeReg = reg;
 52887: 
 52887:         /* Start the hot path where it's easy to patch it. */
 53270:         pic.fastPathStart = masm.label();
 53025:         Jump j = masm.testObject(Assembler::NotEqual, reg);
 52887: 
 53588:         pic.typeCheck = stubcc.linkExit(j, Uses(2));
 52887:         stubcc.leave();
 53492: 
 86542:         stubcc.masm.move(ImmPtr(name), Registers::ArgReg1);
 76194:         OOL_STUBCALL(STRICT_VARIANT(stubs::SetName), REJOIN_FALLTHROUGH);
 86855: 
 52887:         typeCheck = stubcc.masm.jump();
 52887:         pic.hasTypeCheck = true;
 52887:     } else {
 53270:         pic.fastPathStart = masm.label();
 52887:         pic.hasTypeCheck = false;
 52887:         pic.typeReg = Registers::ReturnReg;
 52887:     }
 52887: 
 76194:     frame.forgetMismatchedObject(lhs);
 76194: 
 52887:     /* Get the object into a mutable register. */
 52887:     RegisterID objReg = frame.copyDataIntoReg(lhs);
 52887:     pic.objReg = objReg;
 52887: 
 52887:     /* Get info about the RHS and pin it. */
 52887:     ValueRemat vr;
 54160:     frame.pinEntry(rhs, vr);
 52887:     pic.vr = vr;
 52887: 
 52887:     RegisterID shapeReg = frame.allocReg();
 52887:     pic.shapeReg = shapeReg;
 52887: 
 54160:     frame.unpinEntry(vr);
 52887: 
 52887:     /* Guard on shape. */
 53445:     masm.loadShape(objReg, shapeReg);
 52887:     pic.shapeGuard = masm.label();
 83221:     DataLabelPtr inlineShapeData;
 83221:     Jump j = masm.branchPtrWithPatch(Assembler::NotEqual, shapeReg,
 83221:                                      inlineShapeData, ImmPtr(NULL));
 60595:     Label afterInlineShapeJump = masm.label();
 52887: 
 52887:     /* Slow path. */
 52887:     {
 53588:         pic.slowPathStart = stubcc.linkExit(j, Uses(2));
 52887: 
 52887:         stubcc.leave();
 56738:         passICAddress(&pic);
 76194:         pic.slowPathCall = OOL_STUBCALL(ic::SetProp, REJOIN_FALLTHROUGH);
 60595:         CHECK_OOL_SPACE();
 52887:     }
 52887: 
 52887:     /* Load dslots. */
 83231:     Label dslotsLoadLabel = masm.loadPtrWithPatchToLEA(Address(objReg, JSObject::offsetOfSlots()),
 60595:                                                        objReg);
 52887: 
 52887:     /* Store RHS into object slot. */
 53315:     Address slot(objReg, 1 << 24);
 60781:     DataLabel32 inlineValueStore = masm.storeValueWithAddressOffsetPatch(vr, slot);
 56575:     pic.fastPathRejoin = masm.label();
 53315: 
 52887:     frame.freeReg(objReg);
 52887:     frame.freeReg(shapeReg);
 52887: 
 52887:     /* "Pop under", taking out object (LHS) and leaving RHS. */
 52887:     frame.shimmy(1);
 52887: 
 52887:     /* Finish slow path. */
 52887:     {
 52887:         if (pic.hasTypeCheck)
 52887:             typeCheck.linkTo(stubcc.masm.label(), &stubcc.masm);
 53088:         stubcc.rejoin(Changes(1));
 52887:     }
 52887: 
 56037:     RETURN_IF_OOM(false);
 60590: 
 60590:     SetPropLabels &labels = pic.setPropLabels();
 60595:     labels.setInlineShapeData(masm, pic.shapeGuard, inlineShapeData);
 83221:     labels.setDslotsLoad(masm, pic.fastPathRejoin, dslotsLoadLabel);
 83221:     labels.setInlineValueStore(masm, pic.fastPathRejoin, inlineValueStore);
 60595:     labels.setInlineShapeJump(masm, pic.shapeGuard, afterInlineShapeJump);
 53270: 
 52887:     pics.append(pic);
 56037:     return true;
 52886: }
 60598: 
 53054: void
 86855: mjit::Compiler::jsop_name(PropertyName *name, JSValueType type)
 53054: {
 77884:     /*
 77884:      * If this is a NAME for a variable of a non-reentrant outer function, get
 77884:      * the variable's slot directly for the active call object. We always need
 77884:      * to check for undefined, however.
 77884:      */
 77884:     if (cx->typeInferenceEnabled()) {
 77884:         ScriptAnalysis::NameAccess access =
 97828:             analysis->resolveNameAccess(cx, NameToId(name), true);
 77884:         if (access.nesting) {
 77884:             Address address = frame.loadNameAddress(access);
 77884:             JSValueType type = knownPushedType(0);
 77884:             BarrierState barrier = pushAddressMaybeBarrier(address, type, true,
 77884:                                                            /* testUndefined = */ true);
 77884:             finishBarrier(barrier, REJOIN_GETTER, 0);
 77884:             return;
 77884:         }
 77884:     }
 77884: 
 86855:     PICGenInfo pic(ic::PICInfo::NAME, JSOp(*PC));
 53054: 
 60594:     RESERVE_IC_SPACE(masm);
 60594: 
 53054:     pic.shapeReg = frame.allocReg();
 53054:     pic.objReg = frame.allocReg();
 53054:     pic.typeReg = Registers::ReturnReg;
 86542:     pic.name = name;
 53054:     pic.hasTypeCheck = false;
 53270:     pic.fastPathStart = masm.label();
 53054: 
 60594:     /* There is no inline implementation, so we always jump to the slow path or to a stub. */
 53054:     pic.shapeGuard = masm.label();
 60594:     Jump inlineJump = masm.jump();
 53054:     {
 60594:         RESERVE_OOL_SPACE(stubcc.masm);
 60594:         pic.slowPathStart = stubcc.linkExit(inlineJump, Uses(0));
 53054:         stubcc.leave();
 56738:         passICAddress(&pic);
 86855:         pic.slowPathCall = OOL_STUBCALL(ic::Name, REJOIN_GETTER);
 60594:         CHECK_OOL_SPACE();
 86855:         testPushedType(REJOIN_GETTER, 0);
 60594:     }
 56575:     pic.fastPathRejoin = masm.label();
 60594: 
 60594:     /* Initialize op labels. */
 60594:     ScopeNameLabels &labels = pic.scopeNameLabels();
 60594:     labels.setInlineJump(masm, pic.fastPathStart, inlineJump);
 60594: 
 78455:     CHECK_IC_SPACE();
 78455: 
 76194:     /*
 76194:      * We can't optimize away the PIC for the NAME access itself, but if we've
 76194:      * only seen a single value pushed by this access, mark it as such and
 76194:      * recompile if a different value becomes possible.
 76194:      */
 76194:     JSObject *singleton = pushedSingleton(0);
 76194:     if (singleton) {
 76194:         frame.push(ObjectValue(*singleton));
 76194:         frame.freeReg(pic.shapeReg);
 76194:         frame.freeReg(pic.objReg);
 76194:     } else {
 76194:         frame.pushRegs(pic.shapeReg, pic.objReg, type);
 76194:     }
 76194:     BarrierState barrier = testBarrier(pic.shapeReg, pic.objReg, /* testUndefined = */ true);
 71340: 
 86855:     stubcc.rejoin(Changes(1));
 53054: 
 53054:     pics.append(pic);
 76194: 
 86855:     finishBarrier(barrier, REJOIN_GETTER, 0);
 53054: }
 53054: 
 56037: bool
 86542: mjit::Compiler::jsop_xname(PropertyName *name)
 54847: {
 77884:     /*
 77884:      * If this is a GETXPROP for a variable of a non-reentrant outer function,
 77884:      * treat in the same way as a NAME.
 77884:      */
 77884:     if (cx->typeInferenceEnabled()) {
 77884:         ScriptAnalysis::NameAccess access =
 97828:             analysis->resolveNameAccess(cx, NameToId(name), true);
 77884:         if (access.nesting) {
 77884:             frame.pop();
 77884:             Address address = frame.loadNameAddress(access);
 77884:             JSValueType type = knownPushedType(0);
 77884:             BarrierState barrier = pushAddressMaybeBarrier(address, type, true,
 77884:                                                            /* testUndefined = */ true);
 77884:             finishBarrier(barrier, REJOIN_GETTER, 0);
 77884:             return true;
 77884:         }
 77884:     }
 77884: 
 86855:     PICGenInfo pic(ic::PICInfo::XNAME, JSOp(*PC));
 54847: 
 54847:     FrameEntry *fe = frame.peek(-1);
 54847:     if (fe->isNotType(JSVAL_TYPE_OBJECT)) {
 86542:         return jsop_getprop(name, knownPushedType(0));
 54847:     }
 54847: 
 54847:     if (!fe->isTypeKnown()) {
 54847:         Jump notObject = frame.testObject(Assembler::NotEqual, fe);
 54847:         stubcc.linkExit(notObject, Uses(1));
 54847:     }
 54847: 
 76194:     frame.forgetMismatchedObject(fe);
 76194: 
 60594:     RESERVE_IC_SPACE(masm);
 60594: 
 54847:     pic.shapeReg = frame.allocReg();
 54847:     pic.objReg = frame.copyDataIntoReg(fe);
 54847:     pic.typeReg = Registers::ReturnReg;
 86542:     pic.name = name;
 54847:     pic.hasTypeCheck = false;
 54847:     pic.fastPathStart = masm.label();
 54847: 
 60594:     /* There is no inline implementation, so we always jump to the slow path or to a stub. */
 54847:     pic.shapeGuard = masm.label();
 60594:     Jump inlineJump = masm.jump();
 54847:     {
 60594:         RESERVE_OOL_SPACE(stubcc.masm);
 60594:         pic.slowPathStart = stubcc.linkExit(inlineJump, Uses(1));
 54847:         stubcc.leave();
 56738:         passICAddress(&pic);
 76194:         pic.slowPathCall = OOL_STUBCALL(ic::XName, REJOIN_GETTER);
 60594:         CHECK_OOL_SPACE();
 78456:         testPushedType(REJOIN_GETTER, -1);
 56575:     }
 56575: 
 56575:     pic.fastPathRejoin = masm.label();
 60594: 
 60594:     RETURN_IF_OOM(false);
 60594: 
 60594:     /* Initialize op labels. */
 60598:     ScopeNameLabels &labels = pic.scopeNameLabels();
 60594:     labels.setInlineJumpOffset(masm.differenceBetween(pic.fastPathStart, inlineJump));
 60594: 
 78455:     CHECK_IC_SPACE();
 78455: 
 54847:     frame.pop();
 76194:     frame.pushRegs(pic.shapeReg, pic.objReg, knownPushedType(0));
 76194: 
 76194:     BarrierState barrier = testBarrier(pic.shapeReg, pic.objReg, /* testUndefined = */ true);
 54847: 
 54847:     stubcc.rejoin(Changes(1));
 54847: 
 54847:     pics.append(pic);
 76194: 
 76194:     finishBarrier(barrier, REJOIN_FALLTHROUGH, 0);
 56037:     return true;
 54847: }
 54847: 
 53055: void
 86855: mjit::Compiler::jsop_bindname(PropertyName *name)
 53055: {
 77884:     /*
 77884:      * If this is a BINDNAME for a variable of a non-reentrant outer function,
 77884:      * the object is definitely the outer function's active call object.
 77884:      */
 77884:     if (cx->typeInferenceEnabled()) {
 77884:         ScriptAnalysis::NameAccess access =
 97828:             analysis->resolveNameAccess(cx, NameToId(name), true);
 77884:         if (access.nesting) {
 77884:             RegisterID reg = frame.allocReg();
100006:             JSObject **pobj = &access.nesting->activeCall;
 77884:             masm.move(ImmPtr(pobj), reg);
 77884:             masm.loadPtr(Address(reg), reg);
 77884:             frame.pushTypedPayload(JSVAL_TYPE_OBJECT, reg);
 77884:             return;
 77884:         }
 77884:     }
 77884: 
 86855:     PICGenInfo pic(ic::PICInfo::BIND, JSOp(*PC));
 53055: 
 56586:     // This code does not check the frame flags to see if scopeChain has been
 56586:     // set. Rather, it relies on the up-front analysis statically determining
 56586:     // whether BINDNAME can be used, which reifies the scope chain at the
 56586:     // prologue.
 56602:     JS_ASSERT(analysis->usesScopeChain());
 56586: 
 53055:     pic.shapeReg = frame.allocReg();
 53055:     pic.objReg = frame.allocReg();
 53055:     pic.typeReg = Registers::ReturnReg;
 86542:     pic.name = name;
 53055:     pic.hasTypeCheck = false;
 60593: 
 60593:     RESERVE_IC_SPACE(masm);
 53270:     pic.fastPathStart = masm.label();
 53055: 
 69223:     masm.loadPtr(Address(JSFrameReg, StackFrame::offsetOfScopeChain()), pic.objReg);
 83245:     masm.loadPtr(Address(pic.objReg, JSObject::offsetOfShape()), pic.shapeReg);
 83245:     masm.loadPtr(Address(pic.shapeReg, Shape::offsetOfBase()), pic.shapeReg);
 83245:     Address parent(pic.shapeReg, BaseShape::offsetOfParent());
 53055: 
 53055:     pic.shapeGuard = masm.label();
 83245:     Jump inlineJump = masm.branchPtr(Assembler::NotEqual, parent, ImmPtr(NULL));
 53055:     {
 60593:         RESERVE_OOL_SPACE(stubcc.masm);
 60593:         pic.slowPathStart = stubcc.linkExit(inlineJump, Uses(0));
 53055:         stubcc.leave();
 56738:         passICAddress(&pic);
 77409:         pic.slowPathCall = OOL_STUBCALL(ic::BindName, REJOIN_FALLTHROUGH);
 60593:         CHECK_OOL_SPACE();
 56575:     }
 56575: 
 56575:     pic.fastPathRejoin = masm.label();
 60593: 
 60593:     /* Initialize op labels. */
 60593:     BindNameLabels &labels = pic.bindNameLabels();
 60593:     labels.setInlineJump(masm, pic.shapeGuard, inlineJump);
 60593: 
 53055:     frame.pushTypedPayload(JSVAL_TYPE_OBJECT, pic.objReg);
 53055:     frame.freeReg(pic.shapeReg);
 53055: 
 53088:     stubcc.rejoin(Changes(1));
 53055: 
 53055:     pics.append(pic);
 53055: }
 60598: 
 60598: #else /* !JS_POLYIC */
 60598: 
 52880: void
 86542: mjit::Compiler::jsop_name(PropertyName *name, JSValueType type, bool isCall)
 53054: {
 53087:     prepareStubCall(Uses(0));
 76194:     INLINE_STUBCALL(isCall ? stubs::CallName : stubs::Name, REJOIN_FALLTHROUGH);
 78456:     testPushedType(REJOIN_FALLTHROUGH, 0, /* ool = */ false);
 76194:     frame.pushSynced(type);
 71340:     if (isCall)
 76194:         frame.pushSynced(JSVAL_TYPE_UNKNOWN);
 53054: }
 53054: 
 56037: bool
 86542: mjit::Compiler::jsop_xname(PropertyName *name)
 86542: {
 86542:     return jsop_getprop(name, knownPushedType(0), pushedTypeSet(0));
 54860: }
 60598: 
 56037: bool
 86542: mjit::Compiler::jsop_getprop(PropertyName *name, JSValueType knownType, types::TypeSet *typeSet,
 86855:                              bool typecheck, bool forPrototype)
 86855: {
 86855:     jsop_getprop_slow(name, forPrototype);
 56037:     return true;
 52886: }
 60598: 
 53119: bool
 86855: mjit::Compiler::jsop_setprop(PropertyName *name)
 86855: {
 86855:     jsop_setprop_slow(name);
 56037:     return true;
 54427: }
 60598: 
 52896: void
 86855: mjit::Compiler::jsop_bindname(PropertyName *name)
 53055: {
 53055:     RegisterID reg = frame.allocReg();
 69223:     Address scopeChain(JSFrameReg, StackFrame::offsetOfScopeChain());
 53162:     masm.loadPtr(scopeChain, reg);
 53055: 
 53246:     Address address(reg, offsetof(JSObject, parent));
 53246: 
 68931:     Jump j = masm.branchPtr(Assembler::NotEqual, address, ImmPtr(0));
 53055: 
 53088:     stubcc.linkExit(j, Uses(0));
 53055:     stubcc.leave();
 86855:     stubcc.masm.move(ImmPtr(name), Registers::ArgReg1);
 86752:     OOL_STUBCALL(stubs::BindName, REJOIN_FALLTHROUGH);
 53055: 
 53055:     frame.pushTypedPayload(JSVAL_TYPE_OBJECT, reg);
 53055: 
 53088:     stubcc.rejoin(Changes(1));
 53055: }
 52880: #endif
 52880: 
 52743: void
 52741: mjit::Compiler::jsop_this()
 52741: {
 57787:     frame.pushThis();
 57787: 
 55713:     /*
 55713:      * In strict mode code, we don't wrap 'this'.
 55713:      * In direct-call eval code, we wrapped 'this' before entering the eval.
 55713:      * In global code, 'this' is always an object.
 55713:      */
 83256:     if (script->function() && !script->strictModeCode) {
 57787:         FrameEntry *thisFe = frame.peek(-1);
 76194: 
 76194:         if (!thisFe->isType(JSVAL_TYPE_OBJECT)) {
 80594:             /*
 80594:              * Watch out for an obscure case where we don't know we are pushing
 80594:              * an object: the script has not yet had a 'this' value assigned,
 80594:              * so no pushed 'this' type has been inferred. Don't mark the type
 80594:              * as known in this case, preserving the invariant that compiler
 80594:              * types reflect inferred types.
 80594:              */
 80594:             if (cx->typeInferenceEnabled() && knownPushedType(0) != JSVAL_TYPE_OBJECT) {
 80594:                 prepareStubCall(Uses(1));
 80594:                 INLINE_STUBCALL(stubs::This, REJOIN_FALLTHROUGH);
 80594:                 return;
 80594:             }
 80594: 
 76194:             JSValueType type = cx->typeInferenceEnabled()
 77391:                 ? types::TypeScript::ThisTypes(script)->getKnownTypeTag(cx)
 76194:                 : JSVAL_TYPE_UNKNOWN;
 76194:             if (type != JSVAL_TYPE_OBJECT) {
 57787:                 Jump notObj = frame.testObject(Assembler::NotEqual, thisFe);
 55713:                 stubcc.linkExit(notObj, Uses(1));
 52854:                 stubcc.leave();
 76194:                 OOL_STUBCALL(stubs::This, REJOIN_FALLTHROUGH);
 53088:                 stubcc.rejoin(Changes(1));
 76194:             }
 57787: 
 57787:             // Now we know that |this| is an object.
 57787:             frame.pop();
 76194:             frame.learnThisIsObject(type != JSVAL_TYPE_OBJECT);
 57787:             frame.pushThis();
 57787:         }
 57787: 
 57787:         JS_ASSERT(thisFe->isType(JSVAL_TYPE_OBJECT));
 52741:     }
 53023: }
 52741: 
 61055: bool
 91237: mjit::Compiler::iter(unsigned flags)
 53404: {
 53404:     FrameEntry *fe = frame.peek(-1);
 53404: 
 53404:     /*
 53404:      * Stub the call if this is not a simple 'for in' loop or if the iterated
 53404:      * value is known to not be an object.
 53404:      */
 53404:     if ((flags != JSITER_ENUMERATE) || fe->isNotType(JSVAL_TYPE_OBJECT)) {
 53404:         prepareStubCall(Uses(1));
 53404:         masm.move(Imm32(flags), Registers::ArgReg1);
 76194:         INLINE_STUBCALL(stubs::Iter, REJOIN_FALLTHROUGH);
 53404:         frame.pop();
 76194:         frame.pushSynced(JSVAL_TYPE_UNKNOWN);
 61055:         return true;
 53404:     }
 53404: 
 53404:     if (!fe->isTypeKnown()) {
 53404:         Jump notObject = frame.testObject(Assembler::NotEqual, fe);
 53404:         stubcc.linkExit(notObject, Uses(1));
 53404:     }
 53404: 
 76194:     frame.forgetMismatchedObject(fe);
 76194: 
 53404:     RegisterID reg = frame.tempRegForData(fe);
 53404: 
 53404:     frame.pinReg(reg);
 53404:     RegisterID ioreg = frame.allocReg();  /* Will hold iterator JSObject */
 53404:     RegisterID nireg = frame.allocReg();  /* Will hold NativeIterator */
 53404:     RegisterID T1 = frame.allocReg();
 53404:     RegisterID T2 = frame.allocReg();
 53404:     frame.unpinReg(reg);
 53404: 
 59954:     /* Fetch the most recent iterator. */
 97466:     masm.loadPtr(&cx->runtime->nativeIterCache.last, ioreg);
 53404: 
 53404:     /* Test for NULL. */
 53404:     Jump nullIterator = masm.branchTest32(Assembler::Zero, ioreg, ioreg);
 53404:     stubcc.linkExit(nullIterator, Uses(1));
 53404: 
 60777:     /* Get NativeIterator from iter obj. */
 83233:     masm.loadObjPrivate(ioreg, nireg, JSObject::ITER_CLASS_NFIXED_SLOTS);
 53404: 
 53404:     /* Test for active iterator. */
 53404:     Address flagsAddr(nireg, offsetof(NativeIterator, flags));
 53404:     masm.load32(flagsAddr, T1);
 62573:     Jump activeIterator = masm.branchTest32(Assembler::NonZero, T1,
 62573:                                             Imm32(JSITER_ACTIVE|JSITER_UNREUSABLE));
 53404:     stubcc.linkExit(activeIterator, Uses(1));
 53404: 
 53404:     /* Compare shape of object with iterator. */
 53404:     masm.loadShape(reg, T1);
 53404:     masm.loadPtr(Address(nireg, offsetof(NativeIterator, shapes_array)), T2);
 83332:     masm.loadPtr(Address(T2, 0), T2);
 83332:     Jump mismatchedObject = masm.branchPtr(Assembler::NotEqual, T1, T2);
 53404:     stubcc.linkExit(mismatchedObject, Uses(1));
 53404: 
 53404:     /* Compare shape of object's prototype with iterator. */
 77353:     masm.loadPtr(Address(reg, JSObject::offsetOfType()), T1);
 76194:     masm.loadPtr(Address(T1, offsetof(types::TypeObject, proto)), T1);
 53404:     masm.loadShape(T1, T1);
 53404:     masm.loadPtr(Address(nireg, offsetof(NativeIterator, shapes_array)), T2);
 83332:     masm.loadPtr(Address(T2, sizeof(Shape *)), T2);
 83332:     Jump mismatchedProto = masm.branchPtr(Assembler::NotEqual, T1, T2);
 53404:     stubcc.linkExit(mismatchedProto, Uses(1));
 53404: 
 53404:     /*
 53404:      * Compare object's prototype's prototype with NULL. The last native
 53404:      * iterator will always have a prototype chain length of one
 53404:      * (i.e. it must be a plain object), so we do not need to generate
 53404:      * a loop here.
 53404:      */
 77353:     masm.loadPtr(Address(reg, JSObject::offsetOfType()), T1);
 76194:     masm.loadPtr(Address(T1, offsetof(types::TypeObject, proto)), T1);
 77353:     masm.loadPtr(Address(T1, JSObject::offsetOfType()), T1);
 76194:     masm.loadPtr(Address(T1, offsetof(types::TypeObject, proto)), T1);
 53404:     Jump overlongChain = masm.branchPtr(Assembler::NonZero, T1, T1);
 53404:     stubcc.linkExit(overlongChain, Uses(1));
 53404: 
 82129: #ifdef JSGC_INCREMENTAL_MJ
 82129:     /*
 82129:      * Write barrier for stores to the iterator. We only need to take a write
 82129:      * barrier if NativeIterator::obj is actually going to change.
 82129:      */
 82129:     if (cx->compartment->needsBarrier()) {
 82129:         Jump j = masm.branchPtr(Assembler::NotEqual,
 82129:                                 Address(nireg, offsetof(NativeIterator, obj)), reg);
 82129:         stubcc.linkExit(j, Uses(1));
 82129:     }
 82129: #endif
 82129: 
 53404:     /* Found a match with the most recent iterator. Hooray! */
 53404: 
 53404:     /* Mark iterator as active. */
 60777:     masm.storePtr(reg, Address(nireg, offsetof(NativeIterator, obj)));
 53404:     masm.load32(flagsAddr, T1);
 53404:     masm.or32(Imm32(JSITER_ACTIVE), T1);
 53404:     masm.store32(T1, flagsAddr);
 53404: 
 53404:     /* Chain onto the active iterator stack. */
 53404:     masm.loadPtr(FrameAddress(offsetof(VMFrame, cx)), T1);
 53404:     masm.loadPtr(Address(T1, offsetof(JSContext, enumerators)), T2);
 53404:     masm.storePtr(T2, Address(nireg, offsetof(NativeIterator, next)));
 53404:     masm.storePtr(ioreg, Address(T1, offsetof(JSContext, enumerators)));
 53404: 
 53404:     frame.freeReg(nireg);
 53404:     frame.freeReg(T1);
 53404:     frame.freeReg(T2);
 53404: 
 53404:     stubcc.leave();
 53404:     stubcc.masm.move(Imm32(flags), Registers::ArgReg1);
 76194:     OOL_STUBCALL(stubs::Iter, REJOIN_FALLTHROUGH);
 53404: 
 53404:     /* Push the iterator object. */
 53404:     frame.pop();
 53404:     frame.pushTypedPayload(JSVAL_TYPE_OBJECT, ioreg);
 53404: 
 53404:     stubcc.rejoin(Changes(1));
 61055: 
 61055:     return true;
 53404: }
 53404: 
 52737: /*
 74052:  * This big nasty function implements JSOP_ITERNEXT, which is used in the head
 74052:  * of a for-in loop to put the next value on the stack.
 52737:  */
 52737: void
 77824: mjit::Compiler::iterNext(ptrdiff_t offset)
 77824: {
 77824:     FrameEntry *fe = frame.peek(-offset);
 52737:     RegisterID reg = frame.tempRegForData(fe);
 52737: 
 52737:     /* Is it worth trying to pin this longer? Prolly not. */
 52737:     frame.pinReg(reg);
 52737:     RegisterID T1 = frame.allocReg();
 52737:     frame.unpinReg(reg);
 52737: 
 52737:     /* Test clasp */
 83222:     Jump notFast = masm.testObjClass(Assembler::NotEqual, reg, T1, &IteratorClass);
 53088:     stubcc.linkExit(notFast, Uses(1));
 52737: 
 53178:     /* Get private from iter obj. */
 83233:     masm.loadObjPrivate(reg, T1, JSObject::ITER_CLASS_NFIXED_SLOTS);
 52737: 
 52737:     RegisterID T3 = frame.allocReg();
 52973:     RegisterID T4 = frame.allocReg();
 52737: 
 61055:     /* Test for a value iterator, which could come through an Iterator object. */
 52737:     masm.load32(Address(T1, offsetof(NativeIterator, flags)), T3);
 53841:     notFast = masm.branchTest32(Assembler::NonZero, T3, Imm32(JSITER_FOREACH));
 53088:     stubcc.linkExit(notFast, Uses(1));
 52973: 
 52973:     RegisterID T2 = frame.allocReg();
 52973: 
 52973:     /* Get cursor. */
 52973:     masm.loadPtr(Address(T1, offsetof(NativeIterator, props_cursor)), T2);
 52973: 
 87655:     /* Get the next string in the iterator. */
 52973:     masm.loadPtr(T2, T3);
 52737: 
 52737:     /* It's safe to increase the cursor now. */
 87655:     masm.addPtr(Imm32(sizeof(JSString*)), T2, T4);
 52973:     masm.storePtr(T4, Address(T1, offsetof(NativeIterator, props_cursor)));
 52973: 
 52973:     frame.freeReg(T4);
 52737:     frame.freeReg(T1);
 52973:     frame.freeReg(T2);
 52737: 
 52737:     stubcc.leave();
 77824:     stubcc.masm.move(Imm32(offset), Registers::ArgReg1);
 77397:     OOL_STUBCALL(stubs::IterNext, REJOIN_FALLTHROUGH);
 52737: 
 53025:     frame.pushUntypedPayload(JSVAL_TYPE_STRING, T3);
 52737: 
 52737:     /* Join with the stub call. */
 53088:     stubcc.rejoin(Changes(1));
 52737: }
 52737: 
 56766: bool
 76194: mjit::Compiler::iterMore(jsbytecode *target)
 76194: {
 76194:     if (!frame.syncForBranch(target, Uses(1)))
 76194:         return false;
 76194: 
 52737:     FrameEntry *fe = frame.peek(-1);
 52737:     RegisterID reg = frame.tempRegForData(fe);
 76194:     RegisterID tempreg = frame.allocReg();
 52737: 
 52737:     /* Test clasp */
 83222:     Jump notFast = masm.testObjClass(Assembler::NotEqual, reg, tempreg, &IteratorClass);
 53277:     stubcc.linkExitForBranch(notFast);
 52737: 
 53178:     /* Get private from iter obj. */
 83233:     masm.loadObjPrivate(reg, reg, JSObject::ITER_CLASS_NFIXED_SLOTS);
 52737: 
 61055:     /* Test that the iterator supports fast iteration. */
 76194:     notFast = masm.branchTest32(Assembler::NonZero, Address(reg, offsetof(NativeIterator, flags)),
 61055:                                 Imm32(JSITER_FOREACH));
 61055:     stubcc.linkExitForBranch(notFast);
 61055: 
 52737:     /* Get props_cursor, test */
 76194:     masm.loadPtr(Address(reg, offsetof(NativeIterator, props_cursor)), tempreg);
 76194:     masm.loadPtr(Address(reg, offsetof(NativeIterator, props_end)), reg);
 76194: 
 76194:     Jump jFast = masm.branchPtr(Assembler::LessThan, tempreg, reg);
 52737: 
 52737:     stubcc.leave();
 76194:     OOL_STUBCALL(stubs::IterMore, REJOIN_BRANCH);
 53133:     Jump j = stubcc.masm.branchTest32(Assembler::NonZero, Registers::ReturnReg,
 53133:                                       Registers::ReturnReg);
 53133: 
 53088:     stubcc.rejoin(Changes(1));
 76194:     frame.freeReg(tempreg);
 53133: 
 82738:     return jumpAndRun(jFast, target, &j);
 52737: }
 52737: 
 52815: void
 53404: mjit::Compiler::iterEnd()
 53404: {
 53404:     FrameEntry *fe= frame.peek(-1);
 53404:     RegisterID reg = frame.tempRegForData(fe);
 53404: 
 53404:     frame.pinReg(reg);
 53404:     RegisterID T1 = frame.allocReg();
 53404:     frame.unpinReg(reg);
 53404: 
 53404:     /* Test clasp */
 83222:     Jump notIterator = masm.testObjClass(Assembler::NotEqual, reg, T1, &IteratorClass);
 53404:     stubcc.linkExit(notIterator, Uses(1));
 53404: 
 60777:     /* Get private from iter obj. */
 83233:     masm.loadObjPrivate(reg, T1, JSObject::ITER_CLASS_NFIXED_SLOTS);
 53404: 
 53404:     RegisterID T2 = frame.allocReg();
 53404: 
 53404:     /* Load flags. */
 53404:     Address flagAddr(T1, offsetof(NativeIterator, flags));
 53404:     masm.loadPtr(flagAddr, T2);
 53404: 
 62573:     /* Test for a normal enumerate iterator. */
 62573:     Jump notEnumerate = masm.branchTest32(Assembler::Zero, T2, Imm32(JSITER_ENUMERATE));
 62413:     stubcc.linkExit(notEnumerate, Uses(1));
 53404: 
 53404:     /* Clear active bit. */
 53404:     masm.and32(Imm32(~JSITER_ACTIVE), T2);
 53404:     masm.storePtr(T2, flagAddr);
 53404: 
 53404:     /* Reset property cursor. */
 53404:     masm.loadPtr(Address(T1, offsetof(NativeIterator, props_array)), T2);
 53404:     masm.storePtr(T2, Address(T1, offsetof(NativeIterator, props_cursor)));
 53404: 
 53404:     /* Advance enumerators list. */
 53404:     masm.loadPtr(FrameAddress(offsetof(VMFrame, cx)), T2);
 53404:     masm.loadPtr(Address(T1, offsetof(NativeIterator, next)), T1);
 53404:     masm.storePtr(T1, Address(T2, offsetof(JSContext, enumerators)));
 53404: 
 53404:     frame.freeReg(T1);
 53404:     frame.freeReg(T2);
 53404: 
 53404:     stubcc.leave();
 76194:     OOL_STUBCALL(stubs::EndIter, REJOIN_FALLTHROUGH);
 53404: 
 53404:     frame.pop();
 53404: 
 53404:     stubcc.rejoin(Changes(1));
 53404: }
 53404: 
 53404: void
 84755: mjit::Compiler::jsop_getgname_slow(uint32_t index)
 52826: {
 53087:     prepareStubCall(Uses(0));
 86855:     INLINE_STUBCALL(stubs::Name, REJOIN_GETTER);
 78456:     testPushedType(REJOIN_GETTER, 0, /* ool = */ false);
 76194:     frame.pushSynced(JSVAL_TYPE_UNKNOWN);
 52826: }
 52826: 
 52826: void
 52826: mjit::Compiler::jsop_bindgname()
 52826: {
 76194:     if (globalObj) {
 53081:         frame.push(ObjectValue(*globalObj));
 52826:         return;
 52826:     }
 52826: 
 52826:     /* :TODO: this is slower than it needs to be. */
 53087:     prepareStubCall(Uses(0));
 76194:     INLINE_STUBCALL(stubs::BindGlobalName, REJOIN_NONE);
 52826:     frame.takeReg(Registers::ReturnReg);
 53025:     frame.pushTypedPayload(JSVAL_TYPE_OBJECT, Registers::ReturnReg);
 52826: }
 52826: 
 99781: bool
 84755: mjit::Compiler::jsop_getgname(uint32_t index)
 52826: {
 57823:     /* Optimize undefined, NaN and Infinity. */
 86542:     PropertyName *name = script->getName(index);
 86542:     if (name == cx->runtime->atomState.typeAtoms[JSTYPE_VOID]) {
 57823:         frame.push(UndefinedValue());
 99781:         return true;
 57823:     }
 86542:     if (name == cx->runtime->atomState.NaNAtom) {
 57823:         frame.push(cx->runtime->NaNValue);
 99781:         return true;
 57823:     }
 86542:     if (name == cx->runtime->atomState.InfinityAtom) {
 57823:         frame.push(cx->runtime->positiveInfinityValue);
 99781:         return true;
 57823:     }
 76194: 
 76194:     /* Optimize singletons like Math for JSOP_CALLPROP. */
 76194:     JSObject *obj = pushedSingleton(0);
 99421:     if (obj && !hasTypeBarriers(PC) && testSingletonProperty(globalObj, RootedId(cx, NameToId(name)))) {
 76194:         frame.push(ObjectValue(*obj));
 99781:         return true;
 76194:     }
 76194: 
 97828:     jsid id = NameToId(name);
 77357:     JSValueType type = knownPushedType(0);
 76194:     if (cx->typeInferenceEnabled() && globalObj->isGlobal() && id == types::MakeTypeId(cx, id) &&
 77361:         !globalObj->getType(cx)->unknownProperties()) {
 77361:         types::TypeSet *propertyTypes = globalObj->getType(cx)->getProperty(cx, id, false);
 76194:         if (!propertyTypes)
 99781:             return false;
 77357: 
 77357:         /*
 77357:          * If we are accessing a defined global which is a normal data property
 77357:          * then bake its address into the jitcode and guard against future
 77357:          * reallocation of the global object's slots.
 77357:          */
 97828:         const js::Shape *shape = globalObj->nativeLookup(cx, NameToId(name));
 94227:         if (shape && shape->hasDefaultGetter() && shape->hasSlot()) {
 91146:             HeapSlot *value = &globalObj->getSlotRef(shape->slot());
 77361:             if (!value->isUndefined() &&
 77361:                 !propertyTypes->isOwnProperty(cx, globalObj->getType(cx), true)) {
 76194:                 watchGlobalReallocation();
 76194:                 RegisterID reg = frame.allocReg();
 76194:                 masm.move(ImmPtr(value), reg);
 76194: 
 76194:                 BarrierState barrier = pushAddressMaybeBarrier(Address(reg), type, true);
 76194:                 finishBarrier(barrier, REJOIN_GETTER, 0);
 99781:                 return true;
 76194:             }
 76194:         }
 76194:     }
 76194: 
 53119: #if defined JS_MONOIC
 52826:     jsop_bindgname();
 52826: 
 52826:     FrameEntry *fe = frame.peek(-1);
 53025:     JS_ASSERT(fe->isTypeKnown() && fe->getKnownType() == JSVAL_TYPE_OBJECT);
 52826: 
 62386:     GetGlobalNameICInfo ic;
 58198:     RESERVE_IC_SPACE(masm);
 52826:     RegisterID objReg;
 52826:     Jump shapeGuard;
 52826: 
 62386:     ic.fastPathStart = masm.label();
 52826:     if (fe->isConstant()) {
 53081:         JSObject *obj = &fe->getValue().toObject();
 52826:         frame.pop();
 52826:         JS_ASSERT(obj->isNative());
 52826: 
 52826:         objReg = frame.allocReg();
 52826: 
 83231:         masm.loadPtrFromImm(obj->addressOfShape(), objReg);
 83221:         shapeGuard = masm.branchPtrWithPatch(Assembler::NotEqual, objReg,
 83221:                                              ic.shape, ImmPtr(NULL));
 52826:         masm.move(ImmPtr(obj), objReg);
 52826:     } else {
 52826:         objReg = frame.ownRegForData(fe);
 52826:         frame.pop();
 52826:         RegisterID reg = frame.allocReg();
 52826: 
 53445:         masm.loadShape(objReg, reg);
 83221:         shapeGuard = masm.branchPtrWithPatch(Assembler::NotEqual, reg,
 83221:                                              ic.shape, ImmPtr(NULL));
 52826:         frame.freeReg(reg);
 52826:     }
 62386:     stubcc.linkExit(shapeGuard, Uses(0));
 52826: 
 52826:     stubcc.leave();
 62386:     passMICAddress(ic);
 76194:     ic.slowPathCall = OOL_STUBCALL(ic::GetGlobalName, REJOIN_GETTER);
 52826: 
 78456:     CHECK_IC_SPACE();
 78456: 
 78456:     testPushedType(REJOIN_GETTER, 0);
 78456: 
 52826:     /* Garbage value. */
 84755:     uint32_t slot = 1 << 24;
 52826: 
 83231:     masm.loadPtr(Address(objReg, JSObject::offsetOfSlots()), objReg);
 52826:     Address address(objReg, slot);
 53269: 
 53269:     /* Allocate any register other than objReg. */
 60592:     RegisterID treg = frame.allocReg();
 53269:     /* After dreg is loaded, it's safe to clobber objReg. */
 60592:     RegisterID dreg = objReg;
 53269: 
 62386:     ic.load = masm.loadValueWithAddressOffsetPatch(address, treg, dreg);
 53269: 
 76194:     frame.pushRegs(treg, dreg, type);
 76194: 
 76194:     /*
 76194:      * Note: no undefined check is needed for GNAME opcodes. These were not
 76194:      * declared with 'var', so cannot be undefined without triggering an error
 76194:      * or having been a pre-existing global whose value is undefined (which
 76194:      * type inference will know about).
 76194:      */
 76194:     BarrierState barrier = testBarrier(treg, dreg);
 52826: 
 53088:     stubcc.rejoin(Changes(1));
 62385: 
 62386:     getGlobalNames.append(ic);
 76194:     finishBarrier(barrier, REJOIN_GETTER, 0);
 52826: #else
 52826:     jsop_getgname_slow(index);
 52826: #endif
 99781:     return true;
 52826: }
 52826: 
 63236: void
 86855: mjit::Compiler::jsop_setgname_slow(PropertyName *name)
 52831: {
 53087:     prepareStubCall(Uses(2));
 86542:     masm.move(ImmPtr(name), Registers::ArgReg1);
 76194:     INLINE_STUBCALL(STRICT_VARIANT(stubs::SetGlobalName), REJOIN_FALLTHROUGH);
 52831:     frame.popn(2);
 76194:     pushSyncedEntry(0);
 52831: }
 52831: 
 99781: bool
 86855: mjit::Compiler::jsop_setgname(PropertyName *name, bool popGuaranteed)
 76194: {
 76194:     if (monitored(PC)) {
 76194:         /* Global accesses are monitored only for a few names like __proto__. */
 86855:         jsop_setgname_slow(name);
 99781:         return true;
 76194:     }
 76194: 
 97828:     jsid id = NameToId(name);
 76194:     if (cx->typeInferenceEnabled() && globalObj->isGlobal() && id == types::MakeTypeId(cx, id) &&
 77361:         !globalObj->getType(cx)->unknownProperties()) {
 76194:         /*
 76194:          * Note: object branding is disabled when inference is enabled. With
 76194:          * branding there is no way to ensure that a non-function property
 76194:          * can't get a function later and cause the global object to become
 76194:          * branded, requiring a shape change if it changes again.
 76194:          */
 77361:         types::TypeSet *types = globalObj->getType(cx)->getProperty(cx, id, false);
 76194:         if (!types)
 99781:             return false;
 97828:         const js::Shape *shape = globalObj->nativeLookup(cx, NameToId(name));
 94227:         if (shape && shape->hasDefaultSetter() &&
 77361:             shape->writable() && shape->hasSlot() &&
 77361:             !types->isOwnProperty(cx, globalObj->getType(cx), true)) {
 76194:             watchGlobalReallocation();
 91146:             HeapSlot *value = &globalObj->getSlotRef(shape->slot());
 76194:             RegisterID reg = frame.allocReg();
 82129: #ifdef JSGC_INCREMENTAL_MJ
 82129:             /* Write barrier. */
 82129:             if (cx->compartment->needsBarrier() && types->needsBarrier(cx)) {
 82129:                 stubcc.linkExit(masm.jump(), Uses(0));
 82129:                 stubcc.leave();
 82129:                 stubcc.masm.move(ImmPtr(value), Registers::ArgReg1);
 82129:                 OOL_STUBCALL(stubs::WriteBarrier, REJOIN_NONE);
 82129:                 stubcc.rejoin(Changes(0));
 82129:             }
 82129: #endif
 76194:             masm.move(ImmPtr(value), reg);
 76194:             frame.storeTo(frame.peek(-1), Address(reg), popGuaranteed);
 76194:             frame.shimmy(1);
 76194:             frame.freeReg(reg);
 99781:             return true;
 76194:         }
 76194:     }
 76194: 
 82129: #ifdef JSGC_INCREMENTAL_MJ
 82129:     /* Write barrier. */
 82129:     if (cx->compartment->needsBarrier()) {
 86855:         jsop_setgname_slow(name);
 99781:         return true;
 82129:     }
 82129: #endif
 82129: 
 53119: #if defined JS_MONOIC
 52831:     FrameEntry *objFe = frame.peek(-2);
 62385:     FrameEntry *fe = frame.peek(-1);
 53025:     JS_ASSERT_IF(objFe->isTypeKnown(), objFe->getKnownType() == JSVAL_TYPE_OBJECT);
 52831: 
 76194:     if (!fe->isConstant() && fe->isType(JSVAL_TYPE_DOUBLE))
 76194:         frame.forgetKnownDouble(fe);
 76194: 
 62386:     SetGlobalNameICInfo ic;
 62386: 
 62386:     frame.pinEntry(fe, ic.vr);
 62386:     Jump shapeGuard;
 62385: 
 58198:     RESERVE_IC_SPACE(masm);
 82129: 
 62386:     ic.fastPathStart = masm.label();
 52831:     if (objFe->isConstant()) {
 53081:         JSObject *obj = &objFe->getValue().toObject();
 52831:         JS_ASSERT(obj->isNative());
 52831: 
 62386:         ic.objReg = frame.allocReg();
 62386:         ic.shapeReg = ic.objReg;
 62386:         ic.objConst = true;
 62386: 
 83231:         masm.loadPtrFromImm(obj->addressOfShape(), ic.shapeReg);
 83221:         shapeGuard = masm.branchPtrWithPatch(Assembler::NotEqual, ic.shapeReg,
 83221:                                              ic.shape, ImmPtr(NULL));
 62386:         masm.move(ImmPtr(obj), ic.objReg);
 52831:     } else {
 62386:         ic.objReg = frame.copyDataIntoReg(objFe);
 62386:         ic.shapeReg = frame.allocReg();
 62386:         ic.objConst = false;
 62386: 
 62386:         masm.loadShape(ic.objReg, ic.shapeReg);
 83221:         shapeGuard = masm.branchPtrWithPatch(Assembler::NotEqual, ic.shapeReg,
 83221:                                              ic.shape, ImmPtr(NULL));
 62386:         frame.freeReg(ic.shapeReg);
 62386:     }
 62386:     ic.shapeGuardJump = shapeGuard;
 62386:     ic.slowPathStart = stubcc.linkExit(shapeGuard, Uses(2));
 52831: 
 52831:     stubcc.leave();
 62386:     passMICAddress(ic);
 76194:     ic.slowPathCall = OOL_STUBCALL(ic::SetGlobalName, REJOIN_FALLTHROUGH);
 52831: 
 52831:     /* Garbage value. */
 84755:     uint32_t slot = 1 << 24;
 52831: 
 83231:     masm.loadPtr(Address(ic.objReg, JSObject::offsetOfSlots()), ic.objReg);
 62386:     Address address(ic.objReg, slot);
 62386: 
 62386:     if (ic.vr.isConstant()) {
 62386:         ic.store = masm.storeValueWithAddressOffsetPatch(ic.vr.value(), address);
 62386:     } else if (ic.vr.isTypeKnown()) {
 62386:         ic.store = masm.storeValueWithAddressOffsetPatch(ImmType(ic.vr.knownType()),
 62386:                                                           ic.vr.dataReg(), address);
 52831:     } else {
 62386:         ic.store = masm.storeValueWithAddressOffsetPatch(ic.vr.typeReg(), ic.vr.dataReg(), address);
 62386:     }
 62386: 
 62386:     frame.freeReg(ic.objReg);
 62386:     frame.unpinEntry(ic.vr);
 62385:     frame.shimmy(1);
 52831: 
 53088:     stubcc.rejoin(Changes(1));
 52831: 
 62386:     ic.fastPathRejoin = masm.label();
 62386:     setGlobalNames.append(ic);
 52831: #else
 86855:     jsop_setgname_slow(name);
 52831: #endif
 99781:     return true;
 52831: }
 52831: 
 52838: void
 52838: mjit::Compiler::jsop_setelem_slow()
 52838: {
 53087:     prepareStubCall(Uses(3));
 76194:     INLINE_STUBCALL(STRICT_VARIANT(stubs::SetElem), REJOIN_FALLTHROUGH);
 52838:     frame.popn(3);
 76194:     frame.pushSynced(JSVAL_TYPE_UNKNOWN);
 52838: }
 52838: 
 52843: void
 52843: mjit::Compiler::jsop_getelem_slow()
 52843: {
 53087:     prepareStubCall(Uses(2));
 76194:     INLINE_STUBCALL(stubs::GetElem, REJOIN_FALLTHROUGH);
 78456:     testPushedType(REJOIN_FALLTHROUGH, -2, /* ool = */ false);
 52843:     frame.popn(2);
 76194:     pushSyncedEntry(0);
 52843: }
 52843: 
 56037: bool
 52894: mjit::Compiler::jsop_instanceof()
 52894: {
 53124:     FrameEntry *lhs = frame.peek(-2);
 52894:     FrameEntry *rhs = frame.peek(-1);
 52894: 
 53124:     // The fast path applies only when both operands are objects.
 53124:     if (rhs->isNotType(JSVAL_TYPE_OBJECT) || lhs->isNotType(JSVAL_TYPE_OBJECT)) {
 76194:         stubcc.linkExit(masm.jump(), Uses(2));
 76194:         frame.discardFe(lhs);
 76194:         frame.discardFe(rhs);
 52894:     }
 52894: 
 53124:     MaybeJump firstSlow;
 53124:     if (!rhs->isTypeKnown()) {
 53023:         Jump j = frame.testObject(Assembler::NotEqual, rhs);
 53088:         stubcc.linkExit(j, Uses(2));
 64390:     }
 64390: 
 76194:     frame.forgetMismatchedObject(lhs);
 76194:     frame.forgetMismatchedObject(rhs);
 76194: 
 83222:     RegisterID tmp = frame.allocReg();
 64390:     RegisterID obj = frame.tempRegForData(rhs);
 83222: 
 83248:     masm.loadBaseShape(obj, tmp);
 83248:     Jump notFunction = masm.branchPtr(Assembler::NotEqual,
 83248:                                       Address(tmp, BaseShape::offsetOfClass()),
 83248:                                       ImmPtr(&FunctionClass));
 83248: 
 64390:     stubcc.linkExit(notFunction, Uses(2));
 54410: 
 54410:     /* Test for bound functions. */
 83248:     Jump isBound = masm.branchTest32(Assembler::NonZero,
 83248:                                      Address(tmp, BaseShape::offsetOfFlags()),
 83248:                                      Imm32(BaseShape::BOUND_FUNCTION));
 54410:     {
 54410:         stubcc.linkExit(isBound, Uses(2));
 52894:         stubcc.leave();
 76194:         OOL_STUBCALL(stubs::InstanceOf, REJOIN_FALLTHROUGH);
 52911:         firstSlow = stubcc.masm.jump();
 52911:     }
 52911: 
 83248:     frame.freeReg(tmp);
 54410: 
 52911:     /* This is sadly necessary because the error case needs the object. */
 52894:     frame.dup();
 52894: 
 86855:     if (!jsop_getprop(cx->runtime->atomState.classPrototypeAtom, JSVAL_TYPE_UNKNOWN))
 56037:         return false;
 52894: 
 52911:     /* Primitive prototypes are invalid. */
 52911:     rhs = frame.peek(-1);
 52911:     Jump j = frame.testPrimitive(Assembler::Equal, rhs);
 53088:     stubcc.linkExit(j, Uses(3));
 52911: 
 52911:     /* Allocate registers up front, because of branchiness. */
 54410:     obj = frame.copyDataIntoReg(lhs);
 52911:     RegisterID proto = frame.copyDataIntoReg(rhs);
 52911:     RegisterID temp = frame.allocReg();
 52911: 
 53124:     MaybeJump isFalse;
 53124:     if (!lhs->isTypeKnown())
 53124:         isFalse = frame.testPrimitive(Assembler::Equal, lhs);
 52911: 
 52911:     Label loop = masm.label();
 52911: 
 52911:     /* Walk prototype chain, break out on NULL or hit. */
 77353:     masm.loadPtr(Address(obj, JSObject::offsetOfType()), obj);
 76194:     masm.loadPtr(Address(obj, offsetof(types::TypeObject, proto)), obj);
 52911:     Jump isFalse2 = masm.branchTestPtr(Assembler::Zero, obj, obj);
 52911:     Jump isTrue = masm.branchPtr(Assembler::NotEqual, obj, proto);
 52911:     isTrue.linkTo(loop, &masm);
 52911:     masm.move(Imm32(1), temp);
 52911:     isTrue = masm.jump();
 52911: 
 53124:     if (isFalse.isSet())
 53124:         isFalse.getJump().linkTo(masm.label(), &masm);
 52911:     isFalse2.linkTo(masm.label(), &masm);
 52911:     masm.move(Imm32(0), temp);
 52911:     isTrue.linkTo(masm.label(), &masm);
 52911: 
 52911:     frame.freeReg(proto);
 52911:     frame.freeReg(obj);
 52911: 
 52911:     stubcc.leave();
 76194:     OOL_STUBCALL(stubs::FastInstanceOf, REJOIN_FALLTHROUGH);
 52911: 
 52894:     frame.popn(3);
 53025:     frame.pushTypedPayload(JSVAL_TYPE_BOOLEAN, temp);
 52911: 
 53124:     if (firstSlow.isSet())
 53124:         firstSlow.getJump().linkTo(stubcc.masm.label(), &stubcc.masm);
 53088:     stubcc.rejoin(Changes(1));
 56037:     return true;
 52894: }
 52894: 
 56556: void
 84755: mjit::Compiler::emitEval(uint32_t argc)
 56556: {
 56775:     /* Check for interrupts on function call */
 56775:     interruptCheckHelper();
 56775: 
 76194:     frame.syncAndKill(Uses(argc + 2));
 56775:     prepareStubCall(Uses(argc + 2));
 56775:     masm.move(Imm32(argc), Registers::ArgReg1);
 76194:     INLINE_STUBCALL(stubs::Eval, REJOIN_FALLTHROUGH);
 56775:     frame.popn(argc + 2);
 76194:     pushSyncedEntry(0);
 56556: }
 56556: 
 98147: Compiler::Jump
 98147: Compiler::getNewObject(JSContext *cx, RegisterID result, JSObject *templateObject)
 98147: {
 98147:     rootedTemplates.append(templateObject);
 98147:     return masm.getNewObject(cx, result, templateObject);
 98147: }
 98147: 
 76194: bool
 58056: mjit::Compiler::jsop_newinit()
 58056: {
 58056:     bool isArray;
 58056:     unsigned count = 0;
 99421:     RootedObject baseobj(cx);
 58056:     switch (*PC) {
 58056:       case JSOP_NEWINIT:
 87974:         isArray = (GET_UINT8(PC) == JSProto_Array);
 58056:         break;
 58056:       case JSOP_NEWARRAY:
 58056:         isArray = true;
 58056:         count = GET_UINT24(PC);
 58056:         break;
 58056:       case JSOP_NEWOBJECT:
 76194:         /*
 76194:          * Scripts with NEWOBJECT must be compileAndGo, but treat these like
 76194:          * NEWINIT if the script's associated global is not known (or is not
 76194:          * actually a global object). This should only happen in chrome code.
 76194:          */
 58056:         isArray = false;
 89253:         baseobj = globalObj ? script->getObject(GET_UINT32_INDEX(PC)) : NULL;
 58056:         break;
 58056:       default:
 58056:         JS_NOT_REACHED("Bad op");
 76194:         return false;
 74457:     }
 74457: 
 77413:     void *stub, *stubArg;
 77413:     if (isArray) {
 77413:         stub = JS_FUNC_TO_DATA_PTR(void *, stubs::NewInitArray);
 80505:         stubArg = (void *) uintptr_t(count);
 77413:     } else {
 77413:         stub = JS_FUNC_TO_DATA_PTR(void *, stubs::NewInitObject);
 77413:         stubArg = (void *) baseobj;
 77413:     }
 76194: 
 93664:     /*
 93664:      * Don't bake in types for non-compileAndGo scripts, or at initializers
 93664:      * producing objects with singleton types.
 93664:      */
 99421:     RootedTypeObject type(cx);
 93664:     if (globalObj && !types::UseNewTypeForInitializer(cx, script, PC)) {
 77391:         type = types::TypeScript::InitObject(cx, script, PC,
 77391:                                              isArray ? JSProto_Array : JSProto_Object);
 76194:         if (!type)
 76194:             return false;
 76194:     }
 77413: 
 83281:     size_t maxArraySlots =
 83281:         gc::GetGCKindSlots(gc::FINALIZE_OBJECT_LAST) - ObjectElements::VALUES_PER_HEADER;
 83243: 
 77413:     if (!cx->typeInferenceEnabled() ||
 93664:         !type ||
 83281:         (isArray && count > maxArraySlots) ||
 77413:         (!isArray && !baseobj) ||
 83231:         (!isArray && baseobj->hasDynamicSlots())) {
 58056:         prepareStubCall(Uses(0));
 76194:         masm.storePtr(ImmPtr(type), FrameAddress(offsetof(VMFrame, scratch)));
 77413:         masm.move(ImmPtr(stubArg), Registers::ArgReg1);
 77413:         INLINE_STUBCALL(stub, REJOIN_FALLTHROUGH);
 77413:         frame.pushSynced(JSVAL_TYPE_OBJECT);
 77413: 
 77413:         frame.extra(frame.peek(-1)).initArray = (*PC == JSOP_NEWARRAY);
 77413:         frame.extra(frame.peek(-1)).initObject = baseobj;
 77413: 
 77413:         return true;
 77413:     }
 77413: 
 77413:     JSObject *templateObject;
 93664:     if (isArray)
 77413:         templateObject = NewDenseUnallocatedArray(cx, count);
 93664:     else
 93664:         templateObject = CopyInitializerObject(cx, baseobj);
 77413:     if (!templateObject)
 77413:         return false;
 77413:     templateObject->setType(type);
 77413: 
 77413:     RegisterID result = frame.allocReg();
 98147:     Jump emptyFreeList = getNewObject(cx, result, templateObject);
 77413: 
 77413:     stubcc.linkExit(emptyFreeList, Uses(0));
 77413:     stubcc.leave();
 77413: 
 77413:     stubcc.masm.storePtr(ImmPtr(type), FrameAddress(offsetof(VMFrame, scratch)));
 77413:     stubcc.masm.move(ImmPtr(stubArg), Registers::ArgReg1);
 77413:     OOL_STUBCALL(stub, REJOIN_FALLTHROUGH);
 77413: 
 77413:     frame.pushTypedPayload(JSVAL_TYPE_OBJECT, result);
 77413: 
 77413:     stubcc.rejoin(Changes(1));
 76194: 
 76194:     frame.extra(frame.peek(-1)).initArray = (*PC == JSOP_NEWARRAY);
 76194:     frame.extra(frame.peek(-1)).initObject = baseobj;
 76194: 
 76194:     return true;
 76194: }
 76194: 
 80431: bool
 80271: mjit::Compiler::jsop_regexp()
 80271: {
 87976:     JSObject *obj = script->getRegExp(GET_UINT32_INDEX(PC));
 82144:     RegExpStatics *res = globalObj ? globalObj->getRegExpStatics() : NULL;
 82144: 
 80271:     if (!globalObj ||
 86483:         &obj->global() != globalObj ||
 80271:         !cx->typeInferenceEnabled() ||
 80271:         analysis->localsAliasStack() ||
 80271:         types::TypeSet::HasObjectFlags(cx, globalObj->getType(cx),
 98147:                                        types::OBJECT_FLAG_REGEXP_FLAGS_SET))
 90410:     {
 82144:         prepareStubCall(Uses(0));
 82144:         masm.move(ImmPtr(obj), Registers::ArgReg1);
 82144:         INLINE_STUBCALL(stubs::RegExp, REJOIN_FALLTHROUGH);
 82144:         frame.pushSynced(JSVAL_TYPE_OBJECT);
 82144:         return true;
 82144:     }
 82144: 
 86483:     RegExpObject *reobj = &obj->asRegExp();
 82144: 
 84755:     DebugOnly<uint32_t> origFlags = reobj->getFlags();
 84755:     DebugOnly<uint32_t> staticsFlags = res->getFlags();
 80271:     JS_ASSERT((origFlags & staticsFlags) == staticsFlags);
 80271: 
 80271:     /*
 80271:      * JS semantics require regular expression literals to create different
 80271:      * objects every time they execute. We only need to do this cloning if the
 80271:      * script could actually observe the effect of such cloning, by getting
 80271:      * or setting properties on it. Particular RegExp and String natives take
 80271:      * regular expressions as 'this' or an argument, and do not let that
 80271:      * expression escape and be accessed by the script, so avoid cloning in
 80271:      * these cases.
 80271:      */
 80271:     analyze::SSAUseChain *uses =
 80271:         analysis->useChain(analyze::SSAValue::PushedValue(PC - script->code, 0));
 92698:     if (uses && uses->popped && !uses->next && !reobj->global() && !reobj->sticky()) {
 80271:         jsbytecode *use = script->code + uses->offset;
 84755:         uint32_t which = uses->u.which;
 80271:         if (JSOp(*use) == JSOP_CALLPROP) {
 80271:             JSObject *callee = analysis->pushedTypes(use, 0)->getSingleton(cx);
 80271:             if (callee && callee->isFunction()) {
 83252:                 Native native = callee->toFunction()->maybeNative();
 80271:                 if (native == js::regexp_exec || native == js::regexp_test) {
 80271:                     frame.push(ObjectValue(*obj));
 80431:                     return true;
 80271:                 }
 80271:             }
 80271:         } else if (JSOp(*use) == JSOP_CALL && which == 0) {
 84755:             uint32_t argc = GET_ARGC(use);
 80271:             JSObject *callee = analysis->poppedTypes(use, argc + 1)->getSingleton(cx);
 80271:             if (callee && callee->isFunction() && argc >= 1 && which == argc - 1) {
 83252:                 Native native = callee->toFunction()->maybeNative();
 80271:                 if (native == js::str_match ||
 80271:                     native == js::str_search ||
 80271:                     native == js::str_replace ||
 80271:                     native == js::str_split) {
 80271:                     frame.push(ObjectValue(*obj));
 80431:                     return true;
 80431:                 }
 80431:             }
 80431:         }
 80431:     }
 80431: 
 80431:     /*
 90410:      * Force creation of the RegExpShared in the script's RegExpObject so that
 98147:      * we grab it in the getNewObject template copy. A strong reference to the
 98147:      * RegExpShared will be added when the jitcode is created. Any GC activity
 98147:      * between now and construction of that jitcode could purge the shared
 98147:      * info, but such activity will also abort compilation.
 82146:      */
 90851:     RegExpGuard g;
 90851:     if (!reobj->getShared(cx, &g))
 80431:         return false;
 80271: 
 98147:     rootedRegExps.append(g.re());
 98147: 
 80271:     RegisterID result = frame.allocReg();
 98147:     Jump emptyFreeList = getNewObject(cx, result, obj);
 80271: 
 80271:     stubcc.linkExit(emptyFreeList, Uses(0));
 80271:     stubcc.leave();
 80271: 
 80271:     stubcc.masm.move(ImmPtr(obj), Registers::ArgReg1);
 80271:     OOL_STUBCALL(stubs::RegExp, REJOIN_FALLTHROUGH);
 80271: 
 80271:     frame.pushTypedPayload(JSVAL_TYPE_OBJECT, result);
 80271: 
 80271:     stubcc.rejoin(Changes(1));
 80431:     return true;
 80271: }
 80271: 
 76194: bool
 76194: mjit::Compiler::startLoop(jsbytecode *head, Jump entry, jsbytecode *entryTarget)
 76194: {
 76194:     JS_ASSERT(cx->typeInferenceEnabled() && script == outerScript);
 87654:     JS_ASSERT(shouldStartLoop(head));
 76194: 
 76194:     if (loop) {
 76194:         /*
 76194:          * Convert all loop registers in the outer loop into unassigned registers.
 76194:          * We don't keep track of which registers the inner loop uses, so the only
 76194:          * registers that can be carried in the outer loop must be mentioned before
 76194:          * the inner loop starts.
 76194:          */
 76194:         loop->clearLoopRegisters();
 76194:     }
 76194: 
 89972:     LoopState *nloop = OffTheBooks::new_<LoopState>(cx, &ssa, this, &frame);
 92002:     if (!nloop || !nloop->init(head, entry, entryTarget)) {
 92002:         js_ReportOutOfMemory(cx);
 76194:         return false;
 92002:     }
 76194: 
 76194:     nloop->outer = loop;
 76194:     loop = nloop;
 76194:     frame.setLoop(loop);
 76194: 
 76194:     return true;
 76194: }
 76194: 
 76194: bool
 76194: mjit::Compiler::finishLoop(jsbytecode *head)
 76194: {
 87654:     if (!cx->typeInferenceEnabled() || !bytecodeInChunk(head))
 76194:         return true;
 76194: 
 76194:     /*
 76194:      * We're done processing the current loop. Every loop has exactly one backedge
 76194:      * at the end ('continue' statements are forward jumps to the loop test),
 82738:      * and after jumpAndRun'ing on that edge we can pop it from the frame.
 76194:      */
 84755:     JS_ASSERT(loop && loop->headOffset() == uint32_t(head - script->code));
 76194: 
 76194:     jsbytecode *entryTarget = script->code + loop->entryOffset();
 76194: 
 76194:     /*
 76194:      * Fix up the jump entering the loop. We are doing this after all code has
 76194:      * been emitted for the backedge, so that we are now in the loop's fallthrough
 76194:      * (where we will emit the entry code).
 76194:      */
 76194:     Jump fallthrough = masm.jump();
 76194: 
 76194: #ifdef DEBUG
 76194:     if (IsJaegerSpewChannelActive(JSpew_Regalloc)) {
 76194:         RegisterAllocation *alloc = analysis->getAllocation(head);
 77530:         JaegerSpew(JSpew_Regalloc, "loop allocation at %u:", unsigned(head - script->code));
 76194:         frame.dumpAllocation(alloc);
 76194:     }
 76194: #endif
 76194: 
 76194:     loop->entryJump().linkTo(masm.label(), &masm);
 76194: 
 76194:     jsbytecode *oldPC = PC;
 76194: 
 76194:     PC = entryTarget;
 76194:     {
 76194:         OOL_STUBCALL(stubs::MissedBoundsCheckEntry, REJOIN_RESUME);
 76194: 
 76194:         if (loop->generatingInvariants()) {
 76194:             /*
 76194:              * To do the initial load of the invariants, jump to the invariant
 76194:              * restore point after the call just emitted. :XXX: fix hackiness.
 76194:              */
 76194:             if (oomInVector)
 76194:                 return false;
 76194:             Label label = callSites[callSites.length() - 1].loopJumpLabel;
 76194:             stubcc.linkExitDirect(masm.jump(), label);
 76194:         }
 76194:         stubcc.crossJump(stubcc.masm.jump(), masm.label());
 76194:     }
 76194:     PC = oldPC;
 76194: 
 76194:     frame.prepareForJump(entryTarget, masm, true);
 76194: 
 76194:     if (!jumpInScript(masm.jump(), entryTarget))
 76194:         return false;
 76194: 
 76194:     PC = head;
 76194:     if (!analysis->getCode(head).safePoint) {
 76194:         /*
 76194:          * Emit a stub into the OOL path which loads registers from a synced state
 76194:          * and jumps to the loop head, for rejoining from the interpreter.
 76194:          */
 76194:         LoopEntry entry;
 76194:         entry.pcOffset = head - script->code;
 76194: 
 76194:         OOL_STUBCALL(stubs::MissedBoundsCheckHead, REJOIN_RESUME);
 76194: 
 76194:         if (loop->generatingInvariants()) {
 76194:             if (oomInVector)
 76194:                 return false;
 76194:             entry.label = callSites[callSites.length() - 1].loopJumpLabel;
 76194:         } else {
 76194:             entry.label = stubcc.masm.label();
 76194:         }
 76194: 
 76194:         /*
 76194:          * The interpreter may store integers in slots we assume are doubles,
 76194:          * make sure state is consistent before joining. Note that we don't
 76194:          * need any handling for other safe points the interpreter can enter
 76194:          * from, i.e. from switch and try blocks, as we don't assume double
 76194:          * variables are coherent in such cases.
 76194:          */
 84755:         for (uint32_t slot = ArgSlot(0); slot < TotalSlots(script); slot++) {
 87654:             if (a->varTypes[slot].getTypeTag(cx) == JSVAL_TYPE_DOUBLE) {
 76194:                 FrameEntry *fe = frame.getSlotEntry(slot);
 76194:                 stubcc.masm.ensureInMemoryDouble(frame.addressOf(fe));
 76194:             }
 76194:         }
 76194: 
 76194:         frame.prepareForJump(head, stubcc.masm, true);
 76194:         if (!stubcc.jumpInScript(stubcc.masm.jump(), head))
 76194:             return false;
 76194: 
 76194:         loopEntries.append(entry);
 76194:     }
 76194:     PC = oldPC;
 76194: 
 76194:     /* Write out loads and tests of loop invariants at all calls in the loop body. */
 76194:     loop->flushLoop(stubcc);
 76194: 
 76194:     LoopState *nloop = loop->outer;
 76194:     cx->delete_(loop);
 76194:     loop = nloop;
 76194:     frame.setLoop(loop);
 76194: 
 76194:     fallthrough.linkTo(masm.label(), &masm);
 76194: 
 76194:     /*
 76194:      * Clear all registers used for loop temporaries. In the case of loop
 76194:      * nesting, we do not allocate temporaries for the outer loop.
 76194:      */
 76194:     frame.clearTemporaries();
 76194: 
 76194:     return true;
 58056: }
 58056: 
 53133: /*
 76194:  * The state at the fast jump must reflect the frame's current state. If specified
 76194:  * the state at the slow jump must be fully synced.
 76194:  *
 76194:  * The 'trampoline' argument indicates whether a trampoline was emitted into
 76194:  * the OOL path loading some registers for the target. If this is the case,
 76194:  * the fast path jump was redirected to the stub code's initial label, and the
 76194:  * same must happen for any other fast paths for the target (i.e. paths from
 76194:  * inline caches).
 87654:  *
 87654:  * The 'fallthrough' argument indicates this is a jump emitted for a fallthrough
 87654:  * at the end of the compiled chunk. In this case the opcode may not be a
 87654:  * JOF_JUMP opcode, and the compiler should not watch for fusions.
 53133:  */
 56766: bool
 87654: mjit::Compiler::jumpAndRun(Jump j, jsbytecode *target, Jump *slow, bool *trampoline,
 87654:                            bool fallthrough)
 76194: {
 76194:     if (trampoline)
 76194:         *trampoline = false;
 76194: 
 87654:     if (!a->parent && !bytecodeInChunk(target)) {
 87654:         /*
 87654:          * syncForBranch() must have ensured the stack is synced. Figure out
 87654:          * the source of the jump, which may be the opcode after PC if two ops
 87654:          * were fused for a branch.
 87654:          */
 87654:         OutgoingChunkEdge edge;
 87654:         edge.source = PC - outerScript->code;
 87654:         JSOp op = JSOp(*PC);
 87654:         if (!fallthrough && !(js_CodeSpec[op].format & JOF_JUMP) && op != JSOP_TABLESWITCH)
 87654:             edge.source += GetBytecodeLength(PC);
 87654:         edge.target = target - outerScript->code;
 87654:         edge.fastJump = j;
 87654:         if (slow)
 87654:             edge.slowJump = *slow;
 87654:         chunkEdges.append(edge);
 87654:         return true;
 87654:     }
 87654: 
 76194:     /*
 76194:      * Unless we are coming from a branch which synced everything, syncForBranch
 76194:      * must have been called and ensured an allocation at the target.
 76194:      */
 76194:     RegisterAllocation *lvtarget = NULL;
 76194:     bool consistent = true;
 76194:     if (cx->typeInferenceEnabled()) {
 76194:         RegisterAllocation *&alloc = analysis->getAllocation(target);
 76194:         if (!alloc) {
 79410:             alloc = cx->typeLifoAlloc().new_<RegisterAllocation>(false);
 92002:             if (!alloc) {
 92002:                 js_ReportOutOfMemory(cx);
 56766:                 return false;
 76194:             }
 92002:         }
 76194:         lvtarget = alloc;
 76194:         consistent = frame.consistentRegisters(target);
 76194:     }
 76194: 
 76194:     if (!lvtarget || lvtarget->synced()) {
 76194:         JS_ASSERT(consistent);
 56766:         if (!jumpInScript(j, target))
 56766:             return false;
 59895:         if (slow && !stubcc.jumpInScript(*slow, target))
 59895:             return false;
 76194:     } else {
 76194:         if (consistent) {
 76194:             if (!jumpInScript(j, target))
 76194:                 return false;
 76194:         } else {
 76194:             /*
 76194:              * Make a trampoline to issue remaining loads for the register
 76194:              * state at target.
 76194:              */
 77407:             Label start = stubcc.masm.label();
 77407:             stubcc.linkExitDirect(j, start);
 76194:             frame.prepareForJump(target, stubcc.masm, false);
 76194:             if (!stubcc.jumpInScript(stubcc.masm.jump(), target))
 76194:                 return false;
 76194:             if (trampoline)
 76194:                 *trampoline = true;
 80222:             if (pcLengths) {
 77407:                 /*
 77407:                  * This is OOL code but will usually be executed, so track
 77407:                  * it in the CODE_LENGTH for the opcode.
 77407:                  */
 84755:                 uint32_t offset = ssa.frameLength(a->inlineIndex) + PC - script->code;
 77407:                 size_t length = stubcc.masm.size() - stubcc.masm.distanceOf(start);
 77407:                 pcLengths[offset].codeLength += length;
 77407:             }
 76194:         }
 76194: 
 76194:         if (slow) {
 76194:             slow->linkTo(stubcc.masm.label(), &stubcc.masm);
 76194:             frame.prepareForJump(target, stubcc.masm, true);
 76194:             if (!stubcc.jumpInScript(stubcc.masm.jump(), target))
 76194:                 return false;
 76194:         }
 76194:     }
 76194: 
 76194:     if (target < PC)
 76194:         return finishLoop(target);
 56766:     return true;
 53133: }
 53133: 
 54840: void
 89253: mjit::Compiler::enterBlock(StaticBlockObject *block)
 54840: {
 54840:     /* For now, don't bother doing anything for this opcode. */
 54840:     frame.syncAndForgetEverything();
 89253:     masm.move(ImmPtr(block), Registers::ArgReg1);
 98921:     INLINE_STUBCALL(stubs::EnterBlock, REJOIN_FALLTHROUGH);
 86078:     if (*PC == JSOP_ENTERBLOCK)
 86078:         frame.enterBlock(StackDefs(script, PC));
 54840: }
 54840: 
 54840: void
 54840: mjit::Compiler::leaveBlock()
 54840: {
 54840:     /*
 54840:      * Note: After bug 535912, we can pass the block obj directly, inline
 54840:      * PutBlockObject, and do away with the muckiness in PutBlockObject.
 54840:      */
 86078:     uint32_t n = StackUses(script, PC);
 54840:     prepareStubCall(Uses(n));
 76194:     INLINE_STUBCALL(stubs::LeaveBlock, REJOIN_NONE);
 54840:     frame.leaveBlock(n);
 54840: }
 54840: 
 55503: // Creates the new object expected for constructors, and places it in |thisv|.
 55503: // It is broken down into the following operations:
 55503: //   CALLEE
 55503: //   GETPROP "prototype"
 55503: //   IFPRIMTOP:
 55503: //       NULL
 55503: //   call js_CreateThisFromFunctionWithProto(...)
 55503: //
 56037: bool
 55503: mjit::Compiler::constructThis()
 55503: {
 55503:     JS_ASSERT(isConstructing);
 55503: 
 99421:     RootedFunction fun(cx, script->function());
 77415: 
 78457:     do {
 82956:         if (!cx->typeInferenceEnabled() ||
 82956:             !fun->hasSingletonType() ||
 82956:             fun->getType(cx)->unknownProperties())
 82956:         {
 78457:             break;
 82956:         }
 78457: 
 97828:         jsid id = NameToId(cx->runtime->atomState.classPrototypeAtom);
 77415:         types::TypeSet *protoTypes = fun->getType(cx)->getProperty(cx, id, false);
 77413: 
 77413:         JSObject *proto = protoTypes->getSingleton(cx, true);
 78457:         if (!proto)
 78457:             break;
 78457: 
 78457:         /*
 78457:          * Generate an inline path to create a 'this' object with the given
 78457:          * prototype. Only do this if the type is actually known as a possible
 78457:          * 'this' type of the script.
 78457:          */
 78457:         types::TypeObject *type = proto->getNewType(cx, fun);
 78457:         if (!type)
 78457:             return false;
 78457:         if (!types::TypeScript::ThisTypes(script)->hasType(types::Type::ObjectType(type)))
 78457:             break;
 78457: 
 77415:         JSObject *templateObject = js_CreateThisForFunctionWithProto(cx, fun, proto);
 77414:         if (!templateObject)
 77414:             return false;
 77414: 
 77414:         /*
 77414:          * The template incorporates a shape and/or fixed slots from any
 77414:          * newScript on its type, so make sure recompilation is triggered
 77414:          * should this information change later.
 77414:          */
 77414:         if (templateObject->type()->newScript)
 77414:             types::TypeSet::WatchObjectStateChange(cx, templateObject->type());
 77413: 
 77413:         RegisterID result = frame.allocReg();
 98147:         Jump emptyFreeList = getNewObject(cx, result, templateObject);
 77413: 
 77413:         stubcc.linkExit(emptyFreeList, Uses(0));
 77413:         stubcc.leave();
 77413: 
 77413:         stubcc.masm.move(ImmPtr(proto), Registers::ArgReg1);
 77413:         OOL_STUBCALL(stubs::CreateThis, REJOIN_RESUME);
 77413: 
 77413:         frame.setThis(result);
 77413: 
 77413:         stubcc.rejoin(Changes(1));
 77413:         return true;
 78457:     } while (false);
 77413: 
 55503:     // Load the callee.
 57787:     frame.pushCallee();
 55503: 
 55503:     // Get callee.prototype.
 86855:     if (!jsop_getprop(cx->runtime->atomState.classPrototypeAtom, JSVAL_TYPE_UNKNOWN, false, /* forPrototype = */ true))
 56037:         return false;
 55503: 
 55503:     // Reach into the proto Value and grab a register for its data.
 55503:     FrameEntry *protoFe = frame.peek(-1);
 55503:     RegisterID protoReg = frame.ownRegForData(protoFe);
 55503: 
 55503:     // Now, get the type. If it's not an object, set protoReg to NULL.
 76194:     JS_ASSERT_IF(protoFe->isTypeKnown(), protoFe->isType(JSVAL_TYPE_OBJECT));
 76194:     if (!protoFe->isType(JSVAL_TYPE_OBJECT)) {
 55503:         Jump isNotObject = frame.testObject(Assembler::NotEqual, protoFe);
 55503:         stubcc.linkExitDirect(isNotObject, stubcc.masm.label());
 55503:         stubcc.masm.move(ImmPtr(NULL), protoReg);
 55503:         stubcc.crossJump(stubcc.masm.jump(), masm.label());
 76194:     }
 55503: 
 55503:     // Done with the protoFe.
 55503:     frame.pop();
 55503: 
 55503:     prepareStubCall(Uses(0));
 55503:     if (protoReg != Registers::ArgReg1)
 55503:         masm.move(protoReg, Registers::ArgReg1);
 76194:     INLINE_STUBCALL(stubs::CreateThis, REJOIN_RESUME);
 55503:     frame.freeReg(protoReg);
 56037:     return true;
 55503: }
 55503: 
 61233: bool
 59979: mjit::Compiler::jsop_tableswitch(jsbytecode *pc)
 59979: {
 59979: #if defined JS_CPU_ARM
 59979:     JS_NOT_REACHED("Implement jump(BaseIndex) for ARM");
 61248:     return true;
 59979: #else
 59979:     jsbytecode *originalPC = pc;
 87654:     DebugOnly<JSOp> op = JSOp(*originalPC);
 86877:     JS_ASSERT(op == JSOP_TABLESWITCH);
 86877: 
 86877:     uint32_t defaultTarget = GET_JUMP_OFFSET(pc);
 86877:     pc += JUMP_OFFSET_LEN;
 59979: 
 91450:     int32_t low = GET_JUMP_OFFSET(pc);
 59979:     pc += JUMP_OFFSET_LEN;
 91450:     int32_t high = GET_JUMP_OFFSET(pc);
 59979:     pc += JUMP_OFFSET_LEN;
 59979:     int numJumps = high + 1 - low;
 59979:     JS_ASSERT(numJumps >= 0);
 59979: 
 59979:     FrameEntry *fe = frame.peek(-1);
 59979:     if (fe->isNotType(JSVAL_TYPE_INT32) || numJumps > 256) {
 59979:         frame.syncAndForgetEverything();
 59979:         masm.move(ImmPtr(originalPC), Registers::ArgReg1);
 59979: 
 59979:         /* prepareStubCall() is not needed due to forgetEverything() */
 87983:         INLINE_STUBCALL(stubs::TableSwitch, REJOIN_NONE);
 59979:         frame.pop();
 59979:         masm.jump(Registers::ReturnReg);
 61233:         return true;
 59979:     }
 59979: 
 59979:     RegisterID dataReg;
 59979:     if (fe->isConstant()) {
 59979:         JS_ASSERT(fe->isType(JSVAL_TYPE_INT32));
 59979:         dataReg = frame.allocReg();
 59979:         masm.move(Imm32(fe->getValue().toInt32()), dataReg);
 59979:     } else {
 59979:         dataReg = frame.copyDataIntoReg(fe);
 59979:     }
 59979: 
 59979:     RegisterID reg = frame.allocReg();
 59979:     frame.syncAndForgetEverything();
 59979: 
 59979:     MaybeJump notInt;
 59979:     if (!fe->isType(JSVAL_TYPE_INT32))
 59979:         notInt = masm.testInt32(Assembler::NotEqual, frame.addressOf(fe));
 59979: 
 59979:     JumpTable jt;
 87654:     jt.offsetIndex = jumpTableEdges.length();
 59979:     jt.label = masm.moveWithPatch(ImmPtr(NULL), reg);
 59979:     jumpTables.append(jt);
 59979: 
 59979:     for (int i = 0; i < numJumps; i++) {
 86877:         uint32_t target = GET_JUMP_OFFSET(pc);
 59979:         if (!target)
 59979:             target = defaultTarget;
 87654:         JumpTableEdge edge;
 87654:         edge.source = originalPC - script->code;
 87654:         edge.target = (originalPC + target) - script->code;
 87654:         jumpTableEdges.append(edge);
 86877:         pc += JUMP_OFFSET_LEN;
 59979:     }
 59979:     if (low != 0)
 59979:         masm.sub32(Imm32(low), dataReg);
 59979:     Jump defaultCase = masm.branch32(Assembler::AboveOrEqual, dataReg, Imm32(numJumps));
 59979:     BaseIndex jumpTarget(reg, dataReg, Assembler::ScalePtr);
 59979:     masm.jump(jumpTarget);
 59979: 
 59979:     if (notInt.isSet()) {
 59979:         stubcc.linkExitDirect(notInt.get(), stubcc.masm.label());
 59979:         stubcc.leave();
 59979:         stubcc.masm.move(ImmPtr(originalPC), Registers::ArgReg1);
 87983:         OOL_STUBCALL(stubs::TableSwitch, REJOIN_NONE);
 59979:         stubcc.masm.jump(Registers::ReturnReg);
 59979:     }
 59979:     frame.pop();
 82738:     return jumpAndRun(defaultCase, originalPC + defaultTarget);
 59979: #endif
 59979: }
 59979: 
 59979: void
 77357: mjit::Compiler::jsop_toid()
 77357: {
 77386:     /* Leave integers alone, stub everything else. */
 77357:     FrameEntry *top = frame.peek(-1);
 77357: 
 77357:     if (top->isType(JSVAL_TYPE_INT32))
 77357:         return;
 77357: 
 77357:     if (top->isNotType(JSVAL_TYPE_INT32)) {
 77357:         prepareStubCall(Uses(2));
 77357:         INLINE_STUBCALL(stubs::ToId, REJOIN_FALLTHROUGH);
 77357:         frame.pop();
 77357:         pushSyncedEntry(0);
 77357:         return;
 77357:     }
 77357: 
 77357:     frame.syncAt(-1);
 77357: 
 77357:     Jump j = frame.testInt32(Assembler::NotEqual, top);
 77357:     stubcc.linkExit(j, Uses(2));
 77357: 
 77357:     stubcc.leave();
 77357:     OOL_STUBCALL(stubs::ToId, REJOIN_FALLTHROUGH);
 77357: 
 77357:     frame.pop();
 77357:     pushSyncedEntry(0);
 77357: 
 77357:     stubcc.rejoin(Changes(1));
 77357: }
 77357: 
 88181: void
 88181: mjit::Compiler::jsop_in()
 88181: {
 88181:     FrameEntry *obj = frame.peek(-1);
 88181:     FrameEntry *id = frame.peek(-2);
 88181: 
 88181:     if (cx->typeInferenceEnabled() && id->isType(JSVAL_TYPE_INT32)) {
 88181:         types::TypeSet *types = analysis->poppedTypes(PC, 0);
 88181: 
 88181:         if (obj->mightBeType(JSVAL_TYPE_OBJECT) &&
 88181:             !types->hasObjectFlags(cx, types::OBJECT_FLAG_NON_DENSE_ARRAY) &&
 88181:             !types::ArrayPrototypeHasIndexedProperty(cx, outerScript))
 88181:         {
 88181:             bool isPacked = !types->hasObjectFlags(cx, types::OBJECT_FLAG_NON_PACKED_ARRAY);
 88181: 
 88181:             if (!obj->isTypeKnown()) {
 88181:                 Jump guard = frame.testObject(Assembler::NotEqual, obj);
 88181:                 stubcc.linkExit(guard, Uses(2));
 88181:             }
 88181: 
 88181:             RegisterID dataReg = frame.copyDataIntoReg(obj);
 88181: 
 88181:             Int32Key key = id->isConstant()
 88181:                          ? Int32Key::FromConstant(id->getValue().toInt32())
 88181:                          : Int32Key::FromRegister(frame.tempRegForData(id));
 88181: 
 88181:             masm.loadPtr(Address(dataReg, JSObject::offsetOfElements()), dataReg);
 88181: 
 88181:             // Guard on the array's initialized length.
 88181:             Jump initlenGuard = masm.guardArrayExtent(ObjectElements::offsetOfInitializedLength(),
 88181:                                                       dataReg, key, Assembler::BelowOrEqual);
 88181: 
 88181:             // Guard to make sure we don't have a hole. Skip it if the array is packed.
 88181:             MaybeJump holeCheck;
 88181:             if (!isPacked)
 88181:                 holeCheck = masm.guardElementNotHole(dataReg, key);
 88181: 
 88181:             masm.move(Imm32(1), dataReg);
 88181:             Jump done = masm.jump();
 88181: 
 88181:             Label falseBranch = masm.label();
 88181:             initlenGuard.linkTo(falseBranch, &masm);
 88181:             if (!isPacked)
 88181:                 holeCheck.getJump().linkTo(falseBranch, &masm);
 88181:             masm.move(Imm32(0), dataReg);
 88181: 
 88181:             done.linkTo(masm.label(), &masm);
 88181: 
 88181:             stubcc.leave();
 88181:             OOL_STUBCALL_USES(stubs::In, REJOIN_PUSH_BOOLEAN, Uses(2));
 88181: 
 88181:             frame.popn(2);
 88181:             if (dataReg != Registers::ReturnReg)
 88181:                 stubcc.masm.move(Registers::ReturnReg, dataReg);
 88181: 
 88181:             frame.pushTypedPayload(JSVAL_TYPE_BOOLEAN, dataReg);
 88181: 
 88181:             stubcc.rejoin(Changes(2));
 88181: 
 88181:             return;
 88181:         }
 88181:     }
 88181: 
 88181:     prepareStubCall(Uses(2));
 88181:     INLINE_STUBCALL(stubs::In, REJOIN_PUSH_BOOLEAN);
 88181:     frame.popn(2);
 88181:     frame.takeReg(Registers::ReturnReg);
 88181:     frame.pushTypedPayload(JSVAL_TYPE_BOOLEAN, Registers::ReturnReg);
 88181: }
 88181: 
 76194: /*
 76194:  * For any locals or args which we know to be integers but are treated as
 76194:  * doubles by the type inference, convert to double. These will be assumed to be
 76194:  * doubles at control flow join points. This function must be called before
 76194:  * branching to another opcode.
 76194:  *
 76194:  * We can only carry entries as doubles when we can track all incoming edges to
 76194:  * a join point (no try blocks etc.) and when we can track all writes to the
 76194:  * local/arg (the slot does not escape) and ensure the Compiler representation
 76194:  * matches the inferred type for the variable's SSA value. These properties are
 76194:  * both ensured by analysis->trackSlot.
 76194:  */
 76194: void
 76194: mjit::Compiler::fixDoubleTypes(jsbytecode *target)
 76194: {
 76194:     if (!cx->typeInferenceEnabled())
 76194:         return;
 76194: 
 76194:     /*
 77457:      * Fill fixedIntToDoubleEntries with all variables that are known to be an
 77457:      * int here and a double at the branch target, and fixedDoubleToAnyEntries
 77457:      * with all variables that are known to be a double here but not at the
 77457:      * branch target.
 77457:      *
 77457:      * Per prepareInferenceTypes, the target state consists of the current
 77457:      * state plus any phi nodes or other new values introduced at the target.
 76194:      */
 77457:     JS_ASSERT(fixedIntToDoubleEntries.empty());
 77457:     JS_ASSERT(fixedDoubleToAnyEntries.empty());
 76194:     const SlotValue *newv = analysis->newValues(target);
 76194:     if (newv) {
 76194:         while (newv->slot) {
 76194:             if (newv->value.kind() != SSAValue::PHI ||
 84755:                 newv->value.phiOffset() != uint32_t(target - script->code) ||
 77457:                 !analysis->trackSlot(newv->slot)) {
 76194:                 newv++;
 76194:                 continue;
 76194:             }
 77457:             JS_ASSERT(newv->slot < TotalSlots(script));
 76194:             types::TypeSet *targetTypes = analysis->getValueTypes(newv->value);
 77457:             FrameEntry *fe = frame.getSlotEntry(newv->slot);
 76194:             VarType &vt = a->varTypes[newv->slot];
 87654:             JSValueType type = vt.getTypeTag(cx);
 77457:             if (targetTypes->getKnownTypeTag(cx) == JSVAL_TYPE_DOUBLE) {
 87654:                 if (type == JSVAL_TYPE_INT32) {
 77457:                     fixedIntToDoubleEntries.append(newv->slot);
 76194:                     frame.ensureDouble(fe);
 77471:                     frame.forgetLoopReg(fe);
 87654:                 } else if (type == JSVAL_TYPE_UNKNOWN) {
 76194:                     /*
 76194:                      * Unknown here but a double at the target. The type
 76194:                      * set for the existing value must be empty, so this
 76194:                      * code is doomed and we can just mark the value as
 76194:                      * a double.
 76194:                      */
 76194:                     frame.ensureDouble(fe);
 76194:                 } else {
 87654:                     JS_ASSERT(type == JSVAL_TYPE_DOUBLE);
 87654:                 }
 87654:             } else if (type == JSVAL_TYPE_DOUBLE) {
 77457:                 fixedDoubleToAnyEntries.append(newv->slot);
 77457:                 frame.syncAndForgetFe(fe);
 77471:                 frame.forgetLoopReg(fe);
 76194:             }
 76194:             newv++;
 76194:         }
 76194:     }
 76194: }
 76194: 
 76194: void
 76194: mjit::Compiler::watchGlobalReallocation()
 76194: {
 76194:     JS_ASSERT(cx->typeInferenceEnabled());
 76194:     if (hasGlobalReallocation)
 76194:         return;
 77414:     types::TypeSet::WatchObjectStateChange(cx, globalObj->getType(cx));
 76194:     hasGlobalReallocation = true;
 76194: }
 76194: 
 76194: void
 76194: mjit::Compiler::updateVarType()
 76194: {
 76194:     if (!cx->typeInferenceEnabled())
 76194:         return;
 76194: 
 76194:     /*
 76194:      * For any non-escaping variable written at the current opcode, update the
 76194:      * associated type sets according to the written type, keeping the type set
 76194:      * for each variable in sync with what the SSA analysis has determined
 76194:      * (see prepareInferenceTypes).
 76194:      */
 76194: 
 77363:     types::TypeSet *types = pushedTypeSet(0);
 84755:     uint32_t slot = GetBytecodeSlot(script, PC);
 76194: 
 76194:     if (analysis->trackSlot(slot)) {
 76194:         VarType &vt = a->varTypes[slot];
 87654:         vt.setTypes(types);
 76194: 
 76194:         /*
 76194:          * Variables whose type has been inferred as a double need to be
 76194:          * maintained by the frame as a double. We might forget the exact
 76194:          * representation used by the next call to fixDoubleTypes, fix it now.
 76194:          */
 87654:         if (vt.getTypeTag(cx) == JSVAL_TYPE_DOUBLE)
 76194:             frame.ensureDouble(frame.getSlotEntry(slot));
 76194:     }
 76194: }
 76194: 
 76194: void
 76194: mjit::Compiler::updateJoinVarTypes()
 76194: {
 76194:     if (!cx->typeInferenceEnabled())
 76194:         return;
 76194: 
 76194:     /* Update variable types for all new values at this bytecode. */
 76194:     const SlotValue *newv = analysis->newValues(PC);
 76194:     if (newv) {
 76194:         while (newv->slot) {
 76194:             if (newv->slot < TotalSlots(script)) {
 76194:                 VarType &vt = a->varTypes[newv->slot];
 87654:                 JSValueType type = vt.getTypeTag(cx);
 87654:                 vt.setTypes(analysis->getValueTypes(newv->value));
 87654:                 if (vt.getTypeTag(cx) != type) {
 87654:                     /*
 87654:                      * If the known type of a variable changes (even if the
 87654:                      * variable itself has not been reassigned) then we can't
 87654:                      * carry a loop register for the var.
 87654:                      */
 78457:                     FrameEntry *fe = frame.getSlotEntry(newv->slot);
 78457:                     frame.forgetLoopReg(fe);
 78457:                 }
 76194:             }
 76194:             newv++;
 76194:         }
 76194:     }
 76194: }
 76194: 
 76194: void
 76194: mjit::Compiler::restoreVarType()
 76194: {
 76194:     if (!cx->typeInferenceEnabled())
 76194:         return;
 76194: 
 84755:     uint32_t slot = GetBytecodeSlot(script, PC);
 76194: 
 76194:     if (slot >= analyze::TotalSlots(script))
 76194:         return;
 76194: 
 76194:     /*
 76194:      * Restore the known type of a live local or argument. We ensure that types
 76194:      * of tracked variables match their inferred type (as tracked in varTypes),
 76194:      * but may have forgotten it due to a branch or syncAndForgetEverything.
 76194:      */
 87654:     JSValueType type = a->varTypes[slot].getTypeTag(cx);
 76194:     if (type != JSVAL_TYPE_UNKNOWN &&
 76194:         (type != JSVAL_TYPE_DOUBLE || analysis->trackSlot(slot))) {
 76194:         FrameEntry *fe = frame.getSlotEntry(slot);
 76194:         JS_ASSERT_IF(fe->isTypeKnown(), fe->isType(type));
 76194:         if (!fe->isTypeKnown())
 76194:             frame.learnType(fe, type, false);
 76194:     }
 76194: }
 76194: 
 76194: JSValueType
 84755: mjit::Compiler::knownPushedType(uint32_t pushed)
 76194: {
 76194:     if (!cx->typeInferenceEnabled())
 76194:         return JSVAL_TYPE_UNKNOWN;
 76194:     types::TypeSet *types = analysis->pushedTypes(PC, pushed);
 76194:     return types->getKnownTypeTag(cx);
 76194: }
 76194: 
 76194: bool
 84755: mjit::Compiler::mayPushUndefined(uint32_t pushed)
 76194: {
 76194:     JS_ASSERT(cx->typeInferenceEnabled());
 76194: 
 76194:     /*
 76194:      * This should only be used when the compiler is checking if it is OK to push
 76194:      * undefined without going to a stub that can trigger recompilation.
 76194:      * If this returns false and undefined subsequently becomes a feasible
 76194:      * value pushed by the bytecode, recompilation will *NOT* be triggered.
 76194:      */
 76194:     types::TypeSet *types = analysis->pushedTypes(PC, pushed);
 77353:     return types->hasType(types::Type::UndefinedType());
 76194: }
 76194: 
 76194: types::TypeSet *
 84755: mjit::Compiler::pushedTypeSet(uint32_t pushed)
 76194: {
 76194:     if (!cx->typeInferenceEnabled())
 76194:         return NULL;
 76194:     return analysis->pushedTypes(PC, pushed);
 76194: }
 76194: 
 76194: bool
 76194: mjit::Compiler::monitored(jsbytecode *pc)
 76194: {
 76194:     if (!cx->typeInferenceEnabled())
 76194:         return false;
 76194:     return analysis->getCode(pc).monitoredTypes;
 76194: }
 76194: 
 76194: bool
 76194: mjit::Compiler::hasTypeBarriers(jsbytecode *pc)
 76194: {
 76194:     if (!cx->typeInferenceEnabled())
 76194:         return false;
 76194: 
 78194:     return analysis->typeBarriers(cx, pc) != NULL;
 76194: }
 76194: 
 76194: void
 84755: mjit::Compiler::pushSyncedEntry(uint32_t pushed)
 76194: {
 76194:     frame.pushSynced(knownPushedType(pushed));
 76194: }
 76194: 
 76194: JSObject *
 76194: mjit::Compiler::pushedSingleton(unsigned pushed)
 76194: {
 76194:     if (!cx->typeInferenceEnabled())
 76194:         return NULL;
 76194: 
 76194:     types::TypeSet *types = analysis->pushedTypes(PC, pushed);
 76194:     return types->getSingleton(cx);
 76194: }
 76194: 
 76194: /*
 76194:  * Barriers overview.
 76194:  *
 76194:  * After a property fetch finishes, we may need to do type checks on it to make
 76194:  * sure it matches the pushed type set for this bytecode. This can be either
 76194:  * because there is a type barrier at the bytecode, or because we cannot rule
 76194:  * out an undefined result. For such accesses, we push a register pair, and
 76194:  * then use those registers to check the fetched type matches the inferred
 76194:  * types for the pushed set. The flow here is tricky:
 76194:  *
 76194:  * frame.pushRegs(type, data, knownType);
 76194:  * --- Depending on knownType, the frame's representation for the pushed entry
 76194:  *     may not be a register pair anymore. knownType is based on the observed
 76194:  *     types that have been pushed here and may not actually match type/data.
 76194:  *     pushRegs must not clobber either register, for the test below.
 76194:  *
 76194:  * testBarrier(type, data)
 76194:  * --- Use the type/data regs and generate a single jump taken if the barrier
 76194:  *     has been violated.
 76194:  *
 76194:  * --- Rearrange stack, rejoin from stub paths. No code must be emitted into
 76194:  *     the inline path between testBarrier and finishBarrier. Since a stub path
 76194:  *     may be in progress we can't call finishBarrier before stubcc.rejoin,
 76194:  *     and since typeReg/dataReg may not be intact after the stub call rejoin
 76194:  *     (if knownType != JSVAL_TYPE_UNKNOWN) we can't testBarrier after calling
 76194:  *     stubcc.rejoin.
 76194:  *
 76194:  * finishBarrier()
 76194:  * --- Link the barrier jump to a new stub code path which updates the pushed
 76194:  *     types (possibly triggering recompilation). The frame has changed since
 76194:  *     pushRegs to reflect the final state of the op, which is OK as no inline
 76194:  *     code has been emitted since the barrier jump.
 76194:  */
 76194: 
 76194: mjit::Compiler::BarrierState
 76194: mjit::Compiler::pushAddressMaybeBarrier(Address address, JSValueType type, bool reuseBase,
 76194:                                         bool testUndefined)
 76194: {
 76194:     if (!hasTypeBarriers(PC) && !testUndefined) {
 76194:         frame.push(address, type, reuseBase);
 76194:         return BarrierState();
 76194:     }
 76194: 
 76194:     RegisterID typeReg, dataReg;
 76194:     frame.loadIntoRegisters(address, reuseBase, &typeReg, &dataReg);
 76194: 
 76194:     frame.pushRegs(typeReg, dataReg, type);
 76194:     return testBarrier(typeReg, dataReg, testUndefined);
 76194: }
 76194: 
 80962: MaybeJump
 80962: mjit::Compiler::trySingleTypeTest(types::TypeSet *types, RegisterID typeReg)
 80962: {
 80962:     /*
 80962:      * If a type set we have a barrier on is monomorphic, generate a single
 80962:      * jump taken if a type register has a match. This doesn't handle type sets
 80962:      * containing objects, as these require two jumps regardless (test for
 80962:      * object, then test the type of the object).
 80962:      */
 80962:     MaybeJump res;
 80962: 
 80962:     switch (types->getKnownTypeTag(cx)) {
 80962:       case JSVAL_TYPE_INT32:
 80962:         res.setJump(masm.testInt32(Assembler::NotEqual, typeReg));
 80962:         return res;
 80962: 
 80962:       case JSVAL_TYPE_DOUBLE:
 80962:         res.setJump(masm.testNumber(Assembler::NotEqual, typeReg));
 80962:         return res;
 80962: 
 80962:       case JSVAL_TYPE_BOOLEAN:
 80962:         res.setJump(masm.testBoolean(Assembler::NotEqual, typeReg));
 80962:         return res;
 80962: 
 80962:       case JSVAL_TYPE_STRING:
 80962:         res.setJump(masm.testString(Assembler::NotEqual, typeReg));
 80962:         return res;
 80962: 
 80962:       default:
 80962:         return res;
 80962:     }
 80962: }
 80962: 
 76194: JSC::MacroAssembler::Jump
 76194: mjit::Compiler::addTypeTest(types::TypeSet *types, RegisterID typeReg, RegisterID dataReg)
 76194: {
 76194:     /*
 76194:      * :TODO: It would be good to merge this with GenerateTypeCheck, but the
 76194:      * two methods have a different format for the tested value (in registers
 76194:      * vs. in memory).
 76194:      */
 76194: 
 76194:     Vector<Jump> matches(CompilerAllocPolicy(cx, *this));
 76194: 
 80962:     if (types->hasType(types::Type::Int32Type()))
 76194:         matches.append(masm.testInt32(Assembler::Equal, typeReg));
 76194: 
 80962:     if (types->hasType(types::Type::DoubleType()))
 80962:         matches.append(masm.testDouble(Assembler::Equal, typeReg));
 76194: 
 77353:     if (types->hasType(types::Type::UndefinedType()))
 76194:         matches.append(masm.testUndefined(Assembler::Equal, typeReg));
 76194: 
 77353:     if (types->hasType(types::Type::BooleanType()))
 76194:         matches.append(masm.testBoolean(Assembler::Equal, typeReg));
 76194: 
 77353:     if (types->hasType(types::Type::StringType()))
 76194:         matches.append(masm.testString(Assembler::Equal, typeReg));
 76194: 
 77353:     if (types->hasType(types::Type::NullType()))
 76194:         matches.append(masm.testNull(Assembler::Equal, typeReg));
 76194: 
 77353:     unsigned count = 0;
 77353:     if (types->hasType(types::Type::AnyObjectType()))
 77353:         matches.append(masm.testObject(Assembler::Equal, typeReg));
 77353:     else
 77353:         count = types->getObjectCount();
 77353: 
 76194:     if (count != 0) {
 76194:         Jump notObject = masm.testObject(Assembler::NotEqual, typeReg);
 77353:         Address typeAddress(dataReg, JSObject::offsetOfType());
 76194: 
 76194:         for (unsigned i = 0; i < count; i++) {
 77353:             if (JSObject *object = types->getSingleObject(i))
 77353:                 matches.append(masm.branchPtr(Assembler::Equal, dataReg, ImmPtr(object)));
 77455:         }
 77455: 
 77455:         for (unsigned i = 0; i < count; i++) {
 77455:             if (types::TypeObject *object = types->getTypeObject(i))
 76194:                 matches.append(masm.branchPtr(Assembler::Equal, typeAddress, ImmPtr(object)));
 76194:         }
 76194: 
 76194:         notObject.linkTo(masm.label(), &masm);
 76194:     }
 76194: 
 76194:     Jump mismatch = masm.jump();
 76194: 
 76194:     for (unsigned i = 0; i < matches.length(); i++)
 76194:         matches[i].linkTo(masm.label(), &masm);
 76194: 
 76194:     return mismatch;
 76194: }
 76194: 
 76194: mjit::Compiler::BarrierState
 76194: mjit::Compiler::testBarrier(RegisterID typeReg, RegisterID dataReg,
 78454:                             bool testUndefined, bool testReturn, bool force)
 76194: {
 76194:     BarrierState state;
 76194:     state.typeReg = typeReg;
 76194:     state.dataReg = dataReg;
 76194: 
 76194:     if (!cx->typeInferenceEnabled() || !(js_CodeSpec[*PC].format & JOF_TYPESET))
 76194:         return state;
 76194: 
 77391:     types::TypeSet *types = analysis->bytecodeTypes(PC);
 76194:     if (types->unknown()) {
 76194:         /*
 76194:          * If the result of this opcode is already unknown, there is no way for
 76194:          * a type barrier to fail.
 76194:          */
 76194:         return state;
 76194:     }
 76194: 
 76194:     if (testReturn) {
 76194:         JS_ASSERT(!testUndefined);
 76194:         if (!analysis->getCode(PC).monitoredTypesReturn)
 76194:             return state;
 78454:     } else if (!hasTypeBarriers(PC) && !force) {
 77459:         if (testUndefined && !types->hasType(types::Type::UndefinedType()))
 76194:             state.jump.setJump(masm.testUndefined(Assembler::Equal, typeReg));
 76194:         return state;
 76194:     }
 76194: 
 76194:     types->addFreeze(cx);
 76194: 
 76194:     /* Cannot have type barriers when the result of the operation is already unknown. */
 76194:     JS_ASSERT(!types->unknown());
 76194: 
 80962:     state.jump = trySingleTypeTest(types, typeReg);
 80962:     if (!state.jump.isSet())
 76194:         state.jump.setJump(addTypeTest(types, typeReg, dataReg));
 76194: 
 76194:     return state;
 76194: }
 76194: 
 76194: void
 84755: mjit::Compiler::finishBarrier(const BarrierState &barrier, RejoinState rejoin, uint32_t which)
 76194: {
 76194:     if (!barrier.jump.isSet())
 76194:         return;
 76194: 
 76194:     stubcc.linkExitDirect(barrier.jump.get(), stubcc.masm.label());
 76194: 
 76194:     /*
 76194:      * Before syncing, store the entry to sp[0]. (scanInlineCalls accounted for
 76194:      * this when making sure there is enough froom for all frames). The known
 76194:      * type in the frame may be wrong leading to an incorrect sync, and this
 76194:      * sync may also clobber typeReg and/or dataReg.
 76194:      */
 76194:     frame.pushSynced(JSVAL_TYPE_UNKNOWN);
 76194:     stubcc.masm.storeValueFromComponents(barrier.typeReg, barrier.dataReg,
 76194:                                          frame.addressOf(frame.peek(-1)));
 76194:     frame.pop();
 76194: 
 76194:     stubcc.syncExit(Uses(0));
 76194:     stubcc.leave();
 76194: 
 80505:     stubcc.masm.move(ImmIntPtr(intptr_t(which)), Registers::ArgReg1);
 76194:     OOL_STUBCALL(stubs::TypeBarrierHelper, rejoin);
 76194:     stubcc.rejoin(Changes(0));
 76194: }
 78456: 
 78456: void
 78456: mjit::Compiler::testPushedType(RejoinState rejoin, int which, bool ool)
 78456: {
 78456:     if (!cx->typeInferenceEnabled() || !(js_CodeSpec[*PC].format & JOF_TYPESET))
 78456:         return;
 78456: 
 78456:     types::TypeSet *types = analysis->bytecodeTypes(PC);
 78456:     if (types->unknown())
 78456:         return;
 78456: 
 78456:     Assembler &masm = ool ? stubcc.masm : this->masm;
 78456: 
 78456:     JS_ASSERT(which <= 0);
 78456:     Address address = (which == 0) ? frame.addressOfTop() : frame.addressOf(frame.peek(which));
 78456: 
 78456:     Vector<Jump> mismatches(cx);
 78456:     if (!masm.generateTypeCheck(cx, address, types, &mismatches)) {
 78456:         oomInVector = true;
 78456:         return;
 78456:     }
 78456: 
 78456:     Jump j = masm.jump();
 78456: 
 78456:     for (unsigned i = 0; i < mismatches.length(); i++)
 78456:         mismatches[i].linkTo(masm.label(), &masm);
 78456: 
 78456:     masm.move(Imm32(which), Registers::ArgReg1);
 78456:     if (ool)
 78456:         OOL_STUBCALL(stubs::StubTypeHelper, rejoin);
 78456:     else
 78456:         INLINE_STUBCALL(stubs::StubTypeHelper, rejoin);
 78456: 
 78456:     j.linkTo(masm.label(), &masm);
 78456: }
