52557: /* -*- Mode: C++; tab-width: 4; indent-tabs-mode: nil; c-basic-offset: 4 -*-
52557:  * vim: set ts=4 sw=4 et tw=99:
52557:  *
52557:  * ***** BEGIN LICENSE BLOCK *****
52557:  * Version: MPL 1.1/GPL 2.0/LGPL 2.1
52557:  *
52557:  * The contents of this file are subject to the Mozilla Public License Version
52557:  * 1.1 (the "License"); you may not use this file except in compliance with
52557:  * the License. You may obtain a copy of the License at
52557:  * http://www.mozilla.org/MPL/
52557:  *
52557:  * Software distributed under the License is distributed on an "AS IS" basis,
52557:  * WITHOUT WARRANTY OF ANY KIND, either express or implied. See the License
52557:  * for the specific language governing rights and limitations under the
52557:  * License.
52557:  *
52557:  * The Original Code is Mozilla SpiderMonkey JavaScript 1.9 code, released
52557:  * May 28, 2008.
52557:  *
52557:  * The Initial Developer of the Original Code is
52557:  *   Brendan Eich <brendan@mozilla.org>
52557:  *
52557:  * Contributor(s):
52557:  *
52557:  * Alternatively, the contents of this file may be used under the terms of
52557:  * either of the GNU General Public License Version 2 or later (the "GPL"),
52557:  * or the GNU Lesser General Public License Version 2.1 or later (the "LGPL"),
52557:  * in which case the provisions of the GPL or the LGPL are applicable instead
52557:  * of those above. If you wish to allow use of your version of this file only
52557:  * under the terms of either the GPL or the LGPL, and not to allow others to
52557:  * use your version of this file under the terms of the MPL, indicate your
52557:  * decision by deleting the provisions above and replace them with the notice
52557:  * and other provisions required by the GPL or the LGPL. If you do not delete
52557:  * the provisions above, a recipient may use your version of this file under
52557:  * the terms of any one of the MPL, the GPL or the LGPL. 
52557:  *
52557:  * ***** END LICENSE BLOCK ***** */
52557: 
52557: #if !defined jsjaeger_h__ && defined JS_METHODJIT
52557: #define jsjaeger_h__
52557: 
52557: #include "jscntxt.h"
76185: #include "jscompartment.h"
52557: 
52557: #include "assembler/assembler/MacroAssemblerCodeRef.h"
76185: #include "assembler/assembler/CodeLocation.h"
52557: 
52557: #if !defined JS_CPU_X64 && \
52557:     !defined JS_CPU_X86 && \
68931:     !defined JS_CPU_SPARC && \
52557:     !defined JS_CPU_ARM
52557: # error "Oh no, you should define a platform so this compiles."
52557: #endif
52557: 
53224: #if !defined(JS_NUNBOX32) && !defined(JS_PUNBOX64)
53224: # error "No boxing format selected."
52560: #endif
52560: 
52557: namespace js {
52557: 
58063: namespace mjit { struct JITScript; }
58063: 
52557: struct VMFrame
52557: {
68931: #if defined(JS_CPU_SPARC)
68931:     void *savedL0;
68931:     void *savedL1;
68931:     void *savedL2;
68931:     void *savedL3;
68931:     void *savedL4;
68931:     void *savedL5;
68931:     void *savedL6;
68931:     void *savedL7;
68931:     void *savedI0;
68931:     void *savedI1;
68931:     void *savedI2;
68931:     void *savedI3;
68931:     void *savedI4;
68931:     void *savedI5;
68931:     void *savedI6;
68931:     void *savedI7;
68931: 
68931:     void *str_p;
68931: 
68931:     void *outgoing_p0;
68931:     void *outgoing_p1;
68931:     void *outgoing_p2;
68931:     void *outgoing_p3;
68931:     void *outgoing_p4;
68931:     void *outgoing_p5;
68931: 
68931:     void *outgoing_p6;
68931: 
68931:     void *reserve_0;
68931:     void *reserve_1;
68931: #endif
68931: 
52557:     union Arguments {
52825:         struct {
52825:             void *ptr;
52825:             void *ptr2;
52825:         } x;
57717:         struct {
68952:             uint32 lazyArgsObj;
57717:             uint32 dynamicArgc;
57717:         } call;
52557:     } u;
52557: 
53168:     VMFrame      *previous;
76185:     void         *scratch;
69223:     FrameRegs    regs;
52557:     JSContext    *cx;
53422:     Value        *stackLimit;
69223:     StackFrame   *entryfp;
77341:     FrameRegs    *oldregs;
76185:     JSRejoinState stubRejoin;  /* How to rejoin if inside a call from an IC stub. */
76185: 
76185: #if defined(JS_CPU_X86)
76185:     void         *unused0, *unused1;  /* For 16 byte alignment */
76185: #endif
52557: 
52557: #if defined(JS_CPU_X86)
52557:     void *savedEBX;
52557:     void *savedEDI;
52557:     void *savedESI;
52557:     void *savedEBP;
52557:     void *savedEIP;
52557: 
53012: # ifdef JS_NO_FASTCALL
53168:     inline void** returnAddressLocation() {
58684:         return reinterpret_cast<void**>(this) - 5;
53012:     }
53012: # else
53168:     inline void** returnAddressLocation() {
53168:         return reinterpret_cast<void**>(this) - 1;
52557:     }
53012: # endif
76185: 
76185:     /* The gap between ebp and esp in JaegerTrampoline frames on X86 platforms. */
76185:     static const uint32 STACK_BASE_DIFFERENCE = 0x38;
76185: 
52557: #elif defined(JS_CPU_X64)
52557:     void *savedRBX;
53477: # ifdef _WIN64
52557:     void *savedRSI;
52557:     void *savedRDI;
52557: # endif
52557:     void *savedR15;
52557:     void *savedR14;
52557:     void *savedR13;
52557:     void *savedR12;
52557:     void *savedRBP;
52557:     void *savedRIP;
52557: 
53477: # ifdef _WIN64
53168:     inline void** returnAddressLocation() {
53168:         return reinterpret_cast<void**>(this) - 5;
52557:     }
52557: # else
53168:     inline void** returnAddressLocation() {
53168:         return reinterpret_cast<void**>(this) - 1;
52557:     }
52557: # endif
52557: 
52557: #elif defined(JS_CPU_ARM)
52557:     void *savedR4;
52557:     void *savedR5;
52557:     void *savedR6;
52557:     void *savedR7;
52557:     void *savedR8;
52557:     void *savedR9;
52557:     void *savedR10;
52557:     void *savedR11;
52557:     void *savedLR;
52557: 
53168:     inline void** returnAddressLocation() {
53361:         return reinterpret_cast<void**>(this) - 1;
52557:     }
68931: #elif defined(JS_CPU_SPARC)
68931:     JSStackFrame *topRetrunAddr;
68931:     void* veneerReturn;
68931:     void* _align;
68931:     inline void** returnAddressLocation() {
68931:         return reinterpret_cast<void**>(&this->veneerReturn);
68931:     }
52557: #else
52557: # error "The VMFrame layout isn't defined for your processor architecture!"
52557: #endif
52557: 
52557:     JSRuntime *runtime() { return cx->runtime; }
53422: 
76185:     /*
76185:      * Get the current frame and JIT. Note that these are NOT stable in case
76185:      * of recompilations; all code which expects these to be stable should
76185:      * check that cx->recompilations() has not changed across a call that could
76185:      * trigger recompilation (pretty much any time the VM is called into).
76185:      */
69223:     StackFrame *fp() { return regs.fp(); }
58063:     mjit::JITScript *jit() { return fp()->jit(); }
69223: 
76185:     /* Get the inner script/PC in case of inlining. */
76185:     inline JSScript *script();
76185:     inline jsbytecode *pc();
76185: 
69844: #if defined(JS_CPU_SPARC)
76185:     static const size_t offsetOfFp = 30 * sizeof(void *) + FrameRegs::offsetOfFp;
76185:     static const size_t offsetOfInlined = 30 * sizeof(void *) + FrameRegs::offsetOfInlined;
69844: #else
76185:     static const size_t offsetOfFp = 4 * sizeof(void *) + FrameRegs::offsetOfFp;
76185:     static const size_t offsetOfInlined = 4 * sizeof(void *) + FrameRegs::offsetOfInlined;
69844: #endif
76185: 
69223:     static void staticAssert() {
69223:         JS_STATIC_ASSERT(offsetOfFp == offsetof(VMFrame, regs) + FrameRegs::offsetOfFp);
76185:         JS_STATIC_ASSERT(offsetOfInlined == offsetof(VMFrame, regs) + FrameRegs::offsetOfInlined);
69223:     }
52557: };
52557: 
52557: #ifdef JS_CPU_ARM
53361: // WARNING: Do not call this function directly from C(++) code because it is not ABI-compliant.
52557: extern "C" void JaegerStubVeneer(void);
52557: #endif
52557: 
55503: namespace mjit {
56773: 
56773: /*
76185:  * For a C++ or scripted call made from JIT code, indicates properties of the
76185:  * register and stack state after the call finishes, which RejoinInterpreter
76185:  * must use to construct a coherent state for rejoining into the interpreter.
76185:  */
76185: enum RejoinState {
76185:     /*
76185:      * Return value of call at this bytecode is held in ReturnReg_{Data,Type}
76185:      * and needs to be restored before starting the next bytecode. f.regs.pc
76185:      * is *not* intact when rejoining from a scripted call (unlike all other
76185:      * rejoin states). The pc's offset into the script is stored in the upper
76185:      * 31 bits of the rejoin state, and the remaining values for RejoinState
76185:      * are shifted left by one in stack frames to leave the lower bit set only
76185:      * for scripted calls.
76185:      */
76185:     REJOIN_SCRIPTED = 1,
76185: 
76185:     /* Recompilations and frame expansion are impossible for this call. */
76185:     REJOIN_NONE,
76185: 
76185:     /* State is coherent for the start of the current bytecode. */
76185:     REJOIN_RESUME,
76185: 
76185:     /*
76185:      * State is coherent for the start of the current bytecode, which is a TRAP
76185:      * that has already been invoked and should not be invoked again.
76185:      */
76185:     REJOIN_TRAP,
76185: 
76185:     /* State is coherent for the start of the next (fallthrough) bytecode. */
76185:     REJOIN_FALLTHROUGH,
76185: 
76185:     /*
76185:      * As for REJOIN_FALLTHROUGH, but holds a reference on the compartment's
76185:      * orphaned native pools which needs to be reclaimed by InternalInterpret.
76185:      * The return value needs to be adjusted if REJOIN_NATIVE_LOWERED.
76185:      */
76185:     REJOIN_NATIVE,
76185:     REJOIN_NATIVE_LOWERED,
76185: 
76185:     /*
76185:      * Dummy rejoin stored in VMFrames to indicate they return into a native
76185:      * stub (and their FASTCALL return address should not be observed) but
76185:      * that they have already been patched and can be ignored.
76185:      */
76185:     REJOIN_NATIVE_PATCHED,
76185: 
76185:     /* Call returns a payload, which should be pushed before starting next bytecode. */
76185:     REJOIN_PUSH_BOOLEAN,
76185:     REJOIN_PUSH_OBJECT,
76185: 
76185:     /* Call returns an object, which should be assigned to a local per the current bytecode. */
76185:     REJOIN_DEFLOCALFUN,
76185: 
76185:     /*
76185:      * During the prologue of constructing scripts, after the function's
76185:      * .prototype property has been fetched.
76185:      */
76185:     REJOIN_THIS_PROTOTYPE,
76185: 
76185:     /*
76185:      * Type check on arguments failed during prologue, need stack check and
76185:      * call object creation before script can execute.
76185:      */
76185:     REJOIN_CHECK_ARGUMENTS,
76185: 
77356:     /* A GC while making a call object occurred, discarding the script's jitcode. */
77356:     REJOIN_CREATE_CALL_OBJECT,
77356: 
76185:     /*
76185:      * State after calling a stub which returns a JIT code pointer for a call
76185:      * or NULL for an already-completed call.
76185:      */
76185:     REJOIN_CALL_PROLOGUE,
76185:     REJOIN_CALL_PROLOGUE_LOWERED_CALL,
76185:     REJOIN_CALL_PROLOGUE_LOWERED_APPLY,
76185: 
76185:     /* Triggered a recompilation while placing the arguments to an apply on the stack. */
76185:     REJOIN_CALL_SPLAT,
76185: 
76185:     /* FALLTHROUGH ops which can be implemented as part of an IncOp. */
76185:     REJOIN_BINDNAME,
76185:     REJOIN_GETTER,
76185:     REJOIN_POS,
76185:     REJOIN_BINARY,
76185: 
76185:     /*
76185:      * For an opcode fused with IFEQ/IFNE, call returns a boolean indicating
76185:      * the result of the comparison and whether to take or not take the branch.
76185:      */
76185:     REJOIN_BRANCH
76185: };
76185: 
76185: /* Helper to watch for recompilation and frame expansion activity on a compartment. */
76185: struct RecompilationMonitor
76185: {
76185:     JSContext *cx;
76185: 
76185:     /*
76185:      * If either inline frame expansion or recompilation occurs, then ICs and
76185:      * stubs should not depend on the frame or JITs being intact. The two are
76185:      * separated for logging.
76185:      */
76185:     unsigned recompilations;
76185:     unsigned frameExpansions;
76185: 
77367:     /* If a GC occurs it may discard jit code on the stack. */
77367:     unsigned gcNumber;
77367: 
76185:     RecompilationMonitor(JSContext *cx)
76185:         : cx(cx),
76185:           recompilations(cx->compartment->types.recompilations),
77367:           frameExpansions(cx->compartment->types.frameExpansions),
77367:           gcNumber(cx->runtime->gcNumber)
76185:     {}
76185: 
76185:     bool recompiled() {
76185:         return cx->compartment->types.recompilations != recompilations
77367:             || cx->compartment->types.frameExpansions != frameExpansions
77367:             || cx->runtime->gcNumber != gcNumber;
76185:     }
76185: };
76185: 
76185: /*
56773:  * Trampolines to force returns from jit code.
56773:  * See also TrampolineCompiler::generateForceReturn(Fast).
56773:  */
56773: struct Trampolines {
56773:     typedef void (*TrampolinePtr)();
56773: 
56773:     TrampolinePtr       forceReturn;
56773:     JSC::ExecutablePool *forceReturnPool;
56773: 
56773: #if (defined(JS_NO_FASTCALL) && defined(JS_CPU_X86)) || defined(_WIN64)
56773:     TrampolinePtr       forceReturnFast;
56773:     JSC::ExecutablePool *forceReturnFastPool;
56773: #endif
56773: };
56773: 
77341: /* Result status of executing mjit code on a frame. */
77341: enum JaegerStatus
77341: {
77341:     /* Entry frame finished, and is throwing an exception. */
77341:     Jaeger_Throwing = 0,
77341: 
77341:     /* Entry frame finished, and is returning. */
77341:     Jaeger_Returned = 1,
77341: 
77341:     /*
77341:      * Entry frame did not finish. cx->regs reflects where to resume execution.
77341:      * This result is only possible if 'partial' is passed as true below.
77341:      */
77341:     Jaeger_Unfinished = 2,
77341: 
77341:     /*
77341:      * As for Unfinished, but stopped after a TRAP triggered recompilation.
77341:      * The trap has been reinstalled, but should not execute again when
77341:      * resuming execution.
77341:      */
77341:     Jaeger_UnfinishedAtTrap = 3
77341: };
77341: 
56773: /*
56773:  * Method JIT compartment data. Currently, there is exactly one per
56773:  * JS compartment. It would be safe for multiple JS compartments to
56773:  * share a JaegerCompartment as long as only one thread can enter
56773:  * the JaegerCompartment at a time.
56773:  */
56773: class JaegerCompartment {
64243:     JSC::ExecutableAllocator *execAlloc_;    // allocator for jit code
56773:     Trampolines              trampolines;    // force-return trampolines
56773:     VMFrame                  *activeFrame_;  // current active VMFrame
77341:     JaegerStatus             lastUnfinished_;// result status of last VM frame,
77341:                                              // if unfinished
56773: 
56773:     void Finish();
56773: 
56773:   public:
56773:     bool Initialize();
56773: 
76185:     JaegerCompartment();
56773:     ~JaegerCompartment() { Finish(); }
56773: 
64243:     JSC::ExecutableAllocator *execAlloc() {
64243:         return execAlloc_;
56773:     }
56773: 
56773:     VMFrame *activeFrame() {
56773:         return activeFrame_;
56773:     }
56773: 
56773:     void pushActiveFrame(VMFrame *f) {
77341:         JS_ASSERT(!lastUnfinished_);
56773:         f->previous = activeFrame_;
76185:         f->scratch = NULL;
56773:         activeFrame_ = f;
56773:     }
56773: 
56773:     void popActiveFrame() {
56773:         JS_ASSERT(activeFrame_);
56773:         activeFrame_ = activeFrame_->previous;
56773:     }
56773: 
77341:     void setLastUnfinished(JaegerStatus status) {
77341:         JS_ASSERT(!lastUnfinished_);
77341:         lastUnfinished_ = status;
77341:     }
77341: 
77341:     JaegerStatus lastUnfinished() {
77341:         JaegerStatus result = lastUnfinished_;
77341:         lastUnfinished_ = (JaegerStatus) 0;
77341:         return result;
77341:     }
77341: 
67899:     void *forceReturnFromExternC() const {
67899:         return JS_FUNC_TO_DATA_PTR(void *, trampolines.forceReturn);
56773:     }
56773: 
67899:     void *forceReturnFromFastCall() const {
56773: #if (defined(JS_NO_FASTCALL) && defined(JS_CPU_X86)) || defined(_WIN64)
67899:         return JS_FUNC_TO_DATA_PTR(void *, trampolines.forceReturnFast);
67899: #else
67899:         return JS_FUNC_TO_DATA_PTR(void *, trampolines.forceReturn);
67899: #endif
56773:     }
76185: 
76185:     /*
76185:      * References held on pools created for native ICs, where the IC was
76185:      * destroyed and we are waiting for the pool to finish use and jump
76185:      * into the interpoline.
76185:      */
76185:     Vector<StackFrame *, 8, SystemAllocPolicy> orphanedNativeFrames;
76185:     Vector<JSC::ExecutablePool *, 8, SystemAllocPolicy> orphanedNativePools;
56773: };
56773: 
57679: /*
57679:  * Allocation policy for compiler jstl objects. The goal is to free the
57679:  * compiler from having to check and propagate OOM after every time we
57679:  * append to a vector. We do this by reporting OOM to the engine and
57679:  * setting a flag on the compiler when OOM occurs. The compiler is required
57679:  * to check for OOM only before trying to use the contents of the list.
57679:  */
72091: class CompilerAllocPolicy : public TempAllocPolicy
57679: {
57679:     bool *oomFlag;
57679: 
57679:     void *checkAlloc(void *p) {
57679:         if (!p)
57679:             *oomFlag = true;
57679:         return p;
57679:     }
57679: 
57679:   public:
57679:     CompilerAllocPolicy(JSContext *cx, bool *oomFlag)
72091:     : TempAllocPolicy(cx), oomFlag(oomFlag) {}
57679:     CompilerAllocPolicy(JSContext *cx, Compiler &compiler);
57679: 
72091:     void *malloc_(size_t bytes) { return checkAlloc(TempAllocPolicy::malloc_(bytes)); }
72070:     void *realloc_(void *p, size_t oldBytes, size_t bytes) {
72091:         return checkAlloc(TempAllocPolicy::realloc_(p, oldBytes, bytes));
57679:     }
57679: };
57679: 
55503: namespace ic {
55503: # if defined JS_POLYIC
55503:     struct PICInfo;
56738:     struct GetElementIC;
57671:     struct SetElementIC;
55503: # endif
55503: # if defined JS_MONOIC
62386:     struct GetGlobalNameIC;
62386:     struct SetGlobalNameIC;
56192:     struct EqualityICInfo;
56217:     struct TraceICInfo;
68952:     struct CallICInfo;
55503: # endif
55503: }
55503: }
55503: 
52557: typedef void (JS_FASTCALL *VoidStub)(VMFrame &);
52623: typedef void (JS_FASTCALL *VoidVpStub)(VMFrame &, Value *);
52557: typedef void (JS_FASTCALL *VoidStubUInt32)(VMFrame &, uint32);
52557: typedef void (JS_FASTCALL *VoidStubInt32)(VMFrame &, int32);
52557: typedef JSBool (JS_FASTCALL *BoolStub)(VMFrame &);
52557: typedef void * (JS_FASTCALL *VoidPtrStub)(VMFrame &);
52557: typedef void * (JS_FASTCALL *VoidPtrStubPC)(VMFrame &, jsbytecode *);
52557: typedef void * (JS_FASTCALL *VoidPtrStubUInt32)(VMFrame &, uint32);
52557: typedef JSObject * (JS_FASTCALL *JSObjStub)(VMFrame &);
52557: typedef JSObject * (JS_FASTCALL *JSObjStubUInt32)(VMFrame &, uint32);
52727: typedef JSObject * (JS_FASTCALL *JSObjStubFun)(VMFrame &, JSFunction *);
53591: typedef void (JS_FASTCALL *VoidStubFun)(VMFrame &, JSFunction *);
52738: typedef JSObject * (JS_FASTCALL *JSObjStubJSObj)(VMFrame &, JSObject *);
52738: typedef void (JS_FASTCALL *VoidStubAtom)(VMFrame &, JSAtom *);
52738: typedef JSString * (JS_FASTCALL *JSStrStub)(VMFrame &);
52740: typedef JSString * (JS_FASTCALL *JSStrStubUInt32)(VMFrame &, uint32);
52785: typedef void (JS_FASTCALL *VoidStubJSObj)(VMFrame &, JSObject *);
53168: typedef void (JS_FASTCALL *VoidStubPC)(VMFrame &, jsbytecode *);
53590: typedef JSBool (JS_FASTCALL *BoolStubUInt32)(VMFrame &f, uint32);
55503: #ifdef JS_MONOIC
68952: typedef void (JS_FASTCALL *VoidStubCallIC)(VMFrame &, js::mjit::ic::CallICInfo *);
68952: typedef void * (JS_FASTCALL *VoidPtrStubCallIC)(VMFrame &, js::mjit::ic::CallICInfo *);
62386: typedef void (JS_FASTCALL *VoidStubGetGlobal)(VMFrame &, js::mjit::ic::GetGlobalNameIC *);
62386: typedef void (JS_FASTCALL *VoidStubSetGlobal)(VMFrame &, js::mjit::ic::SetGlobalNameIC *);
56192: typedef JSBool (JS_FASTCALL *BoolStubEqualityIC)(VMFrame &, js::mjit::ic::EqualityICInfo *);
56217: typedef void * (JS_FASTCALL *VoidPtrStubTraceIC)(VMFrame &, js::mjit::ic::TraceICInfo *);
55503: #endif
55503: #ifdef JS_POLYIC
55503: typedef void (JS_FASTCALL *VoidStubPIC)(VMFrame &, js::mjit::ic::PICInfo *);
56738: typedef void (JS_FASTCALL *VoidStubGetElemIC)(VMFrame &, js::mjit::ic::GetElementIC *);
57671: typedef void (JS_FASTCALL *VoidStubSetElemIC)(VMFrame &f, js::mjit::ic::SetElementIC *);
55503: #endif
52557: 
52557: namespace mjit {
52557: 
76185: struct InlineFrame;
55503: struct CallSite;
55503: 
58993: struct NativeMapEntry {
58993:     size_t          bcOff;  /* bytecode offset in script */
58993:     void            *ncode; /* pointer to native code */
58993: };
58993: 
53498: struct JITScript {
55503:     typedef JSC::MacroAssemblerCodeRef CodeRef;
55503:     CodeRef         code;       /* pool & code addresses */
58993: 
76185:     JSScript        *script;
55503: 
59899:     void            *invokeEntry;       /* invoke address */
59899:     void            *fastEntry;         /* cached entry, fastest */
59899:     void            *arityCheckEntry;   /* arity check address */
76185:     void            *argsCheckEntry;    /* arguments check address */
59899: 
62075:     /*
62075:      * This struct has several variable-length sections that are allocated on
62075:      * the end:  nmaps, MICs, callICs, etc.  To save space -- worthwhile
62075:      * because JITScripts are common -- we only record their lengths.  We can
62075:      * find any of the sections from the lengths because we know their order.
62075:      * Therefore, do not change the section ordering in finishThisUp() without
62075:      * changing nMICs() et al as well.
62075:      */
62075:     uint32          nNmapPairs:31;      /* The NativeMapEntrys are sorted by .bcOff.
62075:                                            .ncode values may not be NULL. */
59899:     bool            singleStepMode:1;   /* compiled in "single step mode" */
76185:     uint32          nInlineFrames;
76185:     uint32          nCallSites;
59899: #ifdef JS_MONOIC
62386:     uint32          nGetGlobalNames;
62386:     uint32          nSetGlobalNames;
68952:     uint32          nCallICs;
56192:     uint32          nEqualityICs;
56217:     uint32          nTraceICs;
59899: #endif
59899: #ifdef JS_POLYIC
59899:     uint32          nGetElems;
59899:     uint32          nSetElems;
62075:     uint32          nPICs;
59899: #endif
76185: 
76185: #ifdef JS_MONOIC
76185:     /* Inline cache at function entry for checking this/argument types. */
76185:     JSC::CodeLocationLabel argsCheckStub;
76185:     JSC::CodeLocationLabel argsCheckFallthrough;
76185:     JSC::CodeLocationJump  argsCheckJump;
76185:     JSC::ExecutablePool *argsCheckPool;
76185:     void resetArgsCheck();
76185: #endif
76185: 
76185:     /* List of inline caches jumping to the fastEntry. */
76185:     JSCList          callers;
56192: 
59899: #ifdef JS_MONOIC
56192:     // Additional ExecutablePools that IC stubs were generated into.
56192:     typedef Vector<JSC::ExecutablePool *, 0, SystemAllocPolicy> ExecPoolVector;
56192:     ExecPoolVector execPools;
53498: #endif
55503: 
62075:     NativeMapEntry *nmap() const;
76185:     js::mjit::InlineFrame *inlineFrames() const;
76185:     js::mjit::CallSite *callSites() const;
62075: #ifdef JS_MONOIC
62386:     ic::GetGlobalNameIC *getGlobalNames() const;
62386:     ic::SetGlobalNameIC *setGlobalNames() const;
68952:     ic::CallICInfo *callICs() const;
62075:     ic::EqualityICInfo *equalityICs() const;
62075:     ic::TraceICInfo *traceICs() const;
62075: #endif
62075: #ifdef JS_POLYIC
62075:     ic::GetElementIC *getElems() const;
62075:     ic::SetElementIC *setElems() const;
62075:     ic::PICInfo     *pics() const;
62075: #endif
62075: 
57758:     ~JITScript();
57758: 
55503:     bool isValidCode(void *ptr) {
55503:         char *jitcode = (char *)code.m_code.executableAddress();
55503:         char *jcheck = (char *)ptr;
55503:         return jcheck >= jitcode && jcheck < jitcode + code.m_size;
55503:     }
55503: 
68952:     void nukeScriptDependentICs();
68952:     void sweepCallICs(JSContext *cx, bool purgeAll);
68952:     void purgeMICs();
68952:     void purgePICs();
60207: 
60208:     size_t scriptDataSize();
76185: 
76185:     jsbytecode *nativeToPC(void *returnAddress, CallSite **pinline) const;
76185: 
76185:     void trace(JSTracer *trc);
62075: 
62075:   private:
62075:     /* Helpers used to navigate the variable-length sections. */
76185:     char *commonSectionLimit() const;
62075:     char *monoICSectionsLimit() const;
62075:     char *polyICSectionsLimit() const;
53498: };
53498: 
55565: /*
55565:  * Execute the given mjit code. This is a low-level call and callers must
55565:  * provide the same guarantees as JaegerShot/CheckStackAndEnterMethodJIT.
55565:  */
77341: JaegerStatus EnterMethodJIT(JSContext *cx, StackFrame *fp, void *code, Value *stackLimit,
77341:                             bool partial);
55565: 
53471: /* Execute a method that has been JIT compiled. */
77341: JaegerStatus JaegerShot(JSContext *cx, bool partial);
53471: 
53471: /* Drop into the middle of a method at an arbitrary point, and execute. */
77341: JaegerStatus JaegerShotAtSafePoint(JSContext *cx, void *safePoint, bool partial);
52557: 
52557: enum CompileStatus
52557: {
52557:     Compile_Okay,
76185:     Compile_Abort,        // abort compilation
76185:     Compile_InlineAbort,  // inlining attempt failed, continue compilation
76185:     Compile_Retry,        // static overflow or failed inline, try to recompile
76185:     Compile_Error,        // OOM
62574:     Compile_Skipped
52557: };
52557: 
52853: void JS_FASTCALL
52853: ProfileStubCall(VMFrame &f);
52853: 
54626: CompileStatus JS_NEVER_INLINE
69223: TryCompile(JSContext *cx, StackFrame *fp);
52557: 
52559: void
76185: ReleaseScriptCode(JSContext *cx, JSScript *script, bool normal);
76185: 
76185: // Expand either the topmost stack frame or all stack frames inlined by the JIT.
76185: void
77353: ExpandInlineFrames(JSCompartment *compartment, bool all);
77353: 
77353: // Return all VMFrames in a compartment to the interpreter. This must be
77353: // followed by destroying all JIT code in the compartment.
77353: void
77353: ClearAllFrames(JSCompartment *compartment);
76185: 
76185: // Information about a frame inlined during compilation.
76185: struct InlineFrame
76185: {
76185:     InlineFrame *parent;
76185:     jsbytecode *parentpc;
76185:     JSFunction *fun;
76185: 
76185:     // Total distance between the start of the outer JSStackFrame and the start
76185:     // of this frame, in multiples of sizeof(Value).
76185:     uint32 depth;
76185: };
52559: 
53498: struct CallSite
53168: {
53168:     uint32 codeOffset;
76185:     uint32 inlineIndex;
53168:     uint32 pcOffset;
76185:     RejoinState rejoin;
57766: 
76185:     void initialize(uint32 codeOffset, uint32 inlineIndex, uint32 pcOffset, RejoinState rejoin) {
57766:         this->codeOffset = codeOffset;
76185:         this->inlineIndex = inlineIndex;
57766:         this->pcOffset = pcOffset;
76185:         this->rejoin = rejoin;
57766:     }
57766: 
57766:     bool isTrap() const {
76185:         return rejoin == REJOIN_TRAP;
57766:     }
53168: };
53168: 
60567: /*
60567:  * Re-enables a tracepoint in the method JIT. When full is true, we
60567:  * also reset the iteration counter.
60567:  */
56217: void
60567: ResetTraceHint(JSScript *script, jsbytecode *pc, uint16_t index, bool full);
56217: 
56551: uintN
56551: GetCallTargetCount(JSScript *script, jsbytecode *pc);
56551: 
69852: void
69852: DumpAllProfiles(JSContext *cx);
69852: 
58993: inline void * bsearch_nmap(NativeMapEntry *nmap, size_t nPairs, size_t bcOff)
58993: {
58993:     size_t lo = 1, hi = nPairs;
58993:     while (1) {
58993:         /* current unsearched space is from lo-1 to hi-1, inclusive. */
58993:         if (lo > hi)
58993:             return NULL; /* not found */
58993:         size_t mid       = (lo + hi) / 2;
58993:         size_t bcOff_mid = nmap[mid-1].bcOff;
58993:         if (bcOff < bcOff_mid) {
58993:             hi = mid-1;
58993:             continue;
58993:         } 
58993:         if (bcOff > bcOff_mid) {
58993:             lo = mid+1;
58993:             continue;
58993:         }
58993:         return nmap[mid-1].ncode;
58993:     }
58993: }
58993: 
52557: } /* namespace mjit */
52557: 
76185: inline JSScript *
76185: VMFrame::script()
76185: {
76185:     if (regs.inlined())
76185:         return jit()->inlineFrames()[regs.inlined()->inlineIndex].fun->script();
76185:     return fp()->script();
76185: }
76185: 
76185: inline jsbytecode *
76185: VMFrame::pc()
76185: {
76185:     if (regs.inlined())
76185:         return script()->code + regs.inlined()->pcOffset;
76185:     return regs.pc;
76185: }
76185: 
52557: } /* namespace js */
52557: 
55687: inline void *
55687: JSScript::maybeNativeCodeForPC(bool constructing, jsbytecode *pc)
55687: {
55687:     js::mjit::JITScript *jit = getJIT(constructing);
55687:     if (!jit)
55687:         return NULL;
55687:     JS_ASSERT(pc >= code && pc < code + length);
62075:     return bsearch_nmap(jit->nmap(), jit->nNmapPairs, (size_t)(pc - code));
55687: }
55687: 
55687: inline void *
55687: JSScript::nativeCodeForPC(bool constructing, jsbytecode *pc)
55687: {
58993:     js::mjit::JITScript *jit = getJIT(constructing);
55687:     JS_ASSERT(pc >= code && pc < code + length);
62075:     void* native = bsearch_nmap(jit->nmap(), jit->nNmapPairs, (size_t)(pc - code));
58993:     JS_ASSERT(native);
58993:     return native;
55687: }
55687: 
76185: extern "C" void JaegerTrampolineReturn();
76185: extern "C" void JaegerInterpoline();
76185: extern "C" void JaegerInterpolineScripted();
76185: 
64272: #if defined(_MSC_VER) || defined(_WIN64)
52557: extern "C" void *JaegerThrowpoline(js::VMFrame *vmFrame);
52557: #else
52557: extern "C" void JaegerThrowpoline();
52557: #endif
52557: 
76185: #if defined(_WIN64)
76185: extern "C" void JaegerInterpolinePatched();
76185: #endif
76185: 
52557: #endif /* jsjaeger_h__ */
52880: 
