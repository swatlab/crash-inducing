 52826: /* -*- Mode: C++; tab-width: 4; indent-tabs-mode: nil; c-basic-offset: 4 -*-
 52826:  * vim: set ts=4 sw=4 et tw=99:
 52826:  *
 98983:  * This Source Code Form is subject to the terms of the Mozilla Public
 98983:  * License, v. 2.0. If a copy of the MPL was not distributed with this
 98983:  * file, You can obtain one at http://mozilla.org/MPL/2.0/. */
102263: 
102263: #include "jscntxt.h"
102263: #include "jsnum.h"
102263: #include "jsobj.h"
 52826: #include "jsscope.h"
102263: 
 53301: #include "assembler/assembler/LinkBuffer.h"
 53301: #include "assembler/assembler/MacroAssembler.h"
 53590: #include "assembler/assembler/CodeLocation.h"
102263: 
 60591: #include "methodjit/CodeGenIncludes.h"
 53590: #include "methodjit/Compiler.h"
 60591: #include "methodjit/ICRepatcher.h"
102263: #include "methodjit/InlineFrameAssembler.h"
102263: #include "methodjit/MonoIC.h"
 62385: #include "methodjit/PolyIC.h"
102263: #include "methodjit/StubCalls.h"
 53840: 
 79981: #include "builtin/RegExp.h"
 79981: 
120240: #include "jsinterpinlines.h"
 53263: #include "jsobjinlines.h"
 52826: #include "jsscopeinlines.h"
 53590: #include "jsscriptinlines.h"
 52826: 
102263: #include "methodjit/StubCalls-inl.h"
113623: #ifdef JS_ION
113473: # include "ion/IonMacroAssembler.h"
113623: #endif
102263: 
 52826: using namespace js;
 52826: using namespace js::mjit;
 52826: using namespace js::mjit::ic;
 52826: 
 53590: typedef JSC::MacroAssembler::RegisterID RegisterID;
 53590: typedef JSC::MacroAssembler::Address Address;
 53590: typedef JSC::MacroAssembler::Jump Jump;
 53590: typedef JSC::MacroAssembler::Imm32 Imm32;
 53590: typedef JSC::MacroAssembler::ImmPtr ImmPtr;
 53590: typedef JSC::MacroAssembler::Call Call;
 62385: typedef JSC::MacroAssembler::Label Label;
 62385: typedef JSC::MacroAssembler::DataLabel32 DataLabel32;
 83221: typedef JSC::MacroAssembler::DataLabelPtr DataLabelPtr;
 53590: 
 53119: #if defined JS_MONOIC
 53119: 
 52826: static void
 62386: PatchGetFallback(VMFrame &f, ic::GetGlobalNameIC *ic)
 52826: {
 87654:     Repatcher repatch(f.chunk());
 86855:     JSC::FunctionPtr fptr(JS_FUNC_TO_DATA_PTR(void *, stubs::Name));
 62386:     repatch.relink(ic->slowPathCall, fptr);
 52826: }
 52826: 
 52826: void JS_FASTCALL
 62386: ic::GetGlobalName(VMFrame &f, ic::GetGlobalNameIC *ic)
 52826: {
119065:     AssertCanGC();
119065: 
104384:     RootedObject obj(f.cx, &f.fp()->global());
 90965:     PropertyName *name = f.script()->getName(GET_UINT32_INDEX(f.pc()));
 52826: 
 84655:     RecompilationMonitor monitor(f.cx);
 84655: 
104384:     Shape *shape = obj->nativeLookup(f.cx, NameToId(name));
 84655: 
 84655:     if (monitor.recompiled()) {
 86855:         stubs::Name(f);
 84655:         return;
 84655:     }
 84655: 
 53531:     if (!shape ||
 94227:         !shape->hasDefaultGetter() ||
 53531:         !shape->hasSlot())
 52826:     {
 53531:         if (shape)
 55503:             PatchGetFallback(f, ic);
 86855:         stubs::Name(f);
 52826:         return;
 52826:     }
 84755:     uint32_t slot = shape->slot();
 52826: 
 52826:     /* Patch shape guard. */
 87654:     Repatcher repatcher(f.chunk());
104384:     repatcher.repatch(ic->fastPathStart.dataLabelPtrAtOffset(ic->shapeOffset), obj->lastProperty());
 52826: 
 52826:     /* Patch loads. */
104384:     uint32_t index = obj->dynamicSlotIndex(slot);
 62386:     JSC::CodeLocationLabel label = ic->fastPathStart.labelAtOffset(ic->loadStoreOffset);
 76185:     repatcher.patchAddressOffsetForValueLoad(label, index * sizeof(Value));
 52826: 
 52826:     /* Do load anyway... this time. */
 86855:     stubs::Name(f);
 52826: }
 52826: 
 52831: static void JS_FASTCALL
 62386: DisabledSetGlobal(VMFrame &f, ic::SetGlobalNameIC *ic)
 52831: {
119065:     AssertCanGC();
119065:     RootedPropertyName name(f.cx, f.script()->getName(GET_UINT32_INDEX(f.pc())));
119065:     stubs::SetName(f, name);
 52831: }
 52831: 
 52831: static void
 62386: PatchSetFallback(VMFrame &f, ic::SetGlobalNameIC *ic)
 52831: {
 87654:     Repatcher repatch(f.chunk());
108937:     VoidStubSetGlobal stub = DisabledSetGlobal;
 57784:     JSC::FunctionPtr fptr(JS_FUNC_TO_DATA_PTR(void *, stub));
 62386:     repatch.relink(ic->slowPathCall, fptr);
 62386: }
 62386: 
 62386: void
103639: SetGlobalNameIC::patchInlineShapeGuard(Repatcher &repatcher, Shape *shape)
 62386: {
 83221:     JSC::CodeLocationDataLabelPtr label = fastPathStart.dataLabelPtrAtOffset(shapeOffset);
 62386:     repatcher.repatch(label, shape);
 52831: }
 52831: 
 62385: static LookupStatus
103639: UpdateSetGlobalName(VMFrame &f, ic::SetGlobalNameIC *ic, JSObject *obj, Shape *shape)
 62385: {
 62385:     /* Give globals a chance to appear. */
 62385:     if (!shape)
 62385:         return Lookup_Uncacheable;
 62385: 
 94227:     if (!shape->hasDefaultSetter() ||
 62385:         !shape->writable() ||
 74472:         !shape->hasSlot() ||
 74472:         obj->watched())
 62385:     {
 74472:         /* Disable the IC for weird shape attributes and watchpoints. */
 62385:         PatchSetFallback(f, ic);
 62385:         return Lookup_Uncacheable;
 62385:     }
 62385: 
 62385:     /* Object is not branded, so we can use the inline path. */
 87654:     Repatcher repatcher(f.chunk());
 83221:     ic->patchInlineShapeGuard(repatcher, obj->lastProperty());
 62386: 
 84755:     uint32_t index = obj->dynamicSlotIndex(shape->slot());
 62386:     JSC::CodeLocationLabel label = ic->fastPathStart.labelAtOffset(ic->loadStoreOffset);
 76185:     repatcher.patchAddressOffsetForValueStore(label, index * sizeof(Value),
 62385:                                               ic->vr.isTypeKnown());
 62385: 
 62385:     return Lookup_Cacheable;
 62385: }
 62385: 
 52831: void JS_FASTCALL
 62386: ic::SetGlobalName(VMFrame &f, ic::SetGlobalNameIC *ic)
 52831: {
119065:     AssertCanGC();
119065: 
104384:     RootedObject obj(f.cx, &f.fp()->global());
104384:     RootedPropertyName name(f.cx, f.script()->getName(GET_UINT32_INDEX(f.pc())));
 84655: 
 84655:     RecompilationMonitor monitor(f.cx);
 84655: 
104384:     Shape *shape = obj->nativeLookup(f.cx, NameToId(name));
 52831: 
 84655:     if (!monitor.recompiled()) {
104384:         LookupStatus status = UpdateSetGlobalName(f, ic, obj, shape);
 62385:         if (status == Lookup_Error)
 62385:             THROW();
 84655:     }
 53116: 
108937:     stubs::SetName(f, name);
 52831: }
 52831: 
 56192: class EqualityICLinker : public LinkerHelper
 56192: {
 56192:     VMFrame &f;
 56192: 
 56192:   public:
 58064:     EqualityICLinker(Assembler &masm, VMFrame &f)
114437:         : LinkerHelper(masm, JSC::JAEGER_CODE), f(f)
 56192:     { }
 56192: 
 58064:     bool init(JSContext *cx) {
 58064:         JSC::ExecutablePool *pool = LinkerHelper::init(cx);
 56192:         if (!pool)
 56192:             return false;
 76185:         JS_ASSERT(!f.regs.inlined());
 87654:         if (!f.chunk()->execPools.append(pool)) {
 95079:             markVerified();
 56192:             pool->release();
 56192:             js_ReportOutOfMemory(cx);
 56192:             return false;
 56192:         }
 56192:         return true;
 56192:     }
 56192: };
 56192: 
 56192: /* Rough over-estimate of how much memory we need to unprotect. */
 84755: static const uint32_t INLINE_PATH_LENGTH = 64;
 56192: 
 56192: class EqualityCompiler : public BaseCompiler
 56192: {
 56192:     VMFrame &f;
 56192:     EqualityICInfo &ic;
 56192: 
 56192:     Vector<Jump, 4, SystemAllocPolicy> jumpList;
 56192:     Jump trueJump;
 56192:     Jump falseJump;
 56192: 
 56192:   public:
 56192:     EqualityCompiler(VMFrame &f, EqualityICInfo &ic)
 56192:         : BaseCompiler(f.cx), f(f), ic(ic), jumpList(SystemAllocPolicy())
 56192:     {
 56192:     }
 56192: 
 56192:     void linkToStub(Jump j)
 56192:     {
 56192:         jumpList.append(j);
 56192:     }
 56192: 
 56192:     void linkTrue(Jump j)
 56192:     {
 56192:         trueJump = j;
 56192:     }
 56192: 
 56192:     void linkFalse(Jump j)
 56192:     {
 56192:         falseJump = j;
 56192:     }
 56192: 
 56192:     void generateStringPath(Assembler &masm)
 56192:     {
 56575:         const ValueRemat &lvr = ic.lvr;
 56575:         const ValueRemat &rvr = ic.rvr;
 56192: 
 64344:         JS_ASSERT_IF(lvr.isConstant(), lvr.isType(JSVAL_TYPE_STRING));
 64344:         JS_ASSERT_IF(rvr.isConstant(), rvr.isType(JSVAL_TYPE_STRING));
 64344: 
 64344:         if (!lvr.isType(JSVAL_TYPE_STRING)) {
 56192:             Jump lhsFail = masm.testString(Assembler::NotEqual, lvr.typeReg());
 56192:             linkToStub(lhsFail);
 56192:         }
 56192: 
 64344:         if (!rvr.isType(JSVAL_TYPE_STRING)) {
 56192:             Jump rhsFail = masm.testString(Assembler::NotEqual, rvr.typeReg());
 56192:             linkToStub(rhsFail);
 56192:         }
 56192: 
 56192:         RegisterID tmp = ic.tempReg;
 56192: 
108725:         /* JSString::isAtom === (lengthAndFlags & ATOM_BIT) */
108725:         Imm32 atomBit(JSString::ATOM_BIT);
 56192: 
 59888:         masm.load32(Address(lvr.dataReg(), JSString::offsetOfLengthAndFlags()), tmp);
108725:         Jump lhsNotAtomized = masm.branchTest32(Assembler::Zero, tmp, atomBit);
 56192:         linkToStub(lhsNotAtomized);
 56192: 
 56575:         if (!rvr.isConstant()) {
 59888:             masm.load32(Address(rvr.dataReg(), JSString::offsetOfLengthAndFlags()), tmp);
108725:             Jump rhsNotAtomized = masm.branchTest32(Assembler::Zero, tmp, atomBit);
 56192:             linkToStub(rhsNotAtomized);
 56192:         }
 56192: 
 56575:         if (rvr.isConstant()) {
 56575:             JSString *str = rvr.value().toString();
 64343:             JS_ASSERT(str->isAtom());
 56192:             Jump test = masm.branchPtr(ic.cond, lvr.dataReg(), ImmPtr(str));
 56192:             linkTrue(test);
 56192:         } else {
 56192:             Jump test = masm.branchPtr(ic.cond, lvr.dataReg(), rvr.dataReg());
 56192:             linkTrue(test);
 56192:         }
 56192: 
 56192:         Jump fallthrough = masm.jump();
 56192:         linkFalse(fallthrough);
 56192:     }
 56192: 
 56192:     void generateObjectPath(Assembler &masm)
 56192:     {
 56192:         ValueRemat &lvr = ic.lvr;
 56192:         ValueRemat &rvr = ic.rvr;
 56192: 
 56575:         if (!lvr.isConstant() && !lvr.isType(JSVAL_TYPE_OBJECT)) {
 56192:             Jump lhsFail = masm.testObject(Assembler::NotEqual, lvr.typeReg());
 56192:             linkToStub(lhsFail);
 56192:         }
 56192: 
 56575:         if (!rvr.isConstant() && !rvr.isType(JSVAL_TYPE_OBJECT)) {
 56192:             Jump rhsFail = masm.testObject(Assembler::NotEqual, rvr.typeReg());
 56192:             linkToStub(rhsFail);
 56192:         }
 56192: 
 83248:         masm.loadObjClass(lvr.dataReg(), ic.tempReg);
 83248:         Jump lhsHasEq = masm.branchPtr(Assembler::NotEqual,
 83248:                                        Address(ic.tempReg, offsetof(Class, ext.equality)),
 83248:                                        ImmPtr(NULL));
 56192:         linkToStub(lhsHasEq);
 56192: 
 56575:         if (rvr.isConstant()) {
 56575:             JSObject *obj = &rvr.value().toObject();
 56192:             Jump test = masm.branchPtr(ic.cond, lvr.dataReg(), ImmPtr(obj));
 56192:             linkTrue(test);
 56192:         } else {
 56192:             Jump test = masm.branchPtr(ic.cond, lvr.dataReg(), rvr.dataReg());
 56192:             linkTrue(test);
 56192:         }
 56192: 
 56192:         Jump fallthrough = masm.jump();
 56192:         linkFalse(fallthrough);
 56192:     }
 56192: 
 56192:     bool linkForIC(Assembler &masm)
 56192:     {
 58064:         EqualityICLinker buffer(masm, f);
 58064:         if (!buffer.init(cx))
 56192:             return false;
 56192: 
 87654:         Repatcher repatcher(f.chunk());
 58064: 
 58064:         /* Overwrite the call to the IC with a call to the stub. */
 58064:         JSC::FunctionPtr fptr(JS_FUNC_TO_DATA_PTR(void *, ic.stub));
 58064:         repatcher.relink(ic.stubCall, fptr);
 58064: 
 58064:         // Silently fail, the IC is disabled now.
 87654:         if (!buffer.verifyRange(f.chunk()))
 58064:             return true;
 58064: 
 56192:         /* Set the targets of all type test failures to go to the stub. */
 56192:         for (size_t i = 0; i < jumpList.length(); i++)
 56192:             buffer.link(jumpList[i], ic.stubEntry);
 56192:         jumpList.clear();
 56192: 
 56192:         /* Set the targets for the the success and failure of the actual equality test. */
 56192:         buffer.link(trueJump, ic.target);
 56192:         buffer.link(falseJump, ic.fallThrough);
 56192: 
 80222:         CodeLocationLabel cs = buffer.finalize(f);
 58063: 
 56192:         /* Jump to the newly generated code instead of to the IC. */
 58063:         repatcher.relink(ic.jumpToStub, cs);
 56192: 
 56192:         return true;
 56192:     }
 56192: 
 56192:     bool update()
 56192:     {
 56192:         if (!ic.generated) {
113586:             MJITInstrumentation sps(&f.cx->runtime->spsProfiler);
113586:             Assembler masm(&sps, &f);
 56192:             Value rval = f.regs.sp[-1];
 56192:             Value lval = f.regs.sp[-2];
 56192: 
 56192:             if (rval.isObject() && lval.isObject()) {
 56192:                 generateObjectPath(masm);
 56192:                 ic.generated = true;
 56192:             } else if (rval.isString() && lval.isString()) {
 56192:                 generateStringPath(masm);
 56192:                 ic.generated = true;
 56192:             } else {
 56192:                 return true;
 56192:             }
 56192: 
 56192:             return linkForIC(masm);
 56192:         }
 56192: 
 56192:         return true;
 56192:     }
 56192: };
 56192: 
 56192: JSBool JS_FASTCALL
 56192: ic::Equality(VMFrame &f, ic::EqualityICInfo *ic)
 56192: {
 56192:     EqualityCompiler cc(f, *ic);
 56192:     if (!cc.update())
 56192:         THROWV(JS_FALSE);
 56192: 
 56192:     return ic->stub(f);
 56192: }
 56192: 
122731: // Disable PGO as a precaution (see bug 791214).
122731: #if defined(_MSC_VER)
122731: # pragma optimize("g", off)
122731: #endif
122731: 
 68952: static void * JS_FASTCALL
 68952: SlowCallFromIC(VMFrame &f, ic::CallICInfo *ic)
 68952: {
 68952:     stubs::SlowCall(f, ic->frameSize.getArgc(f));
 68952:     return NULL;
 68952: }
 68952: 
 68952: static void * JS_FASTCALL
 68952: SlowNewFromIC(VMFrame &f, ic::CallICInfo *ic)
 68952: {
 68952:     stubs::SlowNew(f, ic->frameSize.staticArgc());
 68952:     return NULL;
 68952: }
 68952: 
 78454: bool
 78454: NativeStubLinker::init(JSContext *cx)
 78454: {
 78454:     JSC::ExecutablePool *pool = LinkerHelper::init(cx);
 78454:     if (!pool)
 78454:         return false;
 78454: 
 78454:     NativeCallStub stub;
 78454:     stub.pc = pc;
 78454:     stub.pool = pool;
 78454:     stub.jump = locationOf(done);
 87654:     if (!chunk->nativeCallStubs.append(stub)) {
 95079:         markVerified();
 78454:         pool->release();
 78454:         return false;
 78454:     }
 78454: 
 78454:     return true;
 78454: }
 78454: 
 78454: /*
 78454:  * Generate epilogue code to run after a stub ABI call to a native or getter.
 78454:  * This checks for an exception, and either type checks the result against the
 78454:  * observed types for the opcode or loads the result into a register pair
 78454:  * (it will go through a type barrier afterwards).
 78454:  */
 78454: bool
 78454: mjit::NativeStubEpilogue(VMFrame &f, Assembler &masm, NativeStubLinker::FinalJump *result,
 84755:                          int32_t initialFrameDepth, int32_t vpOffset,
 78454:                          MaybeRegisterID typeReg, MaybeRegisterID dataReg)
 78454: {
119065:     AutoAssertNoGC nogc;
119065: 
 78454:     /* Reload fp, which may have been clobbered by restoreStackBase(). */
 78454:     masm.loadPtr(FrameAddress(VMFrame::offsetOfFp), JSFrameReg);
 78454: 
 78454:     Jump hasException = masm.branchTest32(Assembler::Zero, Registers::ReturnReg,
 78454:                                           Registers::ReturnReg);
 78454: 
 78454:     Address resultAddress(JSFrameReg, vpOffset);
 78454: 
 78454:     Vector<Jump> mismatches(f.cx);
 78637:     if (f.cx->typeInferenceEnabled() && !typeReg.isSet()) {
 78454:         /*
 78637:          * Test the result of this native against the known result type set for
 78637:          * the call. We don't assume knowledge about the types that natives can
 78637:          * return, except when generating specialized paths in FastBuiltins.
 78454:          */
 78454:         types::TypeSet *types = f.script()->analysis()->bytecodeTypes(f.pc());
 78454:         if (!masm.generateTypeCheck(f.cx, resultAddress, types, &mismatches))
 78454:             THROWV(false);
 78454:     }
 78454: 
 78454:     /*
 78637:      * Can no longer trigger recompilation in this stub, clear the stub rejoin
 78637:      * on the VMFrame.
 78454:      */
 78454:     masm.storePtr(ImmPtr(NULL), FrameAddress(offsetof(VMFrame, stubRejoin)));
 78454: 
 78454:     if (typeReg.isSet())
 78454:         masm.loadValueAsComponents(resultAddress, typeReg.reg(), dataReg.reg());
 78454: 
 78454:     /*
 78454:      * The final jump is a indirect on x64, so that we'll always be able
 78454:      * to repatch it to the interpoline later.
 78454:      */
 78454:     Label finished = masm.label();
 78454: #ifdef JS_CPU_X64
 78454:     JSC::MacroAssembler::DataLabelPtr done = masm.moveWithPatch(ImmPtr(NULL), Registers::ValueReg);
 78454:     masm.jump(Registers::ValueReg);
 78454: #else
 78454:     Jump done = masm.jump();
 78454: #endif
 78454: 
 78454:     /* Generate a call for type check failures on the native result. */
 78454:     if (!mismatches.empty()) {
 78454:         for (unsigned i = 0; i < mismatches.length(); i++)
 78454:             mismatches[i].linkTo(masm.label(), &masm);
 78454:         masm.addPtr(Imm32(vpOffset), JSFrameReg, Registers::ArgReg1);
 78454:         masm.fallibleVMCall(true, JS_FUNC_TO_DATA_PTR(void *, stubs::TypeBarrierReturn),
 78454:                             f.regs.pc, NULL, initialFrameDepth);
 78454:         masm.storePtr(ImmPtr(NULL), FrameAddress(offsetof(VMFrame, stubRejoin)));
 78454:         masm.jump().linkTo(finished, &masm);
 78454:     }
 78454: 
 78454:     /* Move JaegerThrowpoline into register for very far jump on x64. */
 78454:     hasException.linkTo(masm.label(), &masm);
 78454:     masm.storePtr(ImmPtr(NULL), FrameAddress(offsetof(VMFrame, stubRejoin)));
 78454:     masm.throwInJIT();
 78454: 
 78454:     *result = done;
 78454:     return true;
 78454: }
 78454: 
 68952: /*
 68952:  * Calls have an inline path and an out-of-line path. The inline path is used
 68952:  * in the fastest case: the method has JIT'd code, and |argc == nargs|.
 68952:  *
 68952:  * The inline path and OOL path are separated by a guard on the identity of
 68952:  * the callee object. This guard starts as NULL and always fails on the first
 68952:  * hit. On the OOL path, the callee is verified to be both a function and a
 68952:  * scripted function. If these conditions hold, |ic::Call| is invoked.
 68952:  *
 68952:  * |ic::Call| first ensures that the callee has JIT code. If it doesn't, the
 68952:  * call to |ic::Call| is patched to a slow path. If it does have JIT'd code,
 68952:  * the following cases can occur:
 68952:  *
 68952:  *   1) args != nargs: The call to |ic::Call| is patched with a dynamically
 68952:  *      generated stub. This stub inlines a path that looks like:
 68952:  *      ----
 68952:  *      push frame
 68952:  *      if (callee is not compiled) {
 68952:  *          Compile(callee);
 68952:  *      }
 68952:  *      call callee->arityLabel
 68952:  *
 68952:  *      The arity label is a special entry point for correcting frames for
 68952:  *      arity mismatches.
 68952:  *
 68952:  *   2) args == nargs, and the inline call site was not patched yet.
 68952:  *      The guard dividing the two paths is patched to guard on the given
 68952:  *      function object identity, and the proceeding call is patched to
 68952:  *      directly call the JIT code.
 68952:  *
 68952:  *   3) args == nargs, and the inline call site was patched already.
 68952:  *      A small stub is created which extends the original guard to also
 68952:  *      guard on the JSFunction lying underneath the function object.
 68952:  *
 68952:  * If the OOL path does not have a scripted function, but does have a
 68952:  * scripted native, then a small stub is generated which inlines the native
 68952:  * invocation.
 68952:  */
 94809: namespace js {
 94809: namespace mjit {
 94809: 
 68952: class CallCompiler : public BaseCompiler
 68952: {
 68952:     VMFrame &f;
 68952:     CallICInfo &ic;
 68952:     bool callingNew;
 68952: 
 68952:   public:
 68952:     CallCompiler(VMFrame &f, CallICInfo &ic, bool callingNew)
 68952:       : BaseCompiler(f.cx), f(f), ic(ic), callingNew(callingNew)
 68952:     {
 68952:     }
 68952: 
 68952:     JSC::ExecutablePool *poolForSize(LinkerHelper &linker, CallICInfo::PoolIndex index)
 68952:     {
 68952:         JSC::ExecutablePool *ep = linker.init(f.cx);
 68952:         if (!ep)
 68952:             return NULL;
 68952:         JS_ASSERT(!ic.pools[index]);
 68952:         ic.pools[index] = ep;
 68952:         return ep;
 68952:     }
 68952: 
 87654:     void disable()
 68952:     {
 68952:         JSC::CodeLocationCall oolCall = ic.slowPathStart.callAtOffset(ic.oolCallOffset);
 87654:         Repatcher repatch(f.chunk());
 68952:         JSC::FunctionPtr fptr = callingNew
 68952:                                 ? JSC::FunctionPtr(JS_FUNC_TO_DATA_PTR(void *, SlowNewFromIC))
 68952:                                 : JSC::FunctionPtr(JS_FUNC_TO_DATA_PTR(void *, SlowCallFromIC));
 68952:         repatch.relink(oolCall, fptr);
 68952:     }
 68952: 
113623: #ifdef JS_ION
113473:     bool generateIonStub()
113473:     {
113473:         RecompilationMonitor monitor(cx);
113473: 
115209:         /*
115209:          * When IonMonkey is enabled we never inline in JM. So do not cause any
115209:          * recompilation by setting the UNINLINEABLE flag.
115209:          */
113473:         JS_ASSERT(!f.regs.inlined());
113473: 
113473:         Assembler masm;
113473:         Registers regs(Registers::AvailRegs);
113473: 
113537:         /* Reserve this, so we don't take something setupFallibleABICall will use. */
113473:         regs.takeReg(Registers::ClobberInCall);
113473: 
113537:         /* If we might clobber |ic.funObjReg| later, save it now. */
113537:         RegisterID funObjReg = ic.funObjReg;
113537:         if (funObjReg == Registers::ClobberInCall) {
113537:             funObjReg = regs.takeAnyReg().reg();
113473:             masm.move(ic.funObjReg, funObjReg);
113537:         } else {
113537:             /* Make sure no temporaries collide. */
113537:             regs.takeReg(funObjReg);
113537:         }
113473: 
113473:         size_t argc = ic.frameSize.staticArgc();
113473: 
113473:         /* Load fun->u.i.script->ion */
113473:         RegisterID ionScript = regs.takeAnyReg().reg();
113473:         Address scriptAddr(funObjReg, JSFunction::offsetOfNativeOrScript());
113473:         masm.loadPtr(scriptAddr, ionScript);
113473:         masm.loadPtr(Address(ionScript, offsetof(JSScript, ion)), ionScript);
113473: 
113473:         /* Guard that the ion pointer is valid. */
113473:         Jump noIonCode = masm.branchPtr(Assembler::BelowOrEqual, ionScript,
113582:                                         ImmPtr(ION_COMPILING_SCRIPT));
113473: 
113473:         RegisterID t0 = regs.takeAnyReg().reg();
113473:         RegisterID t1 = Registers::ClobberInCall;
113473: 
113473:         masm.move(ImmPtr(f.regs.pc), t1);
113473: 
113473:         /* Set the CALLING_INTO_ION flag on the existing frame. */
113473:         masm.load32(Address(JSFrameReg, StackFrame::offsetOfFlags()), t0);
113473:         masm.or32(Imm32(StackFrame::CALLING_INTO_ION), t0);
113473:         masm.store32(t0, Address(JSFrameReg, StackFrame::offsetOfFlags()));
113473: 
113473:         /* Store the entry fp and calling pc into the IonActivation. */
113473:         masm.loadPtr(&cx->runtime->ionActivation, t0);
113473:         masm.storePtr(JSFrameReg, Address(t0, ion::IonActivation::offsetOfEntryFp()));
113473:         masm.storePtr(t1, Address(t0, ion::IonActivation::offsetOfPrevPc()));
113473: 
113473:         /* Store critical fields in the VMFrame. This clobbers |t1|. */
113473:         int32_t storeFrameDepth = ic.frameSize.staticLocalSlots();
113473:         masm.storePtr(ImmPtr((void *)ic.frameSize.rejoinState(f.pc(), true)),
113473:                       FrameAddress(offsetof(VMFrame, stubRejoin)));
113473:         masm.setupFallibleABICall(cx->typeInferenceEnabled(), f.regs.pc, storeFrameDepth);
113473: 
113473: #ifdef JS_PUNBOX64
113473:         /* On X64, we must save the value mask registers, since Ion clobbers all. */
113473:         masm.push(Registers::TypeMaskReg);
113473:         masm.push(Registers::PayloadMaskReg);
113473: #endif
113473: 
113473:         /*
113473:          * We manually push onto the stack:
113473:          *
113473:          *   [argv]
113473:          *   thisv
113473:          *   argc
113473:          *   callee
113473:          *   frameDescriptor
113473:          */
113473:         size_t staticPushed =
113473:             (sizeof(Value) * (argc + 1)) +
113473:             sizeof(uintptr_t) +
113473:             sizeof(uintptr_t) +
113473:             sizeof(uintptr_t);
113473: 
113473:         /*
113473:          * Factoring in the return address, which is pushed implicitly, Ion
113473:          * requires that at its prologue, the stack is 8-byte aligned.
113473:          */
113473:         JS_ASSERT(ComputeByteAlignment(staticPushed + sizeof(uintptr_t), 8) == 0);
113473: 
113473:         /*
113473:          * Alas, we may push more arguments dynamically if we need to fill in
113473:          * missing formal arguments with |undefined|. Reserve a register for
113473:          * that, which will be used to compute the frame descriptor.
113473:          *
113473:          * Note that we subtract the stack budget for the descriptor, since it
113473:          * is popped before decoded.
113473:          */
113473:         RegisterID stackPushed = regs.takeAnyReg().reg();
113473:         masm.move(Imm32(staticPushed - sizeof(uintptr_t)), stackPushed);
113473: 
113473:         /*
113473:          * Check whether argc < nargs, because if so, we need to pad the stack.
113473:          *
113473:          * The stack is incoming with 16-byte alignment - this is guaranteed
113473:          * by the VMFrame. On all systems, we push four words as part of the
113473:          * frame, and each Value is eight bytes. This means the stack is
113473:          * always eight-byte aligned in the prologue of IonMonkey functions,
113473:          * which is the alignment it needs.
113473:          */
113473:         masm.load16(Address(funObjReg, offsetof(JSFunction, nargs)), t0);
113473:         Jump noPadding = masm.branch32(Assembler::BelowOrEqual, t0, Imm32(argc));
113473:         {
113473:             /* Compute the number of |undefined| values to push. */
113473:             masm.sub32(Imm32(argc), t0);
113473: 
113473:             /* Factor this dynamic stack into our stack budget. */
113473:             JS_STATIC_ASSERT(sizeof(Value) == 8);
113473:             masm.move(t0, t1);
113473:             masm.lshift32(Imm32(3), t1);
113473:             masm.add32(t1, stackPushed);
113473: 
113473:             Label loop = masm.label();
113473:             masm.subPtr(Imm32(sizeof(Value)), Registers::StackPointer);
113473:             masm.storeValue(UndefinedValue(), Address(Registers::StackPointer, 0));
113497:             Jump test = masm.branchSub32(Assembler::NonZero, Imm32(1), t0);
113473:             test.linkTo(loop, &masm);
113473:         }
113473:         noPadding.linkTo(masm.label(), &masm);
113473: 
113473:         /* Find the end of the argument list. */
113473:         size_t spOffset = sizeof(StackFrame) +
113473:                           ic.frameSize.staticLocalSlots() * sizeof(Value);
113473:         masm.addPtr(Imm32(spOffset), JSFrameReg, t0);
113473: 
113473:         /* Copy all remaining arguments. */
113473:         for (size_t i = 0; i < argc + 1; i++) {
113473:             /* Copy the argument onto the native stack. */
113473: #ifdef JS_NUNBOX32
115778:             masm.push(Address(t0, -int32_t((i + 1) * sizeof(Value)) + 4));
115778:             masm.push(Address(t0, -int32_t((i + 1) * sizeof(Value))));
113473: #elif defined JS_PUNBOX64
115778:             masm.push(Address(t0, -int32_t((i + 1) * sizeof(Value))));
113473: #endif
113473:         }
113473: 
113473:         /* Push argc and calleeToken. */
113473:         masm.push(Imm32(argc));
113473:         masm.push(funObjReg);
113473: 
113473:         /* Make and push a frame descriptor. */
113473:         masm.lshiftPtr(Imm32(ion::FRAMESIZE_SHIFT), stackPushed);
113473:         masm.orPtr(Imm32(ion::IonFrame_Entry), stackPushed);
113473:         masm.push(stackPushed);
113473: 
113473:         /* Call into Ion. */
113473:         masm.loadPtr(Address(ionScript, ion::IonScript::offsetOfMethod()), t0);
113473: #if defined(JS_CPU_X86) || defined(JS_CPU_X64)
115883:         masm.loadPtr(Address(t0, ion::IonCode::offsetOfCode()), t0);
113473:         masm.call(t0);
113473: #elif defined(JS_CPU_ARM)
115884:         masm.loadPtr(Address(t0, ion::IonCode::offsetOfCode()), JSC::ARMRegisters::ip);
113473:         masm.callAddress(JS_FUNC_TO_DATA_PTR(void *, IonVeneer));
113473: #endif
113473: 
113473:         /* Pop arugments off the stack. */
113473:         masm.pop(Registers::ReturnReg);
113473:         masm.rshift32(Imm32(ion::FRAMESIZE_SHIFT), Registers::ReturnReg);
113473:         masm.addPtr(Registers::ReturnReg, Registers::StackPointer);
113473: 
113473: #ifdef JS_PUNBOX64
113473:         /* On X64, we must save the value mask registers, since Ion clobbers all. */
113473:         masm.pop(Registers::PayloadMaskReg);
113473:         masm.pop(Registers::TypeMaskReg);
113473: #endif
113473: 
113525:         /* Grab the original JSFrameReg. */
113525:         masm.loadPtr(FrameAddress(VMFrame::offsetOfFp), JSFrameReg);
113525: 
113473:         /* We need to grab two temporaries, so make sure the rval is safe. */
113473:         regs = Registers(Registers::AvailRegs);
113525:         regs.takeRegUnchecked(JSReturnReg_Type);
113525:         regs.takeRegUnchecked(JSReturnReg_Data);
113525: 
113525:         /*
113525:          * Immediately take the Ion return value and copy it to JM's return
113525:          * registers. Note that we also store the value into the stack in case
113525:          * of recompilation, since the value cannot be recovered from registers.
113525:          */
113525:         Address rval(JSFrameReg, spOffset - ((argc + 2) * sizeof(Value)));
113473: #ifdef JS_NUNBOX32
113525:         RegisterID ionReturnType = (RegisterID)ion::JSReturnReg_Type.code();
113525:         RegisterID ionReturnData = (RegisterID)ion::JSReturnReg_Data.code();
113525: 
113525:         /* None of these registers may overlap. */
113525:         JS_ASSERT(ionReturnType != JSReturnReg_Type);
113525:         JS_ASSERT(ionReturnType != JSReturnReg_Data);
113525:         JS_ASSERT(ionReturnType != JSFrameReg);
113525:         JS_ASSERT(ionReturnData != JSReturnReg_Type);
113525:         JS_ASSERT(ionReturnData != JSReturnReg_Data);
113525:         JS_ASSERT(ionReturnData != JSFrameReg);
113525: 
113525:         masm.move(ionReturnType, JSReturnReg_Type);
113525:         masm.move(ionReturnData, JSReturnReg_Data);
113525:         masm.storeValueFromComponents(JSReturnReg_Type, JSReturnReg_Data, rval);
113473: #elif JS_PUNBOX64
113525:         RegisterID ionReturn = (RegisterID)ion::JSReturnReg.code();
113525: 
113525:         /* None of these registers may overlap. */
113525:         JS_ASSERT(ionReturn != JSReturnReg_Type);
113525:         JS_ASSERT(ionReturn != JSReturnReg_Data);
113525:         JS_ASSERT(ionReturn != JSFrameReg);
113525: 
113525:         masm.move(ionReturn, JSReturnReg_Type);
113525: 
113527:         masm.storePtr(JSReturnReg_Type, rval);
113525:         masm.move(Registers::PayloadMaskReg, JSReturnReg_Data);
113525:         masm.andPtr(JSReturnReg_Type, JSReturnReg_Data);
113525:         masm.xorPtr(JSReturnReg_Data, JSReturnReg_Type);
113473: #endif
113473: 
113473:         /* Unset VMFrame::stubRejoin. */
113473:         masm.storePtr(ImmPtr(NULL), FrameAddress(offsetof(VMFrame, stubRejoin)));
113473: 
113473:         /* Unset IonActivation::entryfp. */
113473:         t0 = regs.takeAnyReg().reg();
113473:         masm.loadPtr(&cx->runtime->ionActivation, t0);
113473:         masm.storePtr(ImmPtr(NULL), Address(t0, ion::IonActivation::offsetOfEntryFp()));
116390:         masm.storePtr(ImmPtr(NULL), Address(t0, ion::IonActivation::offsetOfPrevPc()));
113473: 
113473:         /* Unset CALLING_INTO_ION on the JS stack frame. */
113473:         masm.load32(Address(JSFrameReg, StackFrame::offsetOfFlags()), t0);
113473:         masm.and32(Imm32(~StackFrame::CALLING_INTO_ION), t0);
113473:         masm.store32(t0, Address(JSFrameReg, StackFrame::offsetOfFlags()));
113473: 
113525:         /* Check for an exception. */
113525:         Jump exception = masm.testMagic(Assembler::Equal, JSReturnReg_Type);
113473: 
113473:         /* If no exception, jump to the return address. */
113473:         NativeStubLinker::FinalJump done;
113473: #ifdef JS_CPU_X64
113473:         done = masm.moveWithPatch(ImmPtr(NULL), Registers::ValueReg);
113473:         masm.jump(Registers::ValueReg);
113473: #else
113473:         done = masm.jump();
113473: #endif
113473: 
113473:         /* Otherwise, throw. */
113473:         exception.linkTo(masm.label(), &masm);
113473:         masm.throwInJIT();
113473: 
113473:         NativeStubLinker linker(masm, f.chunk(), f.regs.pc, done);
113473:         if (!linker.init(f.cx))
113473:             return false;
113473: 
113473:         if (!linker.verifyRange(f.chunk())) {
113473:             disable();
113473:             return false;
113473:         }
113473: 
113473:         linker.link(noIonCode, ic.icCall());
113525:         linker.patchJump(ic.ionJoinPoint());
113473:         JSC::CodeLocationLabel cs = linker.finalize(f);
113473: 
113473:         ic.updateLastOolJump(linker.locationOf(noIonCode),
113473:                              JITCode(cs.executableAddress(), linker.size()));
113473:         ic.hasIonStub_ = true;
113473: 
113473:         JaegerSpew(JSpew_PICs, "generated ION stub %p (%lu bytes)\n", cs.executableAddress(),
113473:                    (unsigned long) masm.size());
113473: 
113473:         Repatcher repatch(f.chunk());
113473:         repatch.relink(ic.oolJump(), cs);
113473: 
113473:         return true;
113473:     }
113623: #endif
113473: 
 87654:     bool generateFullCallStub(JSScript *script, uint32_t flags)
 68952:     {
119065:         AutoAssertNoGC nogc;
119065: 
 68952:         /*
 68952:          * Create a stub that works with arity mismatches. Like the fast-path,
 68952:          * this allocates a frame on the caller side, but also performs extra
 68952:          * checks for compilability. Perhaps this should be a separate, shared
 68952:          * trampoline, but for now we generate it dynamically.
 68952:          */
 68952:         Assembler masm;
 68952:         InlineFrameAssembler inlFrame(masm, ic, flags);
 76185:         RegisterID t0 = inlFrame.tempRegs.takeAnyReg().reg();
 68952: 
 68952:         /* Generate the inline frame creation. */
 77341:         void *ncode = ic.funGuard.labelAtOffset(ic.joinPointOffset).executableAddress();
 77341:         inlFrame.assemble(ncode, f.pc());
 68952: 
 83234:         /* funObjReg is still valid. Check if a compilation is needed. */
 83234:         Address scriptAddr(ic.funObjReg, JSFunction::offsetOfNativeOrScript());
 68952:         masm.loadPtr(scriptAddr, t0);
 68952: 
 94809:         // Test that:
106782:         // - script->mJITInfo is not NULL
106782:         // - script->mJITInfo->jitHandle{Ctor,Normal}->value is neither NULL nor UNJITTABLE, and
106782:         // - script->mJITInfo->jitHandle{Ctor,Normal}->value->arityCheckEntry is not NULL.
106782:         masm.loadPtr(Address(t0, JSScript::offsetOfMJITInfo()), t0);
 99476:         Jump hasNoJitInfo = masm.branchPtr(Assembler::Equal, t0, ImmPtr(NULL));
 99476:         size_t offset = JSScript::JITScriptSet::jitHandleOffset(callingNew,
108442:                                                                 f.cx->compartment->compileBarriers());
 68952:         masm.loadPtr(Address(t0, offset), t0);
 94809:         Jump hasNoJitCode = masm.branchPtr(Assembler::BelowOrEqual, t0,
 94809:                                            ImmPtr(JSScript::JITScriptHandle::UNJITTABLE));
 94809: 
 94809:         masm.loadPtr(Address(t0, offsetof(JITScript, arityCheckEntry)), t0);
 94809: 
 94809:         Jump hasCode = masm.branchPtr(Assembler::NotEqual, t0, ImmPtr(0));
 94809: 
 99476:         hasNoJitInfo.linkTo(masm.label(), &masm);
 94809:         hasNoJitCode.linkTo(masm.label(), &masm);
 68952: 
 76185:         /*
 78637:          * Write the rejoin state to indicate this is a compilation call made
 78637:          * from an IC (the recompiler cannot detect calls made from ICs
 78637:          * automatically).
 76185:          */
 76185:         masm.storePtr(ImmPtr((void *) ic.frameSize.rejoinState(f.pc(), false)),
 76185:                       FrameAddress(offsetof(VMFrame, stubRejoin)));
 76185: 
121004:         masm.bumpStubCount(f.script().get(nogc), f.pc(), Registers::tempCallReg());
 77407: 
 68952:         /* Try and compile. On success we get back the nmap pointer. */
 68952:         void *compilePtr = JS_FUNC_TO_DATA_PTR(void *, stubs::CompileFunction);
 78413:         DataLabelPtr inlined;
 68952:         if (ic.frameSize.isStatic()) {
 68952:             masm.move(Imm32(ic.frameSize.staticArgc()), Registers::ArgReg1);
 76185:             masm.fallibleVMCall(cx->typeInferenceEnabled(),
 78413:                                 compilePtr, f.regs.pc, &inlined, ic.frameSize.staticLocalSlots());
 68952:         } else {
 82150:             masm.load32(FrameAddress(VMFrame::offsetOfDynamicArgc()), Registers::ArgReg1);
 76185:             masm.fallibleVMCall(cx->typeInferenceEnabled(),
 78413:                                 compilePtr, f.regs.pc, &inlined, -1);
 68952:         }
 68952: 
 68952:         Jump notCompiled = masm.branchTestPtr(Assembler::Zero, Registers::ReturnReg,
 68952:                                               Registers::ReturnReg);
 82150:         masm.loadPtr(FrameAddress(VMFrame::offsetOfRegsSp()), JSFrameReg);
 76185: 
 76185:         /* Compute the value of ncode to use at this call site. */
 87654:         ncode = (uint8_t *) f.chunk()->code.m_code.executableAddress() + ic.call->codeOffset;
 76185:         masm.storePtr(ImmPtr(ncode), Address(JSFrameReg, StackFrame::offsetOfNcode()));
 68952: 
 68952:         masm.jump(Registers::ReturnReg);
 68952: 
 68952:         hasCode.linkTo(masm.label(), &masm);
 68952: 
 68952:         /* Get nmap[ARITY], set argc, call. */
 68952:         if (ic.frameSize.isStatic())
 68952:             masm.move(Imm32(ic.frameSize.staticArgc()), JSParamReg_Argc);
 68952:         else
 82150:             masm.load32(FrameAddress(VMFrame::offsetOfDynamicArgc()), JSParamReg_Argc);
 68952:         masm.jump(t0);
 68952: 
114437:         LinkerHelper linker(masm, JSC::JAEGER_CODE);
 68952:         JSC::ExecutablePool *ep = poolForSize(linker, CallICInfo::Pool_ScriptStub);
 68952:         if (!ep)
 68952:             return false;
 68952: 
 87654:         if (!linker.verifyRange(f.chunk())) {
 87654:             disable();
 68952:             return true;
 68952:         }
113473:         if (ic.hasStubOolJump() && !linker.verifyRange(ic.lastOolCode())) {
113473:             disable();
113473:             return true;
113473:         }
 68952: 
113473:         linker.link(notCompiled, ic.nativeRejoin());
 80222:         JSC::CodeLocationLabel cs = linker.finalize(f);
 68952: 
 75290:         JaegerSpew(JSpew_PICs, "generated CALL stub %p (%lu bytes)\n", cs.executableAddress(),
 75290:                    (unsigned long) masm.size());
 68952: 
 78413:         if (f.regs.inlined()) {
114437:             JSC::LinkBuffer code((uint8_t *) cs.executableAddress(), masm.size(), JSC::JAEGER_CODE);
 78413:             code.patch(inlined, f.regs.inlined());
 78413:         }
 78413: 
 87654:         Repatcher repatch(f.chunk());
113473:         repatch.relink(ic.lastOolJump(), cs);
 68952: 
 68952:         return true;
 68952:     }
 68952: 
 87654:     bool patchInlinePath(JSScript *script, JSObject *obj)
 68952:     {
 68952:         JS_ASSERT(ic.frameSize.isStatic());
108693:         JITScript *jit = script->getJIT(callingNew, f.cx->compartment->compileBarriers());
 68952: 
 68952:         /* Very fast path. */
 87654:         Repatcher repatch(f.chunk());
 68952: 
 76185:         /*
 76185:          * Use the arguments check entry if this is a monitored call, we might
 76185:          * not have accounted for all possible argument types.
 76185:          */
 76185:         void *entry = ic.typeMonitored ? jit->argsCheckEntry : jit->fastEntry;
 76185: 
 68952:         if (!repatch.canRelink(ic.funGuard.jumpAtOffset(ic.hotJumpOffset),
 76185:                                JSC::CodeLocationLabel(entry))) {
 68952:             return false;
 68952:         }
 68952: 
 68952:         ic.fastGuardedObject = obj;
 76185:         JS_APPEND_LINK(&ic.links, &jit->callers);
 68952: 
 68952:         repatch.repatch(ic.funGuard, obj);
 68952:         repatch.relink(ic.funGuard.jumpAtOffset(ic.hotJumpOffset),
 76185:                        JSC::CodeLocationLabel(entry));
 68952: 
 68952:         JaegerSpew(JSpew_PICs, "patched CALL path %p (obj: %p)\n",
 75299:                    ic.funGuard.executableAddress(),
 75299:                    static_cast<void*>(ic.fastGuardedObject));
 68952: 
 68952:         return true;
 68952:     }
 68952: 
 87654:     bool generateStubForClosures(JSObject *obj)
 68952:     {
119065:         AutoAssertNoGC nogc;
 68952:         JS_ASSERT(ic.frameSize.isStatic());
 68952: 
 83234:         /* Slightly less fast path - guard on fun->script() instead. */
 68952:         Assembler masm;
 68952: 
 76185:         Registers tempRegs(Registers::AvailRegs);
 68952:         tempRegs.takeReg(ic.funObjReg);
 68952: 
 76185:         RegisterID t0 = tempRegs.takeAnyReg().reg();
 68952: 
 68952:         /* Guard that it's actually a function object. */
 83222:         Jump claspGuard = masm.testObjClass(Assembler::NotEqual, ic.funObjReg, t0, &FunctionClass);
 68952: 
 83234:         /* Guard that it's the same script. */
 83234:         Address scriptAddr(ic.funObjReg, JSFunction::offsetOfNativeOrScript());
 83234:         Jump funGuard = masm.branchPtr(Assembler::NotEqual, scriptAddr,
121004:                                        ImmPtr(obj->toFunction()->script().get(nogc)));
 68952:         Jump done = masm.jump();
 68952: 
114437:         LinkerHelper linker(masm, JSC::JAEGER_CODE);
 68952:         JSC::ExecutablePool *ep = poolForSize(linker, CallICInfo::Pool_ClosureStub);
 68952:         if (!ep)
 68952:             return false;
 68952: 
 68952:         ic.hasJsFunCheck = true;
 68952: 
 87654:         if (!linker.verifyRange(f.chunk())) {
 87654:             disable();
 68952:             return true;
 68952:         }
 68952: 
 68952:         linker.link(claspGuard, ic.slowPathStart);
 68952:         linker.link(funGuard, ic.slowPathStart);
 68952:         linker.link(done, ic.funGuard.labelAtOffset(ic.hotPathOffset));
 80222:         JSC::CodeLocationLabel cs = linker.finalize(f);
 68952: 
 75290:         JaegerSpew(JSpew_PICs, "generated CALL closure stub %p (%lu bytes)\n",
 75290:                    cs.executableAddress(), (unsigned long) masm.size());
 68952: 
 87654:         Repatcher repatch(f.chunk());
 68952:         repatch.relink(ic.funJump, cs);
 68952: 
 68952:         return true;
 68952:     }
 68952: 
 68952:     bool generateNativeStub()
 68952:     {
 68952:         /* Snapshot the frameDepth before SplatApplyArgs modifies it. */
 91237:         unsigned initialFrameDepth = f.regs.sp - f.fp()->slots();
 68952: 
115054:         /* Protect against accessing the IC if it may have been purged. */
115054:         RecompilationMonitor monitor(cx);
115054: 
 68952:         /*
 68952:          * SplatApplyArgs has not been called, so we call it here before
 68952:          * potentially touching f.u.call.dynamicArgc.
 68952:          */
 71695:         CallArgs args;
 68952:         if (ic.frameSize.isStatic()) {
 76185:             JS_ASSERT(f.regs.sp - f.fp()->slots() == (int)ic.frameSize.staticLocalSlots());
 71695:             args = CallArgsFromSp(ic.frameSize.staticArgc(), f.regs.sp);
 68952:         } else {
 76185:             JS_ASSERT(!f.regs.inlined());
 68952:             JS_ASSERT(*f.regs.pc == JSOP_FUNAPPLY && GET_ARGC(f.regs.pc) == 2);
115054:             /* Updates regs.sp -- may cause GC. */
115054:             if (!ic::SplatApplyArgs(f))
 68952:                 THROWV(true);
 71695:             args = CallArgsFromSp(f.u.call.dynamicArgc, f.regs.sp);
 68952:         }
 68952: 
104384:         RootedFunction fun(cx);
104384:         if (!IsFunctionObject(args.calleev(), fun.address()))
 68952:             return false;
 68952: 
 86533:         if ((!callingNew && !fun->isNative()) || (callingNew && !fun->isNativeConstructor()))
 68952:             return false;
 68952: 
 68952:         if (callingNew)
108174:             args.setThis(MagicValue(JS_IS_CONSTRUCTING));
 68952: 
 94094:         if (!CallJSNative(cx, fun->native(), args))
 68952:             THROWV(true);
 68952: 
115105:         RootedScript fscript(cx, f.script());
115105:         types::TypeScript::Monitor(f.cx, fscript, f.pc(), args.rval());
 76185: 
 80771:         /*
 80771:          * Native stubs are not generated for inline frames. The overhead of
 80771:          * bailing out from the IC is far greater than the time saved by
 80771:          * inlining the parent frame in the first place, so mark the immediate
 80771:          * caller as uninlineable.
 80771:          */
119065:         if (fscript->function()) {
119065:             fscript->uninlineable = true;
119065:             MarkTypeObjectFlags(cx, fscript->function(), types::OBJECT_FLAG_UNINLINEABLE);
 80771:         }
 80771: 
 76185:         /* Don't touch the IC if the call triggered a recompilation. */
 76185:         if (monitor.recompiled())
 76185:             return true;
 76185: 
 80771:         JS_ASSERT(!f.regs.inlined());
 80771: 
 68952:         /* Right now, take slow-path for IC misses or multiple stubs. */
 68952:         if (ic.fastGuardedNative || ic.hasJsFunCheck)
 68952:             return true;
 68952: 
 68952:         /* Native MIC needs to warm up first. */
 68952:         if (!ic.hit) {
 68952:             ic.hit = true;
 68952:             return true;
 68952:         }
 68952: 
 68952:         /* Generate fast-path for calling this native. */
 68952:         Assembler masm;
 68952: 
 68952:         /* Guard on the function object identity, for now. */
 83234:         Jump funGuard = masm.branchPtr(Assembler::NotEqual, ic.funObjReg, ImmPtr(fun));
 68952: 
 76185:         /*
 76185:          * Write the rejoin state for the recompiler to use if this call
 76185:          * triggers recompilation. Natives use a different stack address to
 76185:          * store the return value than FASTCALLs, and without additional
 76185:          * information we cannot tell which one is active on a VMFrame.
 76185:          */
 76185:         masm.storePtr(ImmPtr((void *) ic.frameSize.rejoinState(f.pc(), true)),
 76185:                       FrameAddress(offsetof(VMFrame, stubRejoin)));
 76185: 
 68952:         /* N.B. After this call, the frame will have a dynamic frame size. */
 68952:         if (ic.frameSize.isDynamic()) {
119065:             masm.bumpStubCount(fscript, f.pc(), Registers::tempCallReg());
 76185:             masm.fallibleVMCall(cx->typeInferenceEnabled(),
 76185:                                 JS_FUNC_TO_DATA_PTR(void *, ic::SplatApplyArgs),
 78413:                                 f.regs.pc, NULL, initialFrameDepth);
 68952:         }
 68952: 
 78454:         Registers tempRegs = Registers::tempCallRegMask();
 76185:         RegisterID t0 = tempRegs.takeAnyReg().reg();
119065:         masm.bumpStubCount(fscript, f.pc(), t0);
 68952: 
 84755:         int32_t storeFrameDepth = ic.frameSize.isStatic() ? initialFrameDepth : -1;
 78454:         masm.setupFallibleABICall(cx->typeInferenceEnabled(), f.regs.pc, storeFrameDepth);
 68952: 
 68952:         /* Grab cx. */
 68952: #ifdef JS_CPU_X86
 76185:         RegisterID cxReg = tempRegs.takeAnyReg().reg();
 68952: #else
 68952:         RegisterID cxReg = Registers::ArgReg0;
 68952: #endif
 68952:         masm.loadPtr(FrameAddress(offsetof(VMFrame, cx)), cxReg);
 68952: 
 76185:         /*
 76185:          * Compute vp. This will always be at the same offset from fp for a
 76185:          * given callsite, regardless of any dynamically computed argc,
 76185:          * so get that offset from the active call.
 76185:          */
 68952: #ifdef JS_CPU_X86
 68952:         RegisterID vpReg = t0;
 68952: #else
 68952:         RegisterID vpReg = Registers::ArgReg2;
 68952: #endif
 84755:         uint32_t vpOffset = (uint32_t) ((char *) args.base() - (char *) f.fp());
 76185:         masm.addPtr(Imm32(vpOffset), JSFrameReg, vpReg);
 76185: 
 76185:         /* Compute argc. */
 68952:         MaybeRegisterID argcReg;
 76185:         if (!ic.frameSize.isStatic()) {
 76185:             argcReg = tempRegs.takeAnyReg().reg();
 82150:             masm.load32(FrameAddress(VMFrame::offsetOfDynamicArgc()), argcReg.reg());
 68952:         }
 68952: 
 68952:         /* Mark vp[1] as magic for |new|. */
 86533:         if (callingNew)
 86533:             masm.storeValue(MagicValue(JS_IS_CONSTRUCTING), Address(vpReg, sizeof(Value)));
 68952: 
 76185:         masm.restoreStackBase();
 68952:         masm.setupABICall(Registers::NormalCall, 3);
 68952:         masm.storeArg(2, vpReg);
 68952:         if (ic.frameSize.isStatic())
 80505:             masm.storeArg(1, ImmIntPtr(intptr_t(ic.frameSize.staticArgc())));
 68952:         else
 68952:             masm.storeArg(1, argcReg.reg());
 68952:         masm.storeArg(0, cxReg);
 68952: 
 94094:         js::Native native = fun->native();
 68952: 
 68952:         /*
 68952:          * Call RegExp.test instead of exec if the result will not be used or
 76185:          * will only be used to test for existence. Note that this will not
 76185:          * break inferred types for the call's result and any subsequent test,
 76185:          * as RegExp.exec has a type handler with unknown result.
 68952:          */
 79981:         if (native == regexp_exec && !CallResultEscapes(f.pc()))
 79981:             native = regexp_test;
 68952: 
 68952:         masm.callWithABI(JS_FUNC_TO_DATA_PTR(void *, native), false);
 68952: 
 78454:         NativeStubLinker::FinalJump done;
 78454:         if (!NativeStubEpilogue(f, masm, &done, initialFrameDepth, vpOffset, MaybeRegisterID(), MaybeRegisterID()))
 78454:             return false;
 87654:         NativeStubLinker linker(masm, f.chunk(), f.regs.pc, done);
 78454:         if (!linker.init(f.cx))
 76185:             THROWV(true);
 73495: 
 87654:         if (!linker.verifyRange(f.chunk())) {
 87654:             disable();
 68952:             return true;
 68952:         }
 68952: 
113473:         linker.patchJump(ic.nativeRejoin());
 76185: 
 83234:         ic.fastGuardedNative = fun;
 76185: 
 68952:         linker.link(funGuard, ic.slowPathStart);
 80222:         JSC::CodeLocationLabel start = linker.finalize(f);
 68952: 
 75290:         JaegerSpew(JSpew_PICs, "generated native CALL stub %p (%lu bytes)\n",
 77434:                    start.executableAddress(), (unsigned long) masm.size());
 68952: 
 87654:         Repatcher repatch(f.chunk());
 76185:         repatch.relink(ic.funJump, start);
 68952: 
 68952:         return true;
 68952:     }
 68952: 
 68952:     void *update()
 68952:     {
 76185:         RecompilationMonitor monitor(cx);
 76185: 
 77341:         bool lowered = ic.frameSize.lowered(f.pc());
 77341:         JS_ASSERT_IF(lowered, !callingNew);
 68952: 
 95031:         StackFrame *initialFp = f.fp();
 95031: 
114311:         stubs::UncachedCallResult ucr(f.cx);
 68952:         if (callingNew)
114311:             stubs::UncachedNewHelper(f, ic.frameSize.staticArgc(), ucr);
 68952:         else
114311:             stubs::UncachedCallHelper(f, ic.frameSize.getArgc(f), lowered, ucr);
 76185: 
 76185:         // Watch out in case the IC was invalidated by a recompilation on the calling
 76185:         // script. This can happen either if the callee is executed or if it compiles
 95031:         // and the compilation has a static overflow. Also watch for cases where
 95031:         // an exception is thrown and the callee frame hasn't unwound yet.
 95031:         if (monitor.recompiled() || f.fp() != initialFp)
 76185:             return ucr.codeAddr;
 68952: 
113473:         JSFunction *fun = ucr.fun;
113473: 
 68952:         if (!ucr.codeAddr) {
113473:             // No JM code is available for this script yet.
 68952:             if (ucr.unjittable)
 87654:                 disable();
113473: 
113623: #ifdef JS_ION
119065:             AutoAssertNoGC nogc;
119065: 
113473:             // If the following conditions pass, try to inline a call into
113473:             // an IonMonkey JIT'd function.
113473:             if (!callingNew &&
113473:                 fun &&
113493:                 !ic.hasJMStub() &&
113473:                 !ic.hasIonStub() &&
113473:                 ic.frameSize.isStatic() &&
113473:                 ic.frameSize.staticArgc() <= ion::SNAPSHOT_MAX_NARGS &&
113473:                 fun->script()->hasIonScript())
113473:             {
113473:                 if (!generateIonStub())
113473:                     THROWV(NULL);
113473:             }
113623: #endif
 68952:             return NULL;
 68952:         }
 68952: 
119065:         AutoAssertNoGC nogc;
 68952:         JS_ASSERT(fun);
121004:         JSScript *script = fun->script().get(nogc);
 68952:         JS_ASSERT(script);
 68952: 
 84755:         uint32_t flags = callingNew ? StackFrame::CONSTRUCTING : 0;
 68952: 
 68952:         if (!ic.hit) {
 68952:             ic.hit = true;
 68952:             return ucr.codeAddr;
 68952:         }
 68952: 
 68952:         if (!ic.frameSize.isStatic() || ic.frameSize.staticArgc() != fun->nargs) {
 87654:             if (!generateFullCallStub(script, flags))
 68952:                 THROWV(NULL);
 68952:         } else {
 87654:             if (!ic.fastGuardedObject && patchInlinePath(script, fun)) {
 68952:                 // Nothing, done.
 68952:             } else if (ic.fastGuardedObject &&
 68952:                        !ic.hasJsFunCheck &&
 68952:                        !ic.fastGuardedNative &&
 83234:                        ic.fastGuardedObject->toFunction()->script() == fun->script()) {
 68952:                 /*
 68952:                  * Note: Multiple "function guard" stubs are not yet
 68952:                  * supported, thus the fastGuardedNative check.
 68952:                  */
 87654:                 if (!generateStubForClosures(fun))
 68952:                     THROWV(NULL);
 68952:             } else {
 87654:                 if (!generateFullCallStub(script, flags))
 68952:                     THROWV(NULL);
 68952:             }
 68952:         }
 68952: 
 68952:         return ucr.codeAddr;
 68952:     }
 68952: };
 68952: 
 94809: } // namespace mjit
 94809: } // namespace js
 94809: 
 68952: void * JS_FASTCALL
 68952: ic::Call(VMFrame &f, CallICInfo *ic)
 68952: {
 68952:     CallCompiler cc(f, *ic, false);
 68952:     return cc.update();
 68952: }
 68952: 
 68952: void * JS_FASTCALL
 68952: ic::New(VMFrame &f, CallICInfo *ic)
 68952: {
 68952:     CallCompiler cc(f, *ic, true);
 68952:     return cc.update();
 68952: }
 68952: 
 76185: void * JS_FASTCALL
 68952: ic::NativeCall(VMFrame &f, CallICInfo *ic)
 68952: {
 68952:     CallCompiler cc(f, *ic, false);
 68952:     if (!cc.generateNativeStub())
 68952:         stubs::SlowCall(f, ic->frameSize.getArgc(f));
 76185:     return NULL;
 68952: }
 68952: 
 76185: void * JS_FASTCALL
 68952: ic::NativeNew(VMFrame &f, CallICInfo *ic)
 68952: {
 68952:     CallCompiler cc(f, *ic, true);
 68952:     if (!cc.generateNativeStub())
 68952:         stubs::SlowNew(f, ic->frameSize.staticArgc());
 76185:     return NULL;
 68952: }
 68952: 
 68885: static JS_ALWAYS_INLINE bool
 91237: BumpStack(VMFrame &f, unsigned inc)
 68885: {
 71363:     if (f.regs.sp + inc < f.stackLimit)
 68885:         return true;
 71363:     return f.cx->stack.space().tryBumpLimit(f.cx, f.regs.sp, inc, &f.stackLimit);
 68885: }
 68885: 
 57717: /*
 57717:  * SplatApplyArgs is only called for expressions of the form |f.apply(x, y)|.
 57717:  * Additionally, the callee has already been checked to be the native apply.
 57717:  * All successful paths through SplatApplyArgs must set f.u.call.dynamicArgc
 57717:  * and f.regs.sp.
 57717:  */
 57717: JSBool JS_FASTCALL
 57717: ic::SplatApplyArgs(VMFrame &f)
 57717: {
 57717:     JSContext *cx = f.cx;
 76185:     JS_ASSERT(!f.regs.inlined());
 57718: 
 95100:     CallArgs args = CallArgsFromSp(GET_ARGC(f.regs.pc), f.regs.sp);
 95100:     JS_ASSERT(args.length() == 2);
 95100:     JS_ASSERT(IsNativeFunction(args.calleev(), js_fun_apply));
 95100: 
103261:     if (IsOptimizedArguments(f.fp(), &args[1])) {
 93251:         /* Mirror isMagic(JS_OPTIMIZED_ARGUMENTS) case in js_fun_apply. */
 93251:         /* Steps 4-6. */
 93251:         unsigned length = f.regs.fp()->numActualArgs();
 93251:         JS_ASSERT(length <= StackSpace::ARGS_LENGTH_MAX);
 57718: 
 95100:         f.regs.sp--;
 93251:         if (!BumpStack(f, length))
 68885:             THROWV(false);
 68885: 
 93251:         /* Steps 7-8. */
101075:         f.regs.fp()->forEachUnaliasedActual(CopyTo(f.regs.sp));
 68885: 
 93251:         f.regs.sp += length;
 93251:         f.u.call.dynamicArgc = length;
 57718:         return true;
 57718:     }
 57718: 
 57717:     /*
 57717:      * This stub should mimic the steps taken by js_fun_apply. Step 1 and part
 57717:      * of Step 2 have already been taken care of by calling jit code.
 57717:      */
 57717: 
 57717:     /* Step 2 (part 2). */
 95100:     if (args[1].isNullOrUndefined()) {
 57717:         f.regs.sp--;
 57717:         f.u.call.dynamicArgc = 0;
 57717:         return true;
 57717:     }
 57717: 
 57717:     /* Step 3. */
 95100:     if (!args[1].isObject()) {
 57717:         JS_ReportErrorNumber(cx, js_GetErrorMessage, NULL, JSMSG_BAD_APPLY_ARGS, js_apply_str);
 57717:         THROWV(false);
 57717:     }
 57717: 
 57717:     /* Steps 4-5. */
 99421:     RootedObject aobj(cx, &args[1].toObject());
 91688:     uint32_t length;
108951:     if (!GetLengthProperty(cx, aobj, &length))
 57717:         THROWV(false);
 57717: 
 57717:     /* Step 6. */
 74602:     if (length > StackSpace::ARGS_LENGTH_MAX) {
 74602:         JS_ReportErrorNumber(cx, js_GetErrorMessage, NULL,
 74602:                              JSMSG_TOO_MANY_FUN_APPLY_ARGS);
 74602:         THROWV(false);
 74602:     }
 57717: 
 91237:     int delta = length - 1;
102263:     if (delta > 0) {
102263:         if (!BumpStack(f, delta))
 57717:             THROWV(false);
102263: 
102263:         MakeRangeGCSafe(f.regs.sp, delta);
102263:     }
102263: 
 57717:     f.regs.sp += delta;
 57717: 
 57717:     /* Steps 7-8. */
 74602:     if (!GetElements(cx, aobj, length, f.regs.sp - length))
 57717:         THROWV(false);
 57717: 
 74602:     f.u.call.dynamicArgc = length;
 57717:     return true;
 53590: }
 53301: 
122731: #if defined(_MSC_VER)
122731: # pragma optimize("", on)
122731: #endif
122731: 
 53405: void
 76185: ic::GenerateArgumentCheckStub(VMFrame &f)
 76185: {
119065:     AutoAssertNoGC nogc;
 76185:     JS_ASSERT(f.cx->typeInferenceEnabled());
 76185: 
 76185:     JITScript *jit = f.jit();
 76185:     StackFrame *fp = f.fp();
 76185:     JSFunction *fun = fp->fun();
121004:     JSScript *script = fun->script().get(nogc);
 76185: 
 76185:     if (jit->argsCheckPool)
 76185:         jit->resetArgsCheck();
 76185: 
 76185:     Assembler masm;
 76185:     Vector<Jump> mismatches(f.cx);
 76185: 
 76185:     if (!f.fp()->isConstructing()) {
 77391:         types::TypeSet *types = types::TypeScript::ThisTypes(script);
 76185:         Address address(JSFrameReg, StackFrame::offsetOfThis(fun));
 78413:         if (!masm.generateTypeCheck(f.cx, address, types, &mismatches))
 76185:             return;
 76185:     }
 76185: 
 76185:     for (unsigned i = 0; i < fun->nargs; i++) {
 77391:         types::TypeSet *types = types::TypeScript::ArgTypes(script, i);
 76185:         Address address(JSFrameReg, StackFrame::offsetOfFormalArg(fun, i));
 78413:         if (!masm.generateTypeCheck(f.cx, address, types, &mismatches))
 76185:             return;
 76185:     }
 76185: 
 76185:     Jump done = masm.jump();
 76185: 
114437:     LinkerHelper linker(masm, JSC::JAEGER_CODE);
 76185:     JSC::ExecutablePool *ep = linker.init(f.cx);
 76185:     if (!ep)
 76185:         return;
 76185:     jit->argsCheckPool = ep;
 76185: 
 87654:     if (!linker.verifyRange(f.chunk())) {
 76185:         jit->resetArgsCheck();
 76185:         return;
 76185:     }
 76185: 
 76185:     for (unsigned i = 0; i < mismatches.length(); i++)
 76185:         linker.link(mismatches[i], jit->argsCheckStub);
 76185:     linker.link(done, jit->argsCheckFallthrough);
 76185: 
 80222:     JSC::CodeLocationLabel cs = linker.finalize(f);
 76185: 
 77429:     JaegerSpew(JSpew_PICs, "generated ARGS CHECK stub %p (%lu bytes)\n",
 77860:                cs.executableAddress(), (unsigned long)masm.size());
 76185: 
 87654:     Repatcher repatch(f.chunk());
 76185:     repatch.relink(jit->argsCheckJump, cs);
 76185: }
 76185: 
 76185: void
 76185: JITScript::resetArgsCheck()
 76185: {
 76185:     argsCheckPool->release();
 76185:     argsCheckPool = NULL;
 76185: 
 87654:     Repatcher repatch(chunk(script->code));
 76185:     repatch.relink(argsCheckJump, argsCheckStub);
 76185: }
 76185: 
 53119: #endif /* JS_MONOIC */
 53405: 
