 80202: /* -*- Mode: C++; tab-width: 4; indent-tabs-mode: nil; c-basic-offset: 4 -*-
 80202:  * vim: set ts=8 sw=4 et tw=99 ft=cpp:
 80202:  *
 98983:  * This Source Code Form is subject to the terms of the Mozilla Public
 98983:  * License, v. 2.0. If a copy of the MPL was not distributed with this
 98983:  * file, You can obtain one at http://mozilla.org/MPL/2.0/. */
 80202: 
 80202: #ifndef js_utility_h__
 80202: #define js_utility_h__
 80202: 
 86058: #include "mozilla/Assertions.h"
102242: #include "mozilla/Attributes.h"
126025: #include "mozilla/Scoped.h"
 86058: 
 80202: #include <stdlib.h>
 80202: #include <string.h>
 80202: 
 92003: #ifdef JS_OOM_DO_BACKTRACES
 92003: #include <stdio.h>
 92003: #include <execinfo.h>
 92003: #endif
 92003: 
 84931: #include "jstypes.h"
 80202: 
110934: #include "js/TemplateLib.h"
 80202: 
 80202: /* The public JS engine namespace. */
 80202: namespace JS {}
 80202: 
 80202: /* The mozilla-shared reusable template/utility namespace. */
 80202: namespace mozilla {}
 80202: 
 80202: /* The private JS engine namespace. */
 80202: namespace js {
 80202: 
 80202: /* The private namespace is a superset of the public/shared namespaces. */
 80202: using namespace JS;
 80202: 
 80202: }  /* namespace js */
 80202: 
 80202: /*
 80202:  * Pattern used to overwrite freed memory. If you are accessing an object with
 80202:  * this pattern, you probably have a dangling pointer.
 80202:  */
 80202: #define JS_FREE_PATTERN 0xDA
 80202: 
 86058: #define JS_ASSERT(expr)           MOZ_ASSERT(expr)
 86474: #define JS_ASSERT_IF(cond, expr)  MOZ_ASSERT_IF(cond, expr)
 86058: #define JS_NOT_REACHED(reason)    MOZ_NOT_REACHED(reason)
 86058: #define JS_ALWAYS_TRUE(expr)      MOZ_ALWAYS_TRUE(expr)
 86058: #define JS_ALWAYS_FALSE(expr)     MOZ_ALWAYS_FALSE(expr)
 86058: 
 80202: #ifdef DEBUG
 80202: # ifdef JS_THREADSAFE
 80202: #  define JS_THREADSAFE_ASSERT(expr) JS_ASSERT(expr)
 80202: # else
 80202: #  define JS_THREADSAFE_ASSERT(expr) ((void) 0)
 80202: # endif
 80202: #else
 80202: # define JS_THREADSAFE_ASSERT(expr) ((void) 0)
 80202: #endif
 80202: 
132345: #if defined(DEBUG)
132345: # define JS_DIAGNOSTICS_ASSERT(expr) MOZ_ASSERT(expr)
132345: #elif defined(JS_CRASH_DIAGNOSTICS)
132345: # define JS_DIAGNOSTICS_ASSERT(expr) do { if (!(expr)) MOZ_CRASH(); } while(0)
132345: #else
132345: # define JS_DIAGNOSTICS_ASSERT(expr) ((void) 0)
132345: #endif
132345: 
 86059: #define JS_STATIC_ASSERT(cond)           MOZ_STATIC_ASSERT(cond, "JS_STATIC_ASSERT")
 86059: #define JS_STATIC_ASSERT_IF(cond, expr)  MOZ_STATIC_ASSERT_IF(cond, expr, "JS_STATIC_ASSERT_IF")
 80202: 
102242: extern MOZ_NORETURN JS_PUBLIC_API(void)
102242: JS_Assert(const char *s, const char *file, int ln);
102242: 
 80202: /*
 80202:  * Abort the process in a non-graceful manner. This will cause a core file,
 80202:  * call to the debugger or other moral equivalent as well as causing the
 80202:  * entire process to stop.
 80202:  */
 80202: extern JS_PUBLIC_API(void) JS_Abort(void);
 80202: 
 80202: /*
 80202:  * Custom allocator support for SpiderMonkey
 80202:  */
 80202: #if defined JS_USE_CUSTOM_ALLOCATOR
 80202: # include "jscustomallocator.h"
 80202: #else
 80202: # ifdef DEBUG
 80202: /*
 80202:  * In order to test OOM conditions, when the shell command-line option
 80202:  * |-A NUM| is passed, we fail continuously after the NUM'th allocation.
 80202:  */
 84755: extern JS_PUBLIC_DATA(uint32_t) OOM_maxAllocations; /* set from shell/js.cpp */
 84755: extern JS_PUBLIC_DATA(uint32_t) OOM_counter; /* data race, who cares. */
 92003: 
 92003: #ifdef JS_OOM_DO_BACKTRACES
 92003: #define JS_OOM_BACKTRACE_SIZE 32
 92003: static JS_ALWAYS_INLINE void
 92003: PrintBacktrace()
 92003: {
 92003:     void* OOM_trace[JS_OOM_BACKTRACE_SIZE];
 92003:     char** OOM_traceSymbols = NULL;
 92003:     int32_t OOM_traceSize = 0;
 92003:     int32_t OOM_traceIdx = 0;
 92003:     OOM_traceSize = backtrace(OOM_trace, JS_OOM_BACKTRACE_SIZE);
 92003:     OOM_traceSymbols = backtrace_symbols(OOM_trace, OOM_traceSize);
 92003: 
 92003:     if (!OOM_traceSymbols)
 92003:         return;
 92003: 
 92003:     for (OOM_traceIdx = 0; OOM_traceIdx < OOM_traceSize; ++OOM_traceIdx) {
 92003:         fprintf(stderr, "#%d %s\n", OOM_traceIdx, OOM_traceSymbols[OOM_traceIdx]);
 92003:     }
 92003: 
 92003:     free(OOM_traceSymbols);
 92003: }
 92003: 
 92003: #define JS_OOM_EMIT_BACKTRACE() \
 92003:     do {\
 92003:         fprintf(stderr, "Forcing artificial memory allocation function failure:\n");\
 92003: 	PrintBacktrace();\
 92003:     } while (0)
 92003: # else
 92003: #  define JS_OOM_EMIT_BACKTRACE() do {} while(0)
 92003: #endif /* JS_OOM_DO_BACKTRACES */
 92003: 
 80202: #  define JS_OOM_POSSIBLY_FAIL() \
 80202:     do \
 80202:     { \
 91357:         if (++OOM_counter > OOM_maxAllocations) { \
 92003:             JS_OOM_EMIT_BACKTRACE();\
 80202:             return NULL; \
 80202:         } \
 80202:     } while (0)
 80202: 
 95434: #  define JS_OOM_POSSIBLY_FAIL_REPORT(cx) \
 95434:     do \
 95434:     { \
 95434:         if (++OOM_counter > OOM_maxAllocations) { \
 95434:             JS_OOM_EMIT_BACKTRACE();\
 95434:             js_ReportOutOfMemory(cx);\
 95434:             return NULL; \
 95434:         } \
 95434:     } while (0)
 95434: 
 80202: # else
 80202: #  define JS_OOM_POSSIBLY_FAIL() do {} while(0)
 95434: #  define JS_OOM_POSSIBLY_FAIL_REPORT(cx) do {} while(0)
 95434: # endif /* DEBUG */
 80202: 
 80202: static JS_INLINE void* js_malloc(size_t bytes)
 80202: {
 80202:     JS_OOM_POSSIBLY_FAIL();
 80202:     return malloc(bytes);
 80202: }
 80202: 
 80202: static JS_INLINE void* js_calloc(size_t bytes)
 80202: {
 80202:     JS_OOM_POSSIBLY_FAIL();
 80202:     return calloc(bytes, 1);
 80202: }
 80202: 
 80202: static JS_INLINE void* js_realloc(void* p, size_t bytes)
 80202: {
 80202:     JS_OOM_POSSIBLY_FAIL();
 80202:     return realloc(p, bytes);
 80202: }
 80202: 
 80202: static JS_INLINE void js_free(void* p)
 80202: {
 80202:     free(p);
 80202: }
 80202: #endif/* JS_USE_CUSTOM_ALLOCATOR */
 80202: 
120585: JS_BEGIN_EXTERN_C
120585: 
 80202: /*
 80202:  * Replace bit-scanning code sequences with CPU-specific instructions to
 80202:  * speedup calculations of ceiling/floor log2.
 80202:  *
 80202:  * With GCC 3.4 or later we can use __builtin_clz for that, see bug 327129.
 80202:  *
 80202:  * SWS: Added MSVC intrinsic bitscan support.  See bugs 349364 and 356856.
 80202:  */
 80202: #if defined(_WIN32) && (_MSC_VER >= 1300) && (defined(_M_IX86) || defined(_M_AMD64) || defined(_M_X64))
 80202: 
 80202: unsigned char _BitScanForward(unsigned long * Index, unsigned long Mask);
 80202: unsigned char _BitScanReverse(unsigned long * Index, unsigned long Mask);
 80202: # pragma intrinsic(_BitScanForward,_BitScanReverse)
 80202: 
 80202: __forceinline static int
 80202: __BitScanForward32(unsigned int val)
 80202: {
 80202:     unsigned long idx;
 80202: 
 80202:     _BitScanForward(&idx, (unsigned long)val);
 80202:     return (int)idx;
 80202: }
 80202: __forceinline static int
 80202: __BitScanReverse32(unsigned int val)
 80202: {
 80202:     unsigned long idx;
 80202: 
 80202:     _BitScanReverse(&idx, (unsigned long)val);
 80202:     return (int)(31-idx);
 80202: }
 80202: # define js_bitscan_ctz32(val)  __BitScanForward32(val)
 80202: # define js_bitscan_clz32(val)  __BitScanReverse32(val)
 80202: # define JS_HAS_BUILTIN_BITSCAN32
 80202: 
 80202: #if defined(_M_AMD64) || defined(_M_X64)
 80202: unsigned char _BitScanForward64(unsigned long * Index, unsigned __int64 Mask);
 80202: unsigned char _BitScanReverse64(unsigned long * Index, unsigned __int64 Mask);
 80202: # pragma intrinsic(_BitScanForward64,_BitScanReverse64)
 80202: 
 80202: __forceinline static int
 80202: __BitScanForward64(unsigned __int64 val)
 80202: {
 80202:     unsigned long idx;
 80202: 
 80202:     _BitScanForward64(&idx, val);
 80202:     return (int)idx;
 80202: }
 80202: __forceinline static int
 80202: __BitScanReverse64(unsigned __int64 val)
 80202: {
 80202:     unsigned long idx;
 80202: 
 80202:     _BitScanReverse64(&idx, val);
 80202:     return (int)(63-idx);
 80202: }
 80202: # define js_bitscan_ctz64(val)  __BitScanForward64(val)
 80202: # define js_bitscan_clz64(val)  __BitScanReverse64(val)
 80202: # define JS_HAS_BUILTIN_BITSCAN64
 80202: #endif
 80202: #elif (__GNUC__ >= 4) || (__GNUC__ == 3 && __GNUC_MINOR__ >= 4)
 80202: 
 80202: # define js_bitscan_ctz32(val)  __builtin_ctz(val)
 80202: # define js_bitscan_clz32(val)  __builtin_clz(val)
 80202: # define JS_HAS_BUILTIN_BITSCAN32
 80202: # if (JS_BYTES_PER_WORD == 8)
 80202: #  define js_bitscan_ctz64(val)  __builtin_ctzll(val)
 80202: #  define js_bitscan_clz64(val)  __builtin_clzll(val)
 80202: #  define JS_HAS_BUILTIN_BITSCAN64
 80202: # endif
 80202: 
 80202: #endif
 80202: 
 80202: /*
 80202: ** Macro version of JS_CeilingLog2: Compute the log of the least power of
 80202: ** 2 greater than or equal to _n. The result is returned in _log2.
 80202: */
 80202: #ifdef JS_HAS_BUILTIN_BITSCAN32
 80202: /*
 80202:  * Use intrinsic function or count-leading-zeros to calculate ceil(log2(_n)).
 80202:  * The macro checks for "n <= 1" and not "n != 0" as js_bitscan_clz32(0) is
 80202:  * undefined.
 80202:  */
 80202: # define JS_CEILING_LOG2(_log2,_n)                                            \
 80202:     JS_BEGIN_MACRO                                                            \
 80202:         unsigned int j_ = (unsigned int)(_n);                                 \
 80202:         (_log2) = (j_ <= 1 ? 0 : 32 - js_bitscan_clz32(j_ - 1));              \
 80202:     JS_END_MACRO
 80202: #else
 80202: # define JS_CEILING_LOG2(_log2,_n)                                            \
 80202:     JS_BEGIN_MACRO                                                            \
 84755:         uint32_t j_ = (uint32_t)(_n);                                         \
 80202:         (_log2) = 0;                                                          \
 80202:         if ((j_) & ((j_)-1))                                                  \
 80202:             (_log2) += 1;                                                     \
 80202:         if ((j_) >> 16)                                                       \
 80202:             (_log2) += 16, (j_) >>= 16;                                       \
 80202:         if ((j_) >> 8)                                                        \
 80202:             (_log2) += 8, (j_) >>= 8;                                         \
 80202:         if ((j_) >> 4)                                                        \
 80202:             (_log2) += 4, (j_) >>= 4;                                         \
 80202:         if ((j_) >> 2)                                                        \
 80202:             (_log2) += 2, (j_) >>= 2;                                         \
 80202:         if ((j_) >> 1)                                                        \
 80202:             (_log2) += 1;                                                     \
 80202:     JS_END_MACRO
 80202: #endif
 80202: 
 80202: /*
 80202: ** Macro version of JS_FloorLog2: Compute the log of the greatest power of
 80202: ** 2 less than or equal to _n. The result is returned in _log2.
 80202: **
 80202: ** This is equivalent to finding the highest set bit in the word.
 80202: */
 80202: #ifdef JS_HAS_BUILTIN_BITSCAN32
 80202: /*
 80202:  * Use js_bitscan_clz32 or count-leading-zeros to calculate floor(log2(_n)).
 80202:  * Since js_bitscan_clz32(0) is undefined, the macro set the loweset bit to 1
 80202:  * to ensure 0 result when _n == 0.
 80202:  */
 80202: # define JS_FLOOR_LOG2(_log2,_n)                                              \
 80202:     JS_BEGIN_MACRO                                                            \
 80202:         (_log2) = 31 - js_bitscan_clz32(((unsigned int)(_n)) | 1);            \
 80202:     JS_END_MACRO
 80202: #else
 80202: # define JS_FLOOR_LOG2(_log2,_n)                                              \
 80202:     JS_BEGIN_MACRO                                                            \
 84755:         uint32_t j_ = (uint32_t)(_n);                                         \
 80202:         (_log2) = 0;                                                          \
 80202:         if ((j_) >> 16)                                                       \
 80202:             (_log2) += 16, (j_) >>= 16;                                       \
 80202:         if ((j_) >> 8)                                                        \
 80202:             (_log2) += 8, (j_) >>= 8;                                         \
 80202:         if ((j_) >> 4)                                                        \
 80202:             (_log2) += 4, (j_) >>= 4;                                         \
 80202:         if ((j_) >> 2)                                                        \
 80202:             (_log2) += 2, (j_) >>= 2;                                         \
 80202:         if ((j_) >> 1)                                                        \
 80202:             (_log2) += 1;                                                     \
 80202:     JS_END_MACRO
 80202: #endif
 80202: 
 80202: #if JS_BYTES_PER_WORD == 4
 80202: # ifdef JS_HAS_BUILTIN_BITSCAN32
 80202: #  define js_FloorLog2wImpl(n)                                                \
 80202:     ((size_t)(JS_BITS_PER_WORD - 1 - js_bitscan_clz32(n)))
 80202: # else
 82531: JS_PUBLIC_API(size_t) js_FloorLog2wImpl(size_t n);
 80202: # endif
 80202: #elif JS_BYTES_PER_WORD == 8
 80202: # ifdef JS_HAS_BUILTIN_BITSCAN64
 80202: #  define js_FloorLog2wImpl(n)                                                \
 80202:     ((size_t)(JS_BITS_PER_WORD - 1 - js_bitscan_clz64(n)))
 80202: # else
 82531: JS_PUBLIC_API(size_t) js_FloorLog2wImpl(size_t n);
 80202: # endif
 80202: #else
 80202: # error "NOT SUPPORTED"
 80202: #endif
 80202: 
120585: JS_END_EXTERN_C
120585: 
 95227: /*
 95227:  * Internal function.
 95227:  * Compute the log of the least power of 2 greater than or equal to n. This is
 95227:  * a version of JS_CeilingLog2 that operates on unsigned integers with
 95227:  * CPU-dependant size.
 95227:  */
 95227: #define JS_CEILING_LOG2W(n) ((n) <= 1 ? 0 : 1 + JS_FLOOR_LOG2W((n) - 1))
 95227: 
 95227: /*
 95227:  * Internal function.
 95227:  * Compute the log of the greatest power of 2 less than or equal to n.
 95227:  * This is a version of JS_FloorLog2 that operates on unsigned integers with
 95227:  * CPU-dependant size and requires that n != 0.
 95227:  */
 95227: static MOZ_ALWAYS_INLINE size_t
 95227: JS_FLOOR_LOG2W(size_t n)
 95227: {
 95227:     JS_ASSERT(n != 0);
 95227:     return js_FloorLog2wImpl(n);
 95227: }
 95227: 
106480: /*
106480:  * JS_ROTATE_LEFT32
106480:  *
106480:  * There is no rotate operation in the C Language so the construct (a << 4) |
106480:  * (a >> 28) is used instead. Most compilers convert this to a rotate
106480:  * instruction but some versions of MSVC don't without a little help.  To get
106480:  * MSVC to generate a rotate instruction, we have to use the _rotl intrinsic
106480:  * and use a pragma to make _rotl inline.
106480:  *
106480:  * MSVC in VS2005 will do an inline rotate instruction on the above construct.
106480:  */
106480: #if defined(_MSC_VER) && (defined(_M_IX86) || defined(_M_AMD64) || \
106480:     defined(_M_X64))
106480: #include <stdlib.h>
106480: #pragma intrinsic(_rotl)
106480: #define JS_ROTATE_LEFT32(a, bits) _rotl(a, bits)
106480: #else
106480: #define JS_ROTATE_LEFT32(a, bits) (((a) << (bits)) | ((a) >> (32 - (bits))))
106480: #endif
106480: 
 80202: #include <new>
 80202: 
 80202: /*
110933:  * Low-level memory management in SpiderMonkey:
 80202:  *
110933:  *  ** Do not use the standard malloc/free/realloc: SpiderMonkey allows these
110933:  *     to be redefined (via JS_USE_CUSTOM_ALLOCATOR) and Gecko even #define's
110933:  *     these symbols.
110933:  *
110933:  *  ** Do not use the builtin C++ operator new and delete: these throw on
110933:  *     error and we cannot override them not to.
 80202:  *
 80202:  * Allocation:
 80202:  *
110933:  * - If the lifetime of the allocation is tied to the lifetime of a GC-thing
110933:  *   (that is, finalizing the GC-thing will free the allocation), call one of
110933:  *   the following functions:
 80202:  *
110933:  *     JSContext::{malloc_,realloc_,calloc_,new_}
110933:  *     JSRuntime::{malloc_,realloc_,calloc_,new_}
110933:  *
110933:  *   These functions accumulate the number of bytes allocated which is used as
110933:  *   part of the GC-triggering heuristic.
110933:  *
110933:  *   The difference between the JSContext and JSRuntime versions is that the
110933:  *   cx version reports an out-of-memory error on OOM. (This follows from the
110933:  *   general SpiderMonkey idiom that a JSContext-taking function reports its
110933:  *   own errors.)
110933:  *
110933:  * - Otherwise, use js_malloc/js_realloc/js_calloc/js_free/js_new
 80202:  *
 80202:  * Deallocation:
 80202:  *
110933:  * - Ordinarily, use js_free/js_delete.
 80202:  *
110933:  * - For deallocations during GC finalization, use one of the following
110933:  *   operations on the FreeOp provided to the finalizer:
 80202:  *
110933:  *     FreeOp::{free_,delete_}
 80202:  *
110933:  *   The advantage of these operations is that the memory is batched and freed
110933:  *   on another thread.
 80202:  */
 80202: 
 80202: #define JS_NEW_BODY(allocator, t, parms)                                       \
 80202:     void *memory = allocator(sizeof(t));                                       \
 80202:     return memory ? new(memory) t parms : NULL;
 80202: 
 80202: /*
110933:  * Given a class which should provide 'new' methods, add
 80202:  * JS_DECLARE_NEW_METHODS (see JSContext for a usage example). This
110933:  * adds news with up to 12 parameters. Add more versions of new below if
 80202:  * you need more than 12 parameters.
 80202:  *
 80202:  * Note: Do not add a ; at the end of a use of JS_DECLARE_NEW_METHODS,
 80202:  * or the build will break.
 80202:  */
110933: #define JS_DECLARE_NEW_METHODS(NEWNAME, ALLOCATOR, QUALIFIERS)\
 80202:     template <class T>\
110933:     QUALIFIERS T *NEWNAME() {\
 80202:         JS_NEW_BODY(ALLOCATOR, T, ())\
 80202:     }\
 80202: \
 80202:     template <class T, class P1>\
110933:     QUALIFIERS T *NEWNAME(P1 p1) {\
 80202:         JS_NEW_BODY(ALLOCATOR, T, (p1))\
 80202:     }\
 80202: \
 80202:     template <class T, class P1, class P2>\
110933:     QUALIFIERS T *NEWNAME(P1 p1, P2 p2) {\
 80202:         JS_NEW_BODY(ALLOCATOR, T, (p1, p2))\
 80202:     }\
 80202: \
 80202:     template <class T, class P1, class P2, class P3>\
110933:     QUALIFIERS T *NEWNAME(P1 p1, P2 p2, P3 p3) {\
 80202:         JS_NEW_BODY(ALLOCATOR, T, (p1, p2, p3))\
 80202:     }\
 80202: \
 80202:     template <class T, class P1, class P2, class P3, class P4>\
110933:     QUALIFIERS T *NEWNAME(P1 p1, P2 p2, P3 p3, P4 p4) {\
 80202:         JS_NEW_BODY(ALLOCATOR, T, (p1, p2, p3, p4))\
 80202:     }\
 80202: \
 80202:     template <class T, class P1, class P2, class P3, class P4, class P5>\
110933:     QUALIFIERS T *NEWNAME(P1 p1, P2 p2, P3 p3, P4 p4, P5 p5) {\
 80202:         JS_NEW_BODY(ALLOCATOR, T, (p1, p2, p3, p4, p5))\
 80202:     }\
 80202: \
 80202:     template <class T, class P1, class P2, class P3, class P4, class P5, class P6>\
110933:     QUALIFIERS T *NEWNAME(P1 p1, P2 p2, P3 p3, P4 p4, P5 p5, P6 p6) {\
 80202:         JS_NEW_BODY(ALLOCATOR, T, (p1, p2, p3, p4, p5, p6))\
 80202:     }\
 80202: \
 80202:     template <class T, class P1, class P2, class P3, class P4, class P5, class P6, class P7>\
110933:     QUALIFIERS T *NEWNAME(P1 p1, P2 p2, P3 p3, P4 p4, P5 p5, P6 p6, P7 p7) {\
 80202:         JS_NEW_BODY(ALLOCATOR, T, (p1, p2, p3, p4, p5, p6, p7))\
 80202:     }\
 80202: \
 80202:     template <class T, class P1, class P2, class P3, class P4, class P5, class P6, class P7, class P8>\
110933:     QUALIFIERS T *NEWNAME(P1 p1, P2 p2, P3 p3, P4 p4, P5 p5, P6 p6, P7 p7, P8 p8) {\
 80202:         JS_NEW_BODY(ALLOCATOR, T, (p1, p2, p3, p4, p5, p6, p7, p8))\
 80202:     }\
 80202: \
 80202:     template <class T, class P1, class P2, class P3, class P4, class P5, class P6, class P7, class P8, class P9>\
110933:     QUALIFIERS T *NEWNAME(P1 p1, P2 p2, P3 p3, P4 p4, P5 p5, P6 p6, P7 p7, P8 p8, P9 p9) {\
 80202:         JS_NEW_BODY(ALLOCATOR, T, (p1, p2, p3, p4, p5, p6, p7, p8, p9))\
 80202:     }\
 80202: \
 80202:     template <class T, class P1, class P2, class P3, class P4, class P5, class P6, class P7, class P8, class P9, class P10>\
110933:     QUALIFIERS T *NEWNAME(P1 p1, P2 p2, P3 p3, P4 p4, P5 p5, P6 p6, P7 p7, P8 p8, P9 p9, P10 p10) {\
 80202:         JS_NEW_BODY(ALLOCATOR, T, (p1, p2, p3, p4, p5, p6, p7, p8, p9, p10))\
 80202:     }\
 80202: \
 80202:     template <class T, class P1, class P2, class P3, class P4, class P5, class P6, class P7, class P8, class P9, class P10, class P11>\
110933:     QUALIFIERS T *NEWNAME(P1 p1, P2 p2, P3 p3, P4 p4, P5 p5, P6 p6, P7 p7, P8 p8, P9 p9, P10 p10, P11 p11) {\
 80202:         JS_NEW_BODY(ALLOCATOR, T, (p1, p2, p3, p4, p5, p6, p7, p8, p9, p10, p11))\
 80202:     }\
 80202: \
 80202:     template <class T, class P1, class P2, class P3, class P4, class P5, class P6, class P7, class P8, class P9, class P10, class P11, class P12>\
110933:     QUALIFIERS T *NEWNAME(P1 p1, P2 p2, P3 p3, P4 p4, P5 p5, P6 p6, P7 p7, P8 p8, P9 p9, P10 p10, P11 p11, P12 p12) {\
 80202:         JS_NEW_BODY(ALLOCATOR, T, (p1, p2, p3, p4, p5, p6, p7, p8, p9, p10, p11, p12))\
 80202:     }\
 80202: 
110933: JS_DECLARE_NEW_METHODS(js_new, js_malloc, static JS_ALWAYS_INLINE)
 80202: 
110933: template <class T>
110933: static JS_ALWAYS_INLINE void
110933: js_delete(T *p)
110933: {
110933:     if (p) {
110933:         p->~T();
110933:         js_free(p);
110933:     }
 80202: }
 80202: 
110934: template <class T>
110934: static JS_ALWAYS_INLINE T *
110934: js_pod_malloc()
110934: {
110934:     return (T *)js_malloc(sizeof(T));
110934: }
110934: 
110934: template <class T>
110934: static JS_ALWAYS_INLINE T *
110934: js_pod_calloc()
110934: {
110934:     return (T *)js_calloc(sizeof(T));
110934: }
110934: 
110934: template <class T>
110934: static JS_ALWAYS_INLINE T *
110934: js_pod_malloc(size_t numElems)
110934: {
110934:     if (numElems & js::tl::MulOverflowMask<sizeof(T)>::result)
110934:         return NULL;
110934:     return (T *)js_malloc(numElems * sizeof(T));
110934: }
110934: 
110934: template <class T>
110934: static JS_ALWAYS_INLINE T *
110934: js_pod_calloc(size_t numElems)
110934: {
110934:     if (numElems & js::tl::MulOverflowMask<sizeof(T)>::result)
110934:         return NULL;
110934:     return (T *)js_calloc(numElems * sizeof(T));
110934: }
110934: 
 80202: namespace js {
 80202: 
101798: template<typename T>
105605: struct ScopedFreePtrTraits
101798: {
101798:     typedef T* type;
101798:     static T* empty() { return NULL; }
110933:     static void release(T* ptr) { js_free(ptr); }
105605: };
129993: SCOPED_TEMPLATE(ScopedJSFreePtr, ScopedFreePtrTraits)
105605: 
105605: template <typename T>
105605: struct ScopedDeletePtrTraits : public ScopedFreePtrTraits<T>
105605: {
110933:     static void release(T *ptr) { js_delete(ptr); }
101798: };
129993: SCOPED_TEMPLATE(ScopedJSDeletePtr, ScopedDeletePtrTraits)
101798: 
 80202: } /* namespace js */
 80202: 
 80202: namespace js {
 80202: 
 80202: /*
 80202:  * "Move" References
 80202:  *
 80202:  * Some types can be copied much more efficiently if we know the original's
 80202:  * value need not be preserved --- that is, if we are doing a "move", not a
 80202:  * "copy". For example, if we have:
 80202:  *
 80202:  *   Vector<T> u;
 80202:  *   Vector<T> v(u);
 80202:  *
 80202:  * the constructor for v must apply a copy constructor to each element of u ---
 80202:  * taking time linear in the length of u. However, if we know we will not need u
 80202:  * any more once v has been initialized, then we could initialize v very
 80202:  * efficiently simply by stealing u's dynamically allocated buffer and giving it
 80202:  * to v --- a constant-time operation, regardless of the size of u.
 80202:  *
 80202:  * Moves often appear in container implementations. For example, when we append
 80202:  * to a vector, we may need to resize its buffer. This entails moving each of
 80202:  * its extant elements from the old, smaller buffer to the new, larger buffer.
 80202:  * But once the elements have been migrated, we're just going to throw away the
 80202:  * old buffer; we don't care if they still have their values. So if the vector's
 80202:  * element type can implement "move" more efficiently than "copy", the vector
 80202:  * resizing should by all means use a "move" operation. Hash tables also need to
 80202:  * be resized.
 80202:  *
 80202:  * The details of the optimization, and whether it's worth applying, vary from
 80202:  * one type to the next. And while some constructor calls are moves, many really
 80202:  * are copies, and can't be optimized this way. So we need:
 80202:  *
 80202:  * 1) a way for a particular invocation of a copy constructor to say that it's
 80202:  *    really a move, and that the value of the original isn't important
 80202:  *    afterwards (althought it must still be safe to destroy); and
 80202:  *
 80202:  * 2) a way for a type (like Vector) to announce that it can be moved more
 80202:  *    efficiently than it can be copied, and provide an implementation of that
 80202:  *    move operation.
 80202:  *
 80202:  * The Move(T &) function takes a reference to a T, and returns an MoveRef<T>
 80202:  * referring to the same value; that's 1). An MoveRef<T> is simply a reference
 80202:  * to a T, annotated to say that a copy constructor applied to it may move that
 80202:  * T, instead of copying it. Finally, a constructor that accepts an MoveRef<T>
 80202:  * should perform a more efficient move, instead of a copy, providing 2).
 80202:  *
 80202:  * So, where we might define a copy constructor for a class C like this:
 80202:  *
 80202:  *   C(const C &rhs) { ... copy rhs to this ... }
 80202:  *
 80202:  * we would declare a move constructor like this:
 80202:  *
 80202:  *   C(MoveRef<C> rhs) { ... move rhs to this ... }
 80202:  *
 80202:  * And where we might perform a copy like this:
 80202:  *
 80202:  *   C c2(c1);
 80202:  *
 80202:  * we would perform a move like this:
 80202:  *
 80202:  *   C c2(Move(c1))
 80202:  *
 80202:  * Note that MoveRef<T> implicitly converts to T &, so you can pass an
 80202:  * MoveRef<T> to an ordinary copy constructor for a type that doesn't support a
 80202:  * special move constructor, and you'll just get a copy. This means that
 80202:  * templates can use Move whenever they know they won't use the original value
 80202:  * any more, even if they're not sure whether the type at hand has a specialized
 80202:  * move constructor. If it doesn't, the MoveRef<T> will just convert to a T &,
 80202:  * and the ordinary copy constructor will apply.
 80202:  *
 80202:  * A class with a move constructor can also provide a move assignment operator,
 80202:  * which runs this's destructor, and then applies the move constructor to
 80202:  * *this's memory. A typical definition:
 80202:  *
 80202:  *   C &operator=(MoveRef<C> rhs) {
 80202:  *     this->~C();
 80202:  *     new(this) C(rhs);
 80202:  *     return *this;
 80202:  *   }
 80202:  *
 80202:  * With that in place, one can write move assignments like this:
 80202:  *
 80202:  *   c2 = Move(c1);
 80202:  *
 80202:  * This destroys c1, moves c1's value to c2, and leaves c1 in an undefined but
 80202:  * destructible state.
 80202:  *
 80202:  * This header file defines MoveRef and Move in the js namespace. It's up to
 80202:  * individual containers to annotate moves as such, by calling Move; and it's up
 80202:  * to individual types to define move constructors.
 80202:  *
 80202:  * One hint: if you're writing a move constructor where the type has members
 80202:  * that should be moved themselves, it's much nicer to write this:
 80202:  *
 80202:  *   C(MoveRef<C> c) : x(c->x), y(c->y) { }
 80202:  *
 80202:  * than the equivalent:
 80202:  *
 80202:  *   C(MoveRef<C> c) { new(&x) X(c->x); new(&y) Y(c->y); }
 80202:  *
 80202:  * especially since GNU C++ fails to notice that this does indeed initialize x
 80202:  * and y, which may matter if they're const.
 80202:  */
 80202: template<typename T>
 80202: class MoveRef {
 80202:   public:
 80202:     typedef T Referent;
 80202:     explicit MoveRef(T &t) : pointer(&t) { }
 80202:     T &operator*()  const { return *pointer; }
 80202:     T *operator->() const { return  pointer; }
 80202:     operator T& ()   const { return *pointer; }
 80202:   private:
 80202:     T *pointer;
 80202: };
 80202: 
 80202: template<typename T>
 80202: MoveRef<T> Move(T &t) { return MoveRef<T>(t); }
 80202: 
 80202: template<typename T>
 80202: MoveRef<T> Move(const T &t) { return MoveRef<T>(const_cast<T &>(t)); }
 80202: 
 80202: /* Useful for implementing containers that assert non-reentrancy */
 80202: class ReentrancyGuard
 80202: {
 80202:     /* ReentrancyGuard is not copyable. */
 80202:     ReentrancyGuard(const ReentrancyGuard &);
 80202:     void operator=(const ReentrancyGuard &);
 80202: 
 80202: #ifdef DEBUG
 80202:     bool &entered;
 80202: #endif
 80202:   public:
 80202:     template <class T>
 80202: #ifdef DEBUG
 80202:     ReentrancyGuard(T &obj)
 80202:       : entered(obj.entered)
 80202: #else
 80202:     ReentrancyGuard(T &/*obj*/)
 80202: #endif
 80202:     {
 80202: #ifdef DEBUG
 80202:         JS_ASSERT(!entered);
 80202:         entered = true;
 80202: #endif
 80202:     }
 80202:     ~ReentrancyGuard()
 80202:     {
 80202: #ifdef DEBUG
 80202:         entered = false;
 80202: #endif
 80202:     }
 80202: };
 80202: 
128736: template <class T>
128736: JS_ALWAYS_INLINE static void
128736: Swap(T &t, T &u)
128736: {
128736:     T tmp(Move(t));
128736:     t = Move(u);
128736:     u = Move(tmp);
128736: }
128736: 
 80202: /*
 80202:  * Round x up to the nearest power of 2.  This function assumes that the most
 80202:  * significant bit of x is not set, which would lead to overflow.
 80202:  */
 80202: JS_ALWAYS_INLINE size_t
 80202: RoundUpPow2(size_t x)
 80202: {
 80202:     return size_t(1) << JS_CEILING_LOG2W(x);
 80202: }
 80202: 
106480: /* Integral types for all hash functions. */
106480: typedef uint32_t HashNumber;
106481: const unsigned HashNumberSizeBits = 32;
106480: 
106480: namespace detail {
106480: 
106480: /*
106480:  * Given a raw hash code, h, return a number that can be used to select a hash
106480:  * bucket.
106480:  *
106480:  * This function aims to produce as uniform an output distribution as possible,
106480:  * especially in the most significant (leftmost) bits, even though the input
106480:  * distribution may be highly nonrandom, given the constraints that this must
106480:  * be deterministic and quick to compute.
106480:  *
106480:  * Since the leftmost bits of the result are best, the hash bucket index is
106480:  * computed by doing ScrambleHashCode(h) / (2^32/N) or the equivalent
106480:  * right-shift, not ScrambleHashCode(h) % N or the equivalent bit-mask.
106480:  *
106480:  * FIXME: OrderedHashTable uses a bit-mask; see bug 775896.
106480:  */
106480: inline HashNumber
106480: ScrambleHashCode(HashNumber h)
106480: {
106480:     /*
106480:      * Simply returning h would not cause any hash tables to produce wrong
106480:      * answers. But it can produce pathologically bad performance: The caller
106480:      * right-shifts the result, keeping only the highest bits. The high bits of
106480:      * hash codes are very often completely entropy-free. (So are the lowest
106480:      * bits.)
106480:      *
106480:      * So we use Fibonacci hashing, as described in Knuth, The Art of Computer
106480:      * Programming, 6.4. This mixes all the bits of the input hash code h.
106480:      * 
106480:      * The value of goldenRatio is taken from the hex
106480:      * expansion of the golden ratio, which starts 1.9E3779B9....
106480:      * This value is especially good if values with consecutive hash codes
106480:      * are stored in a hash table; see Knuth for details.
106480:      */
106480:     static const HashNumber goldenRatio = 0x9E3779B9U;
106480:     return h * goldenRatio;
106480: }
106480: 
106480: } /* namespace detail */
106480: 
 80202: } /* namespace js */
 80202: 
 95356: namespace JS {
 95356: 
 95356: /*
 95356:  * Methods for poisoning GC heap pointer words and checking for poisoned words.
 95356:  * These are in this file for use in Value methods and so forth.
 95356:  *
 95356:  * If the moving GC hazard analysis is in use and detects a non-rooted stack
 95356:  * pointer to a GC thing, one byte of that pointer is poisoned to refer to an
 95356:  * invalid location. For both 32 bit and 64 bit systems, the fourth byte of the
 95356:  * pointer is overwritten, to reduce the likelihood of accidentally changing
 95356:  * a live integer value.
 95356:  */
 95356: 
106505: inline void PoisonPtr(void *v)
 95356: {
 95356: #if defined(JSGC_ROOT_ANALYSIS) && defined(DEBUG)
 95356:     uint8_t *ptr = (uint8_t *) v + 3;
 95356:     *ptr = JS_FREE_PATTERN;
 95356: #endif
 95356: }
 95356: 
 95356: template <typename T>
 95356: inline bool IsPoisonedPtr(T *v)
 95356: {
 95356: #if defined(JSGC_ROOT_ANALYSIS) && defined(DEBUG)
 95356:     uint32_t mask = uintptr_t(v) & 0xff000000;
 95356:     return mask == uint32_t(JS_FREE_PATTERN << 24);
 95356: #else
 95356:     return false;
 95356: #endif
 95356: }
 95356: 
 95356: }
 95356: 
 80202: /*
 82849:  * This is SpiderMonkey's equivalent to |nsMallocSizeOfFun|.
 80202:  */
 88300: typedef size_t(*JSMallocSizeOfFun)(const void *p);
 80202: 
 80202: /* sixgill annotation defines */
 80202: #ifndef HAVE_STATIC_ANNOTATIONS
 80202: # define HAVE_STATIC_ANNOTATIONS
 80202: # ifdef XGILL_PLUGIN
 80202: #  define STATIC_PRECONDITION(COND)         __attribute__((precondition(#COND)))
 80202: #  define STATIC_PRECONDITION_ASSUME(COND)  __attribute__((precondition_assume(#COND)))
 80202: #  define STATIC_POSTCONDITION(COND)        __attribute__((postcondition(#COND)))
 80202: #  define STATIC_POSTCONDITION_ASSUME(COND) __attribute__((postcondition_assume(#COND)))
 80202: #  define STATIC_INVARIANT(COND)            __attribute__((invariant(#COND)))
 80202: #  define STATIC_INVARIANT_ASSUME(COND)     __attribute__((invariant_assume(#COND)))
 80202: #  define STATIC_PASTE2(X,Y) X ## Y
 80202: #  define STATIC_PASTE1(X,Y) STATIC_PASTE2(X,Y)
 80202: #  define STATIC_ASSERT(COND)                        \
 80202:   JS_BEGIN_MACRO                                     \
 80202:     __attribute__((assert_static(#COND), unused))    \
 80202:     int STATIC_PASTE1(assert_static_, __COUNTER__);  \
 80202:   JS_END_MACRO
 80202: #  define STATIC_ASSUME(COND)                        \
 80202:   JS_BEGIN_MACRO                                     \
 80202:     __attribute__((assume_static(#COND), unused))    \
 80202:     int STATIC_PASTE1(assume_static_, __COUNTER__);  \
 80202:   JS_END_MACRO
 80202: #  define STATIC_ASSERT_RUNTIME(COND)                       \
 80202:   JS_BEGIN_MACRO                                            \
 80202:     __attribute__((assert_static_runtime(#COND), unused))   \
 80202:     int STATIC_PASTE1(assert_static_runtime_, __COUNTER__); \
 80202:   JS_END_MACRO
 80202: # else /* XGILL_PLUGIN */
 80202: #  define STATIC_PRECONDITION(COND)          /* nothing */
 80202: #  define STATIC_PRECONDITION_ASSUME(COND)   /* nothing */
 80202: #  define STATIC_POSTCONDITION(COND)         /* nothing */
 80202: #  define STATIC_POSTCONDITION_ASSUME(COND)  /* nothing */
 80202: #  define STATIC_INVARIANT(COND)             /* nothing */
 80202: #  define STATIC_INVARIANT_ASSUME(COND)      /* nothing */
 80202: #  define STATIC_ASSERT(COND)          JS_BEGIN_MACRO /* nothing */ JS_END_MACRO
 80202: #  define STATIC_ASSUME(COND)          JS_BEGIN_MACRO /* nothing */ JS_END_MACRO
 80202: #  define STATIC_ASSERT_RUNTIME(COND)  JS_BEGIN_MACRO /* nothing */ JS_END_MACRO
 80202: # endif /* XGILL_PLUGIN */
 80202: # define STATIC_SKIP_INFERENCE STATIC_INVARIANT(skip_inference())
 80202: #endif /* HAVE_STATIC_ANNOTATIONS */
 80202: 
 80202: #endif /* js_utility_h__ */
